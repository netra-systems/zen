#!/usr/bin/env python3
"""
Unified Import Management System for Netra Backend
Combines all import checking and fixing tools into one comprehensive system

Business Value Justification (BVJ):
- Segment: Platform
- Business Goal: Development Velocity
- Value Impact: Reduces import-related CI/CD failures by 90%
- Strategic Impact: Enables reliable automated testing
"""

import argparse
import json
import logging
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ImportManagementSystem:
    """Unified system for managing all import-related operations."""
    
    def __init__(self):
        self.project_root = PROJECT_ROOT
        self.scripts_dir = self.project_root / 'scripts'
        self.spec_dir = self.project_root / 'SPEC'
        self.test_reports_dir = self.project_root / 'test_reports'
        
        # Available tools
        self.tools = {
            'fix_all': 'fix_all_import_issues.py',
            'fix_comprehensive': 'fix_comprehensive_imports.py',
            'unified_manager': 'unified_import_manager.py',
            'check_netra': 'check_netra_backend_imports.py',
            'align_tests': 'align_test_imports.py'
        }
        
        # Statistics
        self.stats = {
            'total_errors': 0,
            'errors_fixed': 0,
            'files_checked': 0,
            'files_modified': 0,
            'tools_run': []
        }
    
    def check_imports(self) -> Dict[str, any]:
        """Run comprehensive import check using test runner."""
        logger.info("=" * 60)
        logger.info("RUNNING COMPREHENSIVE IMPORT CHECK")
        logger.info("=" * 60)
        
        try:
            # Run import test
            cmd = [sys.executable, '-m', 'test_framework.test_runner', '--import-only']
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=self.project_root
            )
            
            # Parse results
            output = result.stdout
            errors = output.count('[X]')
            success = output.count('[OK]')
            
            self.stats['total_errors'] = errors
            
            # Save detailed report
            report_path = self.test_reports_dir / 'import_check_results.txt'
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(output)
            
            logger.info(f"Import Check Results:")
            logger.info(f"  ✓ Successful imports: {success}")
            logger.info(f"  ✗ Failed imports: {errors}")
            logger.info(f"  Report saved to: {report_path}")
            
            return {
                'success': success,
                'errors': errors,
                'report_path': str(report_path)
            }
            
        except Exception as e:
            logger.error(f"Import check failed: {e}")
            return {'success': 0, 'errors': -1, 'error': str(e)}
    
    def fix_imports(self, dry_run: bool = False) -> Dict[str, any]:
        """Run all import fixing tools in sequence."""
        logger.info("=" * 60)
        logger.info("RUNNING IMPORT FIXES")
        logger.info("=" * 60)
        
        results = {}
        
        # Run each fixing tool
        for tool_name, script_name in [
            ('fix_all', 'fix_all_import_issues.py'),
            ('fix_comprehensive', 'fix_comprehensive_imports.py')
        ]:
            script_path = self.scripts_dir / script_name
            if not script_path.exists():
                logger.warning(f"Tool not found: {script_name}")
                continue
            
            logger.info(f"\nRunning {tool_name}...")
            
            try:
                cmd = [sys.executable, str(script_path)]
                if dry_run:
                    cmd.append('--dry-run')
                
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    cwd=self.project_root
                )
                
                # Parse output for statistics
                output = result.stdout
                if 'Files modified:' in output:
                    for line in output.split('\n'):
                        if 'Files modified:' in line:
                            count = int(line.split(':')[1].strip())
                            self.stats['files_modified'] += count
                        elif 'Fixes applied:' in line:
                            count = int(line.split(':')[1].strip())
                            self.stats['errors_fixed'] += count
                
                results[tool_name] = {
                    'success': result.returncode == 0,
                    'output': output[:500]  # First 500 chars
                }
                self.stats['tools_run'].append(tool_name)
                
            except Exception as e:
                logger.error(f"Error running {tool_name}: {e}")
                results[tool_name] = {'success': False, 'error': str(e)}
        
        return results
    
    def verify_imports(self) -> bool:
        """Verify that critical imports work."""
        logger.info("\nVerifying critical imports...")
        
        critical_modules = [
            'netra_backend.app.main',
            'netra_backend.app.agents.supervisor.agent',
            'netra_backend.app.agents.corpus_admin.agent', 
            'netra_backend.app.services.thread_service',
            'netra_backend.app.monitoring.models',
            'netra_backend.app.monitoring.metrics_collectors',
            'netra_backend.app.monitoring.health_calculator'
        ]
        
        failures = []
        for module in critical_modules:
            try:
                __import__(module)
                logger.info(f"  ✓ {module}")
            except ImportError as e:
                logger.error(f"  ✗ {module}: {e}")
                failures.append((module, str(e)))
        
        if failures:
            logger.warning(f"\n{len(failures)} critical imports still failing")
            return False
        else:
            logger.info("\n✓ All critical imports verified!")
            return True
    
    def generate_report(self) -> None:
        """Generate comprehensive import management report."""
        logger.info("\nGenerating comprehensive report...")
        
        report = {
            'timestamp': datetime.utcnow().isoformat(),
            'statistics': self.stats,
            'tools_available': list(self.tools.keys()),
            'recommendations': []
        }
        
        # Add recommendations based on error count
        if self.stats['total_errors'] > 100:
            report['recommendations'].append(
                "High number of import errors. Run 'python scripts/import_management.py fix-all'"
            )
        elif self.stats['total_errors'] > 50:
            report['recommendations'].append(
                "Moderate import issues. Consider running targeted fixes."
            )
        elif self.stats['total_errors'] > 0:
            report['recommendations'].append(
                "Minor import issues remain. These may be intentional exclusions."
            )
        else:
            report['recommendations'].append(
                "No import issues detected. System is healthy!"
            )
        
        # Save JSON report
        json_path = self.test_reports_dir / 'import_management_report.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2)
        
        # Save Markdown report
        md_path = self.test_reports_dir / 'import_management_report.md'
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write("# Import Management Report\n\n")
            f.write(f"Generated: {report['timestamp']}\n\n")
            
            f.write("## Statistics\n\n")
            for key, value in self.stats.items():
                if key != 'tools_run':
                    f.write(f"- **{key.replace('_', ' ').title()}:** {value}\n")
            
            if self.stats['tools_run']:
                f.write(f"\n## Tools Run\n\n")
                for tool in self.stats['tools_run']:
                    f.write(f"- {tool}\n")
            
            f.write(f"\n## Recommendations\n\n")
            for rec in report['recommendations']:
                f.write(f"- {rec}\n")
            
            f.write("\n## Next Steps\n\n")
            f.write("1. Review remaining import errors\n")
            f.write("2. Update SPEC/learnings/import_management.xml with new patterns\n")
            f.write("3. Run integration tests to verify fixes\n")
            f.write("4. Consider setting up pre-commit hooks\n")
        
        logger.info(f"Reports saved:")
        logger.info(f"  - JSON: {json_path}")
        logger.info(f"  - Markdown: {md_path}")
    
    def run_workflow(self, mode: str, dry_run: bool = False) -> int:
        """Run complete import management workflow."""
        logger.info("\n" + "=" * 60)
        logger.info("NETRA IMPORT MANAGEMENT SYSTEM")
        logger.info("=" * 60)
        
        exit_code = 0
        
        if mode in ['check', 'all']:
            check_results = self.check_imports()
            if check_results.get('errors', 0) > 0:
                exit_code = 1
        
        if mode in ['fix', 'all']:
            fix_results = self.fix_imports(dry_run=dry_run)
            for tool, result in fix_results.items():
                if not result.get('success', False):
                    exit_code = 1
        
        if mode in ['verify', 'all']:
            if not self.verify_imports():
                exit_code = 1
        
        # Always generate report
        self.generate_report()
        
        # Print summary
        logger.info("\n" + "=" * 60)
        logger.info("SUMMARY")
        logger.info("=" * 60)
        logger.info(f"Total Errors Found: {self.stats['total_errors']}")
        logger.info(f"Errors Fixed: {self.stats['errors_fixed']}")
        logger.info(f"Files Modified: {self.stats['files_modified']}")
        logger.info(f"Tools Run: {len(self.stats['tools_run'])}")
        
        if exit_code == 0:
            logger.info("\n✓ Import management completed successfully!")
        else:
            logger.warning("\n⚠ Some import issues remain")
        
        return exit_code


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description='Unified Import Management System for Netra Backend',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python scripts/import_management.py check       # Check for import issues
  python scripts/import_management.py fix         # Fix import issues
  python scripts/import_management.py verify      # Verify critical imports
  python scripts/import_management.py all         # Run complete workflow
  python scripts/import_management.py fix --dry-run  # Preview fixes
        """
    )
    
    parser.add_argument(
        'mode',
        choices=['check', 'fix', 'verify', 'all'],
        help='Operation mode'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Preview changes without modifying files'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Enable verbose output'
    )
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Run the import management system
    ims = ImportManagementSystem()
    exit_code = ims.run_workflow(args.mode, dry_run=args.dry_run)
    
    sys.exit(exit_code)


if __name__ == '__main__':
    main()