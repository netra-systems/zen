#!/usr/bin/env python3
"""
Stability Validation Script for SessionMiddleware Issue #169 Fix
================================================================

This script validates that the SessionMiddleware fix maintains system stability
and introduces no breaking changes or regressions.

CRITICAL VALIDATION AREAS:
1. SessionMiddleware access patterns work correctly
2. Fallback mechanisms function properly
3. Error handling is robust
4. No performance degradation
5. Business continuity preserved
"""

import asyncio
import sys
import traceback
import time
from unittest.mock import Mock, MagicMock
from fastapi import FastAPI, Request
from fastapi.testclient import TestClient
from starlette.middleware.sessions import SessionMiddleware

sys.path.append('.')
from netra_backend.app.middleware.gcp_auth_context_middleware import GCPAuthContextMiddleware


class SessionMiddlewareFixValidator:
    """Comprehensive validation of SessionMiddleware fix."""
    
    def __init__(self):
        self.validation_results = {}
        self.performance_metrics = {}
    
    def validate_all(self):
        """Run comprehensive validation suite."""
        print("SESSIONMIDDLEWARE ISSUE #169 FIX - STABILITY VALIDATION")
        print("=" * 65)
        
        validations = [
            ("Code Analysis", self.validate_code_analysis),
            ("Session Access Patterns", self.validate_session_access_patterns), 
            ("Error Handling", self.validate_error_handling),
            ("Fallback Mechanisms", self.validate_fallback_mechanisms),
            ("Performance Impact", self.validate_performance_impact),
            ("Integration Testing", self.validate_integration),
            ("Business Continuity", self.validate_business_continuity)
        ]
        
        overall_success = True
        
        for name, validation_func in validations:
            print(f"\n{name}")
            print("-" * 40)
            try:
                result = validation_func()
                self.validation_results[name] = result
                if result['status'] == 'PASS':
                    print(f"PASS {name}: PASSED")
                    for detail in result.get('details', []):
                        print(f"   â€¢ {detail}")
                else:
                    print(f"FAIL {name}: FAILED")
                    overall_success = False
                    for error in result.get('errors', []):
                        print(f"   ERROR {error}")
                        
            except Exception as e:
                print(f"CRITICAL {name}: CRITICAL ERROR - {e}")
                traceback.print_exc()
                overall_success = False
                self.validation_results[name] = {
                    'status': 'CRITICAL_ERROR', 
                    'errors': [str(e)]
                }
        
        return self.generate_final_report(overall_success)
    
    def validate_code_analysis(self):
        """Validate code changes and syntax."""
        details = []
        errors = []
        
        try:
            # Import the middleware to ensure no syntax errors
            from netra_backend.app.middleware.gcp_auth_context_middleware import GCPAuthContextMiddleware
            details.append("Module imports successfully - no syntax errors")
            
            # Check the critical fix method exists
            middleware = GCPAuthContextMiddleware(None)
            if hasattr(middleware, '_safe_extract_session_data'):
                details.append("_safe_extract_session_data method exists")
                
                # Check method signature
                import inspect
                sig = inspect.signature(middleware._safe_extract_session_data)
                if 'request' in sig.parameters:
                    details.append("Method signature is correct")
                else:
                    errors.append("Method signature missing required 'request' parameter")
            else:
                errors.append("_safe_extract_session_data method missing")
            
            # Validate defensive patterns in source code
            try:
                import inspect
                source_lines = inspect.getsource(middleware._safe_extract_session_data)
                
                if 'try:' in source_lines and 'except' in source_lines:
                    details.append("Try-catch error handling present")
                else:
                    errors.append("Missing try-catch error handling")
                    
                # Check for the fixed pattern (no hasattr check)
                if 'hasattr(request, \'session\')' in source_lines:
                    errors.append("Old broken hasattr() pattern still present")
                else:
                    details.append("Broken hasattr() pattern successfully removed")
                    
                if 'request.session' in source_lines:
                    details.append("Direct session access pattern implemented")
                else:
                    errors.append("Direct session access pattern missing")
                    
            except Exception as e:
                errors.append(f"Source code inspection failed: {e}")
            
        except Exception as e:
            errors.append(f"Code analysis failed: {e}")
            
        return {
            'status': 'PASS' if not errors else 'FAIL',
            'details': details,
            'errors': errors
        }
    
    def validate_session_access_patterns(self):
        """Validate session access patterns work correctly."""
        details = []
        errors = []
        
        try:
            middleware = GCPAuthContextMiddleware(None)
            
            # Test scenario 1: Mock request with session available
            mock_request_with_session = Mock(spec=Request)
            mock_session = {'user_id': 'test123', 'session_id': 'session123'}
            mock_request_with_session.session = mock_session
            mock_request_with_session.cookies = {}
            mock_request_with_session.state = Mock()
            
            try:
                result = middleware._safe_extract_session_data(mock_request_with_session)
                if isinstance(result, dict):
                    details.append("Session access with available session works")
                else:
                    errors.append("Session access returned non-dict result")
            except Exception as e:
                errors.append(f"Session access with available session failed: {e}")
            
            # Test scenario 2: Mock request with session raising AssertionError
            mock_request_no_session = Mock(spec=Request)
            mock_request_no_session.cookies = {'user_id': 'fallback123'}
            mock_request_no_session.state = Mock()
            
            # Mock session property to raise AssertionError (the original bug scenario)
            def session_property_error():
                raise AssertionError("SessionMiddleware must be installed to access request.session")
            
            type(mock_request_no_session).session = property(lambda self: session_property_error())
            
            try:
                result = middleware._safe_extract_session_data(mock_request_no_session)
                if isinstance(result, dict):
                    details.append("Session access gracefully handles AssertionError")
                else:
                    errors.append("Session access fallback returned non-dict result")
            except AssertionError:
                errors.append("Fix failed - AssertionError still propagating (original bug)")
            except Exception as e:
                details.append(f"Session access properly caught exception: {type(e).__name__}")
            
        except Exception as e:
            errors.append(f"Session access pattern validation failed: {e}")
            
        return {
            'status': 'PASS' if not errors else 'FAIL',
            'details': details,
            'errors': errors
        }
    
    def validate_error_handling(self):
        """Validate error handling improvements."""
        details = []
        errors = []
        
        try:
            middleware = GCPAuthContextMiddleware(None)
            
            # Test various error scenarios
            error_scenarios = [
                {
                    'name': 'AssertionError (SessionMiddleware not installed)',
                    'exception': AssertionError("SessionMiddleware must be installed")
                },
                {
                    'name': 'RuntimeError (Middleware order issue)',
                    'exception': RuntimeError("Session middleware configuration error")
                },
                {
                    'name': 'AttributeError (Missing session attribute)',
                    'exception': AttributeError("'Request' object has no attribute 'session'")
                }
            ]
            
            for scenario in error_scenarios:
                mock_request = Mock(spec=Request)
                mock_request.cookies = {}
                mock_request.state = Mock()
                
                # Mock session access to raise specific error
                def raise_error():
                    raise scenario['exception']
                    
                type(mock_request).session = property(lambda self: raise_error())
                
                try:
                    result = middleware._safe_extract_session_data(mock_request)
                    details.append(f"âœ… Gracefully handled: {scenario['name']}")
                    
                    if not isinstance(result, dict):
                        errors.append(f"Error handling for {scenario['name']} returned non-dict")
                        
                except Exception as e:
                    if type(e) == type(scenario['exception']):
                        errors.append(f"âŒ Failed to handle: {scenario['name']} - error still propagating")
                    else:
                        details.append(f"âœ… Transformed error for: {scenario['name']}")
        
        except Exception as e:
            errors.append(f"Error handling validation failed: {e}")
            
        return {
            'status': 'PASS' if not errors else 'FAIL',
            'details': details,
            'errors': errors
        }
    
    def validate_fallback_mechanisms(self):
        """Validate fallback mechanisms function properly."""
        details = []
        errors = []
        
        try:
            middleware = GCPAuthContextMiddleware(None)
            
            # Create request with multiple fallback sources
            mock_request = Mock(spec=Request)
            mock_request.cookies = {
                'user_id': 'cookie_user_123',
                'session_id': 'cookie_session_456'
            }
            mock_request.state = Mock()
            mock_request.state.user_email = 'state@example.com'
            mock_request.state.session_id = 'state_session_789'
            
            # Mock session to fail (simulating SessionMiddleware not available)
            def session_fails():
                raise AssertionError("SessionMiddleware must be installed")
            type(mock_request).session = property(lambda self: session_fails())
            
            result = middleware._safe_extract_session_data(mock_request)
            
            # Validate fallback data extraction
            if isinstance(result, dict):
                details.append("Fallback extraction returns dict structure")
                
                # Check if fallback sources were accessed
                fallback_sources_found = 0
                if any(k in result for k in ['user_id', 'session_id']):
                    fallback_sources_found += 1
                    details.append("Cookie fallback data extracted")
                    
                if 'user_email' in result:
                    fallback_sources_found += 1
                    details.append("Request state fallback data extracted")
                
                if fallback_sources_found > 0:
                    details.append(f"Successfully used {fallback_sources_found} fallback sources")
                else:
                    errors.append("No fallback data sources were accessed")
                    
            else:
                errors.append("Fallback mechanism returned non-dict result")
        
        except Exception as e:
            errors.append(f"Fallback mechanism validation failed: {e}")
            
        return {
            'status': 'PASS' if not errors else 'FAIL',
            'details': details,
            'errors': errors
        }
    
    def validate_performance_impact(self):
        """Validate no performance degradation."""
        details = []
        errors = []
        
        try:
            middleware = GCPAuthContextMiddleware(None)
            
            # Create test request
            mock_request = Mock(spec=Request)
            mock_request.cookies = {'user_id': 'perf_test_user'}
            mock_request.state = Mock()
            
            def session_fails():
                raise AssertionError("SessionMiddleware must be installed")
            type(mock_request).session = property(lambda self: session_fails())
            
            # Performance test: measure multiple calls
            iterations = 1000
            start_time = time.time()
            
            for _ in range(iterations):
                result = middleware._safe_extract_session_data(mock_request)
                
            end_time = time.time()
            total_time = end_time - start_time
            avg_time_ms = (total_time / iterations) * 1000
            
            self.performance_metrics['avg_session_access_ms'] = avg_time_ms
            
            # Performance criteria (should be very fast)
            if avg_time_ms < 1.0:  # Less than 1ms per call
                details.append(f"Performance excellent: {avg_time_ms:.3f}ms per call")
            elif avg_time_ms < 5.0:  # Less than 5ms per call
                details.append(f"Performance acceptable: {avg_time_ms:.3f}ms per call")
            else:
                errors.append(f"Performance degraded: {avg_time_ms:.3f}ms per call (too slow)")
                
            # Memory usage test (simplified)
            import gc
            gc.collect()
            before_calls = len(gc.get_objects())
            
            # Make many calls to check for memory leaks
            for _ in range(100):
                middleware._safe_extract_session_data(mock_request)
                
            gc.collect()
            after_calls = len(gc.get_objects())
            
            object_growth = after_calls - before_calls
            if object_growth < 50:  # Minimal object growth is acceptable
                details.append(f"Memory usage stable: {object_growth} new objects")
            else:
                errors.append(f"Potential memory leak: {object_growth} new objects")
        
        except Exception as e:
            errors.append(f"Performance validation failed: {e}")
            
        return {
            'status': 'PASS' if not errors else 'FAIL', 
            'details': details,
            'errors': errors
        }
    
    def validate_integration(self):
        """Validate middleware stack integration."""
        details = []
        errors = []
        
        try:
            # Create test FastAPI app
            app = FastAPI()
            
            @app.get("/test")
            async def test_endpoint(request: Request):
                return {"status": "ok"}
            
            # Add SessionMiddleware 
            app.add_middleware(
                SessionMiddleware, 
                secret_key="test-secret-key-32-chars-minimum-required-for-testing"
            )
            
            # Add our fixed middleware
            app.add_middleware(GCPAuthContextMiddleware, enable_user_isolation=True)
            
            # Test with TestClient
            client = TestClient(app)
            response = client.get("/test")
            
            if response.status_code == 200:
                details.append("Middleware integration successful")
                details.append("No exceptions during request processing")
            else:
                errors.append(f"Request failed with status {response.status_code}")
                
            # Test with session data
            with client:
                # Set some session data
                response = client.get("/test", cookies={"session": "test_session_data"})
                if response.status_code == 200:
                    details.append("Session data handling works in integration")
                else:
                    errors.append("Session data handling failed in integration")
        
        except Exception as e:
            errors.append(f"Integration validation failed: {e}")
            
        return {
            'status': 'PASS' if not errors else 'FAIL',
            'details': details,
            'errors': errors
        }
    
    def validate_business_continuity(self):
        """Validate Golden Path business continuity."""
        details = []
        errors = []
        
        try:
            # Business continuity scenarios
            scenarios = [
                {
                    'name': 'User Login Flow',
                    'description': 'Authentication context extraction during login'
                },
                {
                    'name': 'Chat Session Maintenance', 
                    'description': 'Session persistence during chat interactions'
                },
                {
                    'name': 'Enterprise User Isolation',
                    'description': 'Multi-tenant session isolation for enterprise users'
                }
            ]
            
            middleware = GCPAuthContextMiddleware(None)
            
            for scenario in scenarios:
                # Simulate business scenario
                mock_request = Mock(spec=Request)
                mock_request.headers = {'Authorization': 'Bearer enterprise-user-token'}
                mock_request.cookies = {
                    'user_id': 'enterprise_user_12345',
                    'customer_tier': 'Enterprise'
                }
                mock_request.state = Mock()
                mock_request.state.user = Mock()
                mock_request.state.user.user_id = 'enterprise_user_12345'
                mock_request.state.user.email = 'user@enterprise.com'
                mock_request.state.user.customer_tier = 'Enterprise'
                
                # Mock session failure (common in production staging)
                def session_fails():
                    raise AssertionError("SessionMiddleware must be installed")
                type(mock_request).session = property(lambda self: session_fails())
                
                try:
                    # Test auth context extraction (core business flow)
                    session_data = middleware._safe_extract_session_data(mock_request)
                    
                    if isinstance(session_data, dict):
                        details.append(f"âœ… {scenario['name']}: Session data extracted successfully")
                        
                        # Verify business-critical data is available via fallbacks
                        if 'user_id' in session_data:
                            details.append(f"  â€¢ User identification preserved")
                        else:
                            errors.append(f"  âŒ User identification lost in {scenario['name']}")
                            
                    else:
                        errors.append(f"âŒ {scenario['name']}: Invalid session data structure")
                        
                except Exception as e:
                    errors.append(f"âŒ {scenario['name']}: Business flow interrupted - {e}")
            
            # Overall business impact assessment
            if not errors:
                details.append("ðŸŽ¯ Golden Path business flows preserved")
                details.append("ðŸ’° $500K+ ARR authentication reliability maintained")
        
        except Exception as e:
            errors.append(f"Business continuity validation failed: {e}")
            
        return {
            'status': 'PASS' if not errors else 'FAIL',
            'details': details,
            'errors': errors
        }
    
    def generate_final_report(self, overall_success):
        """Generate comprehensive validation report."""
        print("\n" + "=" * 65)
        print("ðŸŽ¯ FINAL STABILITY VALIDATION REPORT")
        print("=" * 65)
        
        if overall_success:
            print("âœ… OVERALL STATUS: SYSTEM STABLE - NO BREAKING CHANGES")
        else:
            print("ðŸš¨ OVERALL STATUS: ISSUES DETECTED - REVIEW REQUIRED")
            
        print(f"\nðŸ“Š VALIDATION SUMMARY:")
        
        pass_count = sum(1 for r in self.validation_results.values() if r['status'] == 'PASS')
        fail_count = len(self.validation_results) - pass_count
        
        print(f"   â€¢ Tests Passed: {pass_count}")
        print(f"   â€¢ Tests Failed: {fail_count}")
        print(f"   â€¢ Success Rate: {(pass_count/len(self.validation_results)*100):.1f}%")
        
        if self.performance_metrics:
            print(f"\nâš¡ PERFORMANCE METRICS:")
            for metric, value in self.performance_metrics.items():
                print(f"   â€¢ {metric}: {value:.3f}")
                
        print(f"\nðŸ” DETAILED RESULTS:")
        for name, result in self.validation_results.items():
            status_icon = "âœ…" if result['status'] == 'PASS' else "âŒ"
            print(f"   {status_icon} {name}: {result['status']}")
            
        print(f"\nðŸ“‹ STABILITY ASSESSMENT:")
        
        if overall_success:
            print("   âœ… Code changes maintain backward compatibility")
            print("   âœ… Error handling improvements are robust")  
            print("   âœ… Fallback mechanisms preserve functionality")
            print("   âœ… Performance impact is negligible")
            print("   âœ… Integration with middleware stack is preserved")
            print("   âœ… Business continuity is maintained")
            print("\nðŸŽ¯ RECOMMENDATION: DEPLOY WITH CONFIDENCE")
            print("   â€¢ Fix eliminates SessionMiddleware errors")
            print("   â€¢ No regressions or breaking changes detected")
            print("   â€¢ System stability is preserved")
            
        else:
            print("   ðŸš¨ Some validation areas need attention")
            print("   ðŸ” Review failed tests before deployment")
            print("   âš ï¸  Consider additional testing in staging environment")
            
        return {
            'overall_success': overall_success,
            'pass_count': pass_count,
            'fail_count': fail_count,
            'success_rate': (pass_count/len(self.validation_results)*100),
            'validation_results': self.validation_results,
            'performance_metrics': self.performance_metrics
        }


if __name__ == "__main__":
    validator = SessionMiddlewareFixValidator()
    report = validator.validate_all()
    
    # Exit with appropriate code
    sys.exit(0 if report['overall_success'] else 1)