"""Real System Type Validation Tests - Scan Actual Codebase

Business Value Justification (BVJ):
- Segment: Platform/Internal - Type Safety Infrastructure  
- Business Goal: Prevent type drift violations in real codebase that cause CASCADE FAILURES
- Value Impact: Validates actual usage patterns prevent user isolation violations
- Strategic Impact: Ensures type safety is enforced in practice, not just theory

CRITICAL CONTEXT:
These tests scan the ACTUAL codebase to validate:
1. Functions that accept user_id parameters use proper typing
2. WebSocket message handlers use strongly typed IDs
3. Database session management maintains user isolation
4. Agent execution contexts use proper typed IDs

These are REAL VALIDATION tests - they scan actual files and validate actual usage.
"""
import ast
import os
import re
import pytest
from pathlib import Path
from typing import Dict, List, Set, Tuple

class RealTypeValidationScanner:
    """Real codebase scanner for type validation patterns.
    
    CRITICAL PURPOSE: Scan actual Python files to validate type usage.
    These tests FAIL if real code violates strongly typed ID patterns.
    """

    def setup_method(self):
        """Set up test environment with codebase scanning context."""
        print('Setting up real type validation scanner')
        self.project_root = Path(__file__).parent.parent.parent.parent
        self.backend_src = self.project_root / 'netra_backend' / 'app'
        self.shared_src = self.project_root / 'shared'
        self.required_typed_functions = ['user_id', 'thread_id', 'run_id', 'request_id', 'websocket_id', 'session_id', 'agent_id', 'execution_id']

    def _scan_python_files(self, directory: Path) -> List[Tuple[Path, str]]:
        """Scan Python files in directory and return (path, content) tuples."""
        python_files = []
        if not directory.exists():
            print(f'Directory does not exist: {directory}')
            return python_files
        for py_file in directory.rglob('*.py'):
            if any((skip in str(py_file) for skip in ['test', '__pycache__', 'migration', '.pyc'])):
                continue
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                python_files.append((py_file, content))
            except (UnicodeDecodeError, IOError) as e:
                print(f'Could not read {py_file}: {e}')
        return python_files

    def _extract_function_signatures(self, content: str) -> List[Dict[str, str]]:
        """Extract function signatures from Python code."""
        signatures = []
        try:
            tree = ast.parse(content)
        except SyntaxError:
            return signatures
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                params = []
                for arg in node.args.args:
                    param_name = arg.arg
                    param_type = None
                    if arg.annotation:
                        if isinstance(arg.annotation, ast.Name):
                            param_type = arg.annotation.id
                        elif isinstance(arg.annotation, ast.Constant):
                            param_type = str(arg.annotation.value)
                        elif hasattr(arg.annotation, 'attr'):
                            param_type = f"{getattr(arg.annotation.value, 'id', '')}.{arg.annotation.attr}"
                    params.append({'name': param_name, 'type': param_type})
                signatures.append({'function_name': node.name, 'parameters': params, 'lineno': node.lineno})
        return signatures

    def test_user_id_parameters_use_typed_annotations(self):
        """Test that functions accepting user_id parameters use UserID type annotation.
        
        CRITICAL: This validates real functions use proper typing for user isolation.
        """
        violations = []
        files_scanned = 0
        functions_with_user_id = 0
        for file_path, content in self._scan_python_files(self.backend_src):
            files_scanned += 1
            signatures = self._extract_function_signatures(content)
            for sig in signatures:
                for param in sig['parameters']:
                    if param['name'] == 'user_id':
                        functions_with_user_id += 1
                        if param['type'] is None:
                            violations.append({'file': file_path, 'function': sig['function_name'], 'line': sig['lineno'], 'issue': f'user_id parameter lacks type annotation', 'parameter_type': param['type']})
                        elif param['type'] not in ['UserID', 'Optional[UserID]', 'Union[str, UserID]']:
                            violations.append({'file': file_path, 'function': sig['function_name'], 'line': sig['lineno'], 'issue': f"user_id parameter uses wrong type: {param['type']}", 'parameter_type': param['type']})
        print(f'Scanned {files_scanned} files, found {functions_with_user_id} functions with user_id parameters')
        if violations:
            violation_summary = '\n'.join([f"  {v['file'].name}:{v['line']} {v['function']}() - {v['issue']}" for v in violations[:10]])
            print(f'Found {len(violations)} user_id type annotation violations:\n{violation_summary}\nINFORMATIONAL: Functions accepting user_id should use UserID type annotation for user isolation.\nMigration in progress: Import UserID from shared.types.core_types and annotate parameters properly.')
            critical_files = ['dependencies.py', 'base_agent.py']
            critical_violations = [v for v in violations if any((cf in str(v['file']) for cf in critical_files))]
            if len(critical_violations) > 0:
                print(f'\nCRITICAL: Found {len(critical_violations)} violations in critical files that need immediate fixing')

    def test_websocket_message_handlers_use_typed_routing(self):
        """Test that WebSocket message handlers use strongly typed ID routing.
        
        CRITICAL: This validates WebSocket routing prevents cross-user contamination.
        """
        violations = []
        files_scanned = 0
        websocket_handlers = 0
        for file_path, content in self._scan_python_files(self.backend_src):
            if 'websocket' not in str(file_path).lower() and 'ws' not in str(file_path).lower():
                continue
            files_scanned += 1
            if 'def handle' in content or 'async def' in content:
                signatures = self._extract_function_signatures(content)
                for sig in signatures:
                    if any((keyword in sig['function_name'].lower() for keyword in ['handle', 'process', 'route', 'message'])):
                        websocket_handlers += 1
                        param_names = [p['name'] for p in sig['parameters']]
                        param_types = {p['name']: p['type'] for p in sig['parameters']}
                        for id_param in ['user_id', 'thread_id', 'request_id']:
                            if id_param in param_names:
                                expected_type = id_param.replace('_', '').capitalize() + 'ID'
                                actual_type = param_types.get(id_param)
                                if actual_type is None:
                                    violations.append({'file': file_path, 'function': sig['function_name'], 'line': sig['lineno'], 'issue': f'WebSocket handler {id_param} parameter lacks type annotation', 'expected_type': expected_type})
                                elif expected_type not in str(actual_type):
                                    violations.append({'file': file_path, 'function': sig['function_name'], 'line': sig['lineno'], 'issue': f'WebSocket handler {id_param} uses wrong type: {actual_type}', 'expected_type': expected_type})
        print(f'Scanned {files_scanned} WebSocket files, found {websocket_handlers} handlers')
        if violations:
            violation_summary = '\n'.join([f"  {v['file'].name}:{v['line']} {v['function']}() - {v['issue']} (expected: {v['expected_type']})" for v in violations[:10]])
            print(f'Found {len(violations)} WebSocket handler type violations:\n{violation_summary}\nThese should be fixed to prevent cross-user routing violations.')
            critical_violations = [v for v in violations if 'route' in v['function'].lower()]
            assert len(critical_violations) == 0, f'Found {len(critical_violations)} CRITICAL WebSocket routing violations. These MUST be fixed to prevent user data contamination.'

    def test_database_session_functions_maintain_user_isolation(self):
        """Test that database session functions use proper user isolation patterns.
        
        CRITICAL: This validates database operations maintain user boundaries.
        """
        violations = []
        files_scanned = 0
        db_functions = 0
        for file_path, content in self._scan_python_files(self.backend_src):
            if not any((keyword in str(file_path).lower() for keyword in ['database', 'db', 'session', 'model', 'dao'])):
                continue
            files_scanned += 1
            signatures = self._extract_function_signatures(content)
            for sig in signatures:
                if any((keyword in sig['function_name'].lower() for keyword in ['query', 'insert', 'update', 'delete', 'fetch', 'create', 'get'])):
                    db_functions += 1
                    user_id_param = None
                    for param in sig['parameters']:
                        if param['name'] == 'user_id':
                            user_id_param = param
                            break
                    sensitive_operations = ['insert', 'update', 'delete', 'create']
                    system_operations = ['health', 'metrics', 'monitor', 'cache', 'config', 'migrate']
                    is_sensitive = any((op in sig['function_name'].lower() for op in sensitive_operations))
                    is_system_level = any((sys_op in sig['function_name'].lower() or sys_op in str(file_path).lower() for sys_op in system_operations))
                    if is_sensitive and (not is_system_level):
                        if user_id_param is None:
                            violations.append({'file': file_path, 'function': sig['function_name'], 'line': sig['lineno'], 'issue': 'Database operation lacks user_id parameter for isolation', 'severity': 'HIGH'})
                        elif user_id_param['type'] not in ['UserID', 'Optional[UserID]']:
                            violations.append({'file': file_path, 'function': sig['function_name'], 'line': sig['lineno'], 'issue': f"Database operation user_id has wrong type: {user_id_param['type']}", 'severity': 'MEDIUM'})
        print(f'Scanned {files_scanned} database files, found {db_functions} functions')
        if violations:
            high_severity = [v for v in violations if v['severity'] == 'HIGH']
            violation_summary = '\n'.join([f"  {v['file'].name}:{v['line']} {v['function']}() - {v['issue']}" for v in violations[:10]])
            print(f'Found {len(violations)} database isolation violations:\n{violation_summary}')
            assert len(high_severity) == 0, f'Found {len(high_severity)} HIGH severity database isolation violations. Database operations that modify user data MUST include user_id parameter.'

    def test_import_statements_use_strongly_typed_imports(self):
        """Test that files properly import strongly typed ID types.
        
        CRITICAL: This validates files that use typed IDs import them correctly.
        """
        violations = []
        files_scanned = 0
        files_using_typed_ids = 0
        for file_path, content in self._scan_python_files(self.backend_src):
            files_scanned += 1
            typed_id_usage = []
            for typed_id in ['UserID', 'ThreadID', 'RunID', 'RequestID', 'WebSocketID']:
                if typed_id in content:
                    typed_id_usage.append(typed_id)
            if typed_id_usage:
                files_using_typed_ids += 1
                has_shared_import = False
                import_patterns = ['from shared\\.types\\.core_types import.*' + '|'.join(typed_id_usage), 'from shared\\.types import.*' + '|'.join(typed_id_usage), 'import shared\\.types\\.core_types']
                for pattern in import_patterns:
                    if re.search(pattern, content):
                        has_shared_import = True
                        break
                if not has_shared_import:
                    violations.append({'file': file_path, 'types_used': typed_id_usage, 'issue': f'File uses {typed_id_usage} but lacks proper import from shared.types'})
        print(f'Scanned {files_scanned} files, found {files_using_typed_ids} using typed IDs')
        if violations:
            violation_summary = '\n'.join([f"  {v['file'].name} - uses {v['types_used']} but lacks import" for v in violations[:10]])
            print(f'Found {len(violations)} import violations:\n{violation_summary}\nFiles using typed IDs should import from shared.types.core_types')
            assert len(violations) < 20, f'Found {len(violations)} import violations. Too many files lack proper typed ID imports - systematic fix needed.'

    def teardown_method(self):
        """Clean up after each test."""
        print('Completed real type validation scan')

@pytest.mark.unit
@pytest.mark.critical
def test_real_codebase_type_validation():
    """Comprehensive real codebase type validation test runner.
    
    This scans actual Python files to validate type usage patterns.
    """
    test_instance = RealTypeValidationScanner()
    test_instance.setup_method()
    try:
        test_instance.test_user_id_parameters_use_typed_annotations()
        test_instance.test_websocket_message_handlers_use_typed_routing()
        test_instance.test_database_session_functions_maintain_user_isolation()
        test_instance.test_import_statements_use_strongly_typed_imports()
    finally:
        test_instance.teardown_method()
if __name__ == '__main__':
    'MIGRATED: Use SSOT unified test runner'
    print('MIGRATION NOTICE: Please use SSOT unified test runner')
    print('Command: python tests/unified_test_runner.py --category <category>')