# ðŸ“Š Metrics Literals

Performance metrics, measurements, and monitoring data

*Generated on 2025-08-21 22:10:00*

## ðŸ“Š Category Statistics

| Metric | Value |
|--------|-------|
| Total Literals | 445 |
| Subcategories | 4 |
| Average Confidence | 0.726 |

## ðŸ“‹ Subcategories

- [general (154 literals)](#subcategory-general)
- [measurement (211 literals)](#subcategory-measurement)
- [performance (8 literals)](#subcategory-performance)
- [status (72 literals)](#subcategory-status)

## Subcategory: general {subcategory-general}

**Count**: 154 literals

### ðŸ”´ Low (<0.5) (154 literals)

| Literal | Files | Context | Related |
|---------|-------|---------|---------|
| `
            </div>` | architecture_dashboard_html.py:59 | DashboardHTMLComponents.gen... | `.js`, `.ts` |
| `
            <div class="metrics\-gri...` | architecture_dashboard_html.py:54 | DashboardHTMLComponents.gen... | `.js`, `.ts` |
| `
\# Agent Modification History
` | agent_tracking_helper.py:227 | AgentTrackingHelper._format... | `.js`, `.ts` |
| `
\# Agent Modification History
` | agent_tracking_helper.py:243 | AgentTrackingHelper._format... | `.js`, `.ts` |
| `
\-\-\- Component Status \-\-\-` | metadata_enabler.py:101 | MetadataTrackingEnabler.pri... | `.js`, `.ts` |
| `
=== Setup Complete: ` | metadata_enabler.py:64 | MetadataTrackingEnabler.ena... | `.js`, `.ts` |
| `
Next steps:` | enabler.py:91 | MetadataTrackingEnabler._pr... | `.js`, `.ts` |
| `
Next steps:` | metadata_enabler.py:68 | MetadataTrackingEnabler.ena... | `.js`, `.ts` |
| `
What's been set up:` | enabler.py:82 | MetadataTrackingEnabler._pr... | `.js`, `.ts` |
| `
ðŸ’¡ Next Steps:` | monitor_oauth_flow.py:190 | OAuthMonitor.run_full_diagn... | `.js`, `.ts` |
| `
ðŸ“Š Summary:` | monitor_oauth_flow.py:171 | OAuthMonitor.run_full_diagn... | `.js`, `.ts` |
| `
ðŸ” Checking service health\.\.\.` | monitor_oauth_flow.py:23 | OAuthMonitor.check_services | `.js`, `.ts` |
| `  1\. All AI\-modified files will now...` | enabler.py:92 | MetadataTrackingEnabler._pr... | `.js`, `.ts` |
| `  2\. Commits will be blocked if meta...` | enabler.py:93 | MetadataTrackingEnabler._pr... | `.js`, `.ts` |
| `  3\. Metadata will be automatically ...` | enabler.py:94 | MetadataTrackingEnabler._pr... | `.js`, `.ts` |
| `  4\. Run 'python scripts/metadata\_v...` | enabler.py:95 | MetadataTrackingEnabler._pr... | `.js`, `.ts` |
| `  Agent Modification Tracking
` | agent_tracking_helper.py:158 | AgentTrackingHelper._format... | `.js`, `.ts` |
| `  Avg File Size: ` | boundary_enforcer_report_generator.py:125 | ConsoleReportPrinter._print... | `.js`, `.ts` |
| `  Complexity Debt: ` | boundary_enforcer_report_generator.py:127 | ConsoleReportPrinter._print... | `.js`, `.ts` |
| `  Created ` | seed_staging_data.py:342 | StagingDataSeeder.seed_metrics | `.js`, `.ts` |
| `  Error: ` | monitor_oauth_flow.py:150 | OAuthMonitor.simulate_oauth... | `.js`, `.ts` |
| `  Growth Velocity: ` | boundary_enforcer_report_generator.py:126 | ConsoleReportPrinter._print... | `.js`, `.ts` |
| `  Module Count: ` | boundary_enforcer_report_generator.py:124 | ConsoleReportPrinter._print... | `.js`, `.ts` |
| `  Redirect: ` | monitor_oauth_flow.py:145 | OAuthMonitor.simulate_oauth... | `.js`, `.ts` |
| `  Response: ` | monitor_oauth_flow.py:143 | OAuthMonitor.simulate_oauth... | `.js`, `.ts` |
| `  Total Files: ` | boundary_enforcer_report_generator.py:122 | ConsoleReportPrinter._print... | `.js`, `.ts` |
| `  Total Lines: ` | boundary_enforcer_report_generator.py:123 | ConsoleReportPrinter._print... | `.js`, `.ts` |
| ` ===` | agent_tracking_helper.py:304 | AgentTrackingHelper._finali... | `.js`, `.ts` |
| ` failed

` | status_renderer.py:80 | StatusReportRenderer._build... | `.js`, `.ts` |
| ` files analyzed, ` | status_renderer.py:77 | StatusReportRenderer._build... | `.js`, `.ts` |
| ` files analyzed, ` | status_renderer.py:78 | StatusReportRenderer._build... | `.js`, `.ts` |
| ` files analyzed, ` | status_renderer.py:79 | StatusReportRenderer._build... | `.js`, `.ts` |
| ` files/sec` | create_enforcement_tools.py:69 | ProgressTracker.update | `.js`, `.ts` |
| ` issues` | main.py:135 | _print_analysis_metrics | `.js`, `.ts` |
| ` lines` | architecture_metrics.py:151 | ArchitectureMetrics._get_fi... | `.js`, `.ts` |
| ` lines` | boundary_enforcer_report_generator.py:125 | ConsoleReportPrinter._print... | `.js`, `.ts` |
| ` metric data points` | seed_staging_data.py:342 | StagingDataSeeder.seed_metrics | `.js`, `.ts` |
| ` metric data points\.\.\.` | seed_staging_data.py:330 | StagingDataSeeder.seed_metrics | `.js`, `.ts` |
| ` monitoring\.` | dev_launcher_processes.py:201 | ProcessMonitor._perform_res... | `.js`, `.ts` |
| ` oversized files into focused modules` | architecture_metrics.py:184 | ArchitectureMetrics._get_fi... | `.js`, `.ts` |
| ` passed, ` | status_renderer.py:80 | StatusReportRenderer._build... | `.js`, `.ts` |
| ` restarted successfully` | dev_launcher_processes.py:196 | ProcessMonitor._perform_res... | `.js`, `.ts` |
| ` steps successful ===` | metadata_enabler.py:64 | MetadataTrackingEnabler.ena... | `.js`, `.ts` |
| `% \|` | generate_report.py:62 | _get_metric_rows | `.js`, `.ts` |
| `\-\-abbrev\-ref` | agent_tracking_helper.py:75 | AgentTrackingHelper._get_gi... | `.js`, `.ts` |
| `\-\-oneline` | boundary_enforcer_system_checks.py:121 | SystemMetricsCalculator._ge... | `.js`, `.ts` |
| `\-\-short` | agent_tracking_helper.py:80 | AgentTrackingHelper._get_gi... | `.js`, `.ts` |
| `\-\-since="30 days ago"` | boundary_enforcer_system_checks.py:121 | SystemMetricsCalculator._ge... | `.js`, `.ts` |
| `\-\-stat` | boundary_enforcer_system_checks.py:129 | SystemMetricsCalculator._ge... | `.js`, `.ts` |
| `\.\.\.` | agent_tracking_helper.py:305 | AgentTrackingHelper._finali... | `.js`, `.ts` |
| `\.0f` | main.py:129 | _print_coverage_metrics | `.js`, `.ts` |
| `\.1f` | main.py:128 | _print_coverage_metrics | `.js`, `.ts` |
| `\.1f` | boundary_enforcer_report_generator.py:125 | ConsoleReportPrinter._print... | `.js`, `.ts` |
| `\.1f` | generate_report.py:62 | _get_metric_rows | `.js`, `.ts` |
| `\.1f` | create_enforcement_tools.py:69 | ProgressTracker.update | `.js`, `.ts` |
| `\.1f` | create_enforcement_tools.py:69 | ProgressTracker.update | `.js`, `.ts` |
| `\.2f` | boundary_enforcer_report_generator.py:126 | ConsoleReportPrinter._print... | `.js`, `.ts` |
| `\.2f` | boundary_enforcer_report_generator.py:127 | ConsoleReportPrinter._print... | `.js`, `.ts` |
| `\.2f` | boundary_enforcer_report_generator.py:223 | PRCommentGenerator._build_s... | `.js`, `.ts` |
| `\.2f` | generate_report.py:63 | _get_metric_rows | `.js`, `.ts` |
| `\.c` | agent_tracking_helper.py:35 | AgentTrackingHelper | `.js`, `.ts` |
| `\.cpp` | agent_tracking_helper.py:34 | AgentTrackingHelper | `.js`, `.ts` |
| `\.cs` | agent_tracking_helper.py:38 | AgentTrackingHelper | `.js`, `.ts` |
| `\.dockerignore` | agent_tracking_helper.py:63 | AgentTrackingHelper | `.js`, `.ts` |
| `\.git` | architecture_metrics.py:265 | ArchitectureMetrics._should... | `.js`, `.ts` |
| `\.gitignore` | agent_tracking_helper.py:63 | AgentTrackingHelper | `.js`, `.ts` |
| `\.go` | agent_tracking_helper.py:40 | AgentTrackingHelper | `.js`, `.ts` |
| `\.h` | agent_tracking_helper.py:36 | AgentTrackingHelper | `.js`, `.ts` |
| `\.hpp` | agent_tracking_helper.py:37 | AgentTrackingHelper | `.js`, `.ts` |
| `\.html` | agent_tracking_helper.py:31 | AgentTrackingHelper | `.js`, `.ts` |
| `\.java` | agent_tracking_helper.py:33 | AgentTrackingHelper | `.js`, `.ts` |
| `\.js` | agent_tracking_helper.py:27 | AgentTrackingHelper | `.ts`, `.jsx` |
| `\.jsx` | agent_tracking_helper.py:29 | AgentTrackingHelper | `.js`, `.ts` |
| `\.kt` | agent_tracking_helper.py:43 | AgentTrackingHelper | `.js`, `.ts` |
| `\.php` | agent_tracking_helper.py:44 | AgentTrackingHelper | `.js`, `.ts` |
| `\.pytest\_cache` | architecture_metrics.py:266 | ArchitectureMetrics._should... | `.js`, `.ts` |
| `\.rb` | agent_tracking_helper.py:39 | AgentTrackingHelper | `.js`, `.ts` |
| `\.rs` | agent_tracking_helper.py:41 | AgentTrackingHelper | `.js`, `.ts` |
| `\.sh` | agent_tracking_helper.py:46 | AgentTrackingHelper | `.js`, `.ts` |
| `\.sql` | agent_tracking_helper.py:45 | AgentTrackingHelper | `.js`, `.ts` |
| `\.swift` | agent_tracking_helper.py:42 | AgentTrackingHelper | `.js`, `.ts` |
| `\.ts` | agent_tracking_helper.py:28 | AgentTrackingHelper | `.js`, `.jsx` |
| `\.tsx` | agent_tracking_helper.py:30 | AgentTrackingHelper | `.js`, `.ts` |
| `\.venv` | architecture_metrics.py:267 | ArchitectureMetrics._should... | `.js`, `.ts` |
| `\.vue` | agent_tracking_helper.py:32 | AgentTrackingHelper | `.js`, `.ts` |
| `/100` | main.py:129 | _print_coverage_metrics | `.js`, `.ts` |
| `/F` | dev_launcher_processes.py:113 | ProcessMonitor._terminate_p... | `.js`, `.ts` |
| `/health` | monitor_oauth_flow.py:28 | OAuthMonitor.check_services | `.js`, `.ts` |
| `/PID` | dev_launcher_processes.py:113 | ProcessMonitor._terminate_p... | `.js`, `.ts` |
| `/T` | dev_launcher_processes.py:113 | ProcessMonitor._terminate_p... | `.js`, `.ts` |
| `1\. Try logging in at: https://app\.s...` | monitor_oauth_flow.py:191 | OAuthMonitor.run_full_diagn... | `.js`, `.ts` |
| `2\. Check browser console for token s...` | monitor_oauth_flow.py:192 | OAuthMonitor.run_full_diagn... | `.js`, `.ts` |
| `2\. Test with: python scripts/metadat...` | metadata_enabler.py:70 | MetadataTrackingEnabler.ena... | `.js`, `.ts` |
| `3\. Make a test commit to verify hook...` | metadata_enabler.py:71 | MetadataTrackingEnabler.ena... | `.js`, `.ts` |
| `3\. Monitor auth service logs during ...` | monitor_oauth_flow.py:194 | OAuthMonitor.run_full_diagn... | `.js`, `.ts` |
| `: OK` | monitor_oauth_flow.py:35 | OAuthMonitor.check_services | `.js`, `.ts` |
| `: Status ` | monitor_oauth_flow.py:37 | OAuthMonitor.check_services | `.js`, `.ts` |
| `=== DRY RUN for ` | agent_tracking_helper.py:304 | AgentTrackingHelper._finali... | `.js`, `.ts` |
| `=== Enabling AI Agent Metadata Tracki...` | metadata_enabler.py:32 | MetadataTrackingEnabler.ena... | `.js`, `.ts` |
| `=== Metadata Tracking System Status ===` | metadata_enabler.py:96 | MetadataTrackingEnabler.pri... | `.js`, `.ts` |
| `Agent: ` | agent_tracking_helper.py:127 | AgentTrackingHelper._create... | `.js`, `.ts` |
| `Auth Service` | monitor_oauth_flow.py:26 | OAuthMonitor.check_services | `.js`, `.ts` |
| `auth\.staging` | monitor_oauth_flow.py:177 | OAuthMonitor.run_full_diagn... | `.js`, `.ts` |
| `Changes: ` | agent_tracking_helper.py:132 | AgentTrackingHelper._create... | `.js`, `.ts` |
| `check\-ignore` | agent_tracking_helper.py:108 | AgentTrackingHelper._should... | `.js`, `.ts` |
| `claude\-3` | seed_staging_data.py:321 | StagingDataSeeder._create_m... | `.js`, `.ts` |
| `Coverage: ` | main.py:128 | _print_coverage_metrics | `.js`, `.ts` |
| `Create database only` | enabler.py:128 | MetadataTrackingEnabler.cre... | `.js`, `.ts` |
| `Creating ` | seed_staging_data.py:330 | StagingDataSeeder.seed_metrics | `.js`, `.ts` |
| `Critical Gaps: ` | main.py:133 | _print_analysis_metrics | `.js`, `.ts` |
| `eu\-west\-1` | seed_staging_data.py:320 | StagingDataSeeder._create_m... | `.js`, `.ts` |
| `File Size` | architecture_metrics.py:150 | ArchitectureMetrics._get_fi... | `.js`, `.ts` |
| `gemini\-pro` | seed_staging_data.py:321 | StagingDataSeeder._create_m... | `.js`, `.ts` |
| `Git Branch: ` | agent_tracking_helper.py:129 | AgentTrackingHelper._create... | `.js`, `.ts` |
| `Git Commit: ` | agent_tracking_helper.py:130 | AgentTrackingHelper._create... | `.js`, `.ts` |
| `gpt\-4` | seed_staging_data.py:321 | StagingDataSeeder._create_m... | `.js`, `.ts` |
| `HEAD~10` | boundary_enforcer_system_checks.py:129 | SystemMetricsCalculator._ge... | `.js`, `.ts` |
| `Last Modified: ` | agent_tracking_helper.py:126 | AgentTrackingHelper._create... | `.js`, `.ts` |
| `Missing Tests: ` | main.py:134 | _print_analysis_metrics | `.js`, `.ts` |
| `Overall Status: ` | metadata_enabler.py:99 | MetadataTrackingEnabler.pri... | `.js`, `.ts` |
| `Pipfile\.lock` | agent_tracking_helper.py:54 | AgentTrackingHelper | `.js`, `.ts` |
| `poetry\.lock` | agent_tracking_helper.py:54 | AgentTrackingHelper | `.js`, `.ts` |
| `Print success summary` | enabler.py:80 | MetadataTrackingEnabler._pr... | `.js`, `.ts` |
| `Project Root: ` | metadata_enabler.py:97 | MetadataTrackingEnabler.pri... | `.js`, `.ts` |
| `Prompt Summary: ` | agent_tracking_helper.py:131 | AgentTrackingHelper._create... | `.js`, `.ts` |
| `Quality Score: ` | main.py:129 | _print_coverage_metrics | `.js`, `.ts` |
| `Reason: ` | staging_error_monitor.py:206 | StagingErrorMonitor.format_... | `.js`, `.ts` |
| `rev\-parse` | agent_tracking_helper.py:75 | AgentTrackingHelper._get_gi... | `.js`, `.ts` |
| `rev\-parse` | agent_tracking_helper.py:80 | AgentTrackingHelper._get_gi... | `.js`, `.ts` |
| `s \|` | generate_report.py:63 | _get_metric_rows | `.js`, `.ts` |
| `Split ` | architecture_metrics.py:184 | ArchitectureMetrics._get_fi... | `.js`, `.ts` |
| `Task ID: ` | agent_tracking_helper.py:128 | AgentTrackingHelper._create... | `.js`, `.ts` |
| `Test Debt: ` | main.py:135 | _print_analysis_metrics | `.js`, `.ts` |
| `test\-code\-invalid` | monitor_oauth_flow.py:138 | OAuthMonitor.simulate_oauth... | `.js`, `.ts` |
| `test\-state` | monitor_oauth_flow.py:139 | OAuthMonitor.simulate_oauth... | `.js`, `.ts` |
| `Time: ` | monitor_oauth_flow.py:157 | OAuthMonitor.run_full_diagn... | `.js`, `.ts` |
| `Timestamp: ` | metadata_enabler.py:98 | MetadataTrackingEnabler.pri... | `.js`, `.ts` |
| `Update progress` | create_enforcement_tools.py:62 | ProgressTracker.update | `.js`, `.ts` |
| `us\-east\-1` | seed_staging_data.py:320 | StagingDataSeeder._create_m... | `.js`, `.ts` |
| `us\-west\-2` | seed_staging_data.py:320 | StagingDataSeeder._create_m... | `.js`, `.ts` |
| `utf\-8` | agent_tracking_helper.py:265 | AgentTrackingHelper._read_f... | `.js`, `.ts` |
| `utf\-8` | agent_tracking_helper.py:308 | AgentTrackingHelper._finali... | `.js`, `.ts` |
| `utf\-8` | architecture_metrics.py:253 | ArchitectureMetrics._count_... | `.js`, `.ts` |
| `utf\-8` | boundary_enforcer_system_checks.py:145 | SystemMetricsCalculator._ge... | `.js`, `.ts` |
| `win32` | dev_launcher_processes.py:111 | ProcessMonitor._terminate_p... | `.js`, `.ts` |
| `\| Duration \| ` | generate_report.py:63 | _get_metric_rows | `.js`, `.ts` |
| `\| Success Rate \| ` | generate_report.py:62 | _get_metric_rows | `.js`, `.ts` |
| `âš ï¸  ` | monitor_oauth_flow.py:37 | OAuthMonitor.check_services | `.js`, `.ts` |
| `âš ï¸  Issues found:` | monitor_oauth_flow.py:184 | OAuthMonitor.run_full_diagn... | `.js`, `.ts` |
| `âœ… Metadata tracking enabled successfu...` | metadata_enabler.py:67 | MetadataTrackingEnabler.ena... | `.js`, `.ts` |
| `âœ… OAuth configuration appears correct` | monitor_oauth_flow.py:188 | OAuthMonitor.run_full_diagn... | `.js`, `.ts` |
| `âŒ Error monitoring failed: ` | staging_error_monitor.py:237 | StagingErrorMonitor.run_err... | `.js`, `.ts` |
| `âŒ Failed to restart ` | dev_launcher_processes.py:199 | ProcessMonitor._perform_res... | `.js`, `.ts` |
| `âŒ Some setup steps failed\. Check err...` | metadata_enabler.py:73 | MetadataTrackingEnabler.ena... | `.js`, `.ts` |

### Usage Examples

- **scripts\architecture_dashboard_html.py:59** - `DashboardHTMLComponents.generate_metrics_section`
- **scripts\architecture_dashboard_html.py:54** - `DashboardHTMLComponents.generate_metrics_section`
- **scripts\agent_tracking_helper.py:227** - `AgentTrackingHelper._format_history`

---

## Subcategory: measurement {subcategory-measurement}

**Count**: 211 literals

### ðŸŸ¢ High (â‰¥0.8) (211 literals)

| Literal | Files | Context | Related |
|---------|-------|---------|---------|
| `/metricDescriptors/run\.googleapis\.c...` | cleanup_staging_environments.py:143 | StagingEnvironmentCleaner.g... | `file_size`, `file_size` |
| `api\_latency` | seed_staging_data.py:283 | StagingDataSeeder._get_metr... | `file_size`, `file_size` |
| `api\_latency` | seed_staging_data.py:299 | StagingDataSeeder._generate... | `file_size`, `file_size` |
| `assertion\_count` | validate_agent_tests.py:302 | AgentTestValidator.export_j... | `file_size`, `file_size` |
| `async\_test\_count` | validate_agent_tests.py:300 | AgentTestValidator.export_j... | `file_size`, `file_size` |
| `average\_duration` | generate_performance_report.py:42 | add_summary_timing | `file_size`, `file_size` |
| `average\_duration` | generate_performance_report.py:126 | add_recommendations | `file_size`, `file_size` |
| `avg\_file\_size` | boundary_enforcer_report_generator.py:125 | ConsoleReportPrinter._print... | `file_size`, `file_size` |
| `avg\_file\_size` | boundary_enforcer_system_checks.py:198 | _build_metrics_dict | `file_size`, `file_size` |
| `cache\_hit\_rate` | seed_staging_data.py:285 | StagingDataSeeder._get_metr... | `file_size`, `file_size` |
| `cache\_hit\_rate` | seed_staging_data.py:307 | StagingDataSeeder._generate... | `file_size`, `file_size` |
| `cache\_hit\_rate` | test_backend_optimized.py:236 | OptimizedTestManager._updat... | `file_size`, `file_size` |
| `categorization\_rate` | scan_string_literals_enhanced.py:182 | EnhancedStringLiteralIndexe... | `file_size`, `file_size` |
| `categorization\_rate` | markdown_reporter.py:130 | MarkdownReporter._calculate... | `file_size`, `file_size` |
| `categorization\_rate` | markdown_reporter.py:170 | MarkdownReporter._calculate... | `file_size`, `file_size` |
| `categorization\_rate` | markdown_reporter.py:242 | MarkdownReporter._generate_... | `file_size`, `file_size` |
| `compliance\_rate` | check_test_compliance.py:136 | scan_test_files | `file_size`, `file_size` |
| `compliance\_rate` | check_test_compliance.py:161 | print_report | `file_size`, `file_size` |
| `compliance\_rate` | check_test_compliance.py:189 | print_report | `file_size`, `file_size` |
| `compliance\_rate` | check_test_compliance.py:214 | main | `file_size`, `file_size` |
| `cpu\_count` | startup_environment.py:46 | StartupEnvironment._record_... | `file_size`, `file_size` |
| `cpu\_count` | startup_reporter.py:135 | MarkdownReportGenerator._bu... | `file_size`, `file_size` |
| `critical\_test\_count` | business_value_test_index.py:603 | BusinessValueTestIndexer.ge... | `file_size`, `file_size` |
| `critical\_test\_count` | business_value_test_index.py:719 | BusinessValueTestIndexer.pr... | `file_size`, `file_size` |
| `error\_count\_total` | categorizer_enhanced.py:591 | module | `file_size`, `file_size` |
| `error\_rate` | seed_staging_data.py:283 | StagingDataSeeder._get_metr... | `file_size`, `file_size` |
| `error\_rate` | seed_staging_data.py:302 | StagingDataSeeder._generate... | `file_size`, `file_size` |
| `error\_rate` | validate_staging_health.py:146 | StagingPerformanceValidator... | `file_size`, `file_size` |
| `error\_rate` | validate_staging_health.py:199 | StagingPerformanceValidator... | `file_size`, `file_size` |
| `estimated\_success\_rate` | analyze_failures.py:84 | TestFailureAnalyzer.analyze... | `file_size`, `file_size` |
| `estimated\_success\_rate` | analyze_failures.py:223 | main | `file_size`, `file_size` |
| `failure\_count` | benchmark_optimization.py:132 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `failure\_count` | benchmark_optimization.py:143 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `failure\_count` | benchmark_optimization.py:154 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `failure\_count` | benchmark_optimization.py:180 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `failure\_count` | benchmark_optimization.py:197 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `failure\_count` | benchmark_optimization.py:220 | TestExecutionBenchmark._sim... | `file_size`, `file_size` |
| `failure\_rate` | test_failure_scanner.py:198 | _finalize_scan_results | `file_size`, `file_size` |
| `failure\_rate` | test_failure_scanner.py:228 | _print_final_summary | `file_size`, `file_size` |
| `fake\_test\_count` | fake_test_scanner.py:176 | FakeTestScanner._get_critic... | `file_size`, `file_size` |
| `fake\_test\_count` | fake_test_scanner.py:181 | FakeTestScanner._get_critic... | `file_size`, `file_size` |
| `fake\_test\_count` | fake_test_scanner.py:288 | FakeTestScanner.generate_co... | `file_size`, `file_size` |
| `file\_size` | architecture_scanner_helpers.py:166 | ScannerHelpers.create_file_... | `function_size`, `function_size` |
| `file\_size` | auto_fix_test_sizes.py:627 | TestSizeFixer.fix_all_viola... | `function_size`, `function_size` |
| `file\_size` | auto_fix_test_violations.py:210 | TestFileAnalyzer.find_viola... | `function_size`, `function_size` |
| `file\_size` | auto_fix_test_violations.py:809 | TestViolationAnalyzer.analy... | `function_size`, `function_size` |
| `file\_size` | auto_fix_test_violations.py:863 | TestViolationAnalyzer.gener... | `function_size`, `function_size` |
| `file\_size` | auto_fix_test_violations.py:890 | TestViolationAnalyzer.gener... | `function_size`, `function_size` |
| `file\_size` | core.py:108 | ViolationBuilder.file_size_... | `function_size`, `function_size` |
| `file\_size` | project_test_validator.py:155 | ProjectTestValidator._check... | `function_size`, `function_size` |
| `file\_size` | real_test_linter.py:171 | RealTestLinter._attempt_fixes | `function_size`, `function_size` |
| `file\_size` | real_test_requirements_enforcer.py:221 | RealTestRequirementsEnforce... | `function_size`, `function_size` |
| `file\_size` | real_test_requirements_enforcer.py:514 | RealTestRequirementsEnforce... | `function_size`, `function_size` |
| `file\_size` | real_test_validator.py:110 | RealTestValidator._check_fi... | `function_size`, `function_size` |
| `file\_size` | reporter.py:50 | ComplianceReporter._report_... | `function_size`, `function_size` |
| `file\_size` | reporter.py:305 | ComplianceReporter._print_a... | `function_size`, `function_size` |
| `file\_size` | reporter.py:306 | ComplianceReporter._print_a... | `function_size`, `function_size` |
| `file\_size` | reporter.py:316 | ComplianceReporter._get_vio... | `function_size`, `function_size` |
| `file\_size` | reporter.py:322 | ComplianceReporter._get_vio... | `function_size`, `function_size` |
| `file\_size` | reporter_stats.py:25 | StatisticsCalculator.calcul... | `function_size`, `function_size` |
| `file\_size` | reporter_stats.py:54 | StatisticsCalculator.displa... | `function_size`, `function_size` |
| `file\_size` | reporter_stats.py:55 | StatisticsCalculator.displa... | `function_size`, `function_size` |
| `file\_size` | test_fixer.py:355 | TestFixer.generate_fix_plan | `function_size`, `function_size` |
| `file\_size` | test_size_validator.py:191 | TestSizeValidator._analyze_... | `function_size`, `function_size` |
| `file\_size` | test_size_validator.py:472 | TestSizeValidator._generate... | `function_size`, `function_size` |
| `file\_size` | create_enforcement_tools.py:140 | EnforcementEngine.check_fil... | `function_size`, `function_size` |
| `file\_size` | enforce_limits.py:47 | FileLineChecker.check_file | `function_size`, `function_size` |
| `fixable\_count` | analyze_failures.py:76 | TestFailureAnalyzer.analyze... | `file_size`, `file_size` |
| `fixable\_count` | analyze_failures.py:222 | main | `file_size`, `file_size` |
| `function\_size` | auto_fix_test_violations.py:234 | TestFileAnalyzer._check_fun... | `file_size`, `file_size` |
| `function\_size` | auto_fix_test_violations.py:246 | TestFileAnalyzer._check_fun... | `file_size`, `file_size` |
| `function\_size` | auto_fix_test_violations.py:271 | TestFileAnalyzer._check_fun... | `file_size`, `file_size` |
| `function\_size` | auto_fix_test_violations.py:291 | TestFileAnalyzer._check_fun... | `file_size`, `file_size` |
| `function\_size` | auto_fix_test_violations.py:304 | TestFileAnalyzer._check_fun... | `file_size`, `file_size` |
| `function\_size` | auto_fix_test_violations.py:810 | TestViolationAnalyzer.analy... | `file_size`, `file_size` |
| `function\_size` | project_test_validator.py:250 | FunctionSizeVisitor._check_... | `file_size`, `file_size` |
| `function\_size` | real_test_linter.py:174 | RealTestLinter._attempt_fixes | `file_size`, `file_size` |
| `function\_size` | real_test_requirements_enforcer.py:328 | FunctionSizeVisitor._check_... | `file_size`, `file_size` |
| `function\_size` | real_test_requirements_enforcer.py:514 | RealTestRequirementsEnforce... | `file_size`, `file_size` |
| `function\_size` | real_test_validator.py:212 | FunctionSizeVisitor._check_... | `file_size`, `file_size` |
| `function\_size` | test_fixer.py:359 | TestFixer.generate_fix_plan | `file_size`, `file_size` |
| `function\_size` | test_size_validator.py:228 | TestSizeValidator._analyze_... | `file_size`, `file_size` |
| `function\_size` | test_size_validator.py:473 | TestSizeValidator._generate... | `file_size`, `file_size` |
| `function\_size` | enforce_limits.py:104 | FunctionLineChecker._check_... | `file_size`, `file_size` |
| `high\_confidence\_count` | analyze_failures.py:78 | TestFailureAnalyzer.analyze... | `file_size`, `file_size` |
| `high\_failure\_rate` | fake_test_scanner.py:299 | FakeTestScanner.generate_co... | `file_size`, `file_size` |
| `high\_failure\_rate` | fake_test_scanner.py:334 | FakeTestScanner._get_combin... | `file_size`, `file_size` |
| `high\_failure\_rate` | fake_test_scanner.py:336 | FakeTestScanner._get_combin... | `file_size`, `file_size` |
| `high\_value\_test\_count` | business_value_test_index.py:602 | BusinessValueTestIndexer.ge... | `file_size`, `file_size` |
| `hit\_rate` | real_service_test_metrics.py:24 | RealServiceTestMetrics.__in... | `file_size`, `file_size` |
| `hit\_rate` | real_service_test_metrics.py:64 | RealServiceTestMetrics.trac... | `file_size`, `file_size` |
| `hit\_rate` | real_service_test_metrics.py:175 | RealServiceTestMetrics._bui... | `file_size`, `file_size` |
| `js\_function\_size` | real_test_requirements_enforcer.py:445 | RealTestRequirementsEnforce... | `file_size`, `file_size` |
| `line\_count` | function_complexity_analyzer.py:386 | _convert_results_to_json | `file_size`, `file_size` |
| `low\_confidence\_count` | analyze_failures.py:80 | TestFailureAnalyzer.analyze... | `file_size`, `file_size` |
| `low\_test\_count` | business_value_test_index.py:629 | BusinessValueTestIndexer._i... | `file_size`, `file_size` |
| `medium\_confidence\_count` | analyze_failures.py:79 | TestFailureAnalyzer.analyze... | `file_size`, `file_size` |
| `memory\_total` | startup_environment.py:47 | StartupEnvironment._record_... | `file_size`, `file_size` |
| `memory\_total` | startup_reporter.py:136 | MarkdownReportGenerator._bu... | `file_size`, `file_size` |
| `mock\_count` | check_test_compliance.py:127 | scan_test_files | `file_size`, `file_size` |
| `mock\_count` | check_test_compliance.py:185 | print_report | `file_size`, `file_size` |
| `module\_count` | boundary_enforcer_report_generator.py:124 | ConsoleReportPrinter._print... | `file_size`, `file_size` |
| `module\_count` | boundary_enforcer_report_generator.py:222 | PRCommentGenerator._build_s... | `file_size`, `file_size` |
| `module\_count` | boundary_enforcer_system_checks.py:44 | SystemBoundaryChecker.check... | `file_size`, `file_size` |
| `module\_count` | boundary_enforcer_system_checks.py:69 | SystemBoundaryChecker._coun... | `file_size`, `file_size` |
| `module\_count` | boundary_enforcer_system_checks.py:203 | _create_module_count_violation | `file_size`, `file_size` |
| `not\_fixable\_count` | analyze_failures.py:77 | TestFailureAnalyzer.analyze... | `file_size`, `file_size` |
| `pass\_rate` | team_updates_formatter.py:69 | HumanFormatter.format_execu... | `file_size`, `file_size` |
| `pass\_rate` | team_updates_formatter.py:128 | HumanFormatter.format_test_... | `file_size`, `file_size` |
| `pass\_rate` | team_updates_test_analyzer.py:146 | TestReportAnalyzer._extract... | `file_size`, `file_size` |
| `priority\_failure\_count` | test_failure_scanner.py:200 | _finalize_scan_results | `file_size`, `file_size` |
| `priority\_failure\_count` | test_failure_scanner.py:229 | _print_final_summary | `file_size`, `file_size` |
| `record\_count` | demo_real_llm_testing.py:85 | demo_environment_validation | `file_size`, `file_size` |
| `record\_count` | demo_real_llm_testing.py:156 | demo_seed_data_management | `file_size`, `file_size` |
| `request\_count` | seed_staging_data.py:207 | StagingDataSeeder._get_opti... | `file_size`, `file_size` |
| `request\_count` | seed_staging_data.py:276 | StagingDataSeeder.seed_opti... | `file_size`, `file_size` |
| `request\_count` | seed_staging_data.py:278 | StagingDataSeeder.seed_opti... | `file_size`, `file_size` |
| `restart\_count` | dev_launcher_processes.py:161 | ProcessMonitor._log_crash | `file_size`, `file_size` |
| `scan\_duration` | comprehensive_import_scanner.py:84 | ComprehensiveScanReport.to_... | `file_size`, `file_size` |
| `security\_issue\_count` | generate_security_report.py:72 | _build_security_metrics_table | `file_size`, `file_size` |
| `settings\_count` | environment_validator.py:231 | EnvironmentValidator.test_c... | `file_size`, `file_size` |
| `size\_bytes` | demo_real_llm_testing.py:84 | demo_environment_validation | `file_size`, `file_size` |
| `success\_count` | benchmark_optimization.py:131 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_count` | benchmark_optimization.py:142 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_count` | benchmark_optimization.py:153 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_count` | benchmark_optimization.py:179 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_count` | benchmark_optimization.py:179 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_count` | benchmark_optimization.py:180 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_count` | benchmark_optimization.py:196 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_count` | benchmark_optimization.py:219 | TestExecutionBenchmark._sim... | `file_size`, `file_size` |
| `success\_count` | test_backend_optimized.py:212 | OptimizedTestManager._compi... | `file_size`, `file_size` |
| `success\_count` | test_backend_optimized.py:270 | OptimizedTestManager._fallb... | `file_size`, `file_size` |
| `success\_count` | test_backend_optimized.py:337 | print_results_summary | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:133 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:144 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:155 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:181 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:181 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:198 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:221 | TestExecutionBenchmark._sim... | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:236 | TestExecutionBenchmark._com... | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:236 | TestExecutionBenchmark._com... | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:355 | TestExecutionBenchmark._pri... | `file_size`, `file_size` |
| `success\_rate` | benchmark_optimization.py:356 | TestExecutionBenchmark._pri... | `file_size`, `file_size` |
| `success\_rate` | generate_performance_report.py:36 | add_summary_section | `file_size`, `file_size` |
| `success\_rate` | generate_report.py:62 | _get_metric_rows | `file_size`, `file_size` |
| `success\_rate` | generate_report.py:215 | main | `file_size`, `file_size` |
| `success\_rate` | generate_security_report.py:70 | _build_security_metrics_table | `file_size`, `file_size` |
| `success\_rate` | merge_results.py:92 | calculate_success_rate | `file_size`, `file_size` |
| `success\_rate` | merge_results.py:94 | calculate_success_rate | `file_size`, `file_size` |
| `success\_rate` | merge_results.py:104 | save_results | `file_size`, `file_size` |
| `success\_rate` | startup_reporter.py:33 | TestSummary.to_dict | `file_size`, `file_size` |
| `success\_rate` | startup_reporter.py:113 | MarkdownReportGenerator._bu... | `file_size`, `file_size` |
| `success\_rate` | startup_reporter.py:183 | StartupReporter._print_summary | `file_size`, `file_size` |
| `success\_rate` | test_backend_optimized.py:213 | OptimizedTestManager._compi... | `file_size`, `file_size` |
| `success\_rate` | test_backend_optimized.py:235 | OptimizedTestManager._updat... | `file_size`, `file_size` |
| `success\_rate` | test_backend_optimized.py:235 | OptimizedTestManager._updat... | `file_size`, `file_size` |
| `success\_rate` | test_backend_optimized.py:271 | OptimizedTestManager._fallb... | `file_size`, `file_size` |
| `success\_rate` | test_backend_optimized.py:338 | print_results_summary | `file_size`, `file_size` |
| `success\_rate` | test_backend_optimized.py:440 | main | `file_size`, `file_size` |
| `success\_rate` | test_backend_optimized.py:442 | main | `file_size`, `file_size` |
| `tables\_count` | environment_validator.py:176 | EnvironmentValidator.test_p... | `file_size`, `file_size` |
| `target\_duration` | test_backend_optimized.py:58 | module | `file_size`, `file_size` |
| `target\_duration` | test_backend_optimized.py:64 | module | `file_size`, `file_size` |
| `target\_duration` | test_backend_optimized.py:70 | module | `file_size`, `file_size` |
| `target\_duration` | test_backend_optimized.py:76 | module | `file_size`, `file_size` |
| `target\_duration` | test_backend_optimized.py:82 | module | `file_size`, `file_size` |
| `target\_duration` | test_backend_optimized.py:92 | module | `file_size`, `file_size` |
| `target\_duration` | test_backend_optimized.py:101 | module | `file_size`, `file_size` |
| `target\_duration` | test_backend_optimized.py:169 | OptimizedTestManager._creat... | `file_size`, `file_size` |
| `target\_duration` | test_backend_optimized.py:169 | OptimizedTestManager._creat... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:130 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:141 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:152 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:178 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:178 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:180 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:195 | TestExecutionBenchmark._run... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:218 | TestExecutionBenchmark._sim... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:241 | TestExecutionBenchmark._com... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:297 | TestExecutionBenchmark._gen... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:297 | TestExecutionBenchmark._gen... | `file_size`, `file_size` |
| `test\_count` | benchmark_optimization.py:360 | TestExecutionBenchmark._pri... | `file_size`, `file_size` |
| `test\_count` | test_backend_optimized.py:211 | OptimizedTestManager._compi... | `file_size`, `file_size` |
| `test\_count` | test_backend_optimized.py:236 | OptimizedTestManager._updat... | `file_size`, `file_size` |
| `test\_count` | test_backend_optimized.py:269 | OptimizedTestManager._fallb... | `file_size`, `file_size` |
| `test\_count` | test_backend_optimized.py:336 | print_results_summary | `file_size`, `file_size` |
| `test\_file\_size` | orchestrator.py:175 | ArchitectureEnforcer.genera... | `file_size`, `file_size` |
| `test\_file\_size` | test_limits_checker.py:42 | TestLimitsChecker.generate_... | `file_size`, `file_size` |
| `test\_file\_size` | test_limits_checker.py:108 | TestLimitsChecker._create_f... | `file_size`, `file_size` |
| `test\_file\_size` | test_violations_reporter.py:31 | TestViolationsReporter.gene... | `file_size`, `file_size` |
| `test\_framework\_size` | generate_test_audit.py:117 | check_test_health | `file_size`, `file_size` |
| `test\_framework\_size` | generate_test_audit.py:124 | check_test_health | `file_size`, `file_size` |
| `test\_framework\_size` | generate_test_audit.py:161 | generate_audit_report | `file_size`, `file_size` |
| `total\_duration` | generate_performance_report.py:41 | add_summary_timing | `file_size`, `file_size` |
| `total\_duration` | test_backend_optimized.py:210 | OptimizedTestManager._compi... | `file_size`, `file_size` |
| `total\_duration` | test_backend_optimized.py:233 | OptimizedTestManager._updat... | `file_size`, `file_size` |
| `total\_duration` | test_backend_optimized.py:268 | OptimizedTestManager._fallb... | `file_size`, `file_size` |
| `total\_duration` | test_backend_optimized.py:331 | print_results_summary | `file_size`, `file_size` |
| `uncommitted\_count` | metadata_header_generator.py:62 | MetadataHeaderGenerator._ge... | `file_size`, `file_size` |
| `uncommitted\_count` | metadata_header_generator.py:69 | MetadataHeaderGenerator._ge... | `file_size`, `file_size` |
| `variables\_count` | environment_validator_core.py:116 | EnvironmentValidatorCore._v... | `file_size`, `file_size` |
| `vulnerability\_count` | generate_security_report.py:56 | _get_security_status_badge | `file_size`, `file_size` |
| `vulnerability\_count` | generate_security_report.py:71 | _build_security_metrics_table | `file_size`, `file_size` |
| `vulnerability\_count` | generate_security_report.py:199 | _generate_security_recommen... | `file_size`, `file_size` |
| `vulnerability\_count` | generate_security_report.py:244 | _generate_compliance_checks | `file_size`, `file_size` |
| `vulnerability\_count` | generate_security_report.py:290 | main | `file_size`, `file_size` |
| `response\_time` | validate_staging_health.py:144 | StagingPerformanceValidator... | `file_size`, `file_size` |
| `response\_time\_ms` | environment_validator.py:423 | EnvironmentValidator.genera... | `file_size`, `file_size` |
| `response\_time\_ms` | validate_staging_health.py:136 | StagingPerformanceValidator... | `file_size`, `file_size` |
| `response\_time\_ms` | validate_staging_health.py:164 | StagingPerformanceValidator... | `file_size`, `file_size` |

### Usage Examples

- **scripts\cleanup_staging_environments.py:143** - `StagingEnvironmentCleaner.get_resource_usage`
- **scripts\seed_staging_data.py:283** - `StagingDataSeeder._get_metric_types`
- **scripts\seed_staging_data.py:299** - `StagingDataSeeder._generate_metric_value`

---

## Subcategory: performance {subcategory-performance}

**Count**: 8 literals

### ðŸŸ¢ High (â‰¥0.8) (7 literals)

| Literal | Files | Context | Related |
|---------|-------|---------|---------|
| `request\_duration\_seconds` | demo_enhanced_categorizer.py:115 | categorize_specific_examples | `time_saved_seco...`, `time_saved_sec... |
| `time\_saved\_seconds` | benchmark_optimization.py:247 | TestExecutionBenchmark._com... | `request_duratio...`, `used_memory_hu... |
| `time\_saved\_seconds` | benchmark_optimization.py:305 | TestExecutionBenchmark._gen... | `request_duratio...`, `used_memory_hu... |
| `time\_saved\_seconds` | benchmark_optimization.py:305 | TestExecutionBenchmark._gen... | `request_duratio...`, `used_memory_hu... |
| `time\_saved\_seconds` | benchmark_optimization.py:352 | TestExecutionBenchmark._pri... | `request_duratio...`, `used_memory_hu... |
| `used\_memory\_human` | environment_validator.py:268 | EnvironmentValidator.test_r... | `time_saved_seco...`, `time_saved_sec... |
| `used\_memory\_human` | validate_staging_config.py:239 | check_redis_connection | `time_saved_seco...`, `time_saved_sec... |

### ðŸ”´ Low (<0.5) (1 literals)

| Literal | Files | Context | Related |
|---------|-------|---------|---------|
| `
Network Constants Validation Script
...` | validate_network_constants.py:2 | module | `time_saved_seco...`, `time_saved_sec... |

### Usage Examples

- **scripts\demo_enhanced_categorizer.py:115** - `categorize_specific_examples`
- **scripts\benchmark_optimization.py:247** - `TestExecutionBenchmark._compare_executions`
- **scripts\benchmark_optimization.py:305** - `TestExecutionBenchmark._generate_benchmark_report`

---

## Subcategory: status {subcategory-status}

**Count**: 72 literals

### ðŸŸ¢ High (â‰¥0.8) (72 literals)

| Literal | Files | Context | Related |
|---------|-------|---------|---------|
| `critical\_failures` | environment_validator.py:428 | EnvironmentValidator.genera... | `error_handlers`, `error_handlers` |
| `critical\_failures` | environment_validator.py:402 | EnvironmentValidator.genera... | `error_handlers`, `error_handlers` |
| `critical\_failures` | environment_validator.py:500 | main | `error_handlers`, `error_handlers` |
| `critical\_failures` | environment_validator.py:501 | main | `error_handlers`, `error_handlers` |
| `critical\_failures` | environment_validator.py:502 | main | `error_handlers`, `error_handlers` |
| `error\_handlers` | test_reviewer.py:89 | AutonomousTestReviewer._per... | `error_handling`, `error_handling` |
| `error\_handlers` | ultra_thinking_analyzer.py:44 | UltraThinkingAnalyzer.analy... | `error_handling`, `error_handling` |
| `error\_handlers` | ultra_thinking_analyzer.py:60 | UltraThinkingAnalyzer.analy... | `error_handling`, `error_handling` |
| `error\_handling` | auto_decompose_functions.py:328 | FunctionDecomposer._suggest... | `error_handlers`, `error_handlers` |
| `error\_handling` | auto_fix_test_sizes.py:351 | TestFileSplitter._determine... | `error_handlers`, `error_handlers` |
| `error\_message` | generate_report.py:107 | _format_single_failure | `error_handlers`, `error_handlers` |
| `error\_message` | generate_report.py:130 | _format_single_error | `error_handlers`, `error_handlers` |
| `error\_message` | fix_all_import_issues.py:49 | ComprehensiveImportFixer._l... | `error_handlers`, `error_handlers` |
| `error\_message` | test_backend_optimized.py:278 | OptimizedTestManager._fallb... | `error_handlers`, `error_handlers` |
| `error\_rate\_percent` | validate_staging_health.py:138 | StagingPerformanceValidator... | `error_handlers`, `error_handlers` |
| `error\_rate\_percent` | validate_staging_health.py:198 | StagingPerformanceValidator... | `error_handlers`, `error_handlers` |
| `error\_score` | staging_error_monitor.py:123 | DeploymentDecision.should_f... | `error_handlers`, `error_handlers` |
| `error\_score` | staging_error_monitor.py:183 | StagingErrorMonitor.check_d... | `error_handlers`, `error_handlers` |
| `error\_score` | staging_error_monitor.py:205 | StagingErrorMonitor.format_... | `error_handlers`, `error_handlers` |
| `error\_score` | test_error_monitor_logic.py:96 | DeploymentDecision.should_f... | `error_handlers`, `error_handlers` |
| `error\_score` | test_error_monitor_logic.py:171 | test_normal_deployment | `error_handlers`, `error_handlers` |
| `error\_score` | test_error_monitor_logic.py:178 | test_normal_deployment | `error_handlers`, `error_handlers` |
| `error\_score` | test_error_monitor_logic.py:195 | test_critical_deployment | `error_handlers`, `error_handlers` |
| `error\_score` | test_error_monitor_logic.py:202 | test_critical_deployment | `error_handlers`, `error_handlers` |
| `error\_simulation` | fix_e2e_tests_comprehensive.py:74 | E2ETestFixer._get_common_fi... | `error_handlers`, `error_handlers` |
| `error\_trace` | analyze_failures.py:142 | TestFailureAnalyzer._determ... | `error_handlers`, `error_handlers` |
| `error\_types` | fix_comprehensive_imports.py:103 | ComprehensiveImportFixerV2.... | `error_handlers`, `error_handlers` |
| `function\_errors` | reporter.py:307 | ComplianceReporter._print_a... | `error_handlers`, `error_handlers` |
| `function\_errors` | reporter.py:308 | ComplianceReporter._print_a... | `error_handlers`, `error_handlers` |
| `function\_errors` | reporter.py:323 | ComplianceReporter._get_vio... | `error_handlers`, `error_handlers` |
| `import\_errors` | check_e2e_imports.py:51 | E2EImportChecker.__init__ | `error_handlers`, `error_handlers` |
| `import\_errors` | check_e2e_imports.py:208 | E2EImportChecker.check_all | `error_handlers`, `error_handlers` |
| `import\_errors` | check_e2e_imports.py:219 | E2EImportChecker.check_all | `error_handlers`, `error_handlers` |
| `import\_errors` | check_e2e_imports.py:256 | E2EImportChecker.generate_r... | `error_handlers`, `error_handlers` |
| `import\_errors` | check_imports.py:31 | ImportAnalyzer.analyze_file | `error_handlers`, `error_handlers` |
| `import\_errors` | check_imports.py:158 | ImportAnalyzer._check_import | `error_handlers`, `error_handlers` |
| `import\_errors` | check_imports.py:165 | ImportAnalyzer._check_import | `error_handlers`, `error_handlers` |
| `import\_errors` | check_imports.py:267 | ImportAnalyzer.generate_report | `error_handlers`, `error_handlers` |
| `import\_errors` | check_imports.py:278 | ImportAnalyzer.generate_report | `error_handlers`, `error_handlers` |
| `import\_errors` | generate_test_audit.py:114 | check_test_health | `error_handlers`, `error_handlers` |
| `priority\_failures` | comprehensive_test_fixer.py:358 | BatchProcessor._get_failing... | `error_handlers`, `error_handlers` |
| `priority\_failures` | fix_test_batch.py:361 | main | `error_handlers`, `error_handlers` |
| `priority\_failures` | test_failure_scanner.py:33 | _initialize_scan_results | `error_handlers`, `error_handlers` |
| `priority\_failures` | test_failure_scanner.py:170 | _add_priority_failures | `error_handlers`, `error_handlers` |
| `priority\_failures` | test_failure_scanner.py:200 | _finalize_scan_results | `error_handlers`, `error_handlers` |
| `priority\_failures` | test_failure_scanner.py:235 | _print_priority_failures | `error_handlers`, `error_handlers` |
| `priority\_failures` | test_failure_scanner.py:240 | _print_priority_failures | `error_handlers`, `error_handlers` |
| `success\_rate\_improvement` | benchmark_optimization.py:249 | TestExecutionBenchmark._com... | `error_handlers`, `error_handlers` |
| `success\_rate\_improvement` | benchmark_optimization.py:357 | TestExecutionBenchmark._pri... | `error_handlers`, `error_handlers` |
| `syntax\_errors` | check_e2e_imports.py:52 | E2EImportChecker.__init__ | `error_handlers`, `error_handlers` |
| `syntax\_errors` | check_imports.py:30 | ImportAnalyzer.analyze_file | `error_handlers`, `error_handlers` |
| `syntax\_errors` | check_imports.py:46 | ImportAnalyzer.analyze_file | `error_handlers`, `error_handlers` |
| `syntax\_errors` | check_imports.py:102 | ImportAnalyzer.analyze_file | `error_handlers`, `error_handlers` |
| `syntax\_errors` | check_imports.py:267 | ImportAnalyzer.generate_report | `error_handlers`, `error_handlers` |
| `syntax\_errors` | check_imports.py:275 | ImportAnalyzer.generate_report | `error_handlers`, `error_handlers` |
| `test\_failures` | team_updates_formatter.py:141 | HumanFormatter.format_test_... | `error_handlers`, `error_handlers` |
| `test\_failures` | team_updates_formatter.py:202 | HumanFormatter.format_actio... | `error_handlers`, `error_handlers` |
| `test\_failures` | team_updates_orchestrator.py:75 | TeamUpdatesOrchestrator._ex... | `error_handlers`, `error_handlers` |
| `test\_failures` | team_updates_test_analyzer.py:28 | TestReportAnalyzer.analyze | `error_handlers`, `error_handlers` |
| `timeout\_error` | analyze_failures.py:47 | TestFailureAnalyzer | `error_handlers`, `error_handlers` |
| `total\_errors` | import_management.py:55 | ImportManagementSystem.__in... | `error_handlers`, `error_handlers` |
| `total\_errors` | import_management.py:83 | ImportManagementSystem.chec... | `error_handlers`, `error_handlers` |
| `total\_errors` | import_management.py:202 | ImportManagementSystem.gene... | `error_handlers`, `error_handlers` |
| `total\_errors` | import_management.py:206 | ImportManagementSystem.gene... | `error_handlers`, `error_handlers` |
| `total\_errors` | import_management.py:210 | ImportManagementSystem.gene... | `error_handlers`, `error_handlers` |
| `total\_errors` | import_management.py:284 | ImportManagementSystem.run_... | `error_handlers`, `error_handlers` |
| `total\_failures` | analyze_failures.py:75 | TestFailureAnalyzer.analyze... | `error_handlers`, `error_handlers` |
| `total\_failures` | analyze_failures.py:222 | main | `error_handlers`, `error_handlers` |
| `total\_failures` | test_failure_scanner.py:197 | _finalize_scan_results | `error_handlers`, `error_handlers` |
| `total\_failures` | test_failure_scanner.py:227 | _print_final_summary | `error_handlers`, `error_handlers` |
| `total\_failures` | test_failure_scanner.py:246 | module | `error_handlers`, `error_handlers` |
| `track\_errors` | categorizer_enhanced.py:591 | module | `error_handlers`, `error_handlers` |

### Usage Examples

- **scripts\environment_validator.py:428** - `EnvironmentValidator.generate_report`
- **scripts\environment_validator.py:402** - `EnvironmentValidator.generate_report`
- **scripts\environment_validator.py:500** - `main`

---

## ðŸ”— Navigation

- ðŸ  [Back to Main Index](../string_literals_index.md)
- ðŸ“‚ [Browse Other Categories](./)

### Related Categories

- ðŸ·ï¸ [Identifiers](identifiers.md) - Metrics often follow identifier patterns

---

*This is the detailed documentation for the `metrics` category.*
*For the complete system overview, see the [Main String Literals Index](../string_literals_index.md).*