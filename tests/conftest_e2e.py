class TestWebSocketConnection:

    """Real WebSocket connection for testing instead of mocks."""

    

    def __init__(self):

        self.messages_sent = []

        self.is_connected = True

        self._closed = False

        

    async def send_json(self, message: dict):

        """Send JSON message."""

        if self._closed:

            raise RuntimeError("WebSocket is closed")

        self.messages_sent.append(message)

        

    async def close(self, code: int = 1000, reason: str = "Normal closure"):

        """Close WebSocket connection."""

        self._closed = True

        self.is_connected = False

        

    def get_messages(self) -> list:

        """Get all sent messages."""

        return self.messages_sent.copy()



"""

End-to-End (E2E) testing fixtures and environment validation.



This module contains fixtures for:

- E2E environment validation and service health checking

- Performance testing with high-volume WebSocket clients

- Environment configuration for local/staging deployments

- Business impact monitoring and logging

- Service availability validation with fallback handling



Memory Impact: HIGH - Complex validation logic, WebSocket clients, HTTP connections

Uses conditional loading to prevent overhead during unit test collection.

"""

import asyncio

import logging

import time

from contextlib import asynccontextmanager

from typing import Any, Dict, Optional



import pytest



# Import environment management with lazy loading

from shared.isolated_environment import get_env



# CRITICAL: Do NOT import heavy backend modules at module level

# This causes Docker to crash on Windows during pytest collection

# These will be imported lazily when needed inside fixtures



# Lazy import flag to prevent heavy imports during collection

_HEAVY_IMPORTS_LOADED = False

_E2E_DEPENDENCIES_AVAILABLE = False



def _lazy_import_e2e_dependencies():

    """Lazy import E2E testing dependencies to avoid collection phase overhead."""

    global _HEAVY_IMPORTS_LOADED, _E2E_DEPENDENCIES_AVAILABLE

    if not _HEAVY_IMPORTS_LOADED:

        try:

            import asyncpg

            import httpx

            import redis.asyncio as redis

            import socket

            globals().update({

                'asyncpg': asyncpg,

                'httpx': httpx,

                'redis': redis,

                'socket': socket

            })

            _HEAVY_IMPORTS_LOADED = True

            _E2E_DEPENDENCIES_AVAILABLE = True

            return True

        except ImportError as e:

            _HEAVY_IMPORTS_LOADED = True 

            _E2E_DEPENDENCIES_AVAILABLE = False

            logging.getLogger(__name__).warning(f"E2E dependencies not available: {e}")

            return False

    return _E2E_DEPENDENCIES_AVAILABLE



# Memory profiling decorator

def memory_profile(description: str = "", impact: str = "HIGH"):

    """Decorator to track memory usage of E2E fixtures."""

    def decorator(func):

        func._memory_description = description

        func._memory_impact = impact

        return func

    return decorator



# Configure E2E test logging

logging.basicConfig(

    level=logging.INFO,

    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'

)

e2e_logger = logging.getLogger("e2e_conftest")



# =============================================================================

# E2E ENVIRONMENT CONFIGURATION

# Memory Impact: LOW - Simple configuration dict

# =============================================================================



def get_e2e_config():

    """Get E2E configuration with environment detection."""

    current_env = get_env().get("ENVIRONMENT", get_env().get("TEST_ENV", "test")).lower()

    is_staging = current_env == "staging"



    if is_staging:

        # Staging environment URLs

        default_auth_url = "https://api.staging.netrasystems.ai"

        default_backend_url = "https://api.staging.netrasystems.ai"

        default_websocket_url = "wss://api.staging.netrasystems.ai/ws"

        default_redis_url = get_env().get("STAGING_REDIS_URL", "redis://localhost:6379")

        default_postgres_url = get_env().get("STAGING_DATABASE_URL", "postgresql://postgres:netra@localhost:5432/netra_staging")

        default_clickhouse_url = get_env().get("STAGING_CLICKHOUSE_URL", "clickhouse://localhost:8123/netra_staging")

    else:

        # Local/test environment URLs

        default_auth_url = "http://localhost:8081"

        default_backend_url = "http://localhost:8000"

        default_websocket_url = "ws://localhost:8000/ws"

        default_redis_url = "redis://localhost:6379"

        default_postgres_url = "postgresql://postgres:netra@localhost:5432/netra_test"

        default_clickhouse_url = "clickhouse://localhost:8123/netra_test"



    return {

        "auth_service_url": get_env().get("E2E_AUTH_SERVICE_URL", default_auth_url),

        "backend_url": get_env().get("E2E_BACKEND_URL", default_backend_url),

        "websocket_url": get_env().get("E2E_WEBSOCKET_URL", default_websocket_url),

        "redis_url": get_env().get("E2E_REDIS_URL", default_redis_url),

        "postgres_url": get_env().get("E2E_POSTGRES_URL", default_postgres_url),

        "clickhouse_url": get_env().get("E2E_CLICKHOUSE_URL", default_clickhouse_url),

        "test_timeout": int(get_env().get("E2E_TEST_TIMEOUT", "300")),  # 5 minutes

        "performance_mode": get_env().get("E2E_PERFORMANCE_MODE", "true").lower() == "true",

        "environment": current_env,

        "is_staging": is_staging

    }



# Global config - loaded once to avoid repeated environment access

E2E_CONFIG = get_e2e_config()



# =============================================================================

# E2E ENVIRONMENT VALIDATOR CLASS

# Memory Impact: MEDIUM - Service validation with network calls

# =============================================================================



class E2EEnvironmentValidator:

    """Validates E2E test environment prerequisites.

    

    Memory Impact: MEDIUM - Creates network connections for health checks

    """

    

    @staticmethod

    async def validate_services_available() -> Dict[str, bool]:

        """Validate that all required services are available.

        

        Memory Impact: HIGH - Multiple HTTP/TCP connections for validation

        """

        # Check if E2E dependencies are available

        if not _lazy_import_e2e_dependencies():

            logging.getLogger(__name__).error("Required E2E dependencies not available")

            return {"import_error": True}

        

        service_status = {}

        

        # Check Auth Service with multiple endpoint attempts

        auth_endpoints = [

            f"{E2E_CONFIG['auth_service_url']}/health",

            f"{E2E_CONFIG['auth_service_url']}/",

            "http://localhost:8081/health",

            "http://localhost:8083/health"  # Alternative port

        ]

        

        service_status["auth_service"] = await E2EEnvironmentValidator._check_service_endpoints(

            "auth_service", auth_endpoints, timeout=15.0

        )

        

        # Check Backend Service with multiple endpoint attempts

        backend_endpoints = [

            f"{E2E_CONFIG['backend_url']}/health",

            f"{E2E_CONFIG['backend_url']}/health/",

            "http://localhost:8000/health",

            "http://localhost:8200/health"  # Alternative port

        ]

        

        service_status["backend"] = await E2EEnvironmentValidator._check_service_endpoints(

            "backend", backend_endpoints, timeout=15.0

        )

        

        # Check Redis with proper async handling and fallback

        redis_configs = [

            E2E_CONFIG["redis_url"],

            "redis://localhost:6379",

            "redis://127.0.0.1:6379"

        ]

        

        service_status["redis"] = await E2EEnvironmentValidator._check_redis_connectivity(redis_configs)

        

        # Check PostgreSQL with proper error handling

        postgres_urls = [

            E2E_CONFIG["postgres_url"],

            "postgresql://test:test@localhost:5434/netra_test",

            "postgresql://netra:netra123@localhost:5433/netra_dev"

        ]

        

        service_status["postgres"] = await E2EEnvironmentValidator._check_postgres_connectivity(postgres_urls)

        

        # Log detailed results

        for service, status in service_status.items():

            status_text = "[OK] Available" if status else "[FAIL] Unavailable"

            logging.getLogger(__name__).info(f"Service {service}: {status_text}")

        

        return service_status

    

    @staticmethod

    async def _check_service_endpoints(service_name: str, endpoints: list, timeout: float = 15.0) -> bool:

        """Check multiple endpoints for a service and return True if any succeed."""

        for endpoint in endpoints:

            try:

                async with httpx.AsyncClient(timeout=timeout, follow_redirects=True) as client:

                    response = await client.get(endpoint)

                    if response.status_code == 200:

                        logging.getLogger(__name__).info(f"[OK] {service_name} health check succeeded at {endpoint}")

                        return True

                    else:

                        logging.getLogger(__name__).debug(f"[FAIL] {service_name} returned HTTP {response.status_code} at {endpoint}")

            except httpx.ConnectError as e:

                logging.getLogger(__name__).debug(f"[FAIL] {service_name} connection failed at {endpoint}: {e}")

            except httpx.TimeoutException:

                logging.getLogger(__name__).debug(f"[FAIL] {service_name} timeout at {endpoint}")

            except Exception as e:

                logging.getLogger(__name__).debug(f"[FAIL] {service_name} unexpected error at {endpoint}: {e}")

        

        # Try port connectivity as fallback

        for endpoint in endpoints:

            if await E2EEnvironmentValidator._check_port_connectivity(endpoint):

                logging.getLogger(__name__).info(f"[OK] {service_name} port accessible (health endpoint may be misconfigured)")

                return True

        

        logging.getLogger(__name__).warning(f"[FAIL] {service_name} not accessible at any endpoint: {endpoints}")

        return False

    

    @staticmethod

    async def _check_port_connectivity(url: str) -> bool:

        """Check if a service port is accessible via socket connection."""

        try:

            from urllib.parse import urlparse

            

            parsed = urlparse(url)

            host = parsed.hostname or 'localhost'

            port = parsed.port or (443 if parsed.scheme == 'https' else 80)

            

            # Try socket connection with timeout

            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

            sock.settimeout(5.0)

            result = sock.connect_ex((host, port))

            sock.close()

            return result == 0

        except Exception:

            return False

    

    @staticmethod

    async def _check_redis_connectivity(redis_configs: list) -> bool:

        """Check Redis connectivity with multiple configurations."""

        for config in redis_configs:

            if not config:

                continue

                

            try:

                client = redis.Redis.from_url(config, decode_responses=True)

                await client.ping()

                await client.aclose()

                logging.getLogger(__name__).info(f"[OK] Redis accessible at {config}")

                return True

            except Exception as e:

                logging.getLogger(__name__).debug(f"[FAIL] Redis connection failed at {config}: {e}")

        

        logging.getLogger(__name__).warning(f"[FAIL] Redis not accessible at any configuration: {redis_configs}")

        return False

    

    @staticmethod

    async def _check_postgres_connectivity(postgres_urls: list) -> bool:

        """Check PostgreSQL connectivity with multiple configurations."""

        for url in postgres_urls:

            if not url:

                continue

                

            try:

                conn = await asyncpg.connect(url, timeout=10.0)

                await conn.fetchval("SELECT 1")

                await conn.close()

                logging.getLogger(__name__).info(f"[OK] PostgreSQL accessible at {url}")

                return True

            except Exception as e:

                logging.getLogger(__name__).debug(f"[FAIL] PostgreSQL connection failed at {url}: {e}")

        

        logging.getLogger(__name__).warning(f"[FAIL] PostgreSQL not accessible at any URL: {postgres_urls}")

        return False

    

    @staticmethod

    def validate_environment_variables() -> Dict[str, bool]:

        """Validate required environment variables are set."""

        required_vars = [

            "GOOGLE_API_KEY",  # For real LLM testing

            "JWT_SECRET_KEY",  # For authentication (primary JWT secret)

            "FERNET_KEY"       # For encryption

        ]

        

        var_status = {}

        for var in required_vars:

            var_status[var] = get_env().get(var) is not None

            

        return var_status



# =============================================================================

# SESSION-SCOPED E2E FIXTURES

# Memory Impact: VERY_HIGH - Full environment validation

# =============================================================================



@pytest.fixture(scope="session")

@memory_profile("Complete E2E environment validation before running tests", "VERY_HIGH")

async def validate_e2e_environment():

    """Validate E2E test environment before running tests.

    

    Memory Impact: VERY_HIGH - Multiple service connections and validations

    Use for: E2E test sessions requiring full environment validation

    """

    current_env = get_env().get("ENVIRONMENT", get_env().get("TEST_ENV", "test")).lower()

    is_staging = current_env == "staging"

    

    logging.getLogger(__name__).info("Validating E2E test environment...")

    

    # REMOVED: Skip condition that was cheating on tests

    # E2E tests should ALWAYS run when requested, no skipping allowed

    # Per CLAUDE.md: CHEATING ON TESTS = ABOMINATION

    

    validator = E2EEnvironmentValidator()

    

    # Validate services

    service_status = await validator.validate_services_available()

    failed_services = [name for name, status in service_status.items() if not status]

    

    if failed_services:

        # FAIL HARD - no skipping allowed per CLAUDE.md

        raise RuntimeError(f"Required services unavailable: {failed_services}. Start services with: python tests/unified_test_runner.py --real-services")

    

    # Validate environment variables

    env_status = validator.validate_environment_variables()

    missing_vars = [var for var, status in env_status.items() if not status]

    

    if missing_vars:

        # FAIL HARD - no skipping allowed per CLAUDE.md

        raise RuntimeError(f"Required environment variables missing: {missing_vars}")

    

    logging.getLogger(__name__).info("E2E environment validation passed")

    return {

        "services": service_status,

        "environment": env_status,

        "config": E2E_CONFIG

    }



# =============================================================================

# PERFORMANCE MONITORING FIXTURES

# Memory Impact: LOW - Simple performance tracking

# =============================================================================



@pytest.fixture

@memory_profile("Performance monitoring and validation against requirements", "LOW")

def performance_monitor():

    """Monitor test performance and validate against requirements.

    

    Memory Impact: LOW - Simple time and metrics tracking

    Use for: Performance testing and SLA validation

    """

    class PerformanceMonitor:

        def __init__(self):

            self.measurements = {}

            

        def start_measurement(self, operation: str):

            self.measurements[operation] = {"start": time.time()}

            

        def end_measurement(self, operation: str):

            if operation in self.measurements:

                self.measurements[operation]["duration"] = time.time() - self.measurements[operation]["start"]

                

        def validate_requirement(self, operation: str, max_duration: float = None):

            if operation not in self.measurements:

                raise ValueError(f"No measurement found for operation: {operation}")

                

            duration = self.measurements[operation]["duration"]

            max_allowed = max_duration or 10.0

            

            if duration > max_allowed:

                raise AssertionError(f"{operation} took {duration:.2f}s (max: {max_allowed}s)")

                

            return duration

    

    return PerformanceMonitor()



@pytest.fixture

@memory_profile("Specialized E2E test logger", "LOW")

def e2e_logger():

    """Provide specialized E2E test logger.

    

    Memory Impact: LOW - Logger wrapper with business impact tracking

    Use for: E2E test logging and business impact measurement

    """

    logger = logging.getLogger("e2e_test")

    logger.setLevel(logging.INFO)

    

    class E2ELogger:

        def __init__(self, base_logger):

            self.logger = base_logger

            

        def test_start(self, test_name: str):

            self.logger.info(f"[START] {test_name}")

            

        def test_success(self, test_name: str, duration: float):

            self.logger.info(f"[SUCCESS] {test_name} completed in {duration:.2f}s")

            

        def test_failure(self, test_name: str, error: str):

            self.logger.error(f"[FAILURE] {test_name} failed: {error}")

            

        def performance_metric(self, operation: str, duration: float, limit: float):

            status = "PASS" if duration <= limit else "FAIL"

            self.logger.info(f"[PERF-{status}] {operation}: {duration:.2f}s (limit: {limit}s)")

            

        def business_impact(self, message: str):

            self.logger.info(f"[BUSINESS] {message}")

    

    return E2ELogger(logger)



# =============================================================================

# HIGH-VOLUME PERFORMANCE TESTING FIXTURES  

# Memory Impact: VERY_HIGH - WebSocket servers and clients

# =============================================================================



@pytest.fixture

@memory_profile("High-volume WebSocket server for performance testing", "VERY_HIGH")

async def high_volume_server():

    """High-volume WebSocket server fixture.

    

    Memory Impact: VERY_HIGH - WebSocket server with connection handling

    Use for: High-volume performance testing scenarios

    """

    test_mode = get_env().get("HIGH_VOLUME_TEST_MODE", "mock")

    

    if test_mode != "mock":

        yield None

        return

        

    try:

        from tests.e2e.test_helpers.performance_base import HighVolumeWebSocketServer

        server = HighVolumeWebSocketServer()

        await server.start()

        

        # Allow server startup time

        await asyncio.sleep(1.0)

        

        yield server

        await server.stop()

    except ImportError:

        # Mock server if performance_base not available

        yield Magic

@pytest.fixture

@memory_profile("High-volume throughput client for performance testing", "VERY_HIGH")

async def throughput_client(test_user_token, high_volume_server):

    """High-volume throughput client fixture.

    

    Memory Impact: VERY_HIGH - WebSocket client with high-frequency messaging

    Use for: Throughput and load testing scenarios

    """

    client = None

    try:

        from tests.e2e.test_helpers.performance_base import HighVolumeThroughputClient

        websocket_uri = E2E_CONFIG["websocket_url"]

        client = HighVolumeThroughputClient(websocket_uri, test_user_token["token"], "primary-client")

        

        # Establish connection with retry logic

        max_retries = 3

        for attempt in range(max_retries):

            try:

                await client.connect()

                break

            except Exception as e:

                if attempt == max_retries - 1:

                    import logging

                    logging.warning(f"WebSocket connection failed after {max_retries} attempts: {e} - using stub client")

                    # Create stub client for testing

                    websocket = TestWebSocketConnection()

                    class StubHighVolumeClient:

                        def __init__(self):

                            self.websocket = websocket

                        async def connect(self):

                            pass

                        async def send_high_volume_messages(self, count, delay=0.01):

                            for i in range(count):

                                await self.websocket.send_json({"type": "stub", "id": i})

                    yield StubHighVolumeClient()

                    return

                await asyncio.sleep(1.0)

        

        yield client

        

    except ImportError:

        # Mock client if performance_base not available

        websocket = TestWebSocketConnection()

        try:

            yield mock_client

        finally:

            await mock_client.disconnect()

            await mock_client.close()

    finally:

        # Enhanced cleanup with timeout

        if client:

            try:

                # Force disconnect with timeout

                await asyncio.wait_for(client.disconnect(), timeout=5.0)

            except asyncio.TimeoutError:

                logging.getLogger(__name__).warning(f"Client disconnect timed out")

            except Exception as e:

                logging.getLogger(__name__).warning(f"Client cleanup error: {e}")



# =============================================================================

# AUTO-SETUP E2E ENVIRONMENT FIXTURE

# Memory Impact: LOW - Environment variable setup

# =============================================================================



@pytest.fixture(autouse=True)

@memory_profile("Auto-setup E2E test environment variables", "LOW")

def setup_e2e_test_environment():

    """Auto-setup E2E test environment variables.

    

    Memory Impact: LOW - Simple environment variable configuration

    Use for: Automatic E2E test environment configuration

    """

    current_env = get_env().get("ENVIRONMENT", get_env().get("TEST_ENV", "test")).lower()

    is_staging = current_env == "staging"

    

    env = get_env()

    env.set("TESTING", "1", source="e2e_test_setup")

    env.set("NETRA_ENV", "e2e_testing", source="e2e_test_setup")

    # Only override ENVIRONMENT if not already set to staging

    if not is_staging:

        env.set("ENVIRONMENT", "test", source="e2e_test_setup")

    env.set("USE_REAL_SERVICES", "true", source="e2e_test_setup")

    env.set("AUTH_FAST_TEST_MODE", "true", source="e2e_test_setup")

    

    # Set Redis to use TEST environment port (6380)

    env.set("REDIS_HOST", "localhost", source="e2e_test_setup")

    env.set("REDIS_PORT", "6380", source="e2e_test_setup")

    env.set("REDIS_URL", "redis://localhost:6380/0", source="e2e_test_setup")

    

    # Set PostgreSQL to use TEST environment port (5433)

    env.set("DATABASE_URL", "postgresql://postgres:postgres@localhost:5433/netra_test", source="e2e_test_setup")

    

    # Set ClickHouse to use TEST environment ports

    env.set("CLICKHOUSE_HOST", "localhost", source="e2e_test_setup")

    env.set("CLICKHOUSE_HTTP_PORT", "8124", source="e2e_test_setup")

    env.set("CLICKHOUSE_TCP_PORT", "9001", source="e2e_test_setup")

    

    # Set longer timeouts for E2E tests

    env.set("HTTP_TIMEOUT", "30", source="e2e_test_setup")

    env.set("WEBSOCKET_TIMEOUT", "30", source="e2e_test_setup")

    env.set("LLM_TIMEOUT", "60", source="e2e_test_setup")

