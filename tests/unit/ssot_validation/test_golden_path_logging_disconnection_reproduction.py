

# PERFORMANCE: Lazy loading for mission critical tests



# PERFORMANCE: Lazy loading for mission critical tests

_lazy_imports = {}



def lazy_import(module_path: str, component: str = None):

    """Lazy import pattern for performance optimization"""

    if module_path not in _lazy_imports:

        try:

            module = __import__(module_path, fromlist=[component] if component else [])

            if component:

                _lazy_imports[module_path] = getattr(module, component)

            else:

                _lazy_imports[module_path] = module

        except ImportError as e:

            print(f"Warning: Failed to lazy load {module_path}: {e}")

            _lazy_imports[module_path] = None

    

    return _lazy_imports[module_path]



_lazy_imports = {}



def lazy_import(module_path: str, component: str = None):

    """Lazy import pattern for performance optimization"""

    if module_path not in _lazy_imports:

        try:

            module = __import__(module_path, fromlist=[component] if component else [])

            if component:

                _lazy_imports[module_path] = getattr(module, component)

            else:

                _lazy_imports[module_path] = module

        except ImportError as e:

            print(f"Warning: Failed to lazy load {module_path}: {e}")

            _lazy_imports[module_path] = None

    

    return _lazy_imports[module_path]



"""

CRITICAL TEST: Golden Path Logging Disconnection Reproduction (MUST FAIL INITIALLY)

============================================================================



PURPOSE: This test MUST FAIL initially to prove logging correlation breaks between 

agent_execution_core.py (central_logger) and agent_execution_tracker.py (logging.getLogger())



BUSINESS IMPACT: $500K+ ARR - customers can't debug agent failures due to disconnected correlation chains



VIOLATION: GitHub Issue #309 - Mixed logging patterns blocking Golden Path debugging



EXPECTED BEHAVIOR: 

- MUST FAIL initially, demonstrating current mixed logging patterns

- WILL PASS after SSOT remediation when both files use central_logger.get_logger()

"""



import asyncio

import logging

import time

import unittest.mock as mock

from typing import Dict, Any

from uuid import UUID, uuid4



from test_framework.ssot.base_test_case import SSotBaseTestCase

from netra_backend.app.services.user_execution_context import UserExecutionContext

from netra_backend.app.agents.supervisor.execution_context import (

    AgentExecutionContext,

    AgentExecutionResult,

)





class TestGoldenPathLoggingDisconnectionReproduction(SSotBaseTestCase):

    """

    CRITICAL: This test MUST FAIL initially.

    

    Proves that agent_execution_core.py (central_logger) and 

    agent_execution_tracker.py (logging.getLogger()) produce 

    disconnected correlation chains that break Golden Path debugging.

    

    BUSINESS IMPACT: $500K+ ARR - customers can't debug agent failures

    """

    

    def setUp(self):

        super().setUp()

        self.test_correlation_id = f"test_correlation_{int(time.time())}"

        self.test_user_id = "test_user_123"

        self.test_thread_id = "test_thread_456"

        self.test_agent_name = "TestAgent"

        self.test_run_id = uuid4()

        

    async def test_logging_correlation_breaks_across_execution_boundary(self):

        """

        CRITICAL: This test MUST FAIL initially.

        

        Proves that correlation ID is lost between agent_execution_core.py 

        and agent_execution_tracker.py due to different logging implementations.

        

        Expected: CORRELATION MUST BREAK (proving the problem exists)

        """

        # Import modules with different logging patterns

        from netra_backend.app.agents.supervisor.agent_execution_core import AgentExecutionCore

        from netra_backend.app.core.agent_execution_tracker import AgentExecutionTracker

        

        # Create mock agent registry and websocket bridge

        mock_registry = mock.MagicMock()

        mock_agent = mock.MagicMock()

        mock_agent.execute = mock.AsyncMock(return_value={"success": True, "data": "test_result"})

        mock_registry.get.return_value = mock_agent

        

        mock_websocket_bridge = mock.MagicMock()

        mock_websocket_bridge.notify_agent_started = mock.AsyncMock()

        mock_websocket_bridge.notify_agent_thinking = mock.AsyncMock()

        mock_websocket_bridge.notify_agent_completed = mock.AsyncMock()

        

        # Create execution context with correlation ID

        user_context = UserExecutionContext.from_agent_execution_context(

            user_id=self.test_user_id,

            thread_id=self.test_thread_id,

            run_id=str(self.test_run_id),

            agent_context={

                'agent_name': self.test_agent_name,

                'user_request': 'test_request',

                'agent_input': {},

                'correlation_id': self.test_correlation_id

            }

        )

        

        execution_context = AgentExecutionContext(

            agent_name=self.test_agent_name,

            run_id=self.test_run_id,

            correlation_id=self.test_correlation_id,

            retry_count=0

        )

        

        # Set up logging capture for both modules

        core_logger_logs = []

        tracker_logger_logs = []

        

        # Mock the loggers to capture their behavior

        with mock.patch('netra_backend.app.agents.supervisor.agent_execution_core.logger') as mock_core_logger:

            with mock.patch('netra_backend.app.core.agent_execution_tracker.logger') as mock_tracker_logger:

                

                # Capture log calls

                def capture_core_log(msg, *args, **kwargs):

                    core_logger_logs.append({

                        'message': msg,

                        'args': args,

                        'kwargs': kwargs,

                        'correlation_id': kwargs.get('extra', {}).get('correlation_id', None)

                    })

                

                def capture_tracker_log(msg, *args, **kwargs):

                    tracker_logger_logs.append({

                        'message': msg,

                        'args': args, 

                        'kwargs': kwargs,

                        'correlation_id': kwargs.get('extra', {}).get('correlation_id', None)

                    })

                

                mock_core_logger.info.side_effect = capture_core_log

                mock_core_logger.error.side_effect = capture_core_log

                mock_core_logger.warning.side_effect = capture_core_log

                mock_core_logger.debug.side_effect = capture_core_log

                

                mock_tracker_logger.info.side_effect = capture_tracker_log

                mock_tracker_logger.error.side_effect = capture_tracker_log

                mock_tracker_logger.warning.side_effect = capture_tracker_log

                mock_tracker_logger.debug.side_effect = capture_tracker_log

                

                # Execute agent through both systems

                execution_core = AgentExecutionCore(mock_registry, mock_websocket_bridge)

                

                try:

                    result = await execution_core.execute_agent(

                        context=execution_context,

                        state=user_context,

                        timeout=30.0

                    )

                    

                    # Verify execution completed

                    self.assertTrue(result.success)

                    

                except Exception as e:

                    # Allow exceptions but still check logging patterns

                    print(f"Test execution exception (expected): {e}")

        

        # CRITICAL CHECK: Verify logging pattern disconnection

        print(f"\n=== LOGGING PATTERN ANALYSIS ===")

        print(f"Core logger calls: {len(core_logger_logs)}")

        print(f"Tracker logger calls: {len(tracker_logger_logs)}")

        

        # Check if correlation IDs are properly propagated

        core_has_correlation = any(

            log_entry.get('correlation_id') == self.test_correlation_id 

            for log_entry in core_logger_logs

        )

        tracker_has_correlation = any(

            log_entry.get('correlation_id') == self.test_correlation_id

            for log_entry in tracker_logger_logs

        )

        

        print(f"Core logger has correlation ID: {core_has_correlation}")

        print(f"Tracker logger has correlation ID: {tracker_has_correlation}")

        

        # THE CRITICAL ASSERTION THAT MUST FAIL:

        # This will fail initially because the two modules use different logging systems

        # and correlation context is not properly shared between them

        

        # Check if BOTH systems have the correlation ID

        both_have_correlation = core_has_correlation and tracker_has_correlation

        

        # THIS ASSERTION SHOULD FAIL initially (proving disconnection exists)

        self.assertTrue(

            both_have_correlation,

            f"LOGGING DISCONNECTION DETECTED: "

            f"agent_execution_core.py (central_logger) correlation: {core_has_correlation}, "

            f"agent_execution_tracker.py (logging.getLogger()) correlation: {tracker_has_correlation}. "

            f"This proves the SSOT logging violation exists and breaks Golden Path debugging. "

            f"Both systems should share the same correlation context for $500K+ ARR protection."

        )

        

        print("CRITICAL: If this test PASSES initially, the logging patterns are already unified!")

        print("EXPECTED: This test should FAIL, proving the mixed logging pattern violation exists.")

    

    def test_detects_mixed_logging_patterns_in_execution_chain(self):

        """

        MUST FAIL: Proves execution chain uses inconsistent logging

        

        Scans agent_execution_core.py (central_logger.get_logger) vs

        agent_execution_tracker.py (logging.getLogger) to detect inconsistency

        """

        import inspect

        

        # Import the modules to analyze

        import netra_backend.app.agents.supervisor.agent_execution_core as core_module

        import netra_backend.app.core.agent_execution_tracker as tracker_module

        

        # Get source code for analysis

        core_source = inspect.getsource(core_module)

        tracker_source = inspect.getsource(tracker_module)

        

        # Check logging patterns

        core_uses_central_logger = 'central_logger.get_logger' in core_source

        core_uses_logging_getlogger = 'logging.getLogger' in core_source

        

        tracker_uses_central_logger = 'central_logger.get_logger' in tracker_source

        tracker_uses_logging_getlogger = 'logging.getLogger' in tracker_source

        

        print(f"\n=== LOGGING PATTERN DETECTION ===")

        print(f"agent_execution_core.py:")

        print(f"  - Uses central_logger.get_logger: {core_uses_central_logger}")

        print(f"  - Uses logging.getLogger: {core_uses_logging_getlogger}")

        print(f"agent_execution_tracker.py:")

        print(f"  - Uses central_logger.get_logger: {tracker_uses_central_logger}")

        print(f"  - Uses logging.getLogger: {tracker_uses_logging_getlogger}")

        

        # THE CRITICAL ASSERTION THAT MUST FAIL:

        # Both files should use the same logging pattern (central_logger)

        same_logging_pattern = (

            core_uses_central_logger and tracker_uses_central_logger and

            not core_uses_logging_getlogger and not tracker_uses_logging_getlogger

        )

        

        # THIS ASSERTION SHOULD FAIL initially (proving mixed patterns exist)

        self.assertTrue(

            same_logging_pattern,

            f"MIXED LOGGING PATTERNS DETECTED: "

            f"agent_execution_core.py uses central_logger: {core_uses_central_logger}, "

            f"agent_execution_tracker.py uses central_logger: {tracker_uses_central_logger}. "

            f"This proves SSOT violation exists. Both files should use central_logger.get_logger() "

            f"for unified correlation tracking in Golden Path execution chain."

        )

        

        print("CRITICAL: If this test PASSES initially, the logging patterns are already unified!")

        print("EXPECTED: This test should FAIL, proving the SSOT logging violation exists.")

    

    def test_golden_path_debug_correlation_failure_impact(self):

        """

        Demonstrates business impact of logging disconnection on Golden Path debugging.

        

        MUST FAIL: Shows how mixed logging patterns break debugging correlation

        affecting $500K+ ARR customer support capability.

        """

        from netra_backend.app.logging_config import central_logger

        import logging

        

        # Simulate Golden Path debugging scenario

        correlation_id = f"golden_path_{int(time.time())}"

        

        # Test central_logger behavior (used by agent_execution_core.py)

        central_log = central_logger.get_logger('test.central')

        

        # Test standard logging behavior (used by agent_execution_tracker.py)  

        standard_log = logging.getLogger('test.standard')

        

        # Capture logs from both systems

        central_logs = []

        standard_logs = []

        

        # Mock handlers to capture log records

        class TestHandler(logging.Handler):

            def __init__(self, log_storage):

                super().__init__()

                self.log_storage = log_storage

                

            def emit(self, record):

                self.log_storage.append({

                    'message': record.getMessage(),

                    'correlation_id': getattr(record, 'correlation_id', None),

                    'logger_name': record.name,

                    'level': record.levelname

                })

        

        central_handler = TestHandler(central_logs)

        standard_handler = TestHandler(standard_logs)

        

        central_log.addHandler(central_handler)

        standard_log.addHandler(standard_handler)

        

        # Simulate execution chain logging with correlation

        central_log.info("Agent execution started", extra={'correlation_id': correlation_id})

        standard_log.info("Execution tracker created", extra={'correlation_id': correlation_id})

        central_log.info("Agent processing request", extra={'correlation_id': correlation_id})

        standard_log.info("State transition recorded", extra={'correlation_id': correlation_id})

        

        # Clean up handlers

        central_log.removeHandler(central_handler)

        standard_log.removeHandler(standard_handler)

        

        # Analyze correlation consistency

        central_corr_count = sum(1 for log in central_logs if log['correlation_id'] == correlation_id)

        standard_corr_count = sum(1 for log in standard_logs if log['correlation_id'] == correlation_id)

        

        print(f"\n=== GOLDEN PATH DEBUG CORRELATION ANALYSIS ===")

        print(f"Central logger correlation matches: {central_corr_count}/{len(central_logs)}")

        print(f"Standard logger correlation matches: {standard_corr_count}/{len(standard_logs)}")

        

        # Check if correlation tracking is consistent between both systems

        central_correlation_perfect = central_corr_count == len(central_logs)

        standard_correlation_perfect = standard_corr_count == len(standard_logs)

        unified_correlation = central_correlation_perfect and standard_correlation_perfect

        

        # THE CRITICAL ASSERTION FOR BUSINESS IMPACT:

        # Golden Path debugging requires unified correlation across all components

        self.assertTrue(

            unified_correlation,

            f"GOLDEN PATH DEBUGGING BROKEN: "

            f"Central logger correlation: {central_correlation_perfect}, "

            f"Standard logger correlation: {standard_correlation_perfect}. "

            f"Mixed logging patterns break correlation chains needed for debugging "

            f"$500K+ ARR customer issues. SSOT logging remediation required."

        )

        

        print("BUSINESS IMPACT: If this test FAILS, customer support cannot correlate")

        print("agent execution flows across the Golden Path execution chain.")





if __name__ == '__main__':

    import asyncio

    

    # Run the async test

    suite = unittest.TestSuite()

    suite.addTest(TestGoldenPathLoggingDisconnectionReproduction('test_logging_correlation_breaks_across_execution_boundary'))

    suite.addTest(TestGoldenPathLoggingDisconnectionReproduction('test_detects_mixed_logging_patterns_in_execution_chain'))

    suite.addTest(TestGoldenPathLoggingDisconnectionReproduction('test_golden_path_debug_correlation_failure_impact'))

    

    runner = unittest.TextTestRunner(verbosity=2)

    

    def run_async_tests():

        loop = asyncio.new_event_loop()

        asyncio.set_event_loop(loop)

        try:

            return runner.run(suite)

        finally:

            loop.close()

    

    result = run_async_tests()

    if result.failures or result.errors:

        print("\nEXPECTED: Tests failed, proving SSOT logging violations exist!")

    else:

        print("\nUNEXPECTED: Tests passed - logging patterns may already be unified!")

