"""
Test module split from original file
Generated by auto_fix_test_violations.py
"""

import pytest
import asyncio
import json
import time
from unittest.mock import Mock, AsyncMock, patch, MagicMock
from typing import Dict, Any, List
from uuid import uuid4
from fastapi.testclient import TestClient
from fastapi import WebSocket
from starlette.websockets import WebSocketDisconnect
from app.routes.example_messages_enhanced import (
    router, MessageSequencer, ConnectionStateManager, 
    message_sequencer, connection_manager, agent_circuit_breaker
)
from app.handlers.example_message_handler_enhanced import (
    EnhancedExampleMessageHandler, SessionManager, RealAgentIntegration,
    ExampleMessageRequest, ExampleMessageResponse, ExampleMessageMetadata
)
from app.core.circuit_breaker import CircuitBreaker
from app.logging_config import central_logger
import sys
from app.routes.example_messages_enhanced import example_message_websocket_enhanced

class TestMessageSequencer:
    """Test Category 1: Message Sequencing and Ordering"""

    @pytest.fixture
    def sequencer(self):
        return MessageSequencer()

    def test_sequence_generation(self, sequencer):
        """Test sequence number generation for users"""
        user_id = "test_user_1"
        
        # First sequence should be 1
        seq1 = sequencer.get_next_sequence(user_id)
        assert seq1 == 1
        
        # Second sequence should be 2
        seq2 = sequencer.get_next_sequence(user_id)
        assert seq2 == 2
        
        # Different user should start at 1
        seq3 = sequencer.get_next_sequence("test_user_2")
        assert seq3 == 1

    def test_transactional_message_handling(self, sequencer):
        """Test transactional pattern for message handling"""
        user_id = "test_user"
        sequence = 1
        message = {"type": "test", "payload": "data"}
        
        # Add pending message
        sequencer.add_pending_message(user_id, sequence, message)
        
        # Message should be in pending state
        pending = sequencer.get_pending_messages(user_id)
        assert sequence in pending
        assert pending[sequence]['status'] == 'pending'
        
        # Mark as sending
        assert sequencer.mark_message_sending(user_id, sequence) == True
        pending = sequencer.get_pending_messages(user_id)
        assert pending[sequence]['status'] == 'sending'
        
        # Acknowledge message
        assert sequencer.acknowledge_message(user_id, sequence) == True
        
        # Message should be removed from pending
        pending = sequencer.get_pending_messages(user_id)
        assert sequence not in pending

    def test_message_retry_logic(self, sequencer):
        """Test message retry logic with failure handling"""
        user_id = "test_user"
        sequence = 1
        message = {"type": "test", "payload": "data"}
        
        # Add message
        sequencer.add_pending_message(user_id, sequence, message)
        
        # Simulate send failure - revert to pending
        sequencer.mark_message_sending(user_id, sequence)
        sequencer.revert_message_to_pending(user_id, sequence)
        
        # Should be pending again with retry count
        pending = sequencer.get_pending_messages(user_id)
        assert pending[sequence]['status'] == 'pending'
        assert sequencer.should_retry_message(user_id, sequence) == True
        
        # After max retries, should not retry
        for i in range(4):  # Exceed max retries
            sequencer.revert_message_to_pending(user_id, sequence)
        
        assert sequencer.should_retry_message(user_id, sequence) == False

    def test_atomic_cleanup(self, sequencer):
        """Test atomic cleanup of user sequences"""
        user_id = "test_user"
        
        # Add multiple messages
        for i in range(3):
            seq = sequencer.get_next_sequence(user_id)
            sequencer.add_pending_message(user_id, seq, {"test": i})
        
        # Verify data exists
        assert len(sequencer.get_pending_messages(user_id)) == 3
        
        # Cleanup
        sequencer.cleanup_user_sequences(user_id)
        
        # All data should be removed
        assert len(sequencer.get_pending_messages(user_id)) == 0
        assert user_id not in sequencer._sequences

class TestConnectionStateManager:
    """Test Category 2: Connection State Management"""

    @pytest.fixture
    def state_manager(self):
        return ConnectionStateManager()

    @pytest.mark.asyncio
    async def test_connection_registration(self, state_manager):
        """Test connection registration with full state tracking"""
        user_id = "test_user"
        connection_id = str(uuid4())
        websocket = Mock(spec=WebSocket)
        
        # Register connection
        await state_manager.register_connection(user_id, connection_id, websocket)
        
        # Verify connection is registered
        assert state_manager.is_connection_valid(user_id)
        
        conn_info = state_manager.get_connection_info(user_id)
        assert conn_info['connection_id'] == connection_id
        assert conn_info['status'] == 'connected'
        assert conn_info['authenticated'] == False

    def test_connection_activity_tracking(self, state_manager):
        """Test connection activity tracking and timeouts"""
        user_id = "test_user"
        connection_id = str(uuid4())
        websocket = Mock(spec=WebSocket)
        
        # Register connection
        asyncio.run(state_manager.register_connection(user_id, connection_id, websocket))
        
        # Update activity
        initial_activity = state_manager.get_connection_info(user_id)['last_activity']
        time.sleep(0.1)  # Brief delay
        state_manager.update_activity(user_id)
        
        updated_activity = state_manager.get_connection_info(user_id)['last_activity']
        assert updated_activity > initial_activity

    def test_error_count_management(self, state_manager):
        """Test error counting and disconnection thresholds"""
        user_id = "test_user"
        connection_id = str(uuid4())
        websocket = Mock(spec=WebSocket)
        
        # Register connection
        asyncio.run(state_manager.register_connection(user_id, connection_id, websocket))
        
        # Increment errors
        for i in range(5):
            state_manager.increment_error_count(user_id)
        
        conn_info = state_manager.get_connection_info(user_id)
        assert conn_info['error_count'] == 5
        
        # Should not disconnect yet (threshold is 10)
        assert not state_manager.should_disconnect_for_errors(user_id)
        
        # Add more errors to exceed threshold
        for i in range(6):
            state_manager.increment_error_count(user_id)
        
        assert state_manager.should_disconnect_for_errors(user_id)

    @pytest.mark.asyncio
    async def test_atomic_cleanup(self, state_manager):
        """Test atomic connection cleanup"""
        user_id = "test_user"
        connection_id = str(uuid4())
        websocket = Mock(spec=WebSocket)
        
        # Register connection
        await state_manager.register_connection(user_id, connection_id, websocket)
        assert state_manager.is_connection_valid(user_id)
        
        # Cleanup
        await state_manager.cleanup_connection(user_id)
        
        # Connection should be removed
        assert not state_manager.is_connection_valid(user_id)
        assert state_manager.get_connection_info(user_id) is None

class TestSessionManager:
    """Test Category 3: Session Management and Memory Cleanup"""

    @pytest.fixture
    def session_manager(self):
        return SessionManager()

    @pytest.mark.asyncio
    async def test_session_creation_with_timeout(self, session_manager):
        """Test session creation with proper timeout management"""
        user_id = "test_user"
        message_id = "test_message"
        metadata = {"category": "test", "complexity": "basic"}
        
        # Create session
        session_id = await session_manager.create_session(
            user_id, message_id, metadata, timeout_minutes=1
        )
        
        # Verify session exists
        session = session_manager.get_session(session_id)
        assert session is not None
        assert session['user_id'] == user_id
        assert session['message_id'] == message_id
        
        # Verify timeout is set
        assert session_id in session_manager.session_timeouts

    def test_session_updates(self, session_manager):
        """Test session data updates"""
        user_id = "test_user"
        message_id = "test_message"
        metadata = {"category": "test"}
        
        session_id = asyncio.run(session_manager.create_session(user_id, message_id, metadata))
        
        # Update session
        updates = {"status": "processing", "progress": 50}
        assert session_manager.update_session(session_id, updates) == True
        
        # Verify updates
        session = session_manager.get_session(session_id)
        assert session['status'] == 'processing'
        assert session['progress'] == 50

    def test_user_session_tracking(self, session_manager):
        """Test tracking sessions by user"""
        user_id = "test_user"
        
        # Create multiple sessions for user
        session_ids = []
        for i in range(3):
            session_id = asyncio.run(session_manager.create_session(
                user_id, f"message_{i}", {"test": i}
            ))
            session_ids.append(session_id)
        
        # Get user sessions
        user_sessions = session_manager.get_user_sessions(user_id)
        assert len(user_sessions) == 3
        
        # Verify all sessions belong to user
        for session in user_sessions:
            assert session['user_id'] == user_id

    @pytest.mark.asyncio
    async def test_session_cleanup_and_memory_management(self, session_manager):
        """Test session cleanup prevents memory leaks"""
        user_id = "test_user"
        message_id = "test_message"
        metadata = {"category": "test"}
        
        # Create session
        session_id = await session_manager.create_session(user_id, message_id, metadata)
        
        # Verify session exists
        assert session_manager.get_session(session_id) is not None
        
        # Cleanup session
        await session_manager._cleanup_session(session_id)
        
        # Verify session is removed
        assert session_manager.get_session(session_id) is None
        assert user_id not in session_manager.user_sessions or not session_manager.user_sessions[user_id]

    def test_session_statistics(self, session_manager):
        """Test session statistics generation"""
        # Create multiple sessions with different statuses
        for i in range(3):
            session_id = asyncio.run(session_manager.create_session(f"user_{i}", f"msg_{i}", {}))
            session_manager.update_session(session_id, {"status": "processing" if i % 2 else "completed"})
        
        stats = session_manager.get_stats()
        
        assert stats['active_sessions'] == 3
        assert stats['total_users'] == 3
        assert 'status_breakdown' in stats
        assert 'memory_usage_estimate' in stats

class TestErrorHandlingAndRecovery:
    """Test Category 6: Comprehensive Error Handling and Recovery"""

    @pytest.fixture
    def handler(self):
        return EnhancedExampleMessageHandler()

    @pytest.mark.asyncio
    async def test_validation_error_handling(self, handler):
        """Test handling of validation errors"""
        
        invalid_message = {
            "content": "short",  # Too short
            "example_message_id": "test",
            "user_id": "user"
            # Missing required fields
        }
        
        response = await handler.handle_example_message(invalid_message)
        
        assert response.status == 'error'
        assert 'validation' in response.error.lower() or 'invalid' in response.error.lower()

    @pytest.mark.asyncio
    async def test_processing_error_recovery(self, handler):
        """Test recovery from processing errors"""
        
        with patch.object(handler.real_agent_integration, 'execute_real_agent_processing') as mock_process:
            # Make processing fail initially, then succeed
            mock_process.side_effect = [Exception("Processing error"), {"agent_name": "Test", "result": "success"}]
            
            # First attempt should handle error gracefully
            response = await handler.handle_example_message({
                "content": "Test optimization request with sufficient length",
                "example_message_id": "test_message",
                "example_message_metadata": {
                    "title": "Test",
                    "category": "cost-optimization",
                    "complexity": "basic",
                    "businessValue": "conversion",
                    "estimatedTime": "30s"
                },
                "user_id": "test_user",
                "timestamp": int(time.time() * 1000)
            })
            
            # Should handle error gracefully
            assert response.status == 'error'
            assert response.error is not None

    @pytest.mark.asyncio
    async def test_timeout_handling(self, handler):
        """Test handling of processing timeouts"""
        
        with patch.object(handler.real_agent_integration, 'execute_real_agent_processing') as mock_process:
            # Simulate timeout
            async def slow_process(*args, **kwargs):
                await asyncio.sleep(2)  # Longer than circuit breaker timeout
                return {"result": "slow"}
            
            mock_process.side_effect = slow_process
            
            # Should handle timeout gracefully
            response = await handler.handle_example_message({
                "content": "Test optimization request with sufficient length for timeout test",
                "example_message_id": "test_message",
                "example_message_metadata": {
                    "title": "Test",
                    "category": "cost-optimization", 
                    "complexity": "basic",
                    "businessValue": "conversion",
                    "estimatedTime": "30s"
                },
                "user_id": "test_user",
                "timestamp": int(time.time() * 1000)
            })
            
            # Should complete (with circuit breaker protection)
            assert response is not None

class TestBusinessLogicValidation:
    """Test Category 9: Business Logic and Value Generation"""

    @pytest.fixture
    def handler(self):
        return EnhancedExampleMessageHandler()

    @pytest.mark.asyncio
    async def test_business_insights_generation(self, handler):
        """Test business insights generation for different value types"""
        
        metadata = ExampleMessageMetadata(
            title="Test",
            category="cost-optimization",
            complexity="advanced",
            businessValue="conversion",
            estimatedTime="30s"
        )
        
        result = {"real_agent_execution": True, "agent_name": "Test"}
        processing_time = 15000  # 15 seconds
        
        insights = handler._generate_enhanced_business_insights(metadata, result, processing_time)
        
        assert insights['business_value_type'] == 'conversion'
        assert insights['real_agent_execution'] == True
        assert insights['performance_score'] > 0.8  # High score for real agent + good time
        assert 'conversion_indicators' in insights

    def test_category_routing_logic(self, handler):
        """Test proper routing logic for different optimization categories"""
        
        categories = ['cost-optimization', 'latency-optimization', 'model-selection', 'scaling', 'advanced']
        
        for category in categories:
            # Test that each category has appropriate processing logic
            integration = handler.real_agent_integration
            
            # Verify the category-specific processing methods exist
            method_name = f"_process_{category.replace('-', '_')}_real"
            assert hasattr(integration, method_name)

    def test_complexity_handling(self, handler):
        """Test handling of different complexity levels"""
        
        complexities = ['basic', 'intermediate', 'advanced']
        
        for complexity in complexities:
            metadata = ExampleMessageMetadata(
                title="Test",
                category="cost-optimization",
                complexity=complexity,
                businessValue="conversion",
                estimatedTime="30s"
            )
            
            # Should handle all complexity levels
            result = {"agent_name": "Test", "complexity_handled": complexity}
            insights = handler._generate_enhanced_business_insights(metadata, result, 20000)
            
            assert insights['complexity_handled'] == complexity

class TestConfiguration:
    """Verify test configuration and setup"""
    
    def test_all_imports_successful(self):
        """Verify all required imports are successful"""
        # This test will fail if any imports are broken
        assert True
    
    def test_mock_objects_configured(self, mock_llm_manager):
        """Verify mock objects are properly configured"""
        assert mock_llm_manager is not None
        assert hasattr(mock_llm_manager, 'get_client')
