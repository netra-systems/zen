"Mission Critical: WebSocket 1011 Error Resolution Tests"

Specifically validates that Redis SSOT consolidation prevents WebSocket 1011 errors
that were blocking 500K+  ARR chat functionality.

Background:
    - WebSocket 1011 errors occurred due to competing Redis connection pools
- Multiple Redis managers caused race conditions during handshake
- Connection pool conflicts prevented reliable WebSocket establishment
- Chat functionality (90% of platform value) was severely impacted

Success Criteria:
    - Zero WebSocket 1011 errors under normal load
- 99%+ WebSocket connection success rate
- Stable connections during concurrent user sessions
- No Redis-related WebSocket failures

REAL SERVICES ONLY - No mocks allowed in mission critical tests.
""

import pytest
import asyncio
import time
import json
import websockets
from typing import Dict, Any, List, Optional
from unittest.mock import patch

from netra_backend.app.redis_manager import redis_manager
from test_framework.ssot.base_test_case import SSotAsyncTestCase


class WebSocket1011FixesTests(SSotAsyncTestCase):
    Mission Critical: Test WebSocket 1011 error fixes through Redis SSOT."
    Mission Critical: Test WebSocket 1011 error fixes through Redis SSOT.""

    
    def setUp(self):
        "Set up test fixtures."
        super().setUp()
        self.test_redis_keys = set()
        self.websocket_connections = []
        
    async def asyncTearDown(self):
        ""Async cleanup of test resources."
        # Close any WebSocket connections
        for ws in self.websocket_connections:
            try:
                if hasattr(ws, 'close'):
                    await ws.close()
            except Exception:
                pass
        
        # Clean up Redis test keys
        for key in self.test_redis_keys:
            try:
                await redis_manager.delete(key)
            except Exception:
                pass
        
        await super().asyncTearDown()
    
    async def test_websocket_redis_race_condition_eliminated(self):
        MISSION CRITICAL: Test Redis race conditions don't cause WebSocket 1011 errors.""'
        
        BUSINESS IMPACT: Prevents primary revenue channel failure.
        ROOT CAUSE: Multiple Redis connection pools caused handshake conflicts.
        FIX: Single SSOT Redis manager eliminates race conditions.
        
        # Ensure Redis SSOT is initialized
        await redis_manager.initialize()
        self.assertTrue(redis_manager.is_connected, Redis SSOT must be connected for WebSocket tests")"
        
        # Simulate rapid WebSocket connection attempts (race condition scenario)
        connection_tasks = []
        for i in range(25):  # Increased from plan to stress test more
            connection_tasks.append(self._simulate_websocket_connection(fuser_{i}))
        
        # Execute all connection attempts concurrently
        start_time = time.time()
        results = await asyncio.gather(*connection_tasks, return_exceptions=True)
        end_time = time.time()
        
        # Analyze results
        successful_connections = sum(1 for r in results if r is True)
        failed_connections = len(results) - successful_connections
        success_rate = (successful_connections / len(results)) * 100
        
        # Performance metrics
        total_time = end_time - start_time
        connections_per_second = len(results) / total_time
        
        # MISSION CRITICAL VALIDATION
        self.assertGreaterEqual(success_rate, 95.0,
                               fWebSocket connection success rate should be >=95%, got {success_rate}%. 
                               f"Failed connections: {failed_connections})"
        
        self.assertGreaterEqual(connections_per_second, 5.0,
                               fShould handle at least 5 connections/sec, got {connections_per_second:.""2f""}")"
        
        # Log results for monitoring
        self.logger.info(fWebSocket race condition test results:)
        self.logger.info(f  Success rate: {success_rate:.1f}%)""
        self.logger.info(f"  Successful: {successful_connections}/{len(results)})"
        self.logger.info(f  Performance: {connections_per_second:.""2f""} connections/sec)""

        
        if failed_connections > 0:
            self.logger.warning(fHad {failed_connections} failed connections - investigating...)
            # Log failed connection details for debugging
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    self.logger.warning(f  Connection {i} failed: {result}")"
    
    async def test_redis_connection_pool_stability_under_websocket_load(self):
        MISSION CRITICAL: Test Redis connection pool remains stable under WebSocket load."
        MISSION CRITICAL: Test Redis connection pool remains stable under WebSocket load.""

        
        BUSINESS IMPACT: Ensures chat system can handle concurrent users without failures.
        ISSUE: Previous multiple connection pools caused instability under load.
        FIX: Single SSOT connection pool maintains stability.
        "
        ""

        initial_status = redis_manager.get_status()
        
        # Simulate high-load WebSocket scenario with Redis operations
        load_tasks = []
        for i in range(50):  # Simulate 50 concurrent users
            load_tasks.append(self._simulate_websocket_session_lifecycle(fload_user_{i}))
        
        # Execute high load scenario
        start_time = time.time()
        results = await asyncio.gather(*load_tasks, return_exceptions=True)
        end_time = time.time()
        
        # Analyze load test results
        successful_sessions = sum(1 for r in results if r is True)
        exception_count = len(results) - successful_sessions
        success_rate = (successful_sessions / len(results)) * 100
        
        # Performance analysis
        total_time = end_time - start_time
        sessions_per_second = len(results) / total_time
        
        # MISSION CRITICAL VALIDATION
        self.assertGreaterEqual(success_rate, 90.0,
                               f"WebSocket session success rate should be >=90% under load, got {success_rate}%)""),"
                       Redis connection should remain stable under WebSocket load)
        
        # Failure count should not increase dramatically
        failure_increase = final_status[consecutive_failures"] - initial_status.get(consecutive_failures, 0)"
        self.assertLessEqual(failure_increase, 3,
                           fRedis failure count should not increase significantly under load, got +{failure_increase})
        
        # Background tasks should remain active
        self.assertTrue(final_status[background_tasks)[reconnect_task_active"),"
                      "Redis reconnection task should remain active)"
        self.assertTrue(final_status[background_tasks)[health_monitor_active),
                      Redis health monitor should remain active")"
        
        # Log load test results
        self.logger.info(fWebSocket load test results:)
        self.logger.info(f  Session success rate: {success_rate:.""1f""}%)
        self.logger.info(f"  Performance: {sessions_per_second:.""2f""} sessions/sec)"
        self.logger.info(f  Redis stability: {final_status['connected']}")"
        
        if exception_count > 0:
            self.logger.warning(fLoad test had {exception_count} exceptions)
    
    async def test_websocket_handshake_redis_operations_atomic(self):
        "MISSION CRITICAL: Test WebSocket handshake Redis operations are atomic."
        
        BUSINESS IMPACT: Prevents partial handshake states that cause 1011 errors.
        ISSUE: Race conditions caused incomplete Redis state during handshake.
        FIX: SSOT Redis manager ensures atomic operations.
"
"
        # Test atomic handshake operations
        user_id = atomic_test_user"
        user_id = atomic_test_user"
        connection_id = fws_{user_id}_{int(time.time() * 1000)}"
        connection_id = fws_{user_id}_{int(time.time() * 1000)}""

        
        # Define all Redis keys that should be set atomically
        connection_key = fwebsocket:active:{connection_id}
        session_key = fwebsocket:session:{user_id}"
        session_key = fwebsocket:session:{user_id}"
        tracking_key = f"user_connections:{user_id}"
        
        self.test_redis_keys.update([connection_key, session_key, tracking_key)
        
        # Perform atomic handshake operations
        handshake_success = await self._perform_atomic_handshake(user_id, connection_id)
        self.assertTrue(handshake_success, Atomic handshake should succeed)
        
        # Verify all Redis keys were set correctly
        connection_data = await redis_manager.get(connection_key)
        self.assertIsNotNone(connection_data, Connection data should be set)"
        self.assertIsNotNone(connection_data, Connection data should be set)""

        
        session_data = await redis_manager.get(session_key)
        self.assertEqual(session_data, valid_session", Session should be valid)"
        
        tracking_length = await redis_manager.llen(tracking_key)
        self.assertGreater(tracking_length, 0, Connection should be tracked)
        
        # Test concurrent atomic operations don't interfere'
        concurrent_handshakes = []
        for i in range(10):
            concurrent_user = f"concurrent_user_{i}"
            concurrent_connection = fws_{concurrent_user}_{int(time.time() * 1000)}_{i}"
            concurrent_connection = fws_{concurrent_user}_{int(time.time() * 1000)}_{i}""

            concurrent_handshakes.append(
                self._perform_atomic_handshake(concurrent_user, concurrent_connection)
            )
        
        concurrent_results = await asyncio.gather(*concurrent_handshakes, return_exceptions=True)
        concurrent_successes = sum(1 for r in concurrent_results if r is True)
        
        self.assertGreaterEqual(concurrent_successes, 8,
                               fConcurrent atomic handshakes should mostly succeed, got {concurrent_successes}/10)
    
    async def test_websocket_1011_error_conditions_resolved(self):
        "MISSION CRITICAL: Test specific conditions that caused 1011 errors are resolved."
        
        BUSINESS IMPACT: Validates specific scenarios that broke chat functionality.
        CONDITIONS TESTED:
        1. Rapid connect/disconnect cycles
        2. Connection timeout during Redis operations
        3. Redis connection pool exhaustion
        4. Concurrent user authentication
"
""

        
        # Condition 1: Rapid connect/disconnect cycles
        cycle_tasks = []
        for i in range(15):
            cycle_tasks.append(self._test_rapid_connection_cycle(fcycle_user_{i}))
        
        cycle_results = await asyncio.gather(*cycle_tasks, return_exceptions=True)
        cycle_successes = sum(1 for r in cycle_results if r is True)
        cycle_success_rate = (cycle_successes / len(cycle_tasks)) * 100
        
        self.assertGreaterEqual(cycle_success_rate, 90.0,
                               fRapid connection cycles should succeed >=90%, got {cycle_success_rate}%")"
        
        # Condition 2: Connection timeout resilience
        timeout_tasks = []
        for i in range(10):
            timeout_tasks.append(self._test_connection_with_timeout(ftimeout_user_{i}))
        
        timeout_results = await asyncio.gather(*timeout_tasks, return_exceptions=True)
        timeout_successes = sum(1 for r in timeout_results if r is True)
        timeout_success_rate = (timeout_successes / len(timeout_tasks)) * 100
        
        self.assertGreaterEqual(timeout_success_rate, 85.0,
                               fTimeout resilience should be >=85%, got {timeout_success_rate}%)
        
        # Condition 3: Redis pool exhaustion prevention
        pool_test_success = await self._test_redis_pool_exhaustion_prevention()
        self.assertTrue(pool_test_success, "Redis pool exhaustion should be prevented)"
        
        # Condition 4: Concurrent authentication
        auth_tasks = []
        for i in range(20):
            auth_tasks.append(self._test_concurrent_user_authentication(fauth_user_{i}))
        
        auth_results = await asyncio.gather(*auth_tasks, return_exceptions=True)
        auth_successes = sum(1 for r in auth_results if r is True)
        auth_success_rate = (auth_successes / len(auth_tasks)) * 100
        
        self.assertGreaterEqual(auth_success_rate, 95.0,
                               fConcurrent authentication should succeed >=95%, got {auth_success_rate}%)
        
        # Overall validation
        self.logger.info(WebSocket 1011 error condition test results:")"
        self.logger.info(f  Rapid cycles: {cycle_success_rate:.""1f""}%)
        self.logger.info(f  Timeout resilience: {timeout_success_rate:.""1f""}%)
        self.logger.info(f"  Pool exhaustion prevention: {pool_test_success})"
        self.logger.info(f  Concurrent auth: {auth_success_rate:.""1f""}%")"
    
    async def _simulate_websocket_connection(self, user_id: str) -> bool:
        Simulate WebSocket connection with Redis operations.""
        try:
            connection_id = fws_{user_id}_{int(time.time() * 1000)}
            
            # Simulate WebSocket handshake Redis operations
            connection_key = fwebsocket:active:{connection_id}
            self.test_redis_keys.add(connection_key)
            
            # Store connection info
            connection_data = {
                user_id": user_id,"
                connected_at: time.time(),
                connection_id: connection_id"
                connection_id: connection_id""

            }
            
            success = await redis_manager.set(
                connection_key,
                json.dumps(connection_data),
                ex=3600
            )
            if not success:
                return False
            
            # Simulate session validation
            session_key = f"websocket:session:{user_id}"
            self.test_redis_keys.add(session_key)
            
            session_success = await redis_manager.set(session_key, valid_session, ex=1800)
            if not session_success:
                return False
            
            # Verify session
            session = await redis_manager.get(session_key)
            if session != valid_session:"
            if session != valid_session:""

                return False
            
            # Simulate connection tracking
            tracking_key = fuser_connections:{user_id}"
            tracking_key = fuser_connections:{user_id}""

            self.test_redis_keys.add(tracking_key)
            
            await redis_manager.lpush(tracking_key, connection_id)
            
            # Brief operation to simulate real usage
            await asyncio.sleep(0.1)
            
            return True
            
        except Exception as e:
            self.logger.debug(fWebSocket connection simulation failed for {user_id}: {e})
            return False
    
    async def _simulate_websocket_session_lifecycle(self, user_id: str) -> bool:
        "Simulate complete WebSocket session lifecycle."
        try:
            # Connect
            connection_success = await self._simulate_websocket_connection(user_id)
            if not connection_success:
                return False
            
            # Simulate session activity
            activity_key = fwebsocket:activity:{user_id}
            self.test_redis_keys.add(activity_key)
            
            for i in range(3):  # 3 activities per session
                await redis_manager.set(f{activity_key}:{i}, f"activity_{i}, ex=60)"
                await asyncio.sleep(0.5)  # Brief pause between activities
            
            # Simulate heartbeat
            heartbeat_key = fwebsocket:heartbeat:{user_id}"
            heartbeat_key = fwebsocket:heartbeat:{user_id}""

            self.test_redis_keys.add(heartbeat_key)
            await redis_manager.set(heartbeat_key, str(time.time()), ex=30)
            
            # Cleanup (disconnect)
            await self._cleanup_websocket_session(user_id)
            
            return True
            
        except Exception as e:
            self.logger.debug(fWebSocket session lifecycle failed for {user_id}: {e})
            return False
    
    async def _perform_atomic_handshake(self, user_id: str, connection_id: str) -> bool:
        Perform atomic WebSocket handshake operations.""
        try:
            # Use Redis pipeline for atomic operations
            async with redis_manager.pipeline() as pipe:
                # Set connection data
                connection_key = fwebsocket:active:{connection_id}
                pipe.set(connection_key, json.dumps({
                    user_id: user_id,
                    "connection_id: connection_id,"
                    timestamp: time.time()
                }, ex=3600)
                
                # Set session
                session_key = fwebsocket:session:{user_id}
                pipe.set(session_key, valid_session", ex=1800)"
                
                # Track connection
                tracking_key = fuser_connections:{user_id}
                pipe.lpush(tracking_key, connection_id)
                
                # Execute atomically
                results = await pipe.execute()
                
                # All operations should succeed
                return all(results)
                
        except Exception as e:
            self.logger.debug(fAtomic handshake failed for {user_id}: {e})
            return False
    
    async def _test_rapid_connection_cycle(self, user_id: str) -> bool:
        "Test rapid connect/disconnect cycles."
        try:
            for cycle in range(3):  # 3 rapid cycles
                # Connect
                connection_success = await self._simulate_websocket_connection(user_id)
                if not connection_success:
                    return False
                
                # Brief pause
                await asyncio.sleep(0.2)
                
                # Disconnect
                await self._cleanup_websocket_session(user_id)
                
                # Very brief pause before next cycle
                await asyncio.sleep(0.1)
            
            return True
            
        except Exception:
            return False
    
    async def _test_connection_with_timeout(self, user_id: str) -> bool:
        "Test connection handling with timeout scenarios."
        try:
            # Set shorter timeout for this test
            original_timeout = getattr(redis_manager, '_operation_timeout', 5.0)
            
            # Simulate connection with potential timeout
            connection_id = fws_timeout_{user_id}_{int(time.time() * 1000)}
            
            # Use timeout for Redis operations
            try:
                success = await asyncio.wait_for(
                    self._perform_atomic_handshake(user_id, connection_id),
                    timeout=2.0
                )
                return success
            except asyncio.TimeoutError:
                # Timeout should be handled gracefully
                self.logger.debug(fConnection timeout for {user_id} - should be handled gracefully)"
                self.logger.debug(fConnection timeout for {user_id} - should be handled gracefully)""

                return True  # Graceful timeout handling is success
            
        except Exception:
            return False
    
    async def _test_redis_pool_exhaustion_prevention(self) -> bool:
        "Test that Redis pool exhaustion is prevented."
        try:
            # Redis SSOT should use single connection pool
            status = redis_manager.get_status()
            
            # Should have single connection
            self.assertTrue(status[connected"], Should have stable connection)"
            
            # Perform many operations without exhausting pool
            operation_tasks = []
            for i in range(100):
                operation_tasks.append(
                    redis_manager.set(fpool_test:{i}, fdata_{i}, ex=10)
                )
            
            results = await asyncio.gather(*operation_tasks, return_exceptions=True)
            success_count = sum(1 for r in results if r is True)
            
            # Should handle high load without pool exhaustion
            return success_count >= 90  # At least 90% success
            
        except Exception:
            return False
    
    async def _test_concurrent_user_authentication(self, user_id: str) -> bool:
        Test concurrent user authentication through Redis.""
        try:
            # Simulate authentication Redis operations
            auth_key = fauth:session:{user_id}
            self.test_redis_keys.add(auth_key)
            
            auth_data = {
                user_id: user_id,
                "authenticated: True,"
                timestamp: time.time()
            }
            
            # Store auth session
            auth_success = await redis_manager.store_session(
                user_id, auth_data, 3600
            )
            if not auth_success:
                return False
            
            # Verify auth session
            retrieved = await redis_manager.get_session(user_id)
            if retrieved != auth_data:
                return False
            
            # Test token operations
            token = ftoken_{user_id}
            await redis_manager.blacklist_token(token, 60)
            is_blacklisted = await redis_manager.is_token_blacklisted(token)
            
            return is_blacklisted
            
        except Exception:
            return False
    
    async def _cleanup_websocket_session(self, user_id: str):
        ""Clean up WebSocket session Redis data.""

        try:
            # Get all keys for this user
            patterns = [
                fwebsocket:active:ws_{user_id}*,
                fwebsocket:session:{user_id}","
                fwebsocket:activity:{user_id}*,
                fwebsocket:heartbeat:{user_id},
                f"user_connections:{user_id}"
            ]
            
            for pattern in patterns:
                if '*' in pattern:
                    # Scan for keys matching pattern
                    base_pattern = pattern.replace('*', '')
                    keys = await redis_manager.scan_keys(base_pattern + '*')
                    for key in keys:
                        await redis_manager.delete(key)
                else:
                    await redis_manager.delete(pattern)
                    
        except Exception as e:
            self.logger.debug(fCleanup failed for {user_id}: {e}")"


class WebSocketRedisIntegrationTests(SSotAsyncTestCase):
    Additional WebSocket-Redis integration tests for edge cases.""
    
    async def test_websocket_redis_circuit_breaker_behavior(self):
        Test WebSocket behavior when Redis circuit breaker is active."
        Test WebSocket behavior when Redis circuit breaker is active."
        # Force circuit breaker to open
        redis_manager._consecutive_failures = 10
        
        # WebSocket operations should gracefully handle circuit breaker
        user_id = "circuit_breaker_user"
        connection_success = await self._simulate_graceful_degradation(user_id)
        
        # Should handle gracefully (not cause 1011 errors)
        self.assertTrue(connection_success, WebSocket should handle Redis circuit breaker gracefully)
        
        # Reset circuit breaker
        await redis_manager.reset_circuit_breaker()
        redis_manager._consecutive_failures = 0
    
    async def _simulate_graceful_degradation(self, user_id: str) -> bool:
        "Simulate WebSocket connection with Redis unavailable."
        try:
            # Should not throw exceptions even with circuit breaker open
            connection_id = fws_degraded_{user_id}"
            connection_id = fws_degraded_{user_id}""

            
            # These operations should fail gracefully
            await redis_manager.set(f"test:{connection_id}, data)"
            await redis_manager.get(ftest:{connection_id})
            
            # Should return False/None but not crash
            return True
            
        except Exception:
            # Any exception means graceful degradation failed
            return False
    
    async def test_websocket_redis_recovery_after_failure(self):
        "Test WebSocket functionality recovers after Redis failure."
        # Simulate Redis failure and recovery
        original_connected = redis_manager._connected
        
        # Simulate disconnection
        redis_manager._connected = False
        
        # Force reconnection
        await redis_manager.force_reconnect()
        
        # Should recover connection
        self.assertTrue(redis_manager.is_connected, Redis should recover after failure)
        
        # WebSocket operations should work after recovery
        user_id = recovery_test_user""
        recovery_success = await self._test_websocket_after_recovery(user_id)
        self.assertTrue(recovery_success, WebSocket should work after Redis recovery)
    
    async def _test_websocket_after_recovery(self, user_id: str) -> bool:
        """Test WebSocket operations after Redis recovery."""
        try:
            # Should work normally after recovery
            session_data = {"user_id: user_id, recovered: True}"
            
            success = await redis_manager.store_session(user_id, session_data, 60)
            if not success:
                return False
            
            retrieved = await redis_manager.get_session(user_id)
            return retrieved == session_data
            
        except Exception:
            return False

))