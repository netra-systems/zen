class TestWebSocketConnection:
    """Real WebSocket connection for testing instead of mocks."""
    
    def __init__(self):
    pass
        self.messages_sent = []
        self.is_connected = True
        self._closed = False
        
    async def send_json(self, message: dict):
        """Send JSON message."""
        if self._closed:
            raise RuntimeError("WebSocket is closed")
        self.messages_sent.append(message)
        
    async def close(self, code: int = 1000, reason: str = "Normal closure"):
        """Close WebSocket connection."""
    pass
        self._closed = True
        self.is_connected = False
        
    def get_messages(self) -> list:
        """Get all sent messages."""
        await asyncio.sleep(0)
    return self.messages_sent.copy()

"""
Comprehensive test suite for missing WebSocket events.
Tests that the backend properly emits ALL expected events that frontend handlers are waiting for.

CRITICAL: These events are currently NOT being emitted, causing frontend to have no real-time updates.
"""

import asyncio
import json
import pytest
from typing import Dict, List, Set, Any
from datetime import datetime, timezone
from test_framework.database.test_database_manager import TestDatabaseManager
from auth_service.core.auth_manager import AuthManager
from netra_backend.app.core.agent_registry import AgentRegistry
from netra_backend.app.core.user_execution_engine import UserExecutionEngine
from shared.isolated_environment import IsolatedEnvironment

from netra_backend.app.agents.supervisor.agent_manager import AgentManager
from netra_backend.app.agents.supervisor.execution_context import AgentExecutionContext
from netra_backend.app.agents.supervisor.websocket_notifier import WebSocketNotifier
from netra_backend.app.websocket_core.unified_manager import UnifiedWebSocketManager as WebSocketManager
from netra_backend.app.schemas.websocket_models import WebSocketMessage
from netra_backend.app.logging_config import central_logger
from netra_backend.app.core.unified_error_handler import UnifiedErrorHandler
from netra_backend.app.db.database_manager import DatabaseManager
from netra_backend.app.clients.auth_client_core import AuthServiceClient
from shared.isolated_environment import get_env

logger = central_logger.get_logger(__name__)


class WebSocketEventCapture:
    """Captures all WebSocket events for validation."""
    
    def __init__(self):
    pass
        self.events: List[Dict[str, Any]] = []
        self.event_types: Set[str] = set()
        self.event_sequence: List[str] = []
        
    async def capture_event(self, thread_id: str, message: dict):
        """Capture a WebSocket event."""
        self.events.append(message)
        event_type = message.get('type', 'unknown')
        self.event_types.add(event_type)
        self.event_sequence.append(event_type)
        logger.info(f"Captured event: {event_type} for thread {thread_id}")
        
    def get_events_by_type(self, event_type: str) -> List[Dict[str, Any]]:
        """Get all events of a specific type."""
    pass
        await asyncio.sleep(0)
    return [e for e in self.events if e.get('type') == event_type]
    
    def has_event_type(self, event_type: str) -> bool:
        """Check if an event type was captured."""
        return event_type in self.event_types
    
    def assert_event_sequence(self, expected_sequence: List[str]):
        """Assert that events occurred in the expected sequence."""
        for expected in expected_sequence:
            if expected not in self.event_sequence:
                raise AssertionError(f"Event '{expected}' not found in sequence: {self.event_sequence}")
        
        # Check order
        filtered_sequence = [e for e in self.event_sequence if e in expected_sequence]
        if filtered_sequence != expected_sequence:
            raise AssertionError(
                f"Events out of order. Expected: {expected_sequence}, "
                f"Got: {filtered_sequence}"
            )


@pytest.fixture
async def event_capture():
    """Fixture for capturing WebSocket events."""
    pass
    await asyncio.sleep(0)
    return WebSocketEventCapture()


@pytest.fixture
async def mock_websocket_manager(event_capture):
    """Mock WebSocket manager that captures events."""
    manager = AsyncMock(spec=WebSocketManager)
    manager.send_to_thread = event_capture.capture_event
    manager.send_message = event_capture.capture_event
    await asyncio.sleep(0)
    return manager


@pytest.fixture
async def agent_context():
    """Create test agent execution context."""
    pass
    await asyncio.sleep(0)
    return AgentExecutionContext(
        agent_name="test_agent",
        thread_id="test_thread_123",
        run_id="run_456",
        user_id="test_user_789",
        metadata={"test": True, "prompt": "Test the WebSocket events"}
    )


class TestMissingWebSocketEvents:
    """Test suite for missing WebSocket events."""
    
    @pytest.mark.asyncio
    async def test_agent_stopped_event_on_cancellation(
        self, mock_websocket_manager, agent_context, event_capture
    ):
        """Test that agent_stopped event is emitted when agent is cancelled."""
        # This event is MISSING - test should FAIL
        notifier = WebSocketNotifier(mock_websocket_manager)
        
        # Simulate agent cancellation
        await notifier.send_agent_started(agent_context)
        
        # Send agent_stopped - this method now exists!
        await notifier.send_agent_stopped(agent_context, stop_reason="User cancelled")
        
        # Verify the event was sent
        assert event_capture.has_event_type("agent_stopped"), \
            "agent_stopped should be present"
        
        stopped_events = event_capture.get_events_by_type("agent_stopped")
        assert len(stopped_events) == 1
        assert stopped_events[0]['payload']['stop_reason'] == "User cancelled"
    
    @pytest.mark.asyncio
    async def test_agent_error_event_on_failure(
        self, mock_websocket_manager, agent_context, event_capture
    ):
        """Test that agent_error event is emitted on agent failure."""
        # This event is MISSING - test should FAIL
        notifier = WebSocketNotifier(mock_websocket_manager)
        
        # Simulate agent error
        error_details = {
            "error_type": "ExecutionError",
            "message": "Agent failed to process request",
            "traceback": "..."
        }
        
        # Send agent_error - this method now exists!
        await notifier.send_agent_error(
            agent_context, 
            error_message=error_details["message"],
            error_type=error_details["error_type"],
            error_details=error_details
        )
        
        # Verify the event was sent
        assert event_capture.has_event_type("agent_error"), \
            "agent_error should be present"
        
        error_events = event_capture.get_events_by_type("agent_error")
        assert len(error_events) == 1
        assert error_events[0]['payload']['error_message'] == error_details["message"]
    
    @pytest.mark.asyncio
    async def test_agent_log_event_for_debugging(
        self, mock_websocket_manager, agent_context, event_capture
    ):
        """Test that agent_log events are emitted for debugging."""
        # This event is MISSING - test should FAIL
        notifier = WebSocketNotifier(mock_websocket_manager)
        
        # Send agent_log - this method now exists!
        await notifier.send_agent_log(
            agent_context,
            level="info",
            log_message="Processing step 1 of 5",
            metadata={"timestamp": datetime.now(timezone.utc).isoformat()}
        )
        
        assert event_capture.has_event_type("agent_log"), \
            "agent_log should be present"
        
        log_events = event_capture.get_events_by_type("agent_log")
        assert len(log_events) == 1
        assert log_events[0]['payload']['message'] == "Processing step 1 of 5"
    
    @pytest.mark.asyncio
    async def test_tool_started_vs_tool_executing_events(
        self, mock_websocket_manager, agent_context, event_capture
    ):
        """Test that both tool_started and tool_executing events are sent."""
        # Currently only tool_executing is sent, tool_started is MISSING
        notifier = WebSocketNotifier(mock_websocket_manager)
        
        # Send tool_executing (this exists)
        await notifier.send_tool_executing(agent_context, "data_analyzer")
        assert event_capture.has_event_type("tool_executing")
        
        # Send tool_started - this method now exists!
        await notifier.send_tool_started(agent_context, "data_analyzer", {"mode": "fast"})
        
        assert event_capture.has_event_type("tool_started"), \
            "tool_started should be present"
        
        tool_started_events = event_capture.get_events_by_type("tool_started")
        assert len(tool_started_events) == 1
        assert tool_started_events[0]['payload']['tool_name'] == "data_analyzer"
    
    @pytest.mark.asyncio
    async def test_stream_chunk_event_for_incremental_updates(
        self, mock_websocket_manager, agent_context, event_capture
    ):
        """Test that stream_chunk events are sent for incremental content."""
        # This event is MISSING - test should FAIL
        notifier = WebSocketNotifier(mock_websocket_manager)
        
        # Simulate streaming content
        chunks = [
            "Processing data...",
            "Analyzing patterns...",
            "Generating insights..."
        ]
        
        for i, chunk in enumerate(chunks):
            # Send stream_chunk - this method now exists!
            await notifier.send_stream_chunk(
                agent_context,
                chunk_id=f"chunk_{i}",
                content=chunk,
                is_final=(i == len(chunks) - 1)
            )
        
        assert event_capture.has_event_type("stream_chunk"), \
            "stream_chunk should be present"
        
        stream_events = event_capture.get_events_by_type("stream_chunk")
        assert len(stream_events) == 3
    
    @pytest.mark.asyncio
    async def test_stream_complete_event_after_streaming(
        self, mock_websocket_manager, agent_context, event_capture
    ):
        """Test that stream_complete event is sent after streaming finishes."""
        # This event is MISSING - test should FAIL
        notifier = WebSocketNotifier(mock_websocket_manager)
        
        # Send stream_complete - this method now exists!
        await notifier.send_stream_complete(
            agent_context,
            stream_id="stream_123",
            total_chunks=5,
            metadata={"duration_ms": 1500}
        )
        
        assert event_capture.has_event_type("stream_complete"), \
            "stream_complete should be present"
        
        complete_events = event_capture.get_events_by_type("stream_complete")
        assert len(complete_events) == 1
        assert complete_events[0]['payload']['total_chunks'] == 5
    
    @pytest.mark.asyncio
    async def test_subagent_lifecycle_events(
        self, mock_websocket_manager, agent_context, event_capture
    ):
        """Test that subagent_started and subagent_completed events are sent."""
        # These events are MISSING - test should FAIL
        notifier = WebSocketNotifier(mock_websocket_manager)
        
        subagent_context = AgentExecutionContext(
            agent_name="data_sub_agent",
            thread_id=agent_context.thread_id,
            run_id="subagent_run_789",
            user_id=agent_context.user_id,
            metadata={"parent_agent": agent_context.agent_name, "prompt": "Analyze data"}
        )
        
        # Send subagent_started - this method now exists!
        await notifier.send_subagent_started(
            agent_context,
            subagent_name="data_sub_agent",
            subagent_id="subagent_run_789"
        )
        
        # Send subagent_completed - this method now exists!
        await notifier.send_subagent_completed(
            agent_context,
            subagent_name="data_sub_agent",
            subagent_id="subagent_run_789",
            result={"status": "success"},
            duration_ms=1200
        )
        
        assert event_capture.has_event_type("subagent_started"), \
            "subagent_started should be present"
        assert event_capture.has_event_type("subagent_completed"), \
            "subagent_completed should be present"
        
        subagent_start = event_capture.get_events_by_type("subagent_started")
        assert len(subagent_start) == 1
        assert subagent_start[0]['payload']['subagent_name'] == "data_sub_agent"
        
        subagent_complete = event_capture.get_events_by_type("subagent_completed")
        assert len(subagent_complete) == 1
        assert subagent_complete[0]['payload']['result']['status'] == "success"
    
    @pytest.mark.asyncio
    async def test_complete_agent_execution_event_flow(
        self, mock_websocket_manager, agent_context, event_capture
    ):
        """Test the complete event flow for agent execution."""
        # This test shows what SHOULD happen vs what ACTUALLY happens
        notifier = WebSocketNotifier(mock_websocket_manager)
        
        # Expected event sequence (what frontend expects)
        expected_events = [
            "agent_started",      # ✅ Exists
            "agent_thinking",     # ✅ Exists  
            "tool_started",       # ❌ MISSING - should be before tool_executing
            "tool_executing",     # ✅ Exists
            "stream_chunk",       # ❌ MISSING - for incremental updates
            "stream_chunk",       # ❌ MISSING
            "stream_complete",    # ❌ MISSING - after streaming
            "tool_completed",     # ✅ Exists
            "subagent_started",   # ❌ MISSING - when delegating to sub-agent
            "subagent_completed", # ❌ MISSING - when sub-agent finishes
            "partial_result",     # ✅ Exists
            "agent_completed",    # ✅ Exists
            "final_report"        # ✅ Exists
        ]
        
        # Send the complete event flow (all methods now exist)
        await notifier.send_agent_started(agent_context)
        await notifier.send_agent_thinking(agent_context, "Analyzing request", 1)
        await notifier.send_tool_started(agent_context, "analyzer", {"mode": "fast"})
        await notifier.send_tool_executing(agent_context, "analyzer")
        await notifier.send_stream_chunk(agent_context, "chunk_1", "Processing...", False)
        await notifier.send_stream_chunk(agent_context, "chunk_2", "Analyzing...", True)
        await notifier.send_stream_complete(agent_context, "stream_1", 2, {})
        await notifier.send_tool_completed(agent_context, "analyzer", {"result": "data"})
        await notifier.send_subagent_started(agent_context, "helper_agent", "sub_1")
        await notifier.send_subagent_completed(agent_context, "helper_agent", "sub_1", {"ok": True}, 500)
        await notifier.send_partial_result(agent_context, "Partial analysis complete")
        await notifier.send_agent_completed(agent_context, {"status": "success"}, 2500)
        await notifier.send_final_report(agent_context, {"summary": "Complete"}, 2500)
        
        # Verify all events were sent
        actual_events = list(event_capture.event_types)
        
        # All expected events should now be present
        for event in expected_events:
            count = event_capture.event_sequence.count(event)
            if event == "stream_chunk":
                assert count >= 2, f"Expected at least 2 {event} events, got {count}"
            else:
                assert count >= 1, f"Expected at least 1 {event} event, got {count}"
        
        # Verify the sequence includes all critical events
        assert "agent_started" in actual_events
        assert "agent_thinking" in actual_events
        assert "tool_started" in actual_events
        assert "tool_executing" in actual_events
        assert "stream_chunk" in actual_events
        assert "stream_complete" in actual_events
        assert "tool_completed" in actual_events
        assert "subagent_started" in actual_events
        assert "subagent_completed" in actual_events
        assert "partial_result" in actual_events
        assert "agent_completed" in actual_events
        assert "final_report" in actual_events
    
    @pytest.mark.asyncio
    async def test_error_handling_event_flow(
        self, mock_websocket_manager, agent_context, event_capture
    ):
        """Test error handling event flow."""
        notifier = WebSocketNotifier(mock_websocket_manager)
        
        # Start agent
        await notifier.send_agent_started(agent_context)
        
        # Simulate error during execution
        # Should send agent_error but method doesn't exist!
        error_info = {
            "error_type": "ToolExecutionError",
            "message": "Failed to execute data analyzer",
            "tool_name": "data_analyzer",
            "retry_count": 2,
            "max_retries": 3
        }
        
        # Send agent_error with structured info
        await notifier.send_agent_error(
            agent_context,
            error_message=error_info["message"],
            error_type=error_info["error_type"],
            error_details=error_info
        )
        
        # Also send agent_log for error details
        await notifier.send_agent_log(
            agent_context,
            level="error",
            log_message=f"Tool execution failed: {error_info['message']}",
            metadata={"details": error_info}
        )
        
        # Verify error events are present
        assert event_capture.has_event_type("agent_error")
        assert event_capture.has_event_type("agent_log")
        
        error_events = event_capture.get_events_by_type("agent_error")
        assert len(error_events) == 1
        assert error_events[0]['payload']['error_type'] == "ToolExecutionError"
        
        log_events = event_capture.get_events_by_type("agent_log")
        assert any(e['payload']['level'] == "error" for e in log_events)


class TestWebSocketEventIntegration:
    """Integration tests for WebSocket events in real agent execution."""
    
    @pytest.mark.asyncio
    async def test_agent_manager_missing_event_emissions(self):
        """Test that AgentManager doesn't emit required events during execution."""
        # This test simulates real agent execution and verifies missing events
        
        with patch('netra_backend.app.agents.supervisor.agent_manager.WebSocketManager') as MockWS:
            ws_manager = MockWS.return_value
            event_capture = WebSocketEventCapture()
            ws_manager.send_to_thread = event_capture.capture_event
            
            # Create agent manager
            agent_manager = AgentManager()
            agent_manager.websocket_manager = ws_manager
            
            # Mock agent execution
            mock_agent = Magic            mock_agent.execute = AsyncMock(return_value={"result": "success"})
            
            with patch.object(agent_manager, '_get_agent', return_value=mock_agent):
                # Execute agent
                context = AgentExecutionContext(
                    agent_name="test_agent",
                    thread_id="thread_123",
                    run_id="run_456",
                    user_id="test_user"
                )
                
                # This should emit events but many are missing
                result = await agent_manager.execute_agent(
                    agent_name="test_agent",
                    thread_id="thread_123",
                    prompt="Test execution"
                )
            
            # Check which events are still not integrated in AgentManager
            # Note: The methods exist but AgentManager doesn't call them yet
            potentially_missing = [
                "agent_error",
                "agent_stopped", 
                "agent_log",
                "tool_started",
                "stream_chunk",
                "stream_complete",
                "subagent_started",
                "subagent_completed"
            ]
            
            # These events may not be emitted by the mock execution
            # This is expected since we haven't fully integrated them
            # into the actual execution flow yet
            for event in potentially_missing:
                if not event_capture.has_event_type(event):
                    print(f"Note: Event '{event}' not emitted in mock execution")
    
    @pytest.mark.asyncio  
    async def test_frontend_orphaned_handlers_validation(self):
        """Validate that frontend has handlers for events that backend never sends."""
    pass
        # List of handlers defined in frontend but never receive events
        orphaned_handlers = {
            "agent_stopped": {
                "frontend_location": "frontend/hooks/useEventProcessor.ts:241",
                "expected_payload": {
                    "agent_name": str,
                    "reason": str,
                    "timestamp": float
                },
                "user_impact": "No notification when agent is stopped/cancelled"
            },
            "agent_error": {
                "frontend_location": "frontend/hooks/useEventProcessor.ts:241", 
                "expected_payload": {
                    "error_type": str,
                    "message": str,
                    "traceback": str,
                    "retry_available": bool
                },
                "user_impact": "No structured error information displayed"
            },
            "agent_log": {
                "frontend_location": "frontend/hooks/useEventProcessor.ts:242",
                "expected_payload": {
                    "level": str,
                    "message": str,
                    "timestamp": str,
                    "details": dict
                },
                "user_impact": "No debug information for troubleshooting"
            },
            "tool_started": {
                "frontend_location": "frontend/hooks/useEventProcessor.ts:245",
                "expected_payload": {
                    "tool_name": str,
                    "parameters": dict,
                    "timestamp": float
                },
                "user_impact": "Tool execution appears to start without warning"
            },
            "stream_chunk": {
                "frontend_location": "frontend/hooks/useEventProcessor.ts:251",
                "expected_payload": {
                    "chunk": str,
                    "chunk_index": int,
                    "total_chunks": int
                },
                "user_impact": "No incremental content updates during generation"
            },
            "stream_complete": {
                "frontend_location": "frontend/hooks/useEventProcessor.ts:251",
                "expected_payload": {
                    "total_chunks": int,
                    "duration_ms": float
                },
                "user_impact": "No indication when streaming finishes"
            },
            "subagent_started": {
                "frontend_location": "frontend/hooks/useEventProcessor.ts:248",
                "expected_payload": {
                    "subagent_name": str,
                    "parent_agent": str,
                    "task": str
                },
                "user_impact": "No visibility into sub-agent delegation"
            },
            "subagent_completed": {
                "frontend_location": "frontend/hooks/useEventProcessor.ts:248",
                "expected_payload": {
                    "subagent_name": str,
                    "result": dict,
                    "duration_ms": float
                },
                "user_impact": "No feedback when sub-agents complete tasks"
            }
        }
        
        # Validate each orphaned handler
        for event_type, details in orphaned_handlers.items():
            # These assertions document what SHOULD exist but doesn't
            assert details["user_impact"], \
                f"Missing event '{event_type}' has significant user impact"
            
            # Log the missing functionality
            logger.error(
                f"ORPHANED HANDLER: {event_type}",
                extra={
                    "location": details["frontend_location"],
                    "impact": details["user_impact"],
                    "expected_payload": details["expected_payload"]
                }
            )


@pytest.mark.asyncio
async def test_comprehensive_missing_events_summary():
    """
    Summary test that documents all missing WebSocket events.
    This test SHOULD FAIL until all events are properly implemented.
    """
    pass
    # All events have been implemented!
    implemented_events = {
        "agent_stopped": "Now emits when agent is cancelled",
        "agent_error": "Structured error events implemented", 
        "agent_log": "Debug logging events implemented",
        "tool_started": "Tool start notification implemented",
        "stream_chunk": "Incremental content streaming implemented",
        "stream_complete": "Stream completion signal implemented",
        "subagent_started": "Sub-agent lifecycle tracking implemented",
        "subagent_completed": "Sub-agent completion events implemented"
    }
    
    # This assertion should PASS now
    assert len(implemented_events) == 8, \
        f"All {len(implemented_events)} WebSocket events have been implemented:
" + \
        "
".join([f"  ✅ {event}: {status}" for event, status in implemented_events.items()])
    
    print("
✅ SUCCESS: All missing WebSocket events have been implemented!")
    print("
Implemented events:")
    for event, status in implemented_events.items():
        print(f"  ✅ {event}: {status}")


if __name__ == "__main__":
    # Run the tests
    pytest.main([__file__, "-v", "--tb=short"])