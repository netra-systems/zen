"""
E2E Staging Tests: Multi-User Concurrent Isolation
=================================================

This module tests multi-user concurrent execution with proper isolation in staging environment.
Tests REAL multi-user scenarios, concurrent agent execution, and user isolation boundaries.

Business Value:
- Validates system can handle multiple users simultaneously (critical for scale)
- Ensures user data isolation prevents $500K+ liability from data leaks
- Tests concurrent execution supports 10+ simultaneous users
- Validates business model can serve multiple customers concurrently

CRITICAL E2E REQUIREMENTS:
- MUST use real authentication for each user (JWT/OAuth)
- MUST test actual concurrent execution scenarios
- MUST validate complete user isolation (no data bleeding)
- MUST test real staging environment under load
- NO MOCKS ALLOWED - uses real services, agents, and user sessions

Test Coverage:
1. Concurrent user authentication and session isolation
2. Parallel agent execution with user context separation
3. WebSocket connection isolation under concurrent load
4. Cross-user data isolation validation
5. System performance under multi-user concurrent load
"""

import asyncio
import json
import logging
import time
import uuid
from datetime import datetime, timezone
from typing import Dict, Any, Optional, List, Tuple, Set

import aiohttp
import pytest
import websockets
from dataclasses import dataclass

from test_framework.ssot.e2e_auth_helper import (
    E2EAuthHelper, 
    E2EWebSocketAuthHelper, 
    E2EAuthConfig,
    create_authenticated_user_context
)
from tests.e2e.staging_config import get_staging_config, StagingTestConfig
from shared.types.execution_types import StronglyTypedUserExecutionContext
from shared.types.core_types import UserID, ThreadID, RunID, RequestID

logger = logging.getLogger(__name__)

# Test configuration
STAGING_CONFIG = get_staging_config()


@dataclass
class MultiUserTestResult:
    """Result of a multi-user isolation test."""
    success: bool
    total_users: int
    successful_users: int
    isolation_violations: List[str]
    performance_metrics: Dict[str, float]
    user_results: List[Dict[str, Any]]
    execution_time: float
    business_value_delivered: bool
    error_message: Optional[str] = None


@dataclass
class UserTestSession:
    """Individual user test session data."""
    user_id: str
    email: str
    jwt_token: str
    user_context: StronglyTypedUserExecutionContext
    websocket: Optional[Any] = None
    responses: List[Dict[str, Any]] = None
    execution_time: float = 0.0
    success: bool = False
    isolated_data: Set[str] = None
    
    def __post_init__(self):
        if self.responses is None:
            self.responses = []
        if self.isolated_data is None:
            self.isolated_data = set()


class TestMultiUserConcurrentIsolation:
    """
    Complete E2E multi-user concurrent isolation tests for staging environment.
    
    CRITICAL: All tests use REAL authentication and concurrent user sessions.
    """
    
    @pytest.fixture(autouse=True)
    async def setup_staging_environment(self):
        """Set up staging environment for all tests."""
        # Validate staging configuration
        assert STAGING_CONFIG.validate_configuration(), "Staging configuration invalid"
        STAGING_CONFIG.log_configuration()
        
        # Create auth helpers for staging
        self.auth_config = E2EAuthConfig.for_staging()
        self.auth_helper = E2EAuthHelper(config=self.auth_config, environment="staging")
        self.ws_helper = E2EWebSocketAuthHelper(config=self.auth_config, environment="staging")
        
        # Verify staging services are accessible
        await self._verify_staging_services_health()
        
        # Track created user sessions for cleanup
        self.user_sessions: List[UserTestSession] = []
        
        yield
        
        # Cleanup after tests
        await self._cleanup_user_sessions()
    
    async def _verify_staging_services_health(self):
        """Verify all staging services are healthy before testing."""
        health_endpoints = STAGING_CONFIG.urls.health_endpoints
        
        async with aiohttp.ClientSession() as session:
            for service, endpoint in health_endpoints.items():
                try:
                    async with session.get(endpoint, timeout=15) as resp:
                        assert resp.status == 200, f"Staging {service} service unhealthy: {resp.status}"
                        logger.info(f"âœ… Staging {service} service healthy")
                except Exception as e:
                    pytest.fail(f"âŒ Staging {service} service unavailable: {e}")
    
    async def _cleanup_user_sessions(self):
        """Clean up all user sessions created during testing."""
        for session in self.user_sessions:
            if session.websocket:
                try:
                    await session.websocket.close()
                except:
                    pass
        logger.info(f"Cleaned up {len(self.user_sessions)} user sessions")
    
    async def _create_user_session(self, user_index: int) -> UserTestSession:
        """Create a complete user session with authentication and context."""
        user_email = f"multi-user-{user_index}-{uuid.uuid4().hex[:8]}@staging-test.com"
        
        # Create user context
        user_context = await create_authenticated_user_context(
            user_email=user_email,
            environment="staging",
            permissions=["read", "write", "agent_execution"],
            websocket_enabled=True
        )
        
        # Get JWT token
        jwt_token = await self.auth_helper.get_staging_token_async(email=user_email)
        
        session = UserTestSession(
            user_id=str(user_context.user_id),
            email=user_email,
            jwt_token=jwt_token,
            user_context=user_context
        )
        
        self.user_sessions.append(session)
        return session
    
    async def _connect_user_websocket(self, session: UserTestSession) -> bool:
        """Connect WebSocket for a user session."""
        try:
            ws_headers = self.ws_helper.get_websocket_headers(session.jwt_token)
            session.websocket = await asyncio.wait_for(
                websockets.connect(
                    self.auth_config.websocket_url,
                    additional_headers=ws_headers,
                    open_timeout=20.0
                ),
                timeout=25.0
            )
            return True
        except Exception as e:
            logger.warning(f"Failed to connect WebSocket for user {session.user_id}: {e}")
            return False
    
    async def _send_user_message_and_collect_responses(
        self,
        session: UserTestSession,
        message: str,
        timeout: float = 60.0
    ) -> List[Dict[str, Any]]:
        """Send message for a user and collect responses."""
        if not session.websocket:
            return []
        
        start_time = time.time()
        
        try:
            # Send user-specific message
            user_message = {
                "type": "chat_message",
                "message": message,
                "user_id": session.user_id,
                "thread_id": str(session.user_context.thread_id),
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            
            await session.websocket.send(json.dumps(user_message))
            
            # Collect responses
            responses = []
            while time.time() - start_time < timeout:
                try:
                    response = await asyncio.wait_for(session.websocket.recv(), timeout=5.0)
                    response_data = json.loads(response)
                    responses.append(response_data)
                    
                    # Track user-specific data for isolation validation
                    if "user_id" in response_data:
                        session.isolated_data.add(response_data["user_id"])
                    
                    # Check for completion
                    if response_data.get("type") in ["agent_completed", "agent_response"]:
                        break
                        
                except asyncio.TimeoutError:
                    if len(responses) > 0:
                        break  # Got some responses, continue
                    continue
                except Exception as e:
                    logger.warning(f"Error receiving response for user {session.user_id}: {e}")
                    break
            
            session.responses = responses
            session.execution_time = time.time() - start_time
            session.success = len(responses) > 0
            
            return responses
            
        except Exception as e:
            logger.error(f"Failed to send message for user {session.user_id}: {e}")
            session.success = False
            return []
    
    @pytest.mark.asyncio
    @pytest.mark.staging
    @pytest.mark.e2e
    async def test_concurrent_user_authentication_and_session_isolation(self):
        """
        Test 1: Concurrent user authentication and session isolation.
        
        Business Value:
        - Validates system can authenticate multiple users simultaneously
        - Ensures user sessions remain isolated from each other
        - Tests foundation for multi-tenant business model
        
        Workflow:
        1. Create multiple user sessions concurrently
        2. Authenticate all users in parallel
        3. Validate each user gets isolated session
        4. Verify no cross-user authentication data leakage
        5. Test session persistence under concurrent load
        """
        start_time = time.time()
        num_concurrent_users = 5
        
        try:
            # Step 1: Create multiple user sessions concurrently
            logger.info(f"ðŸš€ Creating {num_concurrent_users} concurrent user sessions")
            
            async def create_and_authenticate_user(user_index: int) -> UserTestSession:
                try:
                    session = await self._create_user_session(user_index)
                    
                    # Validate authentication by making API call
                    auth_headers = self.auth_helper.get_auth_headers(session.jwt_token)
                    
                    async with aiohttp.ClientSession() as http_session:
                        validate_url = f"{self.auth_config.auth_service_url}/auth/validate"
                        async with http_session.get(validate_url, headers=auth_headers, timeout=10) as resp:
                            if resp.status == 200:
                                validation_data = await resp.json()
                                session.isolated_data.add(validation_data.get("sub", ""))
                                session.success = True
                                logger.info(f"âœ… User {user_index} authenticated successfully")
                            else:
                                session.success = False
                                logger.warning(f"âš ï¸ User {user_index} authentication failed: {resp.status}")
                    
                    return session
                    
                except Exception as e:
                    logger.error(f"âŒ Failed to create user {user_index}: {e}")
                    return UserTestSession(
                        user_id=f"failed-{user_index}",
                        email=f"failed-{user_index}@test.com",
                        jwt_token="",
                        user_context=None,
                        success=False
                    )
            
            # Create all users concurrently
            user_creation_tasks = [
                create_and_authenticate_user(i) for i in range(num_concurrent_users)
            ]
            
            user_sessions = await asyncio.gather(*user_creation_tasks, return_exceptions=True)
            
            # Filter successful sessions
            successful_sessions = [
                session for session in user_sessions 
                if isinstance(session, UserTestSession) and session.success
            ]
            
            # Step 2: Validate session isolation
            isolation_violations = []
            user_data_sets = []
            
            for session in successful_sessions:
                user_data_sets.append(session.isolated_data)
            
            # Check for data bleeding between users
            for i, data_set_a in enumerate(user_data_sets):
                for j, data_set_b in enumerate(user_data_sets):
                    if i != j and data_set_a.intersection(data_set_b):
                        isolation_violations.append(f"Data overlap between user {i} and {j}")
            
            # Step 3: Test concurrent API access
            concurrent_api_results = []
            
            async def test_concurrent_api_access(session: UserTestSession) -> bool:
                if not session.success:
                    return False
                
                try:
                    auth_headers = self.auth_helper.get_auth_headers(session.jwt_token)
                    
                    async with aiohttp.ClientSession() as http_session:
                        # Test multiple concurrent API calls for same user
                        api_calls = [
                            http_session.get(f"{self.auth_config.auth_service_url}/auth/validate", headers=auth_headers, timeout=10)
                            for _ in range(3)
                        ]
                        
                        responses = await asyncio.gather(*api_calls, return_exceptions=True)
                        successful_calls = sum(1 for r in responses if hasattr(r, 'status') and r.status == 200)
                        
                        return successful_calls >= 2  # At least 2 of 3 calls successful
                        
                except Exception:
                    return False
            
            api_test_tasks = [test_concurrent_api_access(session) for session in successful_sessions]
            api_results = await asyncio.gather(*api_test_tasks, return_exceptions=True)
            concurrent_api_success = sum(1 for result in api_results if result is True)
            
            execution_time = time.time() - start_time
            
            # Step 4: Evaluate business value
            performance_metrics = {
                "total_users_created": len(user_sessions),
                "successful_authentications": len(successful_sessions),
                "authentication_success_rate": len(successful_sessions) / num_concurrent_users,
                "concurrent_api_success": concurrent_api_success,
                "isolation_violations": len(isolation_violations),
                "average_auth_time": execution_time / num_concurrent_users
            }
            
            business_value_delivered = (
                performance_metrics["authentication_success_rate"] >= 0.8 and  # 80%+ success rate
                performance_metrics["isolation_violations"] == 0 and  # No isolation violations
                performance_metrics["concurrent_api_success"] >= len(successful_sessions) * 0.8 and  # 80%+ API success
                execution_time < 60.0  # Completed within 1 minute
            )
            
            result = MultiUserTestResult(
                success=True,
                total_users=num_concurrent_users,
                successful_users=len(successful_sessions),
                isolation_violations=isolation_violations,
                performance_metrics=performance_metrics,
                user_results=[{"user_id": s.user_id, "success": s.success} for s in user_sessions],
                execution_time=execution_time,
                business_value_delivered=business_value_delivered
            )
            
            # Assertions for test success
            assert len(successful_sessions) >= 4, f"Too few successful sessions: {len(successful_sessions)}/5"
            assert len(isolation_violations) == 0, f"Session isolation violations: {isolation_violations}"
            assert result.business_value_delivered, "Concurrent authentication failed to deliver business value"
            
            logger.info(f"âœ… BUSINESS VALUE: System supports concurrent user authentication and isolation")
            logger.info(f"   Successful authentications: {len(successful_sessions)}/{num_concurrent_users}")
            logger.info(f"   Authentication success rate: {performance_metrics['authentication_success_rate']:.1%}")
            logger.info(f"   Isolation violations: {len(isolation_violations)}")
            logger.info(f"   Concurrent API success: {concurrent_api_success}/{len(successful_sessions)}")
            logger.info(f"   Total execution time: {execution_time:.1f}s")
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"âŒ Concurrent user authentication test failed: {e}")
            pytest.fail(f"Concurrent user authentication and session isolation failed: {e}")
    
    @pytest.mark.asyncio
    @pytest.mark.staging
    @pytest.mark.e2e
    async def test_parallel_agent_execution_with_user_context_separation(self):
        """
        Test 2: Parallel agent execution with user context separation.
        
        Business Value:
        - Validates multiple users can run agents simultaneously
        - Ensures agent execution contexts remain isolated
        - Tests core AI service delivery under concurrent load
        
        Workflow:
        1. Set up multiple authenticated users
        2. Start agent execution for all users in parallel
        3. Monitor agent execution isolation
        4. Validate each user gets their own agent responses
        5. Verify no cross-contamination of agent contexts
        """
        start_time = time.time()
        num_concurrent_users = 4
        
        try:
            # Step 1: Set up multiple authenticated users
            logger.info(f"ðŸ¤– Setting up {num_concurrent_users} users for parallel agent execution")
            
            user_sessions = []
            for i in range(num_concurrent_users):
                session = await self._create_user_session(i)
                if await self._connect_user_websocket(session):
                    user_sessions.append(session)
                    logger.info(f"âœ… User {i} WebSocket connected")
                else:
                    logger.warning(f"âš ï¸ User {i} WebSocket connection failed")
            
            assert len(user_sessions) >= 3, f"Too few WebSocket connections: {len(user_sessions)}/4"
            
            # Step 2: Start parallel agent execution
            async def run_agent_for_user(session: UserTestSession, user_index: int) -> Dict[str, Any]:
                user_specific_message = (
                    f"Hello, I'm user {user_index} with ID {session.user_id}. "
                    f"Please help me analyze optimization strategies specifically for my context. "
                    f"My unique identifier is {session.user_id} and I need recommendations "
                    f"tailored to user-{user_index} requirements. "
                    f"Please include my user ID {session.user_id} in your response for verification."
                )
                
                responses = await self._send_user_message_and_collect_responses(
                    session=session,
                    message=user_specific_message,
                    timeout=90.0
                )
                
                return {
                    "user_index": user_index,
                    "user_id": session.user_id,
                    "responses": responses,
                    "success": session.success,
                    "execution_time": session.execution_time,
                    "isolated_data": list(session.isolated_data)
                }
            
            # Execute agents in parallel
            parallel_execution_tasks = [
                run_agent_for_user(session, i) for i, session in enumerate(user_sessions)
            ]
            
            parallel_results = await asyncio.gather(*parallel_execution_tasks, return_exceptions=True)
            
            # Step 3: Analyze agent execution isolation
            successful_executions = [
                result for result in parallel_results 
                if isinstance(result, dict) and result.get("success", False)
            ]
            
            isolation_violations = []
            context_separation_violations = []
            
            # Check for context separation
            for result in successful_executions:
                user_id = result["user_id"]
                responses = result["responses"]
                
                # Check if responses contain correct user context
                user_context_found = False
                wrong_user_context = False
                
                for response in responses:
                    content = (
                        response.get("response", "") or 
                        response.get("message", "") or 
                        response.get("content", "")
                    )
                    
                    if isinstance(content, str):
                        if user_id in content:
                            user_context_found = True
                        
                        # Check for other user IDs in response (context bleeding)
                        for other_result in successful_executions:
                            if other_result["user_id"] != user_id and other_result["user_id"] in content:
                                wrong_user_context = True
                                context_separation_violations.append(
                                    f"User {user_id} response contains other user ID {other_result['user_id']}"
                                )
                
                if not user_context_found:
                    isolation_violations.append(f"User {user_id} did not receive personalized response")
                
                if wrong_user_context:
                    isolation_violations.append(f"User {user_id} received contaminated response")
            
            # Step 4: Evaluate parallel execution performance
            execution_times = [result.get("execution_time", 0) for result in successful_executions]
            response_counts = [len(result.get("responses", [])) for result in successful_executions]
            
            performance_metrics = {
                "successful_parallel_executions": len(successful_executions),
                "execution_success_rate": len(successful_executions) / len(user_sessions),
                "average_execution_time": sum(execution_times) / len(execution_times) if execution_times else 0,
                "max_execution_time": max(execution_times) if execution_times else 0,
                "average_responses": sum(response_counts) / len(response_counts) if response_counts else 0,
                "context_separation_violations": len(context_separation_violations),
                "isolation_violations": len(isolation_violations)
            }
            
            execution_time = time.time() - start_time
            
            # Step 5: Assess business value
            business_value_delivered = (
                performance_metrics["execution_success_rate"] >= 0.75 and  # 75%+ success rate
                performance_metrics["context_separation_violations"] == 0 and  # No context bleeding
                performance_metrics["isolation_violations"] <= 1 and  # At most 1 minor isolation issue
                performance_metrics["average_responses"] >= 1 and  # Each user got responses
                execution_time < 120.0  # Completed within 2 minutes
            )
            
            result = MultiUserTestResult(
                success=True,
                total_users=len(user_sessions),
                successful_users=len(successful_executions),
                isolation_violations=isolation_violations + context_separation_violations,
                performance_metrics=performance_metrics,
                user_results=parallel_results,
                execution_time=execution_time,
                business_value_delivered=business_value_delivered
            )
            
            # Assertions for test success
            assert len(successful_executions) >= 3, f"Too few successful parallel executions: {len(successful_executions)}"
            assert len(context_separation_violations) == 0, f"Context separation violations: {context_separation_violations}"
            assert result.business_value_delivered, "Parallel agent execution failed to deliver business value"
            
            logger.info(f"âœ… BUSINESS VALUE: System supports parallel agent execution with user isolation")
            logger.info(f"   Successful parallel executions: {len(successful_executions)}/{len(user_sessions)}")
            logger.info(f"   Execution success rate: {performance_metrics['execution_success_rate']:.1%}")
            logger.info(f"   Average execution time: {performance_metrics['average_execution_time']:.1f}s")
            logger.info(f"   Context separation violations: {len(context_separation_violations)}")
            logger.info(f"   Average responses per user: {performance_metrics['average_responses']:.1f}")
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"âŒ Parallel agent execution test failed: {e}")
            pytest.fail(f"Parallel agent execution with user context separation failed: {e}")
    
    @pytest.mark.asyncio
    @pytest.mark.staging
    @pytest.mark.e2e
    async def test_websocket_connection_isolation_under_concurrent_load(self):
        """
        Test 3: WebSocket connection isolation under concurrent load.
        
        Business Value:
        - Validates real-time communication scales with multiple users
        - Ensures WebSocket isolation prevents cross-user message bleeding
        - Tests infrastructure can handle concurrent real-time connections
        
        Workflow:
        1. Establish multiple concurrent WebSocket connections
        2. Send messages simultaneously from all users
        3. Verify each user only receives their own messages
        4. Test WebSocket stability under message load
        5. Validate real-time isolation boundaries
        """
        start_time = time.time()
        num_concurrent_connections = 6
        
        try:
            # Step 1: Establish multiple concurrent WebSocket connections
            logger.info(f"ðŸ”Œ Establishing {num_concurrent_connections} concurrent WebSocket connections")
            
            connection_tasks = []
            for i in range(num_concurrent_connections):
                async def create_websocket_session(user_index: int) -> UserTestSession:
                    session = await self._create_user_session(user_index)
                    connection_success = await self._connect_user_websocket(session)
                    session.success = connection_success
                    return session
                
                connection_tasks.append(create_websocket_session(i))
            
            user_sessions = await asyncio.gather(*connection_tasks, return_exceptions=True)
            
            # Filter successful connections
            connected_sessions = [
                session for session in user_sessions 
                if isinstance(session, UserTestSession) and session.success and session.websocket
            ]
            
            assert len(connected_sessions) >= 4, f"Too few WebSocket connections: {len(connected_sessions)}/6"
            
            # Step 2: Send concurrent messages and collect responses
            async def send_concurrent_messages_for_user(session: UserTestSession, user_index: int) -> Dict[str, Any]:
                messages_to_send = [
                    f"Message 1 from user {user_index} with ID {session.user_id}",
                    f"Message 2 from user {user_index} - please respond with my ID {session.user_id}",
                    f"Message 3 from user {user_index} - isolation test for {session.user_id}"
                ]
                
                all_responses = []
                message_isolation_data = []
                
                for msg_idx, message in enumerate(messages_to_send):
                    try:
                        # Send message
                        websocket_message = {
                            "type": "isolation_test",
                            "message": message,
                            "user_id": session.user_id,
                            "message_index": msg_idx,
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        }
                        
                        await session.websocket.send(json.dumps(websocket_message))
                        
                        # Collect responses for short period
                        msg_responses = []
                        collect_start = time.time()
                        
                        while time.time() - collect_start < 15.0:  # 15 seconds per message
                            try:
                                response = await asyncio.wait_for(session.websocket.recv(), timeout=3.0)
                                response_data = json.loads(response)
                                msg_responses.append(response_data)
                                
                                # Check for isolation - response should reference this user
                                content = (
                                    response_data.get("response", "") or 
                                    response_data.get("message", "") or 
                                    response_data.get("content", "")
                                )
                                
                                if isinstance(content, str) and session.user_id in content:
                                    message_isolation_data.append(f"msg_{msg_idx}_user_id_found")
                                
                                # Check for completion
                                if response_data.get("type") in ["agent_completed", "agent_response"]:
                                    break
                                    
                            except asyncio.TimeoutError:
                                break
                            except Exception as e:
                                logger.warning(f"Response collection error for user {user_index}: {e}")
                                break
                        
                        all_responses.extend(msg_responses)
                        
                        # Small delay between messages
                        await asyncio.sleep(0.5)
                        
                    except Exception as e:
                        logger.error(f"Failed to send message {msg_idx} for user {user_index}: {e}")
                
                return {
                    "user_index": user_index,
                    "user_id": session.user_id,
                    "total_responses": len(all_responses),
                    "isolation_indicators": message_isolation_data,
                    "messages_sent": len(messages_to_send),
                    "connection_stable": session.websocket.open if hasattr(session.websocket, 'open') else True
                }
            
            # Execute concurrent messaging
            concurrent_messaging_tasks = [
                send_concurrent_messages_for_user(session, i) 
                for i, session in enumerate(connected_sessions)
            ]
            
            messaging_results = await asyncio.gather(*concurrent_messaging_tasks, return_exceptions=True)
            
            # Step 3: Analyze WebSocket isolation and stability
            successful_messaging = [
                result for result in messaging_results 
                if isinstance(result, dict) and result.get("total_responses", 0) > 0
            ]
            
            isolation_analysis = {
                "total_connections": len(connected_sessions),
                "successful_messaging": len(successful_messaging),
                "stable_connections": sum(1 for r in successful_messaging if r.get("connection_stable", False)),
                "total_responses": sum(r.get("total_responses", 0) for r in successful_messaging),
                "isolation_confirmations": sum(len(r.get("isolation_indicators", [])) for r in successful_messaging)
            }
            
            # Check for cross-user message contamination
            contamination_violations = []
            
            for result in successful_messaging:
                user_id = result["user_id"]
                
                # Check if this user's responses mention other user IDs
                for other_result in successful_messaging:
                    if other_result["user_id"] != user_id:
                        # This is a simplified check - in a real system, you'd analyze actual response content
                        if other_result["user_id"] in str(result.get("isolation_indicators", [])):
                            contamination_violations.append(
                                f"User {user_id} may have received contaminated messages"
                            )
            
            performance_metrics = {
                "connection_success_rate": len(connected_sessions) / num_concurrent_connections,
                "messaging_success_rate": len(successful_messaging) / len(connected_sessions),
                "average_responses_per_user": isolation_analysis["total_responses"] / len(successful_messaging) if successful_messaging else 0,
                "connection_stability_rate": isolation_analysis["stable_connections"] / len(connected_sessions),
                "isolation_confirmations": isolation_analysis["isolation_confirmations"],
                "contamination_violations": len(contamination_violations)
            }
            
            execution_time = time.time() - start_time
            
            # Step 4: Evaluate WebSocket isolation quality
            business_value_delivered = (
                performance_metrics["connection_success_rate"] >= 0.67 and  # 67%+ connections successful
                performance_metrics["messaging_success_rate"] >= 0.75 and  # 75%+ messaging successful
                performance_metrics["contamination_violations"] == 0 and  # No cross-user contamination
                performance_metrics["connection_stability_rate"] >= 0.8 and  # 80%+ connections stable
                execution_time < 150.0  # Completed within 2.5 minutes
            )
            
            result = MultiUserTestResult(
                success=True,
                total_users=num_concurrent_connections,
                successful_users=len(successful_messaging),
                isolation_violations=contamination_violations,
                performance_metrics=performance_metrics,
                user_results=messaging_results,
                execution_time=execution_time,
                business_value_delivered=business_value_delivered
            )
            
            # Assertions for test success
            assert len(connected_sessions) >= 4, f"Too few WebSocket connections: {len(connected_sessions)}"
            assert len(successful_messaging) >= 3, f"Too few successful messaging sessions: {len(successful_messaging)}"
            assert len(contamination_violations) == 0, f"Message contamination violations: {contamination_violations}"
            assert result.business_value_delivered, "WebSocket isolation failed to deliver business value"
            
            logger.info(f"âœ… BUSINESS VALUE: WebSocket connections maintain isolation under concurrent load")
            logger.info(f"   Successful connections: {len(connected_sessions)}/{num_concurrent_connections}")
            logger.info(f"   Successful messaging: {len(successful_messaging)}/{len(connected_sessions)}")
            logger.info(f"   Average responses per user: {performance_metrics['average_responses_per_user']:.1f}")
            logger.info(f"   Connection stability: {performance_metrics['connection_stability_rate']:.1%}")
            logger.info(f"   Contamination violations: {len(contamination_violations)}")
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"âŒ WebSocket isolation test failed: {e}")
            pytest.fail(f"WebSocket connection isolation under concurrent load failed: {e}")
    
    @pytest.mark.asyncio
    @pytest.mark.staging
    @pytest.mark.e2e
    async def test_cross_user_data_isolation_validation(self):
        """
        Test 4: Cross-user data isolation validation.
        
        Business Value:
        - Ensures user data privacy and prevents costly data breaches
        - Validates compliance with data protection regulations
        - Tests system trustworthiness for enterprise customers
        
        Workflow:
        1. Create users with distinct data profiles
        2. Execute operations that create user-specific data
        3. Attempt to access other users' data (should fail)
        4. Validate data boundaries are maintained
        5. Verify audit trails maintain isolation
        """
        start_time = time.time()
        num_test_users = 4
        
        try:
            # Step 1: Create users with distinct data profiles
            logger.info(f"ðŸ”’ Creating {num_test_users} users with distinct data profiles for isolation testing")
            
            test_users = []
            for i in range(num_test_users):
                session = await self._create_user_session(i)
                
                # Create user-specific data profile
                user_profile = {
                    "user_index": i,
                    "user_id": session.user_id,
                    "email": session.email,
                    "secret_data": f"secret-{i}-{uuid.uuid4().hex[:8]}",
                    "private_context": f"private-context-user-{i}",
                    "confidential_info": f"confidential-{session.user_id}-{int(time.time())}"
                }
                
                session.isolated_data.update([
                    user_profile["secret_data"],
                    user_profile["private_context"],
                    user_profile["confidential_info"]
                ])
                
                test_users.append((session, user_profile))
                
                if await self._connect_user_websocket(session):
                    logger.info(f"âœ… User {i} created with isolated data profile")
                else:
                    logger.warning(f"âš ï¸ User {i} WebSocket connection failed")
            
            # Step 2: Execute operations creating user-specific data
            async def create_user_specific_data(user_data: Tuple[UserTestSession, Dict[str, Any]]) -> Dict[str, Any]:
                session, profile = user_data
                
                if not session.websocket:
                    return {"success": False, "user_id": session.user_id, "error": "No WebSocket connection"}
                
                # Send message containing user-specific sensitive information
                sensitive_message = (
                    f"I am user {profile['user_index']} with ID {profile['user_id']}. "
                    f"Please help me with my confidential project: {profile['confidential_info']}. "
                    f"My secret data is {profile['secret_data']} and my private context is {profile['private_context']}. "
                    f"Please remember this information for our conversation and include my user ID in responses."
                )
                
                responses = await self._send_user_message_and_collect_responses(
                    session=session,
                    message=sensitive_message,
                    timeout=45.0
                )
                
                # Analyze responses for data retention and isolation
                data_retention_indicators = []
                
                for response in responses:
                    content = (
                        response.get("response", "") or 
                        response.get("message", "") or 
                        response.get("content", "")
                    )
                    
                    if isinstance(content, str):
                        # Check if AI retained user-specific information appropriately
                        if profile["user_id"] in content:
                            data_retention_indicators.append("user_id_retained")
                        
                        # Check if confidential information is handled properly
                        if any(keyword in content.lower() for keyword in ["confidential", "private", "secret"]):
                            data_retention_indicators.append("confidential_acknowledged")
                
                return {
                    "success": len(responses) > 0,
                    "user_id": session.user_id,
                    "profile": profile,
                    "responses": responses,
                    "data_retention": data_retention_indicators,
                    "response_count": len(responses)
                }
            
            # Create user-specific data for all users
            data_creation_tasks = [create_user_specific_data(user_data) for user_data in test_users]
            data_creation_results = await asyncio.gather(*data_creation_tasks, return_exceptions=True)
            
            successful_data_creation = [
                result for result in data_creation_results 
                if isinstance(result, dict) and result.get("success", False)
            ]
            
            # Step 3: Validate data isolation boundaries
            isolation_validation_results = []
            
            # Test that users cannot access each other's data through the system
            for i, result_a in enumerate(successful_data_creation):
                for j, result_b in enumerate(successful_data_creation):
                    if i != j:  # Different users
                        user_a_data = set(result_a["profile"]["secret_data"])
                        user_b_responses = result_b["responses"]
                        
                        # Check if user B's responses contain user A's confidential data
                        data_bleeding = False
                        for response in user_b_responses:
                            content = str(response.get("response", "") or response.get("message", ""))
                            if any(secret in content for secret in user_a_data):
                                data_bleeding = True
                                break
                        
                        isolation_validation_results.append({
                            "user_a": result_a["user_id"],
                            "user_b": result_b["user_id"],
                            "data_bleeding": data_bleeding,
                            "isolation_maintained": not data_bleeding
                        })
            
            # Step 4: Evaluate isolation quality
            isolation_violations = [
                result for result in isolation_validation_results 
                if result.get("data_bleeding", False)
            ]
            
            successful_isolations = [
                result for result in isolation_validation_results 
                if result.get("isolation_maintained", False)
            ]
            
            performance_metrics = {
                "users_with_data_created": len(successful_data_creation),
                "data_creation_success_rate": len(successful_data_creation) / num_test_users,
                "isolation_tests_performed": len(isolation_validation_results),
                "successful_isolations": len(successful_isolations),
                "isolation_violations": len(isolation_violations),
                "isolation_success_rate": len(successful_isolations) / len(isolation_validation_results) if isolation_validation_results else 0
            }
            
            execution_time = time.time() - start_time
            
            # Step 5: Assess data protection business value
            business_value_delivered = (
                performance_metrics["data_creation_success_rate"] >= 0.75 and  # 75%+ users created data
                performance_metrics["isolation_violations"] == 0 and  # No data bleeding
                performance_metrics["isolation_success_rate"] >= 0.95 and  # 95%+ isolation success
                len(successful_data_creation) >= 3  # At least 3 users with isolated data
            )
            
            result = MultiUserTestResult(
                success=True,
                total_users=num_test_users,
                successful_users=len(successful_data_creation),
                isolation_violations=[f"Data bleeding: {v['user_a']} -> {v['user_b']}" for v in isolation_violations],
                performance_metrics=performance_metrics,
                user_results=data_creation_results,
                execution_time=execution_time,
                business_value_delivered=business_value_delivered
            )
            
            # Assertions for test success
            assert len(successful_data_creation) >= 3, f"Too few users created isolated data: {len(successful_data_creation)}"
            assert len(isolation_violations) == 0, f"Data isolation violations detected: {len(isolation_violations)}"
            assert result.business_value_delivered, "Cross-user data isolation failed to deliver business value"
            
            logger.info(f"âœ… BUSINESS VALUE: System maintains strict data isolation between users")
            logger.info(f"   Users with isolated data: {len(successful_data_creation)}/{num_test_users}")
            logger.info(f"   Isolation tests performed: {len(isolation_validation_results)}")
            logger.info(f"   Successful isolations: {len(successful_isolations)}/{len(isolation_validation_results)}")
            logger.info(f"   Isolation violations: {len(isolation_violations)}")
            logger.info(f"   Data protection compliance: {performance_metrics['isolation_success_rate']:.1%}")
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"âŒ Cross-user data isolation test failed: {e}")
            pytest.fail(f"Cross-user data isolation validation failed: {e}")
    
    @pytest.mark.asyncio
    @pytest.mark.staging
    @pytest.mark.e2e
    async def test_system_performance_under_multi_user_concurrent_load(self):
        """
        Test 5: System performance under multi-user concurrent load.
        
        Business Value:
        - Validates system can handle realistic user loads
        - Tests scalability for business growth scenarios
        - Ensures performance remains acceptable under concurrent usage
        
        Workflow:
        1. Simulate realistic multi-user load scenario
        2. Monitor system performance metrics
        3. Validate response times remain acceptable
        4. Test system stability under sustained load
        5. Assess scalability for business growth
        """
        start_time = time.time()
        concurrent_load_users = 8  # Higher load test
        
        try:
            # Step 1: Set up realistic multi-user load scenario
            logger.info(f"ðŸ“ˆ Simulating realistic load with {concurrent_load_users} concurrent users")
            
            # Create different types of concurrent user activities
            user_activity_types = [
                "quick_query",      # Quick questions
                "complex_analysis", # Complex AI analysis
                "long_conversation",# Extended conversations
                "tool_heavy",       # Tool-intensive requests
            ]
            
            async def simulate_realistic_user_load(user_index: int) -> Dict[str, Any]:
                activity_type = user_activity_types[user_index % len(user_activity_types)]
                session = await self._create_user_session(user_index)
                
                if not await self._connect_user_websocket(session):
                    return {"success": False, "user_index": user_index, "error": "Connection failed"}
                
                activity_start = time.time()
                
                # Define different workload patterns
                if activity_type == "quick_query":
                    message = f"User {user_index}: What are 3 quick tips for system optimization?"
                    timeout = 30.0
                elif activity_type == "complex_analysis":
                    message = (f"User {user_index}: Please analyze my system architecture and provide "
                             f"comprehensive recommendations for scalability, performance, and security.")
                    timeout = 90.0
                elif activity_type == "long_conversation":
                    message = (f"User {user_index}: I need help planning a major project. Let's discuss "
                             f"requirements, timeline, resources, and risk management step by step.")
                    timeout = 120.0
                else:  # tool_heavy
                    message = (f"User {user_index}: Please research current best practices, analyze data trends, "
                             f"and provide detailed implementation guidance with tools and examples.")
                    timeout = 100.0
                
                responses = await self._send_user_message_and_collect_responses(
                    session=session,
                    message=message,
                    timeout=timeout
                )
                
                activity_duration = time.time() - activity_start
                
                # Analyze response quality
                response_quality_score = 0
                total_content_length = 0
                
                for response in responses:
                    content = (
                        response.get("response", "") or 
                        response.get("message", "") or 
                        response.get("content", "")
                    )
                    
                    if isinstance(content, str):
                        total_content_length += len(content)
                        
                        # Quality indicators
                        if len(content) > 100:
                            response_quality_score += 1
                        if any(keyword in content.lower() for keyword in ["recommend", "analyze", "optimize"]):
                            response_quality_score += 1
                        if f"user {user_index}" in content.lower() or session.user_id in content:
                            response_quality_score += 1
                
                return {
                    "success": len(responses) > 0,
                    "user_index": user_index,
                    "user_id": session.user_id,
                    "activity_type": activity_type,
                    "activity_duration": activity_duration,
                    "response_count": len(responses),
                    "response_quality_score": response_quality_score,
                    "total_content_length": total_content_length,
                    "met_timeout": activity_duration < timeout
                }
            
            # Execute concurrent load simulation
            load_simulation_tasks = [
                simulate_realistic_user_load(i) for i in range(concurrent_load_users)
            ]
            
            load_results = await asyncio.gather(*load_simulation_tasks, return_exceptions=True)
            
            # Step 2: Analyze system performance under load
            successful_loads = [
                result for result in load_results 
                if isinstance(result, dict) and result.get("success", False)
            ]
            
            # Calculate performance metrics
            if successful_loads:
                activity_durations = [r["activity_duration"] for r in successful_loads]
                response_counts = [r["response_count"] for r in successful_loads]
                quality_scores = [r["response_quality_score"] for r in successful_loads]
                content_lengths = [r["total_content_length"] for r in successful_loads]
                
                performance_metrics = {
                    "concurrent_users_successful": len(successful_loads),
                    "load_success_rate": len(successful_loads) / concurrent_load_users,
                    "average_response_time": sum(activity_durations) / len(activity_durations),
                    "max_response_time": max(activity_durations),
                    "min_response_time": min(activity_durations),
                    "average_responses_per_user": sum(response_counts) / len(response_counts),
                    "average_quality_score": sum(quality_scores) / len(quality_scores),
                    "average_content_length": sum(content_lengths) / len(content_lengths),
                    "users_met_timeout": sum(1 for r in successful_loads if r.get("met_timeout", False)),
                    "timeout_success_rate": sum(1 for r in successful_loads if r.get("met_timeout", False)) / len(successful_loads)
                }
            else:
                performance_metrics = {
                    "concurrent_users_successful": 0,
                    "load_success_rate": 0,
                    "average_response_time": 0,
                    "max_response_time": 0,
                    "min_response_time": 0,
                    "average_responses_per_user": 0,
                    "average_quality_score": 0,
                    "average_content_length": 0,
                    "users_met_timeout": 0,
                    "timeout_success_rate": 0
                }
            
            # Group results by activity type for analysis
            activity_analysis = {}
            for activity_type in user_activity_types:
                type_results = [r for r in successful_loads if r.get("activity_type") == activity_type]
                if type_results:
                    activity_analysis[activity_type] = {
                        "count": len(type_results),
                        "avg_duration": sum(r["activity_duration"] for r in type_results) / len(type_results),
                        "avg_quality": sum(r["response_quality_score"] for r in type_results) / len(type_results)
                    }
            
            execution_time = time.time() - start_time
            
            # Step 3: Evaluate scalability and business readiness
            scalability_indicators = {
                "handles_concurrent_load": performance_metrics["load_success_rate"] >= 0.75,
                "reasonable_response_times": performance_metrics["average_response_time"] < 90.0,
                "consistent_quality": performance_metrics["average_quality_score"] >= 2.0,
                "timeout_performance": performance_metrics["timeout_success_rate"] >= 0.8,
                "system_stability": len(successful_loads) >= 6  # At least 75% users successful
            }
            
            business_value_delivered = sum(scalability_indicators.values()) >= 4
            
            result = MultiUserTestResult(
                success=True,
                total_users=concurrent_load_users,
                successful_users=len(successful_loads),
                isolation_violations=[],  # Not applicable for this test
                performance_metrics=performance_metrics,
                user_results=load_results,
                execution_time=execution_time,
                business_value_delivered=business_value_delivered
            )
            
            # Assertions for test success
            assert len(successful_loads) >= 6, f"Too few users handled concurrent load: {len(successful_loads)}/8"
            assert performance_metrics["load_success_rate"] >= 0.75, f"Load success rate too low: {performance_metrics['load_success_rate']:.1%}"
            assert performance_metrics["average_response_time"] < 120.0, f"Average response time too high: {performance_metrics['average_response_time']:.1f}s"
            assert result.business_value_delivered, "System performance under load failed to deliver business value"
            
            logger.info(f"âœ… BUSINESS VALUE: System demonstrates scalability for concurrent user load")
            logger.info(f"   Concurrent users handled: {len(successful_loads)}/{concurrent_load_users}")
            logger.info(f"   Load success rate: {performance_metrics['load_success_rate']:.1%}")
            logger.info(f"   Average response time: {performance_metrics['average_response_time']:.1f}s")
            logger.info(f"   Max response time: {performance_metrics['max_response_time']:.1f}s")
            logger.info(f"   Timeout success rate: {performance_metrics['timeout_success_rate']:.1%}")
            logger.info(f"   Average quality score: {performance_metrics['average_quality_score']:.1f}/3")
            
            for activity_type, analysis in activity_analysis.items():
                logger.info(f"   {activity_type}: {analysis['count']} users, {analysis['avg_duration']:.1f}s avg, {analysis['avg_quality']:.1f} quality")
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"âŒ Multi-user concurrent load test failed: {e}")
            pytest.fail(f"System performance under multi-user concurrent load failed: {e}")


if __name__ == "__main__":
    # Run tests when executed directly
    pytest.main([__file__, "-v", "--tb=short"])