"""
E2E Staging Tests: Multi-User Concurrent Isolation
=================================================

This module tests multi-user concurrent execution with proper isolation in staging environment.
Tests REAL multi-user scenarios, concurrent agent execution, and user isolation boundaries.

Business Value:
- Validates system can handle multiple users simultaneously (critical for scale)
- Ensures user data isolation prevents $500K+ liability from data leaks
- Tests concurrent execution supports 10+ simultaneous users
- Validates business model can serve multiple customers concurrently

CRITICAL E2E REQUIREMENTS:
- MUST use real authentication for each user (JWT/OAuth)
- MUST test actual concurrent execution scenarios
- MUST validate complete user isolation (no data bleeding)
- MUST test real staging environment under load
- NO MOCKS ALLOWED - uses real services, agents, and user sessions

Test Coverage:
1. Concurrent user authentication and session isolation
2. Parallel agent execution with user context separation
3. WebSocket connection isolation under concurrent load
4. Cross-user data isolation validation
5. System performance under multi-user concurrent load
"""
import asyncio
import json
import logging
import time
import uuid
from datetime import datetime, timezone
from typing import Dict, Any, Optional, List, Tuple, Set
import aiohttp
import pytest
import websockets
from dataclasses import dataclass
from test_framework.ssot.e2e_auth_helper import E2EAuthHelper, E2EWebSocketAuthHelper, E2EAuthConfig, create_authenticated_user_context
from tests.e2e.staging_config import get_staging_config, StagingTestConfig
from shared.types.execution_types import StronglyTypedUserExecutionContext
from shared.types.core_types import UserID, ThreadID, RunID, RequestID
logger = logging.getLogger(__name__)
STAGING_CONFIG = get_staging_config()

@dataclass
class MultiUserTestResult:
    """Result of a multi-user isolation test."""
    success: bool
    total_users: int
    successful_users: int
    isolation_violations: List[str]
    performance_metrics: Dict[str, float]
    user_results: List[Dict[str, Any]]
    execution_time: float
    business_value_delivered: bool
    error_message: Optional[str] = None

@dataclass
class UserTestSession:
    """Individual user test session data."""
    user_id: str
    email: str
    jwt_token: str
    user_context: StronglyTypedUserExecutionContext
    websocket: Optional[Any] = None
    responses: List[Dict[str, Any]] = None
    execution_time: float = 0.0
    success: bool = False
    isolated_data: Set[str] = None

    def __post_init__(self):
        if self.responses is None:
            self.responses = []
        if self.isolated_data is None:
            self.isolated_data = set()

class TestMultiUserConcurrentIsolation:
    """
    Complete E2E multi-user concurrent isolation tests for staging environment.
    
    CRITICAL: All tests use REAL authentication and concurrent user sessions.
    """

    @pytest.fixture(autouse=True)
    async def setup_staging_environment(self):
        """Set up staging environment for all tests."""
        assert STAGING_CONFIG.validate_configuration(), 'Staging configuration invalid'
        STAGING_CONFIG.log_configuration()
        self.auth_config = E2EAuthConfig.for_staging()
        self.auth_helper = E2EAuthHelper(config=self.auth_config, environment='staging')
        self.ws_helper = E2EWebSocketAuthHelper(config=self.auth_config, environment='staging')
        await self._verify_staging_services_health()
        self.user_sessions: List[UserTestSession] = []
        yield
        await self._cleanup_user_sessions()

    async def _verify_staging_services_health(self):
        """Verify all staging services are healthy before testing."""
        health_endpoints = STAGING_CONFIG.urls.health_endpoints
        async with aiohttp.ClientSession() as session:
            for service, endpoint in health_endpoints.items():
                try:
                    async with session.get(endpoint, timeout=15) as resp:
                        assert resp.status == 200, f'Staging {service} service unhealthy: {resp.status}'
                        logger.info(f' PASS:  Staging {service} service healthy')
                except Exception as e:
                    pytest.fail(f' FAIL:  Staging {service} service unavailable: {e}')

    async def _cleanup_user_sessions(self):
        """Clean up all user sessions created during testing."""
        for session in self.user_sessions:
            if session.websocket:
                try:
                    await session.websocket.close()
                except:
                    pass
        logger.info(f'Cleaned up {len(self.user_sessions)} user sessions')

    async def _create_user_session(self, user_index: int) -> UserTestSession:
        """Create a complete user session with authentication and context."""
        user_email = f'multi-user-{user_index}-{uuid.uuid4().hex[:8]}@staging-test.com'
        user_context = await create_authenticated_user_context(user_email=user_email, environment='staging', permissions=['read', 'write', 'agent_execution'], websocket_enabled=True)
        jwt_token = await self.auth_helper.get_staging_token_async(email=user_email)
        session = UserTestSession(user_id=str(user_context.user_id), email=user_email, jwt_token=jwt_token, user_context=user_context)
        self.user_sessions.append(session)
        return session

    async def _connect_user_websocket(self, session: UserTestSession) -> bool:
        """Connect WebSocket for a user session."""
        try:
            ws_headers = self.ws_helper.get_websocket_headers(session.jwt_token)
            session.websocket = await asyncio.wait_for(websockets.connect(self.auth_config.websocket_url, additional_headers=ws_headers, open_timeout=20.0), timeout=25.0)
            return True
        except Exception as e:
            logger.warning(f'Failed to connect WebSocket for user {session.user_id}: {e}')
            return False

    async def _send_user_message_and_collect_responses(self, session: UserTestSession, message: str, timeout: float=60.0) -> List[Dict[str, Any]]:
        """Send message for a user and collect responses."""
        if not session.websocket:
            return []
        start_time = time.time()
        try:
            user_message = {'type': 'chat_message', 'message': message, 'user_id': session.user_id, 'thread_id': str(session.user_context.thread_id), 'timestamp': datetime.now(timezone.utc).isoformat()}
            await session.websocket.send(json.dumps(user_message))
            responses = []
            while time.time() - start_time < timeout:
                try:
                    response = await asyncio.wait_for(session.websocket.recv(), timeout=5.0)
                    response_data = json.loads(response)
                    responses.append(response_data)
                    if 'user_id' in response_data:
                        session.isolated_data.add(response_data['user_id'])
                    if response_data.get('type') in ['agent_completed', 'agent_response']:
                        break
                except asyncio.TimeoutError:
                    if len(responses) > 0:
                        break
                    continue
                except Exception as e:
                    logger.warning(f'Error receiving response for user {session.user_id}: {e}')
                    break
            session.responses = responses
            session.execution_time = time.time() - start_time
            session.success = len(responses) > 0
            return responses
        except Exception as e:
            logger.error(f'Failed to send message for user {session.user_id}: {e}')
            session.success = False
            return []

    @pytest.mark.asyncio
    @pytest.mark.staging
    @pytest.mark.e2e
    async def test_concurrent_user_authentication_and_session_isolation(self):
        """
        Test 1: Concurrent user authentication and session isolation.
        
        Business Value:
        - Validates system can authenticate multiple users simultaneously
        - Ensures user sessions remain isolated from each other
        - Tests foundation for multi-tenant business model
        
        Workflow:
        1. Create multiple user sessions concurrently
        2. Authenticate all users in parallel
        3. Validate each user gets isolated session
        4. Verify no cross-user authentication data leakage
        5. Test session persistence under concurrent load
        """
        start_time = time.time()
        num_concurrent_users = 5
        try:
            logger.info(f'[U+1F680] Creating {num_concurrent_users} concurrent user sessions')

            async def create_and_authenticate_user(user_index: int) -> UserTestSession:
                try:
                    session = await self._create_user_session(user_index)
                    auth_headers = self.auth_helper.get_auth_headers(session.jwt_token)
                    async with aiohttp.ClientSession() as http_session:
                        validate_url = f'{self.auth_config.auth_service_url}/auth/validate'
                        async with http_session.get(validate_url, headers=auth_headers, timeout=10) as resp:
                            if resp.status == 200:
                                validation_data = await resp.json()
                                session.isolated_data.add(validation_data.get('sub', ''))
                                session.success = True
                                logger.info(f' PASS:  User {user_index} authenticated successfully')
                            else:
                                session.success = False
                                logger.warning(f' WARNING: [U+FE0F] User {user_index} authentication failed: {resp.status}')
                    return session
                except Exception as e:
                    logger.error(f' FAIL:  Failed to create user {user_index}: {e}')
                    return UserTestSession(user_id=f'failed-{user_index}', email=f'failed-{user_index}@test.com', jwt_token='', user_context=None, success=False)
            user_creation_tasks = [create_and_authenticate_user(i) for i in range(num_concurrent_users)]
            user_sessions = await asyncio.gather(*user_creation_tasks, return_exceptions=True)
            successful_sessions = [session for session in user_sessions if isinstance(session, UserTestSession) and session.success]
            isolation_violations = []
            user_data_sets = []
            for session in successful_sessions:
                user_data_sets.append(session.isolated_data)
            for i, data_set_a in enumerate(user_data_sets):
                for j, data_set_b in enumerate(user_data_sets):
                    if i != j and data_set_a.intersection(data_set_b):
                        isolation_violations.append(f'Data overlap between user {i} and {j}')
            concurrent_api_results = []

            async def test_concurrent_api_access(session: UserTestSession) -> bool:
                if not session.success:
                    return False
                try:
                    auth_headers = self.auth_helper.get_auth_headers(session.jwt_token)
                    async with aiohttp.ClientSession() as http_session:
                        api_calls = [http_session.get(f'{self.auth_config.auth_service_url}/auth/validate', headers=auth_headers, timeout=10) for _ in range(3)]
                        responses = await asyncio.gather(*api_calls, return_exceptions=True)
                        successful_calls = sum((1 for r in responses if hasattr(r, 'status') and r.status == 200))
                        return successful_calls >= 2
                except Exception:
                    return False
            api_test_tasks = [test_concurrent_api_access(session) for session in successful_sessions]
            api_results = await asyncio.gather(*api_test_tasks, return_exceptions=True)
            concurrent_api_success = sum((1 for result in api_results if result is True))
            execution_time = time.time() - start_time
            performance_metrics = {'total_users_created': len(user_sessions), 'successful_authentications': len(successful_sessions), 'authentication_success_rate': len(successful_sessions) / num_concurrent_users, 'concurrent_api_success': concurrent_api_success, 'isolation_violations': len(isolation_violations), 'average_auth_time': execution_time / num_concurrent_users}
            business_value_delivered = performance_metrics['authentication_success_rate'] >= 0.8 and performance_metrics['isolation_violations'] == 0 and (performance_metrics['concurrent_api_success'] >= len(successful_sessions) * 0.8) and (execution_time < 60.0)
            result = MultiUserTestResult(success=True, total_users=num_concurrent_users, successful_users=len(successful_sessions), isolation_violations=isolation_violations, performance_metrics=performance_metrics, user_results=[{'user_id': s.user_id, 'success': s.success} for s in user_sessions], execution_time=execution_time, business_value_delivered=business_value_delivered)
            assert len(successful_sessions) >= 4, f'Too few successful sessions: {len(successful_sessions)}/5'
            assert len(isolation_violations) == 0, f'Session isolation violations: {isolation_violations}'
            assert result.business_value_delivered, 'Concurrent authentication failed to deliver business value'
            logger.info(f' PASS:  BUSINESS VALUE: System supports concurrent user authentication and isolation')
            logger.info(f'   Successful authentications: {len(successful_sessions)}/{num_concurrent_users}')
            logger.info(f"   Authentication success rate: {performance_metrics['authentication_success_rate']:.1%}")
            logger.info(f'   Isolation violations: {len(isolation_violations)}')
            logger.info(f'   Concurrent API success: {concurrent_api_success}/{len(successful_sessions)}')
            logger.info(f'   Total execution time: {execution_time:.1f}s')
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f' FAIL:  Concurrent user authentication test failed: {e}')
            pytest.fail(f'Concurrent user authentication and session isolation failed: {e}')

    @pytest.mark.asyncio
    @pytest.mark.staging
    @pytest.mark.e2e
    async def test_parallel_agent_execution_with_user_context_separation(self):
        """
        Test 2: Parallel agent execution with user context separation.
        
        Business Value:
        - Validates multiple users can run agents simultaneously
        - Ensures agent execution contexts remain isolated
        - Tests core AI service delivery under concurrent load
        
        Workflow:
        1. Set up multiple authenticated users
        2. Start agent execution for all users in parallel
        3. Monitor agent execution isolation
        4. Validate each user gets their own agent responses
        5. Verify no cross-contamination of agent contexts
        """
        start_time = time.time()
        num_concurrent_users = 4
        try:
            logger.info(f'[U+1F916] Setting up {num_concurrent_users} users for parallel agent execution')
            user_sessions = []
            for i in range(num_concurrent_users):
                session = await self._create_user_session(i)
                if await self._connect_user_websocket(session):
                    user_sessions.append(session)
                    logger.info(f' PASS:  User {i} WebSocket connected')
                else:
                    logger.warning(f' WARNING: [U+FE0F] User {i} WebSocket connection failed')
            assert len(user_sessions) >= 3, f'Too few WebSocket connections: {len(user_sessions)}/4'

            async def run_agent_for_user(session: UserTestSession, user_index: int) -> Dict[str, Any]:
                user_specific_message = f"Hello, I'm user {user_index} with ID {session.user_id}. Please help me analyze optimization strategies specifically for my context. My unique identifier is {session.user_id} and I need recommendations tailored to user-{user_index} requirements. Please include my user ID {session.user_id} in your response for verification."
                responses = await self._send_user_message_and_collect_responses(session=session, message=user_specific_message, timeout=90.0)
                return {'user_index': user_index, 'user_id': session.user_id, 'responses': responses, 'success': session.success, 'execution_time': session.execution_time, 'isolated_data': list(session.isolated_data)}
            parallel_execution_tasks = [run_agent_for_user(session, i) for i, session in enumerate(user_sessions)]
            parallel_results = await asyncio.gather(*parallel_execution_tasks, return_exceptions=True)
            successful_executions = [result for result in parallel_results if isinstance(result, dict) and result.get('success', False)]
            isolation_violations = []
            context_separation_violations = []
            for result in successful_executions:
                user_id = result['user_id']
                responses = result['responses']
                user_context_found = False
                wrong_user_context = False
                for response in responses:
                    content = response.get('response', '') or response.get('message', '') or response.get('content', '')
                    if isinstance(content, str):
                        if user_id in content:
                            user_context_found = True
                        for other_result in successful_executions:
                            if other_result['user_id'] != user_id and other_result['user_id'] in content:
                                wrong_user_context = True
                                context_separation_violations.append(f"User {user_id} response contains other user ID {other_result['user_id']}")
                if not user_context_found:
                    isolation_violations.append(f'User {user_id} did not receive personalized response')
                if wrong_user_context:
                    isolation_violations.append(f'User {user_id} received contaminated response')
            execution_times = [result.get('execution_time', 0) for result in successful_executions]
            response_counts = [len(result.get('responses', [])) for result in successful_executions]
            performance_metrics = {'successful_parallel_executions': len(successful_executions), 'execution_success_rate': len(successful_executions) / len(user_sessions), 'average_execution_time': sum(execution_times) / len(execution_times) if execution_times else 0, 'max_execution_time': max(execution_times) if execution_times else 0, 'average_responses': sum(response_counts) / len(response_counts) if response_counts else 0, 'context_separation_violations': len(context_separation_violations), 'isolation_violations': len(isolation_violations)}
            execution_time = time.time() - start_time
            business_value_delivered = performance_metrics['execution_success_rate'] >= 0.75 and performance_metrics['context_separation_violations'] == 0 and (performance_metrics['isolation_violations'] <= 1) and (performance_metrics['average_responses'] >= 1) and (execution_time < 120.0)
            result = MultiUserTestResult(success=True, total_users=len(user_sessions), successful_users=len(successful_executions), isolation_violations=isolation_violations + context_separation_violations, performance_metrics=performance_metrics, user_results=parallel_results, execution_time=execution_time, business_value_delivered=business_value_delivered)
            assert len(successful_executions) >= 3, f'Too few successful parallel executions: {len(successful_executions)}'
            assert len(context_separation_violations) == 0, f'Context separation violations: {context_separation_violations}'
            assert result.business_value_delivered, 'Parallel agent execution failed to deliver business value'
            logger.info(f' PASS:  BUSINESS VALUE: System supports parallel agent execution with user isolation')
            logger.info(f'   Successful parallel executions: {len(successful_executions)}/{len(user_sessions)}')
            logger.info(f"   Execution success rate: {performance_metrics['execution_success_rate']:.1%}")
            logger.info(f"   Average execution time: {performance_metrics['average_execution_time']:.1f}s")
            logger.info(f'   Context separation violations: {len(context_separation_violations)}')
            logger.info(f"   Average responses per user: {performance_metrics['average_responses']:.1f}")
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f' FAIL:  Parallel agent execution test failed: {e}')
            pytest.fail(f'Parallel agent execution with user context separation failed: {e}')

    @pytest.mark.asyncio
    @pytest.mark.staging
    @pytest.mark.e2e
    async def test_websocket_connection_isolation_under_concurrent_load(self):
        """
        Test 3: WebSocket connection isolation under concurrent load.
        
        Business Value:
        - Validates real-time communication scales with multiple users
        - Ensures WebSocket isolation prevents cross-user message bleeding
        - Tests infrastructure can handle concurrent real-time connections
        
        Workflow:
        1. Establish multiple concurrent WebSocket connections
        2. Send messages simultaneously from all users
        3. Verify each user only receives their own messages
        4. Test WebSocket stability under message load
        5. Validate real-time isolation boundaries
        """
        start_time = time.time()
        num_concurrent_connections = 6
        try:
            logger.info(f'[U+1F50C] Establishing {num_concurrent_connections} concurrent WebSocket connections')
            connection_tasks = []
            for i in range(num_concurrent_connections):

                async def create_websocket_session(user_index: int) -> UserTestSession:
                    session = await self._create_user_session(user_index)
                    connection_success = await self._connect_user_websocket(session)
                    session.success = connection_success
                    return session
                connection_tasks.append(create_websocket_session(i))
            user_sessions = await asyncio.gather(*connection_tasks, return_exceptions=True)
            connected_sessions = [session for session in user_sessions if isinstance(session, UserTestSession) and session.success and session.websocket]
            assert len(connected_sessions) >= 4, f'Too few WebSocket connections: {len(connected_sessions)}/6'

            async def send_concurrent_messages_for_user(session: UserTestSession, user_index: int) -> Dict[str, Any]:
                messages_to_send = [f'Message 1 from user {user_index} with ID {session.user_id}', f'Message 2 from user {user_index} - please respond with my ID {session.user_id}', f'Message 3 from user {user_index} - isolation test for {session.user_id}']
                all_responses = []
                message_isolation_data = []
                for msg_idx, message in enumerate(messages_to_send):
                    try:
                        websocket_message = {'type': 'isolation_test', 'message': message, 'user_id': session.user_id, 'message_index': msg_idx, 'timestamp': datetime.now(timezone.utc).isoformat()}
                        await session.websocket.send(json.dumps(websocket_message))
                        msg_responses = []
                        collect_start = time.time()
                        while time.time() - collect_start < 15.0:
                            try:
                                response = await asyncio.wait_for(session.websocket.recv(), timeout=3.0)
                                response_data = json.loads(response)
                                msg_responses.append(response_data)
                                content = response_data.get('response', '') or response_data.get('message', '') or response_data.get('content', '')
                                if isinstance(content, str) and session.user_id in content:
                                    message_isolation_data.append(f'msg_{msg_idx}_user_id_found')
                                if response_data.get('type') in ['agent_completed', 'agent_response']:
                                    break
                            except asyncio.TimeoutError:
                                break
                            except Exception as e:
                                logger.warning(f'Response collection error for user {user_index}: {e}')
                                break
                        all_responses.extend(msg_responses)
                        await asyncio.sleep(0.5)
                    except Exception as e:
                        logger.error(f'Failed to send message {msg_idx} for user {user_index}: {e}')
                return {'user_index': user_index, 'user_id': session.user_id, 'total_responses': len(all_responses), 'isolation_indicators': message_isolation_data, 'messages_sent': len(messages_to_send), 'connection_stable': session.websocket.open if hasattr(session.websocket, 'open') else True}
            concurrent_messaging_tasks = [send_concurrent_messages_for_user(session, i) for i, session in enumerate(connected_sessions)]
            messaging_results = await asyncio.gather(*concurrent_messaging_tasks, return_exceptions=True)
            successful_messaging = [result for result in messaging_results if isinstance(result, dict) and result.get('total_responses', 0) > 0]
            isolation_analysis = {'total_connections': len(connected_sessions), 'successful_messaging': len(successful_messaging), 'stable_connections': sum((1 for r in successful_messaging if r.get('connection_stable', False))), 'total_responses': sum((r.get('total_responses', 0) for r in successful_messaging)), 'isolation_confirmations': sum((len(r.get('isolation_indicators', [])) for r in successful_messaging))}
            contamination_violations = []
            for result in successful_messaging:
                user_id = result['user_id']
                for other_result in successful_messaging:
                    if other_result['user_id'] != user_id:
                        if other_result['user_id'] in str(result.get('isolation_indicators', [])):
                            contamination_violations.append(f'User {user_id} may have received contaminated messages')
            performance_metrics = {'connection_success_rate': len(connected_sessions) / num_concurrent_connections, 'messaging_success_rate': len(successful_messaging) / len(connected_sessions), 'average_responses_per_user': isolation_analysis['total_responses'] / len(successful_messaging) if successful_messaging else 0, 'connection_stability_rate': isolation_analysis['stable_connections'] / len(connected_sessions), 'isolation_confirmations': isolation_analysis['isolation_confirmations'], 'contamination_violations': len(contamination_violations)}
            execution_time = time.time() - start_time
            business_value_delivered = performance_metrics['connection_success_rate'] >= 0.67 and performance_metrics['messaging_success_rate'] >= 0.75 and (performance_metrics['contamination_violations'] == 0) and (performance_metrics['connection_stability_rate'] >= 0.8) and (execution_time < 150.0)
            result = MultiUserTestResult(success=True, total_users=num_concurrent_connections, successful_users=len(successful_messaging), isolation_violations=contamination_violations, performance_metrics=performance_metrics, user_results=messaging_results, execution_time=execution_time, business_value_delivered=business_value_delivered)
            assert len(connected_sessions) >= 4, f'Too few WebSocket connections: {len(connected_sessions)}'
            assert len(successful_messaging) >= 3, f'Too few successful messaging sessions: {len(successful_messaging)}'
            assert len(contamination_violations) == 0, f'Message contamination violations: {contamination_violations}'
            assert result.business_value_delivered, 'WebSocket isolation failed to deliver business value'
            logger.info(f' PASS:  BUSINESS VALUE: WebSocket connections maintain isolation under concurrent load')
            logger.info(f'   Successful connections: {len(connected_sessions)}/{num_concurrent_connections}')
            logger.info(f'   Successful messaging: {len(successful_messaging)}/{len(connected_sessions)}')
            logger.info(f"   Average responses per user: {performance_metrics['average_responses_per_user']:.1f}")
            logger.info(f"   Connection stability: {performance_metrics['connection_stability_rate']:.1%}")
            logger.info(f'   Contamination violations: {len(contamination_violations)}')
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f' FAIL:  WebSocket isolation test failed: {e}')
            pytest.fail(f'WebSocket connection isolation under concurrent load failed: {e}')

    @pytest.mark.asyncio
    @pytest.mark.staging
    @pytest.mark.e2e
    async def test_cross_user_data_isolation_validation(self):
        """
        Test 4: Cross-user data isolation validation.
        
        Business Value:
        - Ensures user data privacy and prevents costly data breaches
        - Validates compliance with data protection regulations
        - Tests system trustworthiness for enterprise customers
        
        Workflow:
        1. Create users with distinct data profiles
        2. Execute operations that create user-specific data
        3. Attempt to access other users' data (should fail)
        4. Validate data boundaries are maintained
        5. Verify audit trails maintain isolation
        """
        start_time = time.time()
        num_test_users = 4
        try:
            logger.info(f'[U+1F512] Creating {num_test_users} users with distinct data profiles for isolation testing')
            test_users = []
            for i in range(num_test_users):
                session = await self._create_user_session(i)
                user_profile = {'user_index': i, 'user_id': session.user_id, 'email': session.email, 'secret_data': f'secret-{i}-{uuid.uuid4().hex[:8]}', 'private_context': f'private-context-user-{i}', 'confidential_info': f'confidential-{session.user_id}-{int(time.time())}'}
                session.isolated_data.update([user_profile['secret_data'], user_profile['private_context'], user_profile['confidential_info']])
                test_users.append((session, user_profile))
                if await self._connect_user_websocket(session):
                    logger.info(f' PASS:  User {i} created with isolated data profile')
                else:
                    logger.warning(f' WARNING: [U+FE0F] User {i} WebSocket connection failed')

            async def create_user_specific_data(user_data: Tuple[UserTestSession, Dict[str, Any]]) -> Dict[str, Any]:
                session, profile = user_data
                if not session.websocket:
                    return {'success': False, 'user_id': session.user_id, 'error': 'No WebSocket connection'}
                sensitive_message = f"I am user {profile['user_index']} with ID {profile['user_id']}. Please help me with my confidential project: {profile['confidential_info']}. My secret data is {profile['secret_data']} and my private context is {profile['private_context']}. Please remember this information for our conversation and include my user ID in responses."
                responses = await self._send_user_message_and_collect_responses(session=session, message=sensitive_message, timeout=45.0)
                data_retention_indicators = []
                for response in responses:
                    content = response.get('response', '') or response.get('message', '') or response.get('content', '')
                    if isinstance(content, str):
                        if profile['user_id'] in content:
                            data_retention_indicators.append('user_id_retained')
                        if any((keyword in content.lower() for keyword in ['confidential', 'private', 'secret'])):
                            data_retention_indicators.append('confidential_acknowledged')
                return {'success': len(responses) > 0, 'user_id': session.user_id, 'profile': profile, 'responses': responses, 'data_retention': data_retention_indicators, 'response_count': len(responses)}
            data_creation_tasks = [create_user_specific_data(user_data) for user_data in test_users]
            data_creation_results = await asyncio.gather(*data_creation_tasks, return_exceptions=True)
            successful_data_creation = [result for result in data_creation_results if isinstance(result, dict) and result.get('success', False)]
            isolation_validation_results = []
            for i, result_a in enumerate(successful_data_creation):
                for j, result_b in enumerate(successful_data_creation):
                    if i != j:
                        user_a_data = set(result_a['profile']['secret_data'])
                        user_b_responses = result_b['responses']
                        data_bleeding = False
                        for response in user_b_responses:
                            content = str(response.get('response', '') or response.get('message', ''))
                            if any((secret in content for secret in user_a_data)):
                                data_bleeding = True
                                break
                        isolation_validation_results.append({'user_a': result_a['user_id'], 'user_b': result_b['user_id'], 'data_bleeding': data_bleeding, 'isolation_maintained': not data_bleeding})
            isolation_violations = [result for result in isolation_validation_results if result.get('data_bleeding', False)]
            successful_isolations = [result for result in isolation_validation_results if result.get('isolation_maintained', False)]
            performance_metrics = {'users_with_data_created': len(successful_data_creation), 'data_creation_success_rate': len(successful_data_creation) / num_test_users, 'isolation_tests_performed': len(isolation_validation_results), 'successful_isolations': len(successful_isolations), 'isolation_violations': len(isolation_violations), 'isolation_success_rate': len(successful_isolations) / len(isolation_validation_results) if isolation_validation_results else 0}
            execution_time = time.time() - start_time
            business_value_delivered = performance_metrics['data_creation_success_rate'] >= 0.75 and performance_metrics['isolation_violations'] == 0 and (performance_metrics['isolation_success_rate'] >= 0.95) and (len(successful_data_creation) >= 3)
            result = MultiUserTestResult(success=True, total_users=num_test_users, successful_users=len(successful_data_creation), isolation_violations=[f"Data bleeding: {v['user_a']} -> {v['user_b']}" for v in isolation_violations], performance_metrics=performance_metrics, user_results=data_creation_results, execution_time=execution_time, business_value_delivered=business_value_delivered)
            assert len(successful_data_creation) >= 3, f'Too few users created isolated data: {len(successful_data_creation)}'
            assert len(isolation_violations) == 0, f'Data isolation violations detected: {len(isolation_violations)}'
            assert result.business_value_delivered, 'Cross-user data isolation failed to deliver business value'
            logger.info(f' PASS:  BUSINESS VALUE: System maintains strict data isolation between users')
            logger.info(f'   Users with isolated data: {len(successful_data_creation)}/{num_test_users}')
            logger.info(f'   Isolation tests performed: {len(isolation_validation_results)}')
            logger.info(f'   Successful isolations: {len(successful_isolations)}/{len(isolation_validation_results)}')
            logger.info(f'   Isolation violations: {len(isolation_violations)}')
            logger.info(f"   Data protection compliance: {performance_metrics['isolation_success_rate']:.1%}")
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f' FAIL:  Cross-user data isolation test failed: {e}')
            pytest.fail(f'Cross-user data isolation validation failed: {e}')

    @pytest.mark.asyncio
    @pytest.mark.staging
    @pytest.mark.e2e
    async def test_system_performance_under_multi_user_concurrent_load(self):
        """
        Test 5: System performance under multi-user concurrent load.
        
        Business Value:
        - Validates system can handle realistic user loads
        - Tests scalability for business growth scenarios
        - Ensures performance remains acceptable under concurrent usage
        
        Workflow:
        1. Simulate realistic multi-user load scenario
        2. Monitor system performance metrics
        3. Validate response times remain acceptable
        4. Test system stability under sustained load
        5. Assess scalability for business growth
        """
        start_time = time.time()
        concurrent_load_users = 8
        try:
            logger.info(f'[U+1F4C8] Simulating realistic load with {concurrent_load_users} concurrent users')
            user_activity_types = ['quick_query', 'complex_analysis', 'long_conversation', 'tool_heavy']

            async def simulate_realistic_user_load(user_index: int) -> Dict[str, Any]:
                activity_type = user_activity_types[user_index % len(user_activity_types)]
                session = await self._create_user_session(user_index)
                if not await self._connect_user_websocket(session):
                    return {'success': False, 'user_index': user_index, 'error': 'Connection failed'}
                activity_start = time.time()
                if activity_type == 'quick_query':
                    message = f'User {user_index}: What are 3 quick tips for system optimization?'
                    timeout = 30.0
                elif activity_type == 'complex_analysis':
                    message = f'User {user_index}: Please analyze my system architecture and provide comprehensive recommendations for scalability, performance, and security.'
                    timeout = 90.0
                elif activity_type == 'long_conversation':
                    message = f"User {user_index}: I need help planning a major project. Let's discuss requirements, timeline, resources, and risk management step by step."
                    timeout = 120.0
                else:
                    message = f'User {user_index}: Please research current best practices, analyze data trends, and provide detailed implementation guidance with tools and examples.'
                    timeout = 100.0
                responses = await self._send_user_message_and_collect_responses(session=session, message=message, timeout=timeout)
                activity_duration = time.time() - activity_start
                response_quality_score = 0
                total_content_length = 0
                for response in responses:
                    content = response.get('response', '') or response.get('message', '') or response.get('content', '')
                    if isinstance(content, str):
                        total_content_length += len(content)
                        if len(content) > 100:
                            response_quality_score += 1
                        if any((keyword in content.lower() for keyword in ['recommend', 'analyze', 'optimize'])):
                            response_quality_score += 1
                        if f'user {user_index}' in content.lower() or session.user_id in content:
                            response_quality_score += 1
                return {'success': len(responses) > 0, 'user_index': user_index, 'user_id': session.user_id, 'activity_type': activity_type, 'activity_duration': activity_duration, 'response_count': len(responses), 'response_quality_score': response_quality_score, 'total_content_length': total_content_length, 'met_timeout': activity_duration < timeout}
            load_simulation_tasks = [simulate_realistic_user_load(i) for i in range(concurrent_load_users)]
            load_results = await asyncio.gather(*load_simulation_tasks, return_exceptions=True)
            successful_loads = [result for result in load_results if isinstance(result, dict) and result.get('success', False)]
            if successful_loads:
                activity_durations = [r['activity_duration'] for r in successful_loads]
                response_counts = [r['response_count'] for r in successful_loads]
                quality_scores = [r['response_quality_score'] for r in successful_loads]
                content_lengths = [r['total_content_length'] for r in successful_loads]
                performance_metrics = {'concurrent_users_successful': len(successful_loads), 'load_success_rate': len(successful_loads) / concurrent_load_users, 'average_response_time': sum(activity_durations) / len(activity_durations), 'max_response_time': max(activity_durations), 'min_response_time': min(activity_durations), 'average_responses_per_user': sum(response_counts) / len(response_counts), 'average_quality_score': sum(quality_scores) / len(quality_scores), 'average_content_length': sum(content_lengths) / len(content_lengths), 'users_met_timeout': sum((1 for r in successful_loads if r.get('met_timeout', False))), 'timeout_success_rate': sum((1 for r in successful_loads if r.get('met_timeout', False))) / len(successful_loads)}
            else:
                performance_metrics = {'concurrent_users_successful': 0, 'load_success_rate': 0, 'average_response_time': 0, 'max_response_time': 0, 'min_response_time': 0, 'average_responses_per_user': 0, 'average_quality_score': 0, 'average_content_length': 0, 'users_met_timeout': 0, 'timeout_success_rate': 0}
            activity_analysis = {}
            for activity_type in user_activity_types:
                type_results = [r for r in successful_loads if r.get('activity_type') == activity_type]
                if type_results:
                    activity_analysis[activity_type] = {'count': len(type_results), 'avg_duration': sum((r['activity_duration'] for r in type_results)) / len(type_results), 'avg_quality': sum((r['response_quality_score'] for r in type_results)) / len(type_results)}
            execution_time = time.time() - start_time
            scalability_indicators = {'handles_concurrent_load': performance_metrics['load_success_rate'] >= 0.75, 'reasonable_response_times': performance_metrics['average_response_time'] < 90.0, 'consistent_quality': performance_metrics['average_quality_score'] >= 2.0, 'timeout_performance': performance_metrics['timeout_success_rate'] >= 0.8, 'system_stability': len(successful_loads) >= 6}
            business_value_delivered = sum(scalability_indicators.values()) >= 4
            result = MultiUserTestResult(success=True, total_users=concurrent_load_users, successful_users=len(successful_loads), isolation_violations=[], performance_metrics=performance_metrics, user_results=load_results, execution_time=execution_time, business_value_delivered=business_value_delivered)
            assert len(successful_loads) >= 6, f'Too few users handled concurrent load: {len(successful_loads)}/8'
            assert performance_metrics['load_success_rate'] >= 0.75, f"Load success rate too low: {performance_metrics['load_success_rate']:.1%}"
            assert performance_metrics['average_response_time'] < 120.0, f"Average response time too high: {performance_metrics['average_response_time']:.1f}s"
            assert result.business_value_delivered, 'System performance under load failed to deliver business value'
            logger.info(f' PASS:  BUSINESS VALUE: System demonstrates scalability for concurrent user load')
            logger.info(f'   Concurrent users handled: {len(successful_loads)}/{concurrent_load_users}')
            logger.info(f"   Load success rate: {performance_metrics['load_success_rate']:.1%}")
            logger.info(f"   Average response time: {performance_metrics['average_response_time']:.1f}s")
            logger.info(f"   Max response time: {performance_metrics['max_response_time']:.1f}s")
            logger.info(f"   Timeout success rate: {performance_metrics['timeout_success_rate']:.1%}")
            logger.info(f"   Average quality score: {performance_metrics['average_quality_score']:.1f}/3")
            for activity_type, analysis in activity_analysis.items():
                logger.info(f"   {activity_type}: {analysis['count']} users, {analysis['avg_duration']:.1f}s avg, {analysis['avg_quality']:.1f} quality")
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f' FAIL:  Multi-user concurrent load test failed: {e}')
            pytest.fail(f'System performance under multi-user concurrent load failed: {e}')
if __name__ == '__main__':
    'MIGRATED: Use SSOT unified test runner'
    print('MIGRATION NOTICE: Please use SSOT unified test runner')
    print('Command: python tests/unified_test_runner.py --category <category>')