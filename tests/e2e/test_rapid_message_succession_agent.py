"""
Test module split from original file
Generated by auto_fix_test_violations.py
"""

import pytest
import asyncio
import time
import uuid
import json
import logging
import random
import threading
import gc
import psutil
import os
import functools
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Tuple, Union
from unittest.mock import AsyncMock, MagicMock, patch
from collections import defaultdict, deque
from dataclasses import dataclass, field
import websockets
import httpx

# Import required classes
from .utils.rapid_message_sender import RapidMessageSender

class AgentStateMonitor:
    """Monitors agent state consistency during rapid messaging."""
    
    def __init__(self):
        self.state_snapshots = []
        self.consistency_violations = []
        
    async def capture_state_snapshot(self, label: str, sender: RapidMessageSender) -> Dict:
        """Capture current agent state."""
        state = await sender.get_agent_state()
        snapshot = {
            "label": label,
            "timestamp": time.time(),
            "state": state.copy() if isinstance(state, dict) else state,
            "memory_usage": {"rss": psutil.Process().memory_info().rss},
            "thread_count": threading.active_count()
        }
        
        self.state_snapshots.append(snapshot)
        return snapshot
    
    def validate_state_consistency(self) -> Dict[str, Any]:
        """Validate agent state remained consistent."""
        if len(self.state_snapshots) < 2:
            return {"error": "Insufficient snapshots for comparison"}
        
        validation_result = {
            "memory_growth": 0,
            "thread_growth": 0,
            "state_corruption_detected": False,
            "consistency_violations": [],
            "memory_leak_detected": False
        }
        
        # Check memory growth
        initial_memory = self.state_snapshots[0]["memory_usage"]["rss"]
        final_memory = self.state_snapshots[-1]["memory_usage"]["rss"]
        memory_growth = final_memory - initial_memory
        validation_result["memory_growth"] = memory_growth
        
        if memory_growth > RAPID_MESSAGE_TEST_CONFIG["max_memory_growth"]:
            validation_result["memory_leak_detected"] = True
            validation_result["consistency_violations"].append(
                f"Memory leak detected: {memory_growth:,} bytes growth"
            )
        
        # Check thread growth
        initial_threads = self.state_snapshots[0]["thread_count"]
        final_threads = self.state_snapshots[-1]["thread_count"]
        thread_growth = final_threads - initial_threads
        validation_result["thread_growth"] = thread_growth
        
        if thread_growth > 5:  # Allow some thread variance
            validation_result["consistency_violations"].append(
                f"Thread leak detected: {thread_growth} threads created"
            )
        
        # Check for state corruption
        for snapshot in self.state_snapshots:
            state = snapshot.get("state", {})
            if isinstance(state, dict) and state.get("corrupted", False):
                validation_result["state_corruption_detected"] = True
                validation_result["consistency_violations"].append(
                    f"State corruption detected at {snapshot['label']}"
                )
        
        return validation_result
    
    def assert_state_consistency(self):
        """Assert agent state consistency."""
        validation_result = self.validate_state_consistency()
        violations = validation_result.get("consistency_violations", [])
        
        assert len(violations) == 0, f"State consistency violations: {violations}"
        return validation_result

class TestAgentStateConsistencyRapidUpdates:
    """Test Case 4: Agent State Consistency Under Rapid Updates"""
    
    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_agent_state_consistency_rapid_updates(
        self, rapid_message_sender, message_sequence_validator, agent_state_monitor
    ):
        """
        Scenario: Rapid messages that should build upon each other's context
        Expected: Agent state updates atomically, context remains coherent
        """
        await agent_state_monitor.capture_state_snapshot("consistency_test_start", rapid_message_sender)
        
        # Create interdependent message sequence
        conversation_sequence = [
            {"content": "Let's analyze sales data", "expected_context": "sales_analysis"},
            {"content": "Focus on Q3 2024", "expected_context": "sales_analysis_q3_2024"},
            {"content": "Compare with Q2", "expected_context": "sales_comparison_q2_q3"},
            {"content": "Show regional breakdown", "expected_context": "regional_sales_breakdown"},
            {"content": "Highlight top performers", "expected_context": "top_performers_regional"},
            {"content": "Export to spreadsheet", "expected_context": "export_sales_analysis"},
            {"content": "Schedule monthly update", "expected_context": "scheduled_sales_reports"},
            {"content": "Set alert thresholds", "expected_context": "sales_monitoring_alerts"},
            {"content": "Create dashboard view", "expected_context": "sales_dashboard_creation"},
            {"content": "Share with team", "expected_context": "team_collaboration_sales"}
        ]
        
        # Send messages with state monitoring
        messages = []
        state_snapshots = []
        
        for i, msg_data in enumerate(conversation_sequence):
            # Capture state before sending
            pre_state = await agent_state_monitor.capture_state_snapshot(f"pre_message_{i}", rapid_message_sender)
            
            message = {
                "type": "user_message",
                "content": msg_data["content"],
                "sequence_id": i,
                "message_id": f"context-msg-{i}",
                "timestamp": time.time(),
                "context_building": True
            }
            
            messages.append(message)
            message_sequence_validator.track_expected_sequence(i, message["message_id"])
        
        # Send all messages in rapid succession
        results = await rapid_message_sender.send_rapid_burst(messages, burst_interval=0.2)
        
        # Capture state after each expected processing
        for i in range(len(conversation_sequence)):
            await asyncio.sleep(1.0)  # Allow processing time
            await agent_state_monitor.capture_state_snapshot(f"post_message_{i}", rapid_message_sender)
        
        # Collect responses
        responses = await rapid_message_sender.receive_responses(
            expected_count=len(conversation_sequence),
            timeout=30.0
        )
        
        # Track received sequences
        for response in responses:
            sequence_id = response.get("sequence_id")
            message_id = response.get("message_id", response.get("correlation_id"))
            if sequence_id is not None and message_id:
                message_sequence_validator.track_received_sequence(sequence_id, message_id, response)
        
        # Validation
        assert len(responses) == len(conversation_sequence), \
            f"Expected {len(conversation_sequence)} responses, got {len(responses)}"
        
        # Verify sequence integrity
        sequence_validation = message_sequence_validator.validate_sequence_integrity()
        assert len(sequence_validation["violations"]) == 0, \
            f"Sequence violations: {sequence_validation['violations']}"
        
        # Verify context progression
        final_state = await rapid_message_sender.get_agent_state()
        if isinstance(final_state, dict):
            conversation_context = final_state.get("conversation_context", {})
            
            # Check if final context contains expected elements
            final_expected_context = conversation_sequence[-1]["expected_context"]
            context_str = str(conversation_context).lower()
            
            assert "sales" in context_str, "Sales context not preserved"
            assert "team" in context_str or "collaboration" in context_str, "Final context not reached"
            
            # Verify message count consistency
            expected_message_count = len(conversation_sequence)
            actual_message_count = final_state.get("message_count", 0)
            assert actual_message_count == expected_message_count, \
                f"Message count mismatch: {actual_message_count} != {expected_message_count}"
        
        await agent_state_monitor.capture_state_snapshot("consistency_test_end", rapid_message_sender)
        
        logger.info(f"Agent consistency test completed: {len(responses)} messages processed with context preservation")

class TestCrossAgentStateSynchronization:
    """Test Case 6: Cross-Agent State Synchronization During Rapid Messages"""
    
    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_cross_agent_state_synchronization(
        self, rapid_message_sender, message_sequence_validator, agent_state_monitor
    ):
        """
        Scenario: Rapid messages requiring coordination between multiple sub-agents
        Expected: All sub-agents maintain consistent shared state, no race conditions
        """
        await agent_state_monitor.capture_state_snapshot("sync_test_start", rapid_message_sender)
        
        # Enable multi-agent mode
        agent_config = {
            "type": "configure_agents",
            "agents": ["data_sub_agent", "analysis_sub_agent", "reporting_sub_agent"],
            "timestamp": time.time()
        }
        
        await rapid_message_sender.connection.send(json.dumps(agent_config))
        await asyncio.sleep(2.0)  # Allow configuration time
        
        # Create messages requiring cross-agent coordination
        coordination_messages = [
            {
                "content": "Load customer database",
                "target_agents": ["data_sub_agent"],
                "shared_state_key": "customer_data"
            },
            {
                "content": "Analyze customer segments",
                "target_agents": ["data_sub_agent", "analysis_sub_agent"],
                "shared_state_key": "customer_segments"
            },
            {
                "content": "Calculate segment metrics",
                "target_agents": ["analysis_sub_agent"],
                "shared_state_key": "segment_metrics"
            },
            {
                "content": "Generate segment report",
                "target_agents": ["analysis_sub_agent", "reporting_sub_agent"],
                "shared_state_key": "segment_report"
            },
            {
                "content": "Export to dashboard",
                "target_agents": ["reporting_sub_agent"],
                "shared_state_key": "dashboard_export"
            }
        ]
        
        # Send coordination messages
        messages = []
        for i, msg_data in enumerate(coordination_messages):
            message = {
                "type": "user_message",
                "content": msg_data["content"],
                "sequence_id": i,
                "message_id": f"coord-msg-{i}",
                "coordination_required": True,
                "target_agents": msg_data["target_agents"],
                "shared_state_key": msg_data["shared_state_key"],
                "timestamp": time.time()
            }
            messages.append(message)
            message_sequence_validator.track_expected_sequence(i, message["message_id"])
        
        # Send in rapid succession
        results = await rapid_message_sender.send_rapid_burst(messages, burst_interval=0.1)
        
        # Monitor agent states during processing
        agent_state_timeline = []
        for i in range(len(coordination_messages) + 2):  # Extra snapshots
            await asyncio.sleep(1.0)
            snapshot = await agent_state_monitor.capture_state_snapshot(f"coord_state_{i}", rapid_message_sender)
            agent_state_timeline.append(snapshot)
        
        # Collect responses
        responses = await rapid_message_sender.receive_responses(
            expected_count=len(coordination_messages),
            timeout=20.0
        )
        
        # Track received sequences
        for response in responses:
            sequence_id = response.get("sequence_id")
            message_id = response.get("message_id", response.get("correlation_id"))
            if sequence_id is not None and message_id:
                message_sequence_validator.track_received_sequence(sequence_id, message_id, response)
        
        # Validation
        assert len(responses) == len(coordination_messages), \
            f"Expected {len(coordination_messages)} responses, got {len(responses)}"
        
        # Verify sequence integrity
        sequence_validation = message_sequence_validator.validate_sequence_integrity()
        assert len(sequence_validation["violations"]) == 0, \
            f"Coordination sequence violations: {sequence_validation['violations']}"
        
        # Verify cross-agent state synchronization
        final_state = await rapid_message_sender.get_agent_state()
        if isinstance(final_state, dict):
            agents_state = final_state.get("agents", {})
            
            # Check that all target agents processed their messages
            for i, msg_data in enumerate(coordination_messages):
                shared_key = msg_data["shared_state_key"]
                target_agents = msg_data["target_agents"]
                
                # Verify agents have consistent shared state
                shared_values = []
                for agent_name in target_agents:
                    if agent_name in agents_state:
                        agent_state = agents_state[agent_name]
                        shared_state = agent_state.get("shared_state", {})
                        if shared_key in shared_state:
                            shared_values.append(shared_state[shared_key])
                
                # All agents should have same shared state value
                if len(shared_values) > 1:
                    assert all(v == shared_values[0] for v in shared_values), \
                        f"Inconsistent shared state for {shared_key}: {shared_values}"
            
            # Verify no agent state corruption
            for agent_name, agent_state in agents_state.items():
                assert not agent_state.get("corrupted", False), \
                    f"Agent {agent_name} state corrupted during coordination"
                
                # Check message processing counts
                processed_count = agent_state.get("messages_processed", 0)
                expected_count = len([
                    msg for msg in coordination_messages 
                    if agent_name in msg["target_agents"]
                ])
                
                if expected_count > 0:  # Only check if agent should have processed messages
                    assert processed_count == expected_count, \
                        f"Agent {agent_name} processed {processed_count}, expected {expected_count}"
        
        await agent_state_monitor.capture_state_snapshot("sync_test_end", rapid_message_sender)
        
        logger.info(f"Cross-agent synchronization test completed: {len(responses)} coordinated messages processed")
