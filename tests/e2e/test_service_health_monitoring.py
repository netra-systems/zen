"""
Service Health Monitoring Cascade Test

Business Value Justification (BVJ):
- Segment: Enterprise
- Business Goal: System uptime and availability monitoring
- Value Impact: $25K MRR from health monitoring features and SLA compliance
- Strategic/Revenue Impact: Prevents cascading failures, reduces downtime costs by 85%

CRITICAL test for service health monitoring cascade:
- All services report health correctly
- Dependency health checks work properly
- Service discovery functions as expected
- Health response time SLA compliance (<1 second)
- Cascade failure scenarios handled correctly

Implementation uses REAL services with comprehensive error handling and SLA validation.
"""

import asyncio
import time
from datetime import UTC, datetime
from typing import Any, Dict, List
from shared.isolated_environment import IsolatedEnvironment

import httpx
import pytest

from netra_backend.app.logging_config import central_logger
from tests.e2e.health_check_core import (
    HEALTH_STATUS,
    SERVICE_ENDPOINTS,
    HealthCheckResult,
    calculate_overall_health_score,
    create_healthy_result,
    create_service_error_result,
    get_critical_services)
from tests.e2e.health_service_checker import ServiceHealthChecker

logger = central_logger.get_logger(__name__)

# Health response time SLA threshold (milliseconds)
HEALTH_SLA_THRESHOLD_MS = 1000

# Service discovery configuration
SERVICE_DISCOVERY_CONFIG = {
    "auth_service": {
        "default_port": 8081,
        "health_endpoint": "/health",
        "expected_response_fields": ["status", "service", "version", "timestamp"]
    },
    "backend_service": {
        "default_port": 8000,
        "health_endpoint": "/health/ready",
        "expected_response_fields": ["status", "service", "details"]
    },
    "frontend_service": {
        "default_port": 3000,
        "health_endpoint": "/",
        "check_type": "build_verification"
    }
}

# Dependency chain mapping for cascade testing
DEPENDENCY_CHAINS = {
    "frontend": ["backend"],
    "backend": ["auth", "postgres", "clickhouse"],
    "auth": ["postgres"]
}


class ServiceHealthMonitor:
    """Comprehensive service health monitoring with cascade detection."""
    
    def __init__(self):
    pass
        self.health_checker = ServiceHealthChecker()
        self.discovery_cache = {}
        self.last_discovery_time = None
    
    async def discover_service_ports(self) -> Dict[str, Dict[str, Any]]:
        """Discover active service ports and endpoints."""
        discovery_results = {}
        
        for service_name, config in SERVICE_DISCOVERY_CONFIG.items():
            discovery_result = await self._discover_single_service(service_name, config)
            discovery_results[service_name] = discovery_result
        
        # Cache results for 30 seconds
        self.discovery_cache = discovery_results
        self.last_discovery_time = datetime.now(UTC)
        
        return discovery_results
    
    async def _discover_single_service(self, service_name: str, config: Dict) -> Dict[str, Any]:
        """Discover individual service availability and configuration."""
        port = config["default_port"]
        health_endpoint = config["health_endpoint"]
        url = f"http://localhost:{port}{health_endpoint}"
        
        discovery_info = {
            "service_name": service_name,
            "port": port,
            "endpoint": url,
            "discovered": False,
            "response_time_ms": None,
            "error": None
        }
        
        try:
            start_time = time.time()
            async with httpx.AsyncClient(timeout=5.0, follow_redirects=True) as client:
                response = await client.get(url)
                response_time_ms = (time.time() - start_time) * 1000
                
                if response.status_code == 200:
                    discovery_info.update({
                        "discovered": True,
                        "response_time_ms": response_time_ms,
                        "status_code": response.status_code
                    })
                    
                    # Validate response structure for JSON endpoints
                    if config.get("check_type") != "build_verification":
                        try:
                            response_data = response.json()
                            expected_fields = config.get("expected_response_fields", [])
                            
                            discovery_info["response_validation"] = self._validate_response_structure(
                                response_data, expected_fields
                            )
                        except Exception as e:
                            discovery_info["response_validation"] = {
                                "valid": False,
                                "error": f"JSON parsing failed: {str(e)}"
                            }
                else:
                    discovery_info.update({
                        "error": f"HTTP {response.status_code}",
                        "response_time_ms": response_time_ms
                    })
                    
        except Exception as e:
            discovery_info["error"] = str(e)
        
        return discovery_info
    
    def _validate_response_structure(self, response_data: Dict, expected_fields: List[str]) -> Dict[str, Any]:
        """Validate health response structure against expected fields."""
        validation_result = {
            "valid": True,
            "missing_fields": [],
            "extra_fields": [],
            "field_types": {}
        }
        
        # Check for missing required fields
        for field in expected_fields:
            if field not in response_data:
                validation_result["missing_fields"].append(field)
                validation_result["valid"] = False
            else:
                validation_result["field_types"][field] = type(response_data[field]).__name__
        
        # Note extra fields (not an error, just informational)
        response_fields = set(response_data.keys())
        expected_fields_set = set(expected_fields)
        extra_fields = response_fields - expected_fields_set
        validation_result["extra_fields"] = list(extra_fields)
        
        return validation_result
    
    async def check_dependency_health_cascade(self) -> Dict[str, Any]:
        """Test dependency health cascade - how failures propagate through services."""
        cascade_results = {}
        
        for service, dependencies in DEPENDENCY_CHAINS.items():
            cascade_result = await self._check_service_dependency_cascade(service, dependencies)
            cascade_results[service] = cascade_result
        
        overall_cascade_health = self._evaluate_cascade_health(cascade_results)
        
        return {
            "cascade_results": cascade_results,
            "overall_cascade_health": overall_cascade_health,
            "timestamp": datetime.now(UTC).isoformat()
        }
    
    async def _check_service_dependency_cascade(self, service: str, dependencies: List[str]) -> Dict[str, Any]:
        """Check how a service's health depends on its dependencies."""
        dependency_checks = []
        
        for dependency in dependencies:
            if dependency in SERVICE_ENDPOINTS:
                # Check actual service endpoint
                config = SERVICE_ENDPOINTS[dependency]
                result = await self.health_checker.check_service_endpoint(dependency, config)
            else:
                # Check database or other infrastructure dependencies
                result = await self._check_infrastructure_dependency(dependency)
            
            dependency_checks.append(result)
        
        # Determine service health based on dependency health
        healthy_dependencies = sum(1 for check in dependency_checks if check.is_healthy())
        total_dependencies = len(dependency_checks)
        
        cascade_status = self._determine_cascade_status(healthy_dependencies, total_dependencies)
        
        return {
            "service": service,
            "dependencies": dependency_checks,
            "healthy_dependencies": healthy_dependencies,
            "total_dependencies": total_dependencies,
            "cascade_status": cascade_status,
            "dependency_health_score": healthy_dependencies / max(1, total_dependencies)
        }
    
    async def _check_infrastructure_dependency(self, dependency: str) -> HealthCheckResult:
        """Check infrastructure dependencies like databases."""
        start_time = time.time()
        
        if dependency == "postgres":
            return await self._check_postgres_dependency(start_time)
        elif dependency == "clickhouse":
            return await self._check_clickhouse_dependency(start_time)
        elif dependency == "redis":
            return await self._check_redis_dependency(start_time)
        else:
            response_time_ms = (time.time() - start_time) * 1000
            return create_service_error_result(dependency, "Unknown dependency type", response_time_ms)
    
    async def _check_postgres_dependency(self, start_time: float) -> HealthCheckResult:
        """Check PostgreSQL database dependency."""
        try:
            # Import here to avoid circular imports
            from sqlalchemy import text

            from netra_backend.app.db.postgres import async_engine
            
            async with async_engine.begin() as conn:
                await conn.execute(text("SELECT 1"))
                
            response_time_ms = (time.time() - start_time) * 1000
            return create_healthy_result("postgres", response_time_ms, {"connection": "successful"})
            
        except Exception as e:
            response_time_ms = (time.time() - start_time) * 1000
            return create_service_error_result("postgres", f"Database connection failed: {str(e)}", response_time_ms)
    
    async def _check_clickhouse_dependency(self, start_time: float) -> HealthCheckResult:
        """Check ClickHouse database dependency."""
        try:
            from netra_backend.app.db.clickhouse import get_clickhouse_client
            
            async with get_clickhouse_client() as client:
                client.ping()
                
            response_time_ms = (time.time() - start_time) * 1000
            return create_healthy_result("clickhouse", response_time_ms, {"connection": "successful"})
            
        except Exception as e:
            response_time_ms = (time.time() - start_time) * 1000
            # ClickHouse may not be available in test environments
            logger.warning(f"ClickHouse dependency check failed: {e}")
            return create_service_error_result("clickhouse", f"ClickHouse unavailable: {str(e)}", response_time_ms)
    
    async def _check_redis_dependency(self, start_time: float) -> HealthCheckResult:
        """Check Redis dependency if configured."""
        try:
            # Redis may not be required for core functionality
            response_time_ms = (time.time() - start_time) * 1000
            return create_healthy_result("redis", response_time_ms, {"status": "not_configured"})
            
        except Exception as e:
            response_time_ms = (time.time() - start_time) * 1000
            return create_service_error_result("redis", f"Redis check failed: {str(e)}", response_time_ms)
    
    def _determine_cascade_status(self, healthy_count: int, total_count: int) -> str:
        """Determine cascade status based on dependency health."""
        if total_count == 0:
            return "independent"
        
        health_ratio = healthy_count / total_count
        
        if health_ratio == 1.0:
            return "healthy"
        elif health_ratio >= 0.8:
            return "degraded"
        elif health_ratio >= 0.5:
            return "at_risk"
        else:
            return "failing"
    
    def _evaluate_cascade_health(self, cascade_results: Dict) -> Dict[str, Any]:
        """Evaluate overall system cascade health."""
        total_services = len(cascade_results)
        healthy_services = sum(1 for result in cascade_results.values() 
                             if result["cascade_status"] in ["healthy", "independent"])
        
        degraded_services = sum(1 for result in cascade_results.values() 
                              if result["cascade_status"] == "degraded")
        
        failing_services = sum(1 for result in cascade_results.values() 
                             if result["cascade_status"] in ["at_risk", "failing"])
        
        overall_status = "healthy"
        if failing_services > 0:
            overall_status = "cascade_failure"
        elif degraded_services > total_services * 0.3:  # More than 30% degraded
            overall_status = "cascade_degradation"
        elif degraded_services > 0:
            overall_status = "partial_degradation"
        
        return {
            "overall_status": overall_status,
            "total_services": total_services,
            "healthy_services": healthy_services,
            "degraded_services": degraded_services,
            "failing_services": failing_services,
            "cascade_health_score": (healthy_services + degraded_services * 0.5) / max(1, total_services)
        }


# Test class with comprehensive health monitoring scenarios
@pytest.mark.e2e
class TestServiceHealthMonitoring:
    """Comprehensive service health monitoring test suite."""
    
    @pytest.fixture
    async def health_monitor(self):
        """Create service health monitor instance."""
        await asyncio.sleep(0)
    return ServiceHealthMonitor()
    
    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_all_services_health_endpoints(self, health_monitor):
        """Test that all services report health correctly with proper response structure."""
    pass
        logger.info("Starting comprehensive service health endpoint validation...")
        
        # Discover all service endpoints
        discovery_results = await health_monitor.discover_service_ports()
        
        # Verify service discovery worked
        discovered_services = [name for name, info in discovery_results.items() if info["discovered"]]
        assert len(discovered_services) >= 1, f"Expected at least 1 service, found: {discovered_services}"
        
        # Check health endpoints for discovered services
        health_results = await health_monitor.health_checker.check_all_services()
        
        # Validate health response structure
        for result in health_results:
            assert isinstance(result, HealthCheckResult), f"Invalid result type for {result.service}"
            assert result.service is not None, f"Service name missing in {result}"
            assert result.status in HEALTH_STATUS.values(), f"Invalid status '{result.status}' for {result.service}"
            assert result.response_time_ms >= 0, f"Invalid response time for {result.service}"
            
            # Log health status for monitoring
            logger.info(f"Service {result.service}: {result.status} ({result.response_time_ms:.1f}ms)")
        
        # Calculate overall system health
        overall_health_score = calculate_overall_health_score(health_results)
        assert overall_health_score > 0.0, "System health score should be positive"
        
        logger.info(f"Service health check completed - Overall score: {overall_health_score:.2f}")
    
    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_health_dependency_cascade(self, health_monitor):
        """Test health dependency cascade and failure propagation."""
        logger.info("Starting dependency cascade health validation...")
        
        cascade_results = await health_monitor.check_dependency_health_cascade()
        
        assert "cascade_results" in cascade_results, "Missing cascade results"
        assert "overall_cascade_health" in cascade_results, "Missing overall cascade health"
        
        overall_health = cascade_results["overall_cascade_health"]
        
        # Validate cascade health structure
        assert "overall_status" in overall_health, "Missing overall status"
        assert "cascade_health_score" in overall_health, "Missing cascade health score"
        assert 0.0 <= overall_health["cascade_health_score"] <= 1.0, "Invalid cascade health score"
        
        # Check each service's dependency cascade
        for service_name, cascade_info in cascade_results["cascade_results"].items():
            assert "service" in cascade_info, f"Missing service name in {service_name} cascade"
            assert "dependencies" in cascade_info, f"Missing dependencies in {service_name} cascade"
            assert "cascade_status" in cascade_info, f"Missing cascade status for {service_name}"
            
            # Validate dependency health checks
            for dependency in cascade_info["dependencies"]:
                assert isinstance(dependency, HealthCheckResult), f"Invalid dependency result for {service_name}"
            
            logger.info(f"Service {service_name}: {cascade_info['cascade_status']} "
                       f"({cascade_info['healthy_dependencies']}/{cascade_info['total_dependencies']} deps healthy)")
        
        # Log overall cascade status
        logger.info(f"Cascade health check completed - Status: {overall_health['overall_status']} "
                   f"(Score: {overall_health['cascade_health_score']:.2f})")
    
    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_service_discovery_mechanism(self, health_monitor):
        """Test service discovery functionality and port detection."""
    pass
        logger.info("Starting service discovery mechanism validation...")
        
        discovery_results = await health_monitor.discover_service_ports()
        
        # Validate discovery results structure
        assert isinstance(discovery_results, dict), "Discovery results should be a dictionary"
        assert len(discovery_results) > 0, "Should discover at least one service"
        
        # Validate each discovered service
        for service_name, discovery_info in discovery_results.items():
            assert "service_name" in discovery_info, f"Missing service name for {service_name}"
            assert "port" in discovery_info, f"Missing port for {service_name}"
            assert "endpoint" in discovery_info, f"Missing endpoint for {service_name}"
            assert "discovered" in discovery_info, f"Missing discovered status for {service_name}"
            
            if discovery_info["discovered"]:
                assert discovery_info["response_time_ms"] is not None, f"Missing response time for discovered service {service_name}"
                assert discovery_info["response_time_ms"] > 0, f"Invalid response time for {service_name}"
                
                # Validate response structure if available
                if "response_validation" in discovery_info:
                    validation = discovery_info["response_validation"]
                    assert "valid" in validation, f"Missing validation status for {service_name}"
                    
                    if validation["valid"]:
                        logger.info(f"Service {service_name} discovered successfully at port {discovery_info['port']} "
                                   f"({discovery_info['response_time_ms']:.1f}ms)")
                    else:
                        logger.warning(f"Service {service_name} discovered but response validation failed: "
                                     f"{validation.get('error', 'Unknown validation error')}")
            else:
                logger.info(f"Service {service_name} not discovered - {discovery_info.get('error', 'Unknown error')}")
        
        # Test cache functionality
        cached_results = await health_monitor.discover_service_ports()
        assert discovery_results.keys() == cached_results.keys(), "Cached discovery should await asyncio.sleep(0)
    return same services"
        
        logger.info(f"Service discovery completed - {len(discovery_results)} services processed")
    
    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_health_response_time_sla(self, health_monitor):
        """Test health check response time SLA compliance (<1 second)."""
        logger.info("Starting health response time SLA validation...")
        
        # Check all service health endpoints with timing
        start_time = time.time()
        health_results = await health_monitor.health_checker.check_all_services()
        total_check_time = (time.time() - start_time) * 1000
        
        sla_violations = []
        sla_compliant = []
        
        for result in health_results:
            if result.response_time_ms > HEALTH_SLA_THRESHOLD_MS:
                sla_violations.append({
                    "service": result.service,
                    "response_time_ms": result.response_time_ms,
                    "threshold_ms": HEALTH_SLA_THRESHOLD_MS
                })
            else:
                sla_compliant.append(result.service)
            
            logger.info(f"Service {result.service}: {result.response_time_ms:.1f}ms "
                       f"({'SLA OK' if result.response_time_ms <= HEALTH_SLA_THRESHOLD_MS else 'SLA VIOLATION'})")
        
        # Validate SLA compliance
        total_services = len(health_results)
        compliant_services = len(sla_compliant)
        compliance_ratio = compliant_services / max(1, total_services)
        
        # Allow some flexibility in test environments but log violations
        if sla_violations:
            logger.warning(f"SLA violations detected: {len(sla_violations)} services exceeded {HEALTH_SLA_THRESHOLD_MS}ms threshold")
            for violation in sla_violations:
                logger.warning(f"  - {violation['service']}: {violation['response_time_ms']:.1f}ms")
        
        # Ensure overall health check completes within reasonable time (5 seconds for all services)
        assert total_check_time <= 5000, f"Total health check time {total_check_time:.1f}ms exceeds 5 second limit"
        
        logger.info(f"Health SLA check completed - {compliant_services}/{total_services} services compliant "
                   f"(Total time: {total_check_time:.1f}ms)")
    
    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_health_check_error_handling(self, health_monitor):
        """Test health check error handling for various failure scenarios."""
    pass
        logger.info("Starting health check error handling validation...")
        
        # Test with non-existent service endpoint
        fake_config = {
            "url": "http://localhost:9999/health",
            "timeout": 2.0,
            "expected_service": "fake-service",
            "critical": False
        }
        
        error_result = await health_monitor.health_checker.check_service_endpoint("fake_service", fake_config)
        
        # Validate error handling
        assert not error_result.is_healthy(), "Fake service should not be healthy"
        assert error_result.status in [HEALTH_STATUS["ERROR"], HEALTH_STATUS["TIMEOUT"]], \
            f"Expected error or timeout status, got: {error_result.status}"
        assert error_result.error is not None, "Error message should be present"
        assert error_result.response_time_ms >= 0, "Response time should be recorded even for errors"
        
        logger.info(f"Error handling test - Service: {error_result.service}, "
                   f"Status: {error_result.status}, Error: {error_result.error}")
        
        # Test inter-service communication error handling
        inter_service_result = await health_monitor.health_checker.check_inter_service_communication()
        
        # Validate inter-service communication result structure
        assert isinstance(inter_service_result, HealthCheckResult), "Inter-service result should be HealthCheckResult"
        assert inter_service_result.service == "inter_service", "Service name should be 'inter_service'"
        
        if inter_service_result.is_healthy():
            logger.info("Inter-service communication test passed")
        else:
            logger.info(f"Inter-service communication test - Status: {inter_service_result.status}, "
                       f"Error: {inter_service_result.error}")
        
        # Test critical services identification
        critical_services = get_critical_services()
        assert len(critical_services) > 0, "Should identify at least one critical service"
        
        logger.info(f"Critical services identified: {critical_services}")
        
        # Test critical services health
        critical_results = await health_monitor.health_checker.check_critical_services_only()
        
        for result in critical_results:
            assert result.service in critical_services, f"Result service {result.service} should be in critical list"
            logger.info(f"Critical service {result.service}: {result.status} "
                       f"({result.response_time_ms:.1f}ms)")
        
        logger.info("Health check error handling validation completed")


# Integration test entry point
if __name__ == "__main__":
    async def run_health_monitoring_tests():
        """Run health monitoring tests directly."""
        monitor = ServiceHealthMonitor()
        
        print("=== Service Health Monitoring Tests ===
")
        
        # Test 1: Service Discovery
        print("1. Testing Service Discovery...")
        discovery_results = await monitor.discover_service_ports()
        for service, info in discovery_results.items():
            status = "✓ DISCOVERED" if info["discovered"] else "✗ NOT FOUND"
            print(f"   {service}: {status}")
        
        # Test 2: Health Endpoints
        print("
2. Testing Health Endpoints...")
        health_results = await monitor.health_checker.check_all_services()
        for result in health_results:
            status_symbol = "✓" if result.is_healthy() else "✗"
            print(f"   {status_symbol} {result.service}: {result.status} ({result.response_time_ms:.1f}ms)")
        
        # Test 3: Dependency Cascade
        print("
3. Testing Dependency Cascade...")
        cascade_results = await monitor.check_dependency_health_cascade()
        overall_health = cascade_results["overall_cascade_health"]
        print(f"   Overall Status: {overall_health['overall_status']}")
        print(f"   Health Score: {overall_health['cascade_health_score']:.2f}")
        
        for service, cascade_info in cascade_results["cascade_results"].items():
            deps_healthy = cascade_info['healthy_dependencies']
            deps_total = cascade_info['total_dependencies']
            status_symbol = "✓" if cascade_info['cascade_status'] == 'healthy' else "⚠" if cascade_info['cascade_status'] == 'degraded' else "✗"
            print(f"   {status_symbol} {service}: {cascade_info['cascade_status']} ({deps_healthy}/{deps_total} deps)")
        
        print("
=== Health Monitoring Tests Complete ===")
    
    # Run tests
    asyncio.run(run_health_monitoring_tests())
    pass