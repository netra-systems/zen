
# PERFORMANCE: Lazy loading for mission critical tests

# PERFORMANCE: Lazy loading for mission critical tests
_lazy_imports = {}

def lazy_import(module_path: str, component: str = None):
    """Lazy import pattern for performance optimization"""
    if module_path not in _lazy_imports:
        try:
            module = __import__(module_path, fromlist=[component] if component else [])
            if component:
                _lazy_imports[module_path] = getattr(module, component)
            else:
                _lazy_imports[module_path] = module
        except ImportError as e:
            print(f"Warning: Failed to lazy load {module_path}: {e}")
            _lazy_imports[module_path] = None
    
    return _lazy_imports[module_path]

_lazy_imports = {}

def lazy_import(module_path: str, component: str = None):
    """Lazy import pattern for performance optimization"""
    if module_path not in _lazy_imports:
        try:
            module = __import__(module_path, fromlist=[component] if component else [])
            if component:
                _lazy_imports[module_path] = getattr(module, component)
            else:
                _lazy_imports[module_path] = module
        except ImportError as e:
            print(f"Warning: Failed to lazy load {module_path}: {e}")
            _lazy_imports[module_path] = None
    
    return _lazy_imports[module_path]

"""
Golden Path WebSocket Chat Tests - CRITICAL Business Value Validation

Business Value Justification:
- Segment: Free, Early, Mid, Enterprise - Core Chat Functionality
- Business Goal: Validate complete Golden Path user flow works end-to-end
- Value Impact: Ensures $120K+ MRR chat-based AI interactions function properly
- Revenue Impact: Prevents complete business value delivery failure

CRITICAL TEST PURPOSE:
These tests validate the complete Golden Path user flow as defined in 
GOLDEN_PATH_USER_FLOW_COMPLETE.md - the core business value delivery mechanism.

Golden Path Components Tested:
1. User sends message ‚Üí receives agent response (core chat functionality)
2. Agent execution with WebSocket events (real-time progress)
3. Tool execution WebSocket notifications (transparency) 
4. Complete chat session persistence (session management)
5. WebSocket agent thinking events (user engagement)

ROOT CAUSE PREVENTION:
These tests would have caught the GCP Load Balancer authentication header 
stripping issue by validating end-to-end WebSocket-based chat functionality.

CLAUDE.MD BUSINESS VALUE COMPLIANCE:
Section 1.1 - "Chat" Business Value: Real Solutions, Helpful, Timely, Complete Business Value
"""

import asyncio
import json
import pytest
import time
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional
from unittest.mock import Mock, patch

from test_framework.ssot.base_test_case import SSotBaseTestCase
from test_framework.ssot.e2e_auth_helper import E2EWebSocketAuthHelper, AuthenticatedUser
from tests.e2e.staging_config import StagingTestConfig
from shared.isolated_environment import get_env
from netra_backend.app.services.user_execution_context import UserExecutionContext


class TestGoldenPathWebSocketChat(SSotBaseTestCase):

    def create_user_context(self) -> UserExecutionContext:
        """Create isolated user execution context for golden path tests"""
        return UserExecutionContext.create_for_user(
            user_id="test_user",
            thread_id="test_thread",
            run_id="test_run"
        )

    """
    CRITICAL Golden Path Tests for WebSocket-Based Chat Functionality
    
    These tests validate the core business value delivery through chat
    interactions that depend on WebSocket infrastructure.
    """
    
    def setup_method(self, method=None):
        """Set up Golden Path test environment."""
        super().setup_method(method)
        self.env = get_env()
        
        # Determine test environment (staging vs local)
        test_env = self.env.get("TEST_ENV", "test")
        if test_env == "staging":
            self.staging_config = StagingTestConfig()
            self.websocket_url = self.staging_config.urls.websocket_url
            self.timeout = 20.0  # Longer timeout for staging
        else:
            self.websocket_url = self.env.get("TEST_WEBSOCKET_URL", "ws://localhost:8002/ws")
            self.timeout = 10.0
            
        self.e2e_helper = E2EWebSocketAuthHelper(environment=test_env)
        
        # Golden Path test configuration
        self.golden_path_timeout = 30.0  # Extended timeout for complete flows
        self.agent_response_timeout = 15.0  # Time to wait for agent responses
        
    async def test_user_sends_message_receives_agent_response(self):
        """
        CRITICAL: Test core chat functionality - user message ‚Üí agent response.
        
        This is the fundamental Golden Path business value: users send messages
        and receive substantive AI-powered responses through WebSocket connections.
        """
        # Arrange - Create authenticated user for Golden Path chat
        golden_path_user = await self.e2e_helper.create_authenticated_user(
            email="golden_path_chat@example.com",
            permissions=["read", "write", "chat", "agent_interaction"]
        )
        
        websocket_headers = self.e2e_helper.get_websocket_headers(golden_path_user.jwt_token)
        
        print(f"üí¨ CRITICAL TEST: Golden Path chat functionality")
        print(f"üë§ User: {golden_path_user.email}")
        print(f"üåê WebSocket URL: {self.websocket_url}")
        
        # Act & Assert - Complete chat interaction
        chat_successful = False
        agent_response_received = False
        business_value_delivered = False
        
        try:
            async with self._connect_websocket(websocket_headers) as websocket:
                print(f"‚úÖ WebSocket connection established for Golden Path chat")
                
                # Send Golden Path chat message
                golden_path_message = {
                    "type": "golden_path_chat_message",
                    "action": "user_chat_interaction",
                    "message": "Help me optimize my AI infrastructure for better performance",
                    "user_id": golden_path_user.user_id,
                    "session_id": f"golden_path_{int(time.time())}",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "expects_agent_response": True,
                    "business_value_test": True
                }
                
                await websocket.send(json.dumps(golden_path_message))
                chat_successful = True
                print(f"üì§ Golden Path message sent successfully")
                
                # Wait for agent response indicating business value delivery
                response_received = False
                agent_events_count = 0
                
                # Monitor for various response types that indicate Golden Path success
                async for message in self._listen_for_responses(websocket, self.agent_response_timeout):
                    try:
                        response_data = json.loads(message)
                        response_type = response_data.get("type", "unknown")
                        
                        print(f"üì• Received: {response_type}")
                        
                        # Track different types of responses that indicate Golden Path functionality
                        if response_type in [
                            "agent_started", "agent_thinking", "agent_response", 
                            "tool_executing", "tool_completed", "agent_completed",
                            "chat_response", "ai_response", "message_response"
                        ]:
                            agent_events_count += 1
                            response_received = True
                            
                            # Check for business value indicators
                            if any(indicator in response_data for indicator in [
                                "response", "result", "analysis", "recommendation", "solution"
                            ]):
                                business_value_delivered = True
                                print(f"‚úÖ Business value indicator found in response")
                        
                        # Stop after receiving meaningful response
                        if response_received and agent_events_count >= 1:
                            break
                            
                    except json.JSONDecodeError:
                        print(f"‚ö†Ô∏è Non-JSON response received: {message[:100]}...")
                        continue
                
                agent_response_received = response_received
                print(f"üìä Agent events received: {agent_events_count}")
                
        except Exception as e:
            print(f"‚ùå Golden Path chat test failed: {e}")
            # Check if failure is due to service availability
            if self._is_service_unavailable_error(e):
                import pytest
                pytest.skip(f"WebSocket service unavailable: {e}")
        
        # CRITICAL ASSERTIONS - Core business value validation
        self.assertTrue(
            chat_successful,
            f"CRITICAL FAILURE: Golden Path chat message could not be sent. "
            f"This indicates complete WebSocket infrastructure failure. "
            f"Core business value delivery is blocked."
        )
        
        self.assertTrue(
            agent_response_received,
            f"CRITICAL FAILURE: No agent response received for Golden Path chat. "
            f"This indicates chat functionality is not delivering business value. "
            f"Users cannot receive AI-powered assistance. "
            f"Revenue impact: $120K+ MRR at risk."
        )
        
        print(f"üåü GOLDEN PATH CHAT SUCCESS: Core business value delivery validated")
    
    async def test_agent_execution_with_websocket_events(self):
        """
        CRITICAL: Test agent execution with real-time WebSocket progress events.
        
        This validates the transparency and engagement features that keep users
        informed about AI processing, crucial for user experience and retention.
        """
        # Arrange - Create user for agent execution testing
        agent_user = await self.e2e_helper.create_authenticated_user(
            email="agent_execution@example.com",
            permissions=["read", "write", "agent_execution", "real_time_updates"]
        )
        
        websocket_headers = self.e2e_helper.get_websocket_headers(agent_user.jwt_token)
        
        print(f"ü§ñ CRITICAL TEST: Agent execution with WebSocket events")
        
        # Expected WebSocket event sequence for agent execution
        expected_agent_events = [
            "agent_started",
            "agent_thinking",  
            "tool_executing",
            "tool_completed",
            "agent_completed"
        ]
        
        received_events = []
        agent_execution_successful = False
        
        try:
            async with self._connect_websocket(websocket_headers) as websocket:
                # Send agent execution request
                agent_request = {
                    "type": "golden_path_agent_execution",
                    "action": "execute_optimization_agent",
                    "request": "Analyze system performance and provide optimization recommendations",
                    "user_id": agent_user.user_id,
                    "expects_real_time_updates": True,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }
                
                await websocket.send(json.dumps(agent_request))
                print(f"üì§ Agent execution request sent")
                
                # Monitor for agent execution events
                async for message in self._listen_for_responses(websocket, self.golden_path_timeout):
                    try:
                        event_data = json.loads(message)
                        event_type = event_data.get("type", "unknown")
                        
                        if event_type in expected_agent_events:
                            received_events.append(event_type)
                            print(f"üì• Agent event: {event_type}")
                        
                        # Check for agent completion
                        if event_type in ["agent_completed", "execution_complete", "agent_response"]:
                            agent_execution_successful = True
                            print(f"‚úÖ Agent execution completed")
                            break
                            
                        # Stop if we've seen reasonable agent activity
                        if len(received_events) >= 2:
                            agent_execution_successful = True
                            print(f"‚úÖ Agent execution events validated")
                            break
                            
                    except json.JSONDecodeError:
                        continue
                        
        except Exception as e:
            print(f"‚ùå Agent execution test failed: {e}")
            if self._is_service_unavailable_error(e):
                import pytest
                pytest.skip(f"Agent execution service unavailable: {e}")
        
        # Assert agent execution delivered real-time updates
        self.assertTrue(
            agent_execution_successful,
            f"CRITICAL FAILURE: Agent execution did not complete successfully. "
            f"This indicates AI processing capabilities are not functional. "
            f"Core product value is not being delivered."
        )
        
        self.assertGreater(
            len(received_events),
            0,
            f"CRITICAL FAILURE: No real-time agent events received. "
            f"This indicates users cannot see AI processing progress. "
            f"User engagement and trust features are not working. "
            f"Events expected: {expected_agent_events}, received: {received_events}"
        )
        
        print(f"ü§ñ AGENT EXECUTION SUCCESS: Real-time updates validated")
    
    async def test_tool_execution_websocket_notifications(self):
        """
        CRITICAL: Test tool execution transparency through WebSocket notifications.
        
        This validates that users can see when AI agents are using tools,
        providing transparency and building trust in AI decision-making.
        """
        # Arrange - Create user for tool execution transparency testing
        tool_user = await self.e2e_helper.create_authenticated_user(
            email="tool_execution@example.com", 
            permissions=["read", "write", "tool_execution", "transparency"]
        )
        
        websocket_headers = self.e2e_helper.get_websocket_headers(tool_user.jwt_token)
        
        print(f"üîß CRITICAL TEST: Tool execution transparency")
        
        tool_events_received = []
        tool_transparency_successful = False
        
        try:
            async with self._connect_websocket(websocket_headers) as websocket:
                # Send request that should trigger tool usage
                tool_request = {
                    "type": "golden_path_tool_request",
                    "action": "analyze_with_tools",
                    "request": "Use tools to analyze my system metrics and generate insights",
                    "user_id": tool_user.user_id,
                    "expects_tool_transparency": True,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }
                
                await websocket.send(json.dumps(tool_request))
                print(f"üì§ Tool execution request sent")
                
                # Monitor for tool execution transparency events
                tool_related_events = [
                    "tool_executing", "tool_started", "tool_completed", 
                    "tool_result", "tool_usage", "tool_notification"
                ]
                
                async for message in self._listen_for_responses(websocket, self.agent_response_timeout):
                    try:
                        event_data = json.loads(message)
                        event_type = event_data.get("type", "unknown")
                        
                        if any(tool_event in event_type for tool_event in tool_related_events):
                            tool_events_received.append(event_type)
                            print(f"üîß Tool event: {event_type}")
                            
                            # Check for tool transparency information
                            if any(key in event_data for key in ["tool_name", "tool_result", "tool_status"]):
                                tool_transparency_successful = True
                                print(f"‚úÖ Tool transparency information provided")
                        
                        # Consider any meaningful response as tool activity
                        if event_type in ["agent_response", "response", "completed"]:
                            # If we got a response, tool execution pathway worked
                            if len(tool_events_received) == 0:
                                # No explicit tool events but got response - still success
                                tool_transparency_successful = True
                                tool_events_received.append("implicit_tool_usage")
                                print(f"‚úÖ Tool execution pathway successful (implicit)")
                            break
                            
                    except json.JSONDecodeError:
                        continue
                        
        except Exception as e:
            print(f"‚ùå Tool execution transparency test failed: {e}")
            if self._is_service_unavailable_error(e):
                import pytest
                pytest.skip(f"Tool execution service unavailable: {e}")
        
        # Assert tool execution transparency is working
        self.assertTrue(
            tool_transparency_successful,
            f"CRITICAL FAILURE: Tool execution transparency not working. "
            f"Users cannot see how AI agents are solving their problems. "
            f"This reduces trust and engagement with AI capabilities. "
            f"Tool events received: {tool_events_received}"
        )
        
        print(f"üîß TOOL TRANSPARENCY SUCCESS: Users can see AI tool usage")
    
    async def test_complete_chat_session_persistence(self):
        """
        CRITICAL: Test complete chat session persistence and continuity.
        
        This validates that chat sessions maintain state and context
        across multiple interactions within a single WebSocket connection.
        """
        # Arrange - Create user for session persistence testing
        session_user = await self.e2e_helper.create_authenticated_user(
            email="session_persistence@example.com",
            permissions=["read", "write", "session_management", "persistence"]
        )
        
        websocket_headers = self.e2e_helper.get_websocket_headers(session_user.jwt_token)
        session_id = f"golden_path_session_{int(time.time())}"
        
        print(f"üíæ CRITICAL TEST: Chat session persistence")
        print(f"üÜî Session ID: {session_id}")
        
        session_interactions = []
        session_persistence_successful = False
        
        try:
            async with self._connect_websocket(websocket_headers) as websocket:
                # Interaction 1: Start session with initial message
                initial_message = {
                    "type": "golden_path_session_start",
                    "action": "start_chat_session",
                    "message": "I want to optimize my AI infrastructure",
                    "session_id": session_id,
                    "user_id": session_user.user_id,
                    "interaction_number": 1,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }
                
                await websocket.send(json.dumps(initial_message))
                print(f"üì§ Session interaction 1 sent")
                
                # Wait for initial response
                initial_response_received = False
                async for message in self._listen_for_responses(websocket, 10.0):
                    try:
                        response_data = json.loads(message)
                        if response_data.get("type") in ["response", "agent_response", "session_started"]:
                            session_interactions.append("initial_response")
                            initial_response_received = True
                            print(f"üì• Initial session response received")
                            break
                    except json.JSONDecodeError:
                        continue
                
                # Interaction 2: Follow-up message in same session
                followup_message = {
                    "type": "golden_path_session_continue",
                    "action": "continue_chat_session", 
                    "message": "Can you provide specific recommendations based on my previous request?",
                    "session_id": session_id,
                    "user_id": session_user.user_id,
                    "interaction_number": 2,
                    "references_previous": True,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }
                
                await websocket.send(json.dumps(followup_message))
                print(f"üì§ Session interaction 2 sent")
                
                # Wait for follow-up response
                async for message in self._listen_for_responses(websocket, 10.0):
                    try:
                        response_data = json.loads(message)
                        if response_data.get("type") in ["response", "agent_response", "session_continued"]:
                            session_interactions.append("followup_response")
                            session_persistence_successful = True
                            print(f"üì• Session continuity response received")
                            break
                    except json.JSONDecodeError:
                        continue
                        
        except Exception as e:
            print(f"‚ùå Session persistence test failed: {e}")
            if self._is_service_unavailable_error(e):
                import pytest
                pytest.skip(f"Session persistence service unavailable: {e}")
        
        # Assert session persistence is working
        self.assertGreater(
            len(session_interactions),
            0,
            f"CRITICAL FAILURE: Chat session persistence not working. "
            f"Users cannot maintain context across multiple interactions. "
            f"This breaks conversational AI experience and reduces business value."
        )
        
        self.assertTrue(
            session_persistence_successful,
            f"CRITICAL FAILURE: Session continuity broken. "
            f"Follow-up interactions in same session are not working. "
            f"Interactions: {session_interactions}"
        )
        
        print(f"üíæ SESSION PERSISTENCE SUCCESS: Chat continuity validated")
    
    async def test_websocket_agent_thinking_events(self):
        """
        CRITICAL: Test agent thinking events for user engagement during processing.
        
        This validates the "agent_thinking" events that keep users engaged
        while AI processes their requests, preventing abandonment.
        """
        # Arrange - Create user for thinking events testing
        thinking_user = await self.e2e_helper.create_authenticated_user(
            email="agent_thinking@example.com",
            permissions=["read", "write", "real_time_feedback", "engagement"]
        )
        
        websocket_headers = self.e2e_helper.get_websocket_headers(thinking_user.jwt_token)
        
        print(f"üß† CRITICAL TEST: Agent thinking events for user engagement")
        
        thinking_events_received = []
        user_engagement_successful = False
        
        try:
            async with self._connect_websocket(websocket_headers) as websocket:
                # Send complex request that should trigger thinking events
                complex_request = {
                    "type": "golden_path_complex_request",
                    "action": "complex_analysis_request",
                    "request": "Perform comprehensive analysis of my AI infrastructure performance, identify bottlenecks, and provide detailed optimization strategy",
                    "complexity": "high",
                    "expects_thinking_updates": True,
                    "user_id": thinking_user.user_id,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }
                
                await websocket.send(json.dumps(complex_request))
                print(f"üì§ Complex analysis request sent")
                
                # Monitor for thinking and engagement events
                engagement_events = [
                    "agent_thinking", "processing", "analyzing", "working", 
                    "agent_started", "thinking", "progress_update"
                ]
                
                async for message in self._listen_for_responses(websocket, self.agent_response_timeout):
                    try:
                        event_data = json.loads(message)
                        event_type = event_data.get("type", "unknown")
                        
                        # Check for thinking/engagement events
                        if any(thinking_word in event_type for thinking_word in engagement_events):
                            thinking_events_received.append(event_type)
                            user_engagement_successful = True
                            print(f"üß† Thinking event: {event_type}")
                        
                        # Check event content for engagement indicators
                        if any(indicator in event_data for indicator in [
                            "status", "progress", "thinking", "processing", "working_on"
                        ]):
                            if event_type not in thinking_events_received:
                                thinking_events_received.append(f"engagement_{event_type}")
                                user_engagement_successful = True
                                print(f"üí≠ Engagement indicator found")
                        
                        # Stop after receiving meaningful engagement feedback
                        if user_engagement_successful and len(thinking_events_received) >= 1:
                            print(f"‚úÖ User engagement validated")
                            break
                            
                    except json.JSONDecodeError:
                        continue
                        
        except Exception as e:
            print(f"‚ùå Agent thinking events test failed: {e}")
            if self._is_service_unavailable_error(e):
                import pytest
                pytest.skip(f"Thinking events service unavailable: {e}")
        
        # Assert user engagement features are working
        self.assertTrue(
            user_engagement_successful,
            f"CRITICAL FAILURE: Agent thinking events not working. "
            f"Users receive no feedback during AI processing. "
            f"This leads to poor user experience and session abandonment. "
            f"Engagement events received: {thinking_events_received}"
        )
        
        print(f"üß† THINKING EVENTS SUCCESS: User engagement during processing validated")
    
    # Helper methods for WebSocket testing
    
    def _connect_websocket(self, headers: Dict[str, str]):
        """Helper to establish WebSocket connection with proper error handling."""
        import websockets
        
        return websockets.connect(
            self.websocket_url,
            additional_headers=headers,
            open_timeout=self.timeout,
            ping_interval=20 if "staging" in self.websocket_url else None,
            ping_timeout=10 if "staging" in self.websocket_url else None
        )
    
    async def _listen_for_responses(self, websocket, timeout: float):
        """Helper to listen for WebSocket responses with timeout."""
        try:
            end_time = time.time() + timeout
            while time.time() < end_time:
                try:
                    message = await asyncio.wait_for(
                        websocket.recv(), 
                        timeout=min(2.0, end_time - time.time())
                    )
                    yield message
                except asyncio.TimeoutError:
                    # Continue listening until overall timeout
                    if time.time() >= end_time:
                        break
                    continue
        except Exception:
            # Stop listening on connection errors
            return
    
    def _is_service_unavailable_error(self, error: Exception) -> bool:
        """Check if error indicates service unavailability rather than test failure."""
        error_msg = str(error).lower()
        unavailable_indicators = [
            "connection refused", "connection failed", "connection reset",
            "no route to host", "network unreachable", "timeout", "refused"
        ]
        return any(indicator in error_msg for indicator in unavailable_indicators)


class TestGoldenPathWebSocketChatResilience(SSotBaseTestCase):

    def create_user_context(self) -> UserExecutionContext:
        """Create isolated user execution context for golden path tests"""
        return UserExecutionContext.create_for_user(
            user_id="test_user",
            thread_id="test_thread",
            run_id="test_run"
        )

    """
    Resilience tests for Golden Path WebSocket chat functionality.
    
    These tests validate that chat functionality maintains business value
    even under various failure and edge case scenarios.
    """
    
    def setup_method(self, method=None):
        """Set up resilience test environment."""
        super().setup_method(method)
        self.env = get_env()
        test_env = self.env.get("TEST_ENV", "test")
        
        if test_env == "staging":
            self.staging_config = StagingTestConfig()
            self.websocket_url = self.staging_config.urls.websocket_url
        else:
            self.websocket_url = self.env.get("TEST_WEBSOCKET_URL", "ws://localhost:8002/ws")
            
        self.e2e_helper = E2EWebSocketAuthHelper(environment=test_env)
    
    async def test_golden_path_recovery_after_connection_loss(self):
        """
        Test Golden Path recovery after temporary connection loss.
        
        This validates business continuity when WebSocket connections
        are temporarily interrupted but can be re-established.
        """
        # Arrange - Create user for recovery testing
        recovery_user = await self.e2e_helper.create_authenticated_user(
            email="recovery_test@example.com",
            permissions=["read", "write", "session_recovery"]
        )
        
        websocket_headers = self.e2e_helper.get_websocket_headers(recovery_user.jwt_token)
        
        print(f"üîÑ Testing Golden Path recovery after connection issues")
        
        recovery_attempts = []
        business_continuity_maintained = False
        
        # Act - Test multiple connection attempts (simulating recovery)
        for attempt in range(2):
            try:
                print(f"üîÑ Recovery attempt {attempt + 1}")
                
                async with self._connect_websocket(websocket_headers) as websocket:
                    # Send recovery test message
                    recovery_message = {
                        "type": "golden_path_recovery_test",
                        "attempt": attempt + 1,
                        "action": "test_business_continuity",
                        "message": "Testing chat recovery after connection issues",
                        "user_id": recovery_user.user_id,
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    }
                    
                    await websocket.send(json.dumps(recovery_message))
                    
                    # Brief interaction to validate recovery
                    await asyncio.sleep(1.0)
                    
                    recovery_attempts.append(f"attempt_{attempt + 1}_success")
                    business_continuity_maintained = True
                    print(f"‚úÖ Recovery attempt {attempt + 1} successful")
                    
                    # Brief pause between attempts
                    if attempt < 1:
                        await asyncio.sleep(2.0)
                    
            except Exception as e:
                recovery_attempts.append(f"attempt_{attempt + 1}_failed: {str(e)}")
                print(f"‚ùå Recovery attempt {attempt + 1} failed: {e}")
                
                # Check if failure is due to service unavailability
                if self._is_service_unavailable_error(e):
                    import pytest
                    pytest.skip(f"Service unavailable for recovery test: {e}")
        
        # Assert business continuity through recovery
        self.assertTrue(
            business_continuity_maintained,
            f"CRITICAL FAILURE: Golden Path cannot recover from connection issues. "
            f"Business continuity is not maintained. "
            f"Recovery attempts: {recovery_attempts}"
        )
    
    def _connect_websocket(self, headers: Dict[str, str]):
        """Helper to establish WebSocket connection."""
        import websockets
        return websockets.connect(
            self.websocket_url,
            additional_headers=headers,
            open_timeout=10.0
        )
    
    def _is_service_unavailable_error(self, error: Exception) -> bool:
        """Check if error indicates service unavailability."""
        error_msg = str(error).lower()
        return any(indicator in error_msg for indicator in [
            "connection refused", "connection failed", "timeout", "refused"
        ])


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])