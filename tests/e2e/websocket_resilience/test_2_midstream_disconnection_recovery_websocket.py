"""
Test module split from original file
Generated by auto_fix_test_violations.py
"""

import asyncio
import json
import time
import uuid
import hashlib
import random
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Tuple, AsyncGenerator
from dataclasses import dataclass, field
from enum import Enum
import pytest
import websockets
from websockets.exceptions import ConnectionClosed, InvalidStatusCode
from netra_backend.app.logging_config import central_logger
from shared.isolated_environment import IsolatedEnvironment

# Import required classes from core module
from tests.e2e.websocket_resilience.midstream_disconnection_recovery import (
    ConnectionState, ResponseType, NetworkCondition, StreamBuffer, NetworkSimulator
)

logger = central_logger.get_logger(__name__)

class MockStreamingWebSocket:
    """Mock WebSocket connection with streaming response capabilities."""
    
    def __init__(self, uri: str, session_token: str):
        self.uri = uri
        self.session_token = session_token
        self.state = ConnectionState.DISCONNECTED
        self.buffers: Dict[str, StreamBuffer] = {}
        self.current_stream: Optional[AsyncGenerator] = None
        self.network_simulator = NetworkSimulator()
        self.connection_id = str(uuid.uuid4())
        self.last_sequence_num = 0
        self.response_metadata = {}
        self.disconnect_callbacks: List[callable] = []
        self.reconnect_callbacks: List[callable] = []
        
        # Add default network conditions
        self.network_simulator.add_condition(NetworkCondition("stable", 0.0, 10))
        self.network_simulator.add_condition(NetworkCondition("unstable", 0.1, 100, packet_loss_rate=0.05))
        self.network_simulator.add_condition(NetworkCondition("poor", 0.2, 500, packet_loss_rate=0.15))
        
    async def connect(self) -> bool:
        """Connect to the WebSocket server."""
        try:
            self.state = ConnectionState.CONNECTING
            await asyncio.sleep(0.1)  # Simulate connection time
            self.state = ConnectionState.CONNECTED
            logger.info(f"Mock WebSocket connected: {self.connection_id[:8]}")
            return True
        except Exception as e:
            logger.error(f"Connection failed: {e}")
            self.state = ConnectionState.FAILED
            pytest.fail(f"Unexpected connection failure in MockStreamingWebSocket: {e}")
    
    async def disconnect(self) -> None:
        """Disconnect from the WebSocket server."""
        if self.state != ConnectionState.DISCONNECTED:
            self.state = ConnectionState.DISCONNECTED
            
            # Call disconnect callbacks
            for callback in self.disconnect_callbacks:
                try:
                    await callback()
                except Exception as e:
                    # Log and continue with other callbacks, but track the failure
                    logger.error(f"Disconnect callback failed: {e}")
                    # In real tests, we'd want to track callback failures but not stop disconnection
            
            logger.info(f"Mock WebSocket disconnected: {self.connection_id[:8]}")
    
    async def _simulate_disconnect(self) -> None:
        """Simulate an unexpected disconnection."""
        if self.state in [ConnectionState.CONNECTED, ConnectionState.STREAMING]:
            self.state = ConnectionState.INTERRUPTED
            logger.info(f"Simulated disconnect: {self.connection_id[:8]}")
            await self.disconnect()
    
    async def start_streaming_response(
        self, 
        response_type: ResponseType,
        response_config: Dict[str, Any]
    ) -> str:
        """Start streaming a response."""
        if self.state not in [ConnectionState.CONNECTED, ConnectionState.STREAMING]:
            raise ConnectionError("WebSocket not connected")
        
        self.state = ConnectionState.STREAMING
        stream_id = str(uuid.uuid4())
        
        # Create buffer for this stream
        buffer = StreamBuffer(
            buffer_id=stream_id,
            response_type=response_type,
            total_size=response_config.get("size", 0)
        )
        self.buffers[stream_id] = buffer
        
        # Generate appropriate stream and store it per stream_id
        if response_type == ResponseType.TEXT:
            stream = StreamingResponseGenerator.generate_text_stream(
                response_config.get("size", 10240),
                response_config.get("chunk_size", 1024)
            )
        elif response_type == ResponseType.JSON:
            stream = StreamingResponseGenerator.generate_json_stream(
                response_config.get("schema", {"name": "string", "value": "number"}),
                response_config.get("progressive", True),
                response_config.get("num_objects", 100)
            )
        elif response_type == ResponseType.MULTIPART:
            stream = StreamingResponseGenerator.generate_multipart_stream(
                response_config.get("components", [])
            )
        
        # Store stream per buffer to support multiple concurrent streams
        buffer.stream_generator = stream
        
        logger.info(f"Started streaming response: {stream_id[:8]} ({response_type.value})")
        return stream_id
    
    async def continue_streaming(self, stream_id: str, max_chunks: int = 10) -> List[Dict[str, Any]]:
        """Continue streaming response chunks."""
        if stream_id not in self.buffers:
            raise ValueError(f"Unknown stream: {stream_id}")
        
        buffer = self.buffers[stream_id]
        if buffer.is_complete:
            return []
        
        # Get the stream generator for this specific stream
        if not hasattr(buffer, 'stream_generator') or buffer.stream_generator is None:
            logger.warning(f"No stream generator for stream {stream_id}")
            return []
        
        chunks_delivered = []
        chunks_processed = 0
        
        try:
            while chunks_processed < max_chunks and buffer.stream_generator:
                # Check network conditions
                if self.network_simulator.should_drop_packet():
                    logger.debug("Packet dropped due to network condition")
                    break
                
                # Add network latency
                latency = self.network_simulator.get_latency()
                if latency > 0:
                    await asyncio.sleep(latency)
                
                # Get next chunk from stream
                try:
                    if buffer.response_type == ResponseType.MULTIPART:
                        chunk_data, sequence_num, component_id = await buffer.stream_generator.__anext__()
                        chunk_info = {
                            "stream_id": stream_id,
                            "sequence_num": sequence_num,
                            "component_id": component_id,
                            "data": chunk_data,
                            "timestamp": time.time()
                        }
                    else:
                        chunk_data, sequence_num = await buffer.stream_generator.__anext__()
                        chunk_info = {
                            "stream_id": stream_id,
                            "sequence_num": sequence_num,
                            "data": chunk_data,
                            "timestamp": time.time()
                        }
                    
                    # Add to buffer
                    buffer.add_chunk(chunk_data, sequence_num)
                    chunks_delivered.append(chunk_info)
                    chunks_processed += 1
                    
                except StopAsyncIteration:
                    # Stream complete
                    buffer.is_complete = True
                    buffer.checksum = buffer.get_content_hash()
                    buffer.stream_generator = None
                    logger.info(f"Stream completed: {stream_id[:8]}")
                    break
                    
        except Exception as e:
            logger.error(f"Error during streaming: {e}")
            raise
        
        return chunks_delivered
    
    async def get_buffer_state(self, stream_id: str) -> Dict[str, Any]:
        """Get current buffer state."""
        if stream_id not in self.buffers:
            return {}
        
        buffer = self.buffers[stream_id]
        return {
            "buffer_id": buffer.buffer_id,
            "response_type": buffer.response_type.value,
            "total_size": buffer.total_size,
            "received_size": buffer.received_size,
            "chunks_count": len(buffer.content),
            "sequence_numbers": buffer.sequence_numbers,
            "is_complete": buffer.is_complete,
            "checksum": buffer.checksum,
            "integrity_valid": buffer.verify_integrity(),
            "duration": time.time() - buffer.start_time
        }
    
    async def resume_stream(self, stream_id: str) -> bool:
        """Resume a streaming response after reconnection."""
        if stream_id not in self.buffers:
            return False
        
        buffer = self.buffers[stream_id]
        if buffer.is_complete:
            return True
        
        # Ensure the stream generator is still available
        if not hasattr(buffer, 'stream_generator') or buffer.stream_generator is None:
            logger.warning(f"Cannot resume stream {stream_id}: no stream generator")
            return False
        
        logger.info(f"Resuming stream: {stream_id[:8]} from sequence {buffer.sequence_numbers[-1] if buffer.sequence_numbers else 0}")
        self.state = ConnectionState.STREAMING
        return True
