"""
Test module split from original file
Generated by auto_fix_test_violations.py
"""

import asyncio
import hashlib
import json
import random
import time
import uuid
from dataclasses import dataclass, field
from datetime import datetime, timedelta, timezone
from enum import Enum
from typing import Any, AsyncGenerator, Dict, List, Optional, Tuple
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
import websockets
from websockets.exceptions import ConnectionClosed, InvalidStatusCode

from netra_backend.app.logging_config import central_logger


class ConnectionState(Enum):
    """WebSocket connection states for testing."""
    DISCONNECTED = "disconnected"
    CONNECTING = "connecting"
    CONNECTED = "connected"
    STREAMING = "streaming"
    INTERRUPTED = "interrupted"
    RECOVERING = "recovering"
    FAILED = "failed"

class ResponseType(Enum):
    """Types of streaming responses for testing."""
    TEXT = "text"
    JSON = "json"
    MULTIPART = "multipart"
    BINARY = "binary"

class StreamBuffer:
    """Buffer for partial streaming response data."""
    buffer_id: str
    response_type: ResponseType
    content: List[bytes] = field(default_factory=list)
    total_size: int = 0
    received_size: int = 0
    sequence_numbers: List[int] = field(default_factory=list)
    start_time: float = field(default_factory=time.time)
    last_update: float = field(default_factory=time.time)
    checksum: str = ""
    is_complete: bool = False
    stream_generator: Optional[Any] = None
    
    def add_chunk(self, chunk: bytes, sequence_num: int) -> None:
        """Add a chunk to the buffer."""
        self.content.append(chunk)
        self.received_size += len(chunk)
        self.sequence_numbers.append(sequence_num)
        self.last_update = time.time()
        
    def get_content_hash(self) -> str:
        """Calculate hash of buffer content."""
        full_content = b''.join(self.content)
        return hashlib.sha256(full_content).hexdigest()
    
    def verify_integrity(self) -> bool:
        """Verify buffer integrity."""
        if not self.content:
            return False
        
        # Check sequence continuity
        if len(self.sequence_numbers) > 1:
            for i in range(1, len(self.sequence_numbers)):
                if self.sequence_numbers[i] != self.sequence_numbers[i-1] + 1:
                    return False
        
        # Check size consistency
        calculated_size = sum(len(chunk) for chunk in self.content)
        return calculated_size == self.received_size

class NetworkCondition:
    """Network condition simulation parameters."""
    name: str
    disconnect_probability: float = 0.0
    latency_ms: int = 0
    bandwidth_limit: Optional[int] = None
    packet_loss_rate: float = 0.0
    is_active: bool = True

class NetworkSimulator:
    """Simulates various network conditions for testing."""
    
    def __init__(self):
        self.conditions: Dict[str, NetworkCondition] = {}
        self.active_condition: Optional[str] = None
        self.disconnect_events: List[Dict[str, Any]] = []
        
    def add_condition(self, condition: NetworkCondition) -> None:
        """Add a network condition."""
        self.conditions[condition.name] = condition
        
    async def apply_condition(self, condition_name: str, duration: float = 0.0) -> None:
        """Apply a network condition for specified duration."""
        if condition_name not in self.conditions:
            raise ValueError(f"Unknown network condition: {condition_name}")
            
        self.active_condition = condition_name
        condition = self.conditions[condition_name]
        
        logger.info(f"Applying network condition: {condition_name}")
        
        if duration > 0:
            await asyncio.sleep(duration)
            self.active_condition = None
            logger.info(f"Network condition {condition_name} expired")
    
    async def simulate_disconnect(self, connection, delay: float = 0.0) -> None:
        """Simulate a network disconnection."""
        if delay > 0:
            await asyncio.sleep(delay)
            
        disconnect_event = {
            "timestamp": time.time(),
            "condition": self.active_condition,
            "delay": delay
        }
        self.disconnect_events.append(disconnect_event)
        
        # Simulate connection closure
        if hasattr(connection, 'close'):
            await connection.close()
        elif hasattr(connection, '_simulate_disconnect'):
            await connection._simulate_disconnect()
            
        logger.info(f"Simulated disconnect with delay {delay:.3f}s")
    
    def should_drop_packet(self) -> bool:
        """Determine if packet should be dropped based on current conditions."""
        if not self.active_condition:
            return False
            
        condition = self.conditions[self.active_condition]
        return random.random() < condition.packet_loss_rate
    
    def get_latency(self) -> float:
        """Get current network latency."""
        if not self.active_condition:
            return 0.0
            
        condition = self.conditions[self.active_condition]
        base_latency = condition.latency_ms / 1000.0
        # Add some jitter
        jitter = random.uniform(-0.1, 0.1) * base_latency
        return max(0.0, base_latency + jitter)

class StreamingResponseGenerator:
    """Generates various types of streaming responses for testing."""
    
    @staticmethod
    async def generate_text_stream(
        size: int, 
        chunk_size: int = 1024,
        simulate_processing: bool = True
    ) -> AsyncGenerator[Tuple[bytes, int], None]:
        """Generate a text stream with specified size."""
        total_generated = 0
        sequence_num = 0
        
        # Generate meaningful text content
        base_text = (
            "This is a comprehensive analysis of AI optimization strategies "
            "that includes detailed recommendations for token usage reduction, "
            "model selection optimization, and cost-effective deployment patterns. "
        )
        
        while total_generated < size:
            if simulate_processing:
                # Simulate realistic processing delays
                await asyncio.sleep(random.uniform(0.01, 0.05))
            
            remaining = size - total_generated
            current_chunk_size = min(chunk_size, remaining)
            
            # Create chunk content
            chunk_content = (base_text * (current_chunk_size // len(base_text) + 1))[:current_chunk_size]
            chunk_bytes = chunk_content.encode('utf-8')
            
            total_generated += len(chunk_bytes)
            sequence_num += 1
            
            yield chunk_bytes, sequence_num
    
    @staticmethod
    async def generate_json_stream(
        schema: Dict[str, Any],
        progressive: bool = True,
        num_objects: int = 100
    ) -> AsyncGenerator[Tuple[bytes, int], None]:
        """Generate a JSON stream with progressive object delivery."""
        sequence_num = 0
        
        # Start JSON array
        if progressive:
            yield b'{"data": [', 0
            sequence_num = 1
        
        for i in range(num_objects):
            # Simulate processing delay
            await asyncio.sleep(random.uniform(0.001, 0.01))
            
            # Generate object based on schema
            obj_data = {}
            for key, value_type in schema.items():
                if value_type == "string":
                    obj_data[key] = f"value_{i}_{key}"
                elif value_type == "number":
                    obj_data[key] = random.randint(1, 1000)
                elif value_type == "boolean":
                    obj_data[key] = random.choice([True, False])
                elif value_type == "array":
                    obj_data[key] = [f"item_{j}" for j in range(random.randint(1, 5))]
            
            # Add metadata
            obj_data["_id"] = str(uuid.uuid4())
            obj_data["_sequence"] = i
            obj_data["_timestamp"] = datetime.now(timezone.utc).isoformat()
            
            # Create JSON chunk
            json_str = json.dumps(obj_data)
            if i < num_objects - 1:
                json_str += ","
            
            chunk_bytes = json_str.encode('utf-8')
            yield chunk_bytes, sequence_num
            sequence_num += 1
        
        # Close JSON array
        if progressive:
            yield b']}', sequence_num
    
    @staticmethod
    async def generate_multipart_stream(
        components: List[Dict[str, Any]]
    ) -> AsyncGenerator[Tuple[bytes, int, str], None]:
        """Generate a multi-part response stream."""
        sequence_num = 0
        
        for component in components:
            component_type = component.get("type", "text")
            component_size = component.get("size", 1024)
            component_id = component.get("id", str(uuid.uuid4()))
            
            # Component header
            header = {
                "component_id": component_id,
                "component_type": component_type,
                "component_size": component_size,
                "sequence_start": sequence_num
            }
            header_bytes = json.dumps(header).encode('utf-8')
            yield header_bytes, sequence_num, f"header_{component_id}"
            sequence_num += 1
            
            # Component content
            if component_type == "text":
                async for chunk, seq in StreamingResponseGenerator.generate_text_stream(
                    component_size, chunk_size=256, simulate_processing=False
                ):
                    yield chunk, sequence_num, f"content_{component_id}"
                    sequence_num += 1
            
            elif component_type == "data":
                schema = component.get("schema", {"name": "string", "value": "number"})
                num_items = component_size // 100  # Estimate objects per size
                async for chunk, _ in StreamingResponseGenerator.generate_json_stream(
                    schema, progressive=False, num_objects=num_items
                ):
                    yield chunk, sequence_num, f"content_{component_id}"
                    sequence_num += 1
            
            # Component footer
            footer = {"component_id": component_id, "component_complete": True}
            footer_bytes = json.dumps(footer).encode('utf-8')
            yield footer_bytes, sequence_num, f"footer_{component_id}"
            sequence_num += 1
            
            # Brief pause between components
            await asyncio.sleep(0.01)

async def test_disconnection_during_text_streaming_response(mock_websocket, response_configs):
    """
    Test Case 1: Disconnection during text streaming response.
    
    Validates that agent streaming long-form text response preserves partial 
    response and resumes from correct position on reconnection.
    """
    ws = mock_websocket
    config = response_configs["medium_text"]
    
    # Start streaming response
    stream_id = await ws.start_streaming_response(ResponseType.TEXT, config)
    
    # Stream initial chunks
    initial_chunks = await ws.continue_streaming(stream_id, max_chunks=5)
    assert len(initial_chunks) == 5, "Should deliver 5 initial chunks"
    
    # Capture state before disconnection
    pre_disconnect_state = await ws.get_buffer_state(stream_id)
    pre_disconnect_size = pre_disconnect_state["received_size"]
    pre_disconnect_sequences = pre_disconnect_state["sequence_numbers"].copy()
    
    logger.info(f"Pre-disconnect: {pre_disconnect_size} bytes, {len(pre_disconnect_sequences)} chunks")
    
    # Simulate network disconnection during streaming
    await ws.network_simulator.simulate_disconnect(ws, delay=0.1)
    assert ws.state == ConnectionState.DISCONNECTED
    
    # Verify buffer preservation during disconnection
    await asyncio.sleep(2.0)  # Simulate network outage
    
    buffer_state = await ws.get_buffer_state(stream_id)
    assert buffer_state["received_size"] == pre_disconnect_size, "Buffer size should be preserved"
    assert buffer_state["sequence_numbers"] == pre_disconnect_sequences, "Sequence numbers should be preserved"
    assert buffer_state["integrity_valid"], "Buffer integrity should be maintained"
    
    # Reconnect and resume streaming
    reconnect_start = time.time()
    reconnection_success = await ws.connect()
    assert reconnection_success, "Reconnection should succeed"
    
    resume_success = await ws.resume_stream(stream_id)
    assert resume_success, "Stream resume should succeed"
    
    reconnect_time = time.time() - reconnect_start
    
    # Continue streaming from where left off
    remaining_chunks = await ws.continue_streaming(stream_id, max_chunks=20)
    
    # Get final state
    final_state = await ws.get_buffer_state(stream_id)
    
    # Validate response completion
    assert final_state["received_size"] > pre_disconnect_size, "Additional data should be received"
    assert final_state["integrity_valid"], "Final buffer should maintain integrity"
    assert len(final_state["sequence_numbers"]) > len(pre_disconnect_sequences), "More sequences should be added"
    
    # Validate no duplication
    sequences = final_state["sequence_numbers"]
    assert len(sequences) == len(set(sequences)), "No duplicate sequence numbers"
    
    # Performance validation
    assert reconnect_time < 2.0, f"Reconnection took {reconnect_time:.3f}s, expected < 2.0s"
    
    # Validate sequence continuity
    for i in range(1, len(sequences)):
        assert sequences[i] == sequences[i-1] + 1, f"Sequence gap at position {i}"
    
    logger.info(f"✓ Text streaming recovery: {final_state['received_size']} bytes, {reconnect_time:.3f}s reconnect")

async def test_disconnection_during_json_data_streaming(mock_websocket, response_configs):
    """
    Test Case 2: Disconnection during JSON data streaming.
    
    Ensures JSON structure integrity is maintained and complete data 
    is delivered after reconnection.
    """
    ws = mock_websocket
    config = response_configs["json_data"]
    
    # Start JSON streaming
    stream_id = await ws.start_streaming_response(ResponseType.JSON, config)
    
    # Stream partial JSON data
    initial_chunks = await ws.continue_streaming(stream_id, max_chunks=8)
    assert len(initial_chunks) > 0, "Should receive initial JSON chunks"
    
    # Capture partial JSON state
    pre_disconnect_state = await ws.get_buffer_state(stream_id)
    partial_content = b''.join(ws.buffers[stream_id].content)
    
    logger.info(f"Pre-disconnect JSON: {len(partial_content)} bytes")
    
    # Simulate disconnection mid-JSON
    await ws.network_simulator.simulate_disconnect(ws)
    await asyncio.sleep(1.0)
    
    # Verify JSON buffer preservation
    buffer_state = await ws.get_buffer_state(stream_id)
    assert buffer_state["integrity_valid"], "JSON buffer integrity should be maintained"
    
    # Reconnect and resume
    await ws.connect()
    await ws.resume_stream(stream_id)
    
    # Complete JSON streaming
    completion_start = time.time()
    remaining_chunks = []
    max_iterations = 50  # Prevent infinite loop
    iteration = 0
    
    while not ws.buffers[stream_id].is_complete and iteration < max_iterations:
        new_chunks = await ws.continue_streaming(stream_id, max_chunks=5)
        remaining_chunks.extend(new_chunks)
        if not new_chunks:
            break
        iteration += 1
    
    completion_time = time.time() - completion_start
    
    # Get complete JSON content
    final_state = await ws.get_buffer_state(stream_id)
    complete_content = b''.join(ws.buffers[stream_id].content)
    
    # Validate JSON structure integrity
    try:
        json_data = json.loads(complete_content.decode('utf-8'))
        json_valid = True
    except json.JSONDecodeError as e:
        json_valid = False
        logger.error(f"JSON validation failed: {e}")
    
    assert json_valid, "Complete JSON should be valid"
    assert "data" in json_data, "JSON should contain data array"
    assert isinstance(json_data["data"], list), "Data should be an array"
    
    # Validate no data corruption
    assert final_state["integrity_valid"], "Final JSON buffer should maintain integrity"
    assert final_state["is_complete"], "JSON stream should be complete"
    
    # Performance validation
    assert completion_time < 5.0, f"JSON completion took {completion_time:.3f}s, expected < 5.0s"
    
    # Validate JSON object structure
    for obj in json_data["data"]:
        assert "_id" in obj, "Each object should have an ID"
        assert "_sequence" in obj, "Each object should have a sequence number"
        assert "_timestamp" in obj, "Each object should have a timestamp"
    
    logger.info(f"✓ JSON streaming recovery: {len(json_data['data'])} objects, {completion_time:.3f}s completion")

async def test_disconnection_during_multipart_response_delivery(mock_websocket, response_configs):
    """
    Test Case 3: Disconnection during multi-part response delivery.
    
    Validates that each component is tracked independently and missing 
    components are identified and re-sent.
    """
    ws = mock_websocket
    config = response_configs["multipart_response"]
    
    # Start multipart streaming
    stream_id = await ws.start_streaming_response(ResponseType.MULTIPART, config)
    
    # Stream first component partially
    initial_chunks = await ws.continue_streaming(stream_id, max_chunks=10)
    assert len(initial_chunks) > 0, "Should receive initial multipart chunks"
    
    # Track component delivery
    component_tracking = {}
    for chunk in initial_chunks:
        component_id = chunk.get("component_id", "unknown")
        if component_id not in component_tracking:
            component_tracking[component_id] = {"chunks": 0, "types": set()}
        component_tracking[component_id]["chunks"] += 1
        
        # Determine chunk type from component_id
        if component_id.startswith("header_"):
            component_tracking[component_id]["types"].add("header")
        elif component_id.startswith("content_"):
            component_tracking[component_id]["types"].add("content")
        elif component_id.startswith("footer_"):
            component_tracking[component_id]["types"].add("footer")
    
    logger.info(f"Pre-disconnect components: {list(component_tracking.keys())}")
    
    # Simulate disconnection during multipart delivery
    await ws.network_simulator.simulate_disconnect(ws)
    await asyncio.sleep(2.0)
    
    # Verify component state preservation
    buffer_state = await ws.get_buffer_state(stream_id)
    assert buffer_state["integrity_valid"], "Multipart buffer integrity should be maintained"
    
    # Reconnect and resume
    await ws.connect()
    await ws.resume_stream(stream_id)
    
    # Complete multipart delivery
    completion_chunks = []
    max_iterations = 100
    iteration = 0
    
    while not ws.buffers[stream_id].is_complete and iteration < max_iterations:
        new_chunks = await ws.continue_streaming(stream_id, max_chunks=5)
        completion_chunks.extend(new_chunks)
        if not new_chunks:
            break
        iteration += 1
    
    # Analyze complete component delivery
    all_chunks = initial_chunks + completion_chunks
    final_component_tracking = {}
    
    for chunk in all_chunks:
        component_id = chunk.get("component_id", "unknown")
        if component_id not in final_component_tracking:
            final_component_tracking[component_id] = {"chunks": 0, "types": set(), "sequences": []}
        
        final_component_tracking[component_id]["chunks"] += 1
        final_component_tracking[component_id]["sequences"].append(chunk["sequence_num"])
        
        if component_id.startswith("header_"):
            final_component_tracking[component_id]["types"].add("header")
        elif component_id.startswith("content_"):
            final_component_tracking[component_id]["types"].add("content")
        elif component_id.startswith("footer_"):
            final_component_tracking[component_id]["types"].add("footer")
    
    # Validate component completeness
    expected_components = set()
    for component in config["components"]:
        comp_id = component["id"]
        expected_components.add(f"header_{comp_id}")
        expected_components.add(f"content_{comp_id}")
        expected_components.add(f"footer_{comp_id}")
    
    delivered_components = set(final_component_tracking.keys())
    missing_components = expected_components - delivered_components
    
    assert len(missing_components) == 0, f"Missing components: {missing_components}"
    
    # Validate component ordering and integrity
    for comp_id, tracking in final_component_tracking.items():
        sequences = sorted(tracking["sequences"])
        assert len(sequences) == len(set(sequences)), f"Duplicate sequences in {comp_id}"
        
        # Check sequence continuity within component
        if len(sequences) > 1:
            for i in range(1, len(sequences)):
                # Note: sequences across components may not be continuous
                pass  # Component-specific sequence validation would go here
    
    # Validate no duplicate component delivery
    component_ids = [chunk.get("component_id") for chunk in all_chunks]
    header_count = len([cid for cid in component_ids if cid and cid.startswith("header_")])
    footer_count = len([cid for cid in component_ids if cid and cid.startswith("footer_")])
    
    expected_component_count = len(config["components"])
    
    # Allow for some flexibility in header/footer counting due to the way we track
    logger.info(f"Component delivery: {len(final_component_tracking)} unique IDs")
    
    final_state = await ws.get_buffer_state(stream_id)
    assert final_state["is_complete"], "Multipart stream should be complete"
    
    logger.info(f"✓ Multipart recovery: {len(config['components'])} components, {len(all_chunks)} total chunks")

async def test_recovery_with_partial_message_buffer_preservation(mock_websocket, response_configs):
    """
    Test Case 4: Recovery with partial message buffer preservation.
    
    Validates that all buffer states are preserved during disconnection and 
    buffer synchronization is maintained on reconnection.
    """
    ws = mock_websocket
    
    # Start multiple concurrent streams
    text_config = response_configs["small_text"]
    json_config = response_configs["json_data"]
    
    text_stream_id = await ws.start_streaming_response(ResponseType.TEXT, text_config)
    
    # Stream some data in text stream
    text_chunks = await ws.continue_streaming(text_stream_id, max_chunks=3)
    
    # Capture buffer states before disconnection
    text_buffer_pre = await ws.get_buffer_state(text_stream_id)
    
    # Create multiple buffers manually to test preservation
    additional_buffer_id = str(uuid.uuid4())
    additional_buffer = StreamBuffer(
        buffer_id=additional_buffer_id,
        response_type=ResponseType.JSON,
        total_size=5000
    )
    
    # Add test data to additional buffer
    test_chunks = [b'{"test": "data1"}', b'{"test": "data2"}', b'{"test": "data3"}']
    for i, chunk in enumerate(test_chunks):
        additional_buffer.add_chunk(chunk, i + 1)
    
    # Mark as complete since it's test data
    additional_buffer.is_complete = True
    additional_buffer.checksum = additional_buffer.get_content_hash()
    
    ws.buffers[additional_buffer_id] = additional_buffer
    
    buffer_states_pre = {}
    for buf_id in ws.buffers.keys():
        buffer_states_pre[buf_id] = await ws.get_buffer_state(buf_id)
    
    logger.info(f"Pre-disconnect buffers: {len(buffer_states_pre)}")
    
    # Simulate disconnection with multiple buffers active
    await ws.network_simulator.simulate_disconnect(ws)
    await asyncio.sleep(3.0)  # Extended disconnection
    
    # Verify all buffer states are preserved
    buffer_states_during = {}
    for buf_id in ws.buffers.keys():
        buffer_states_during[buf_id] = await ws.get_buffer_state(buf_id)
    
    assert len(buffer_states_during) == len(buffer_states_pre), "All buffers should be preserved"
    
    for buf_id in buffer_states_pre.keys():
        pre_state = buffer_states_pre[buf_id]
        during_state = buffer_states_during[buf_id]
        
        assert during_state["received_size"] == pre_state["received_size"], f"Buffer {buf_id} size changed"
        assert during_state["chunks_count"] == pre_state["chunks_count"], f"Buffer {buf_id} chunk count changed"
        assert during_state["integrity_valid"], f"Buffer {buf_id} integrity lost"
        assert during_state["sequence_numbers"] == pre_state["sequence_numbers"], f"Buffer {buf_id} sequences changed"
    
    # Reconnect and verify buffer synchronization
    reconnect_start = time.time()
    await ws.connect()
    
    # Resume all streams
    resume_results = {}
    for buf_id in ws.buffers.keys():
        if not ws.buffers[buf_id].is_complete:
            resume_results[buf_id] = await ws.resume_stream(buf_id)
    
    reconnect_time = time.time() - reconnect_start
    
    # Verify buffer synchronization post-reconnect
    buffer_states_post = {}
    for buf_id in ws.buffers.keys():
        buffer_states_post[buf_id] = await ws.get_buffer_state(buf_id)
    
    # Continue active streams
    if text_stream_id in resume_results and resume_results[text_stream_id]:
        additional_text_chunks = await ws.continue_streaming(text_stream_id, max_chunks=5)
        
        # Verify continuation integrity
        final_text_state = await ws.get_buffer_state(text_stream_id)
        assert final_text_state["received_size"] > text_buffer_pre["received_size"], "Text stream should continue"
        assert final_text_state["integrity_valid"], "Text stream integrity should be maintained"
    
    # Validate message sequence numbers are preserved and continuous
    for buf_id, buffer in ws.buffers.items():
        sequences = buffer.sequence_numbers
        if len(sequences) > 1:
            for i in range(1, len(sequences)):
                assert sequences[i] == sequences[i-1] + 1, f"Sequence gap in buffer {buf_id} at position {i}"
    
    # Performance validation
    assert reconnect_time < 1.0, f"Multi-buffer reconnection took {reconnect_time:.3f}s, expected < 1.0s"
    
    # Memory efficiency validation
    total_buffer_memory = sum(
        sum(len(chunk) for chunk in buffer.content) 
        for buffer in ws.buffers.values()
    )
    
    # Should be reasonable for test data
    assert total_buffer_memory < 100 * 1024 * 1024, f"Buffer memory {total_buffer_memory} bytes too high"
    
    logger.info(f"✓ Buffer preservation: {len(ws.buffers)} buffers, {reconnect_time:.3f}s sync time")

async def test_timeout_and_retry_mechanisms(mock_websocket, response_configs):
    """
    Test Case 5: Timeout and retry mechanisms.
    
    Validates exponential backoff, maximum retry attempts, and graceful 
    degradation after timeout.
    """
    ws = mock_websocket
    config = response_configs["medium_text"]
    
    # Start streaming
    stream_id = await ws.start_streaming_response(ResponseType.TEXT, config)
    initial_chunks = await ws.continue_streaming(stream_id, max_chunks=3)
    
    # Setup retry tracking
    retry_attempts = []
    connection_failures = []
    
    # Mock connection failures for retry testing
    original_connect = ws.connect
    
    async def failing_connect():
        attempt_time = time.time()
        connection_failures.append(attempt_time)
        
        # Fail first 3 attempts, succeed on 4th
        if len(connection_failures) <= 3:
            logger.info(f"Connection attempt {len(connection_failures)} failed")
            return False
        else:
            logger.info(f"Connection attempt {len(connection_failures)} succeeded")
            return await original_connect()
    
    ws.connect = failing_connect
    
    # Simulate disconnection
    await ws.network_simulator.simulate_disconnect(ws)
    
    # Implement retry mechanism with exponential backoff
    max_retries = 5
    base_delay = 0.1
    max_delay = 2.0
    
    retry_start = time.time()
    
    for attempt in range(max_retries):
        retry_attempt_start = time.time()
        
        # Calculate exponential backoff delay
        delay = min(base_delay * (2 ** attempt), max_delay)
        
        if attempt > 0:
            await asyncio.sleep(delay)
        
        # Attempt reconnection
        connection_success = await ws.connect()
        
        retry_info = {
            "attempt": attempt + 1,
            "delay": delay,
            "success": connection_success,
            "timestamp": time.time(),
            "duration": time.time() - retry_attempt_start
        }
        retry_attempts.append(retry_info)
        
        if connection_success:
            logger.info(f"Reconnection succeeded on attempt {attempt + 1}")
            break
        else:
            logger.info(f"Reconnection failed on attempt {attempt + 1}, delay {delay:.3f}s")
    
    total_retry_time = time.time() - retry_start
    
    # Validate retry mechanism behavior
    assert len(retry_attempts) >= 1, "Should have at least one retry attempt"
    assert len(retry_attempts) <= max_retries, f"Should not exceed {max_retries} attempts"
    
    # Validate exponential backoff
    for i, attempt in enumerate(retry_attempts[1:], 1):  # Skip first attempt (no delay)
        expected_delay = min(base_delay * (2 ** i), max_delay)
        actual_delay = attempt["delay"]
        assert abs(actual_delay - expected_delay) < 0.01, f"Incorrect delay on attempt {i + 1}"
    
    # Check if retry eventually succeeded
    final_success = retry_attempts[-1]["success"]
    
    if final_success:
        # Test stream resumption after successful retry
        resume_success = await ws.resume_stream(stream_id)
        assert resume_success, "Stream resume should succeed after retry"
        
        # Continue streaming to validate recovery
        recovery_chunks = await ws.continue_streaming(stream_id, max_chunks=3)
        final_state = await ws.get_buffer_state(stream_id)
        
        assert final_state["integrity_valid"], "Stream integrity should be maintained after retry"
        
        # Performance validation for successful retry
        assert total_retry_time < 10.0, f"Total retry time {total_retry_time:.3f}s too long"
        
        logger.info(f"✓ Retry succeeded: {len(retry_attempts)} attempts, {total_retry_time:.3f}s total")
        
    else:
        # Test graceful degradation after max retries
        logger.info("Testing graceful degradation after max retries")
        
        # Verify system handles timeout gracefully
        buffer_state = await ws.get_buffer_state(stream_id)
        assert buffer_state["integrity_valid"], "Buffer should remain intact after timeout"
        
        # Test error reporting
        assert ws.state == ConnectionState.FAILED, "WebSocket should be in failed state"
        
        # Validate retry timing was appropriate
        assert total_retry_time >= 2.0, "Should have adequate retry time"
        assert total_retry_time < 15.0, "Should not retry indefinitely"
        
        logger.info(f"✓ Graceful degradation: {len(retry_attempts)} attempts, {total_retry_time:.3f}s timeout")
    
    # Validate retry attempt timing
    for i in range(1, len(retry_attempts)):
        time_between = retry_attempts[i]["timestamp"] - retry_attempts[i-1]["timestamp"]
        expected_min_time = retry_attempts[i]["delay"]
        assert time_between >= expected_min_time * 0.9, f"Retry {i} too fast: {time_between:.3f}s"
    
    # Check for proper cleanup after retries
    assert len(ws.buffers) > 0, "Buffers should be preserved during retry"
    
    logger.info(f"✓ Timeout/retry validation: {len(retry_attempts)} attempts, backoff working correctly")

async def test_concurrent_stream_interruptions(mock_websocket, response_configs):
    """Test multiple streams being interrupted simultaneously."""
    ws = mock_websocket
    
    # Start multiple streams
    text_id = await ws.start_streaming_response(ResponseType.TEXT, response_configs["small_text"])
    json_id = await ws.start_streaming_response(ResponseType.JSON, response_configs["json_data"])
    
    # Stream partial data from both
    text_chunks = await ws.continue_streaming(text_id, max_chunks=2)
    json_chunks = await ws.continue_streaming(json_id, max_chunks=2)
    
    # Simulate simultaneous disconnection
    await ws.network_simulator.simulate_disconnect(ws)
    await asyncio.sleep(1.0)
    
    # Verify both streams preserved
    text_state = await ws.get_buffer_state(text_id)
    json_state = await ws.get_buffer_state(json_id)
    
    assert text_state["integrity_valid"], "Text stream integrity should be preserved"
    assert json_state["integrity_valid"], "JSON stream integrity should be preserved"
    
    # Reconnect and resume both
    await ws.connect()
    await ws.resume_stream(text_id)
    await ws.resume_stream(json_id)
    
    # Continue both streams
    more_text = await ws.continue_streaming(text_id, max_chunks=3)
    more_json = await ws.continue_streaming(json_id, max_chunks=3)
    
    # Validate independent recovery
    final_text_state = await ws.get_buffer_state(text_id)
    final_json_state = await ws.get_buffer_state(json_id)
    
    assert final_text_state["received_size"] > text_state["received_size"]
    assert final_json_state["received_size"] > json_state["received_size"]
    
    logger.info("✓ Concurrent stream interruption handling verified")

async def test_network_quality_degradation_during_stream(mock_websocket, response_configs):
    """Test adaptive behavior during network quality degradation."""
    ws = mock_websocket
    
    # Add degraded network conditions with lower packet loss
    ws.network_simulator.add_condition(NetworkCondition("degrading", 0.0, 50, packet_loss_rate=0.02))
    
    # Start streaming
    stream_id = await ws.start_streaming_response(ResponseType.TEXT, response_configs["medium_text"])
    
    # Stream with good conditions
    good_chunks = await ws.continue_streaming(stream_id, max_chunks=5)
    good_performance = time.time()
    
    # Apply degraded conditions
    await ws.network_simulator.apply_condition("degrading", duration=0.0)  # Persistent
    
    # Check if stream is still active before applying degradation
    buffer_state_pre = await ws.get_buffer_state(stream_id)
    logger.info(f"Buffer state before degradation: complete={buffer_state_pre['is_complete']}, size={buffer_state_pre['received_size']}")
    
    # Continue streaming with poor conditions - try more chunks to account for packet loss
    degraded_start = time.time()
    degraded_chunks = []
    attempts = 0
    max_attempts = 20  # Allow more attempts to account for packet loss
    
    while len(degraded_chunks) < 3 and attempts < max_attempts:
        new_chunks = await ws.continue_streaming(stream_id, max_chunks=2)
        degraded_chunks.extend(new_chunks)
        attempts += 1
        
        # Check if stream completed
        current_state = await ws.get_buffer_state(stream_id)
        if current_state["is_complete"]:
            logger.info(f"Stream completed during degradation test after {attempts} attempts")
            break
            
        if not new_chunks:
            # No chunks but stream not complete - could be packet loss
            logger.debug(f"No chunks on attempt {attempts}, continuing...")
            await asyncio.sleep(0.01)  # Brief pause before retry
    
    degraded_time = time.time() - degraded_start
    
    # Validate stream behavior - it should either continue or complete gracefully
    final_state = await ws.get_buffer_state(stream_id)
    if final_state["is_complete"]:
        # Stream completed during test - that's acceptable
        assert final_state["received_size"] > buffer_state_pre["received_size"] or len(degraded_chunks) > 0, \
            "Stream should make progress even under degraded conditions"
        logger.info(f"Stream completed under degraded conditions: {final_state['received_size']} bytes total")
    else:
        # Stream still active - should have delivered some chunks
        assert len(degraded_chunks) > 0, "Stream should continue despite network degradation"
        logger.info(f"Stream continuing under degraded conditions: {len(degraded_chunks)} chunks delivered")
    
    # Some packets may be lost due to conditions, but stream should adapt
    buffer_state = await ws.get_buffer_state(stream_id)
    assert buffer_state["integrity_valid"], "Buffer integrity should be maintained"
    
    logger.info(f"✓ Network degradation handling: {len(degraded_chunks)} chunks delivered")

async def test_large_response_stream_interruption_efficiency(mock_websocket, response_configs):
    """Test efficient resume of large response streams."""
    ws = mock_websocket
    
    # Create large response configuration
    large_config = {
        "type": ResponseType.TEXT,
        "size": 2 * 1024 * 1024,  # 2MB
        "chunk_size": 8192
    }
    
    # Start large stream
    stream_id = await ws.start_streaming_response(ResponseType.TEXT, large_config)
    
    # Stream significant portion
    initial_chunks = []
    for _ in range(50):  # Stream ~400KB
        new_chunks = await ws.continue_streaming(stream_id, max_chunks=1)
        initial_chunks.extend(new_chunks)
        if not new_chunks:
            break
    
    # Capture progress
    pre_disconnect_state = await ws.get_buffer_state(stream_id)
    progress_before = pre_disconnect_state["received_size"] / large_config["size"]
    
    logger.info(f"Pre-disconnect progress: {progress_before:.1%}")
    
    # Simulate disconnection
    await ws.network_simulator.simulate_disconnect(ws)
    await asyncio.sleep(1.0)
    
    # Reconnect and resume
    await ws.connect()
    resume_start = time.time()
    await ws.resume_stream(stream_id)
    resume_time = time.time() - resume_start
    
    # Continue from where left off (should not retransmit)
    continuation_start = time.time()
    continuation_chunks = []
    for _ in range(20):
        new_chunks = await ws.continue_streaming(stream_id, max_chunks=5)
        continuation_chunks.extend(new_chunks)
        if not new_chunks:
            break
    
    continuation_time = time.time() - continuation_start
    
    # Validate efficient resume
    post_resume_state = await ws.get_buffer_state(stream_id)
    
    # No data should be lost or duplicated
    assert post_resume_state["received_size"] >= pre_disconnect_state["received_size"]
    
    # Resume should be fast
    assert resume_time < 0.5, f"Large stream resume took {resume_time:.3f}s, too slow"
    
    # Continuation should proceed efficiently
    if continuation_chunks:
        avg_chunk_time = continuation_time / len(continuation_chunks)
        assert avg_chunk_time < 0.1, f"Chunk delivery too slow after resume: {avg_chunk_time:.3f}s"
    
    logger.info(f"✓ Large stream efficiency: {progress_before:.1%} before, {resume_time:.3f}s resume")
