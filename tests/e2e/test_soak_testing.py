"""
Long-Duration Soak Testing Suite
===============================

Business Value Justification (BVJ):
- Segment: Enterprise/Platform  
- Business Goal: Platform Stability, Risk Reduction, Customer Retention
- Value Impact: Ensures 99.9% uptime SLA compliance for Enterprise customers
- Strategic/Revenue Impact: Prevents enterprise churn, supports premium pricing

This comprehensive soak testing suite validates system stability under 
sustained load for 24-48 hours, detecting memory leaks, resource exhaustion,
performance degradation, and long-term stability issues.

Test Duration: 48 hours continuous operation
Load Profile: Sustained 60-80% capacity utilization  
Monitoring: Real-time resource tracking with 1-minute granularity
"""

import asyncio
import gc
import json
import logging
import os
import threading
import time
import tracemalloc
import uuid
from concurrent.futures import ThreadPoolExecutor, as_completed
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple, Union

import asyncpg
import httpx
import psutil
import pytest
import redis
import websockets

try:
    import resource
except ImportError:
    # Windows doesn't have the resource module
    resource = None

# Configure soak test logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('soak_test.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("soak_testing")

# Test configuration
SOAK_CONFIG = {
    "auth_service_url": os.getenv("E2E_AUTH_SERVICE_URL", "http://localhost:8001"),
    "backend_url": os.getenv("E2E_BACKEND_URL", "http://localhost:8000"),
    "websocket_url": os.getenv("E2E_WEBSOCKET_URL", "ws://localhost:8000/ws"),
    "redis_url": os.getenv("E2E_REDIS_URL", "redis://localhost:6379"),
    "postgres_url": os.getenv("E2E_POSTGRES_URL", "postgresql://postgres:netra@localhost:5432/netra_test"),
    "clickhouse_url": os.getenv("E2E_CLICKHOUSE_URL", "clickhouse://localhost:8123/netra_test"),
    "test_duration_hours": int(os.getenv("SOAK_TEST_DURATION_HOURS", "48")),
    "monitoring_interval_seconds": int(os.getenv("SOAK_MONITORING_INTERVAL", "60")),
    "max_concurrent_connections": int(os.getenv("SOAK_MAX_CONNECTIONS", "500")),
    "agent_spawn_rate_per_minute": int(os.getenv("SOAK_AGENT_SPAWN_RATE", "10")),
    "database_ops_per_minute": int(os.getenv("SOAK_DB_OPS_RATE", "1000")),
}


@dataclass
class ResourceSnapshot:
    """Represents a point-in-time snapshot of system resources."""
    timestamp: float
    memory_usage_mb: float
    memory_percent: float
    cpu_percent: float
    open_files: int
    connections: int
    gc_stats: Dict[str, Any]
    process_count: int
    heap_size_mb: float = 0.0
    gc_cycles: int = 0


@dataclass
class PerformanceMetrics:
    """Tracks performance metrics over time."""
    operation: str
    start_time: float
    end_time: float
    duration: float
    success: bool
    error_message: Optional[str] = None
    resource_snapshot: Optional[ResourceSnapshot] = None


@dataclass
class SoakTestResults:
    """Comprehensive results from soak testing."""
    test_start: datetime
    test_end: datetime
    total_duration_hours: float
    resource_snapshots: List[ResourceSnapshot] = field(default_factory=list)
    performance_metrics: List[PerformanceMetrics] = field(default_factory=list)
    memory_leak_detected: bool = False
    max_memory_usage_mb: float = 0.0
    avg_response_time_ms: float = 0.0
    error_count: int = 0
    success_rate: float = 0.0
    gc_efficiency: float = 0.0
    connection_pool_health: Dict[str, Any] = field(default_factory=dict)


class ResourceMonitor:
    """Monitors system resources during soak testing."""
    
    def __init__(self, monitoring_interval: int = 60):
        self.monitoring_interval = monitoring_interval
        self.snapshots: List[ResourceSnapshot] = []
        self.is_monitoring = False
        self.monitor_thread: Optional[threading.Thread] = None
        self.process = psutil.Process()
        
    def start_monitoring(self):
        """Start continuous resource monitoring."""
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitor_thread.start()
        logger.info(f"Resource monitoring started (interval: {self.monitoring_interval}s)")
        
    def stop_monitoring(self):
        """Stop resource monitoring."""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        logger.info("Resource monitoring stopped")
        
    def _monitoring_loop(self):
        """Continuous monitoring loop."""
        while self.is_monitoring:
            try:
                snapshot = self._capture_snapshot()
                self.snapshots.append(snapshot)
                
                # Log critical metrics
                if snapshot.memory_percent > 90:
                    logger.warning(f"High memory usage: {snapshot.memory_percent:.1f}%")
                if snapshot.cpu_percent > 95:
                    logger.warning(f"High CPU usage: {snapshot.cpu_percent:.1f}%")
                    
                time.sleep(self.monitoring_interval)
            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}")
                time.sleep(self.monitoring_interval)
                
    def _capture_snapshot(self) -> ResourceSnapshot:
        """Capture current resource state."""
        memory_info = self.process.memory_info()
        memory_percent = self.process.memory_percent()
        cpu_percent = self.process.cpu_percent()
        
        # Get file descriptor count
        try:
            open_files = self.process.num_fds() if hasattr(self.process, 'num_fds') else len(self.process.open_files())
        except (psutil.AccessDenied, psutil.NoSuchProcess):
            open_files = -1
            
        # Get connection count
        try:
            connections = len(self.process.connections())
        except (psutil.AccessDenied, psutil.NoSuchProcess):
            connections = -1
            
        # Get GC stats
        gc_stats = {
            'gen0': gc.get_count()[0],
            'gen1': gc.get_count()[1], 
            'gen2': gc.get_count()[2],
            'total_collections': sum(gc.get_stats()[i]['collections'] for i in range(3))
        }
        
        return ResourceSnapshot(
            timestamp=time.time(),
            memory_usage_mb=memory_info.rss / 1024 / 1024,
            memory_percent=memory_percent,
            cpu_percent=cpu_percent,
            open_files=open_files,
            connections=connections,
            gc_stats=gc_stats,
            process_count=len(psutil.pids()),
            heap_size_mb=memory_info.vms / 1024 / 1024 if hasattr(memory_info, 'vms') else 0.0,
            gc_cycles=gc_stats['total_collections']
        )
        
    def analyze_memory_leaks(self) -> Tuple[bool, Dict[str, Any]]:
        """Analyze snapshots for memory leaks."""
        if len(self.snapshots) < 10:
            return False, {"reason": "Insufficient data points"}
            
        # Calculate memory growth trend
        recent_snapshots = self.snapshots[-20:]  # Last 20 snapshots
        initial_memory = recent_snapshots[0].memory_usage_mb
        final_memory = recent_snapshots[-1].memory_usage_mb
        growth_rate = (final_memory - initial_memory) / len(recent_snapshots)
        
        # Check for sustained memory growth
        leak_detected = growth_rate > 2.0  # More than 2MB per snapshot
        
        analysis = {
            "growth_rate_mb_per_snapshot": growth_rate,
            "initial_memory_mb": initial_memory,
            "final_memory_mb": final_memory,
            "total_growth_mb": final_memory - initial_memory,
            "gc_efficiency": self._calculate_gc_efficiency()
        }
        
        return leak_detected, analysis
        
    def _calculate_gc_efficiency(self) -> float:
        """Calculate garbage collection efficiency."""
        if len(self.snapshots) < 2:
            return 1.0
            
        # Compare memory before and after GC cycles
        gc_reductions = []
        for i in range(1, len(self.snapshots)):
            prev_snap = self.snapshots[i-1]
            curr_snap = self.snapshots[i]
            
            # If GC cycles increased, check memory reduction
            if curr_snap.gc_cycles > prev_snap.gc_cycles:
                memory_reduction = prev_snap.memory_usage_mb - curr_snap.memory_usage_mb
                if memory_reduction > 0:
                    gc_reductions.append(memory_reduction)
                    
        return sum(gc_reductions) / len(gc_reductions) if gc_reductions else 0.0


class AIAgentSimulator:
    """Simulates AI agent operations for soak testing."""
    
    def __init__(self, backend_url: str):
        self.backend_url = backend_url
        self.active_agents = 0
        self.total_agents_created = 0
        self.performance_metrics: List[PerformanceMetrics] = []
        
    async def simulate_agent_lifecycle(self) -> PerformanceMetrics:
        """Simulate complete AI agent lifecycle."""
        start_time = time.time()
        agent_id = str(uuid.uuid4())
        success = True
        error_message = None
        
        try:
            self.active_agents += 1
            self.total_agents_created += 1
            
            # Simulate agent creation
            async with httpx.AsyncClient(timeout=30.0) as client:
                # Agent initialization
                await client.post(f"{self.backend_url}/agents", json={
                    "agent_id": agent_id,
                    "type": "analysis",
                    "config": {"max_iterations": 5}
                })
                
                # Simulate processing operations
                for i in range(5):
                    await client.post(f"{self.backend_url}/agents/{agent_id}/process", json={
                        "input": f"Analysis task {i+1}",
                        "context": {"iteration": i+1}
                    })
                    await asyncio.sleep(0.1)  # Brief processing delay
                    
                # Agent cleanup
                await client.delete(f"{self.backend_url}/agents/{agent_id}")
                
        except Exception as e:
            success = False
            error_message = str(e)
            logger.error(f"Agent {agent_id} failed: {e}")
        finally:
            self.active_agents -= 1
            
        end_time = time.time()
        metric = PerformanceMetrics(
            operation="agent_lifecycle",
            start_time=start_time,
            end_time=end_time,
            duration=end_time - start_time,
            success=success,
            error_message=error_message
        )
        self.performance_metrics.append(metric)
        return metric


class WebSocketStressTest:
    """Stress tests WebSocket connections."""
    
    def __init__(self, websocket_url: str, max_connections: int):
        self.websocket_url = websocket_url
        self.max_connections = max_connections
        self.active_connections: List[websockets.WebSocketServerProtocol] = []
        self.message_count = 0
        self.connection_errors = 0
        
    async def establish_persistent_connections(self, target_count: int):
        """Establish multiple persistent WebSocket connections."""
        logger.info(f"Establishing {target_count} persistent WebSocket connections")
        
        async def create_connection():
            try:
                connection = await websockets.connect(self.websocket_url)
                self.active_connections.append(connection)
                return connection
            except Exception as e:
                self.connection_errors += 1
                logger.error(f"Failed to create WebSocket connection: {e}")
                return None
                
        # Create connections concurrently
        tasks = [create_connection() for _ in range(target_count)]
        connections = await asyncio.gather(*tasks, return_exceptions=True)
        
        successful_connections = [c for c in connections if c is not None and not isinstance(c, Exception)]
        logger.info(f"Successfully established {len(successful_connections)} connections")
        
    async def send_periodic_messages(self, interval_seconds: int = 60):
        """Send periodic messages through all connections."""
        while self.active_connections:
            try:
                message = json.dumps({
                    "type": "heartbeat",
                    "timestamp": time.time(),
                    "message_id": self.message_count
                })
                
                # Send to all connections
                send_tasks = []
                for connection in self.active_connections[:]:  # Copy to avoid modification during iteration
                    if connection.closed:
                        self.active_connections.remove(connection)
                        continue
                    send_tasks.append(connection.send(message))
                    
                if send_tasks:
                    await asyncio.gather(*send_tasks, return_exceptions=True)
                    self.message_count += len(send_tasks)
                    
                await asyncio.sleep(interval_seconds)
                
            except Exception as e:
                logger.error(f"Error sending periodic messages: {e}")
                await asyncio.sleep(interval_seconds)
                
    async def cleanup_connections(self):
        """Clean up all WebSocket connections."""
        logger.info(f"Cleaning up {len(self.active_connections)} WebSocket connections")
        
        close_tasks = []
        for connection in self.active_connections:
            if not connection.closed:
                close_tasks.append(connection.close())
                
        if close_tasks:
            await asyncio.gather(*close_tasks, return_exceptions=True)
            
        self.active_connections.clear()


class DatabaseStressTest:
    """Stress tests database operations."""
    
    def __init__(self, postgres_url: str):
        self.postgres_url = postgres_url
        self.query_count = 0
        self.error_count = 0
        self.connection_pool_size = 20
        
    async def execute_continuous_operations(self, ops_per_minute: int, duration_hours: float):
        """Execute continuous database operations."""
        total_duration = duration_hours * 3600
        operation_interval = 60.0 / ops_per_minute
        
        logger.info(f"Starting continuous DB operations: {ops_per_minute}/min for {duration_hours}h")
        
        start_time = time.time()
        while (time.time() - start_time) < total_duration:
            try:
                await self._execute_mixed_operations()
                await asyncio.sleep(operation_interval)
            except Exception as e:
                self.error_count += 1
                logger.error(f"Database operation failed: {e}")
                
    async def _execute_mixed_operations(self):
        """Execute a mix of read and write operations."""
        conn = await asyncpg.connect(self.postgres_url)
        
        try:
            # Read operations (70%)
            if self.query_count % 10 < 7:
                await conn.fetchrow("SELECT COUNT(*) FROM users")
                await conn.fetch("SELECT * FROM agents LIMIT 10")
            
            # Write operations (30%)
            else:
                test_data = {
                    "name": f"soak_test_{self.query_count}",
                    "created_at": datetime.utcnow()
                }
                await conn.execute(
                    "INSERT INTO test_data (name, created_at) VALUES ($1, $2) ON CONFLICT DO NOTHING",
                    test_data["name"], test_data["created_at"]
                )
                
            self.query_count += 1
            
        finally:
            await conn.close()


class SoakTestOrchestrator:
    """Orchestrates the complete soak testing suite."""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.resource_monitor = ResourceMonitor(config["monitoring_interval_seconds"])
        self.ai_agent_simulator = AIAgentSimulator(config["backend_url"])
        self.websocket_stress = WebSocketStressTest(
            config["websocket_url"], 
            config["max_concurrent_connections"]
        )
        self.database_stress = DatabaseStressTest(config["postgres_url"])
        self.test_results = SoakTestResults(
            test_start=datetime.utcnow(),
            test_end=datetime.utcnow(),
            total_duration_hours=0.0
        )
        
    async def run_complete_soak_test(self) -> SoakTestResults:
        """Execute the complete soak testing suite."""
        logger.info(f"Starting {self.config['test_duration_hours']}h soak test")
        
        # Enable memory tracing
        tracemalloc.start()
        
        # Start resource monitoring
        self.resource_monitor.start_monitoring()
        
        try:
            # Execute all test scenarios concurrently
            await asyncio.gather(
                self._run_memory_leak_detection(),
                self._run_websocket_stress_test(),
                self._run_database_stress_test(),
                self._run_performance_degradation_analysis(),
                self._run_cache_memory_management_test(),
                self._run_gc_impact_analysis(),
                return_exceptions=True
            )
            
        finally:
            # Stop monitoring and collect results
            self.resource_monitor.stop_monitoring()
            tracemalloc.stop()
            
            # Generate final results
            self.test_results.test_end = datetime.utcnow()
            self.test_results.total_duration_hours = (
                self.test_results.test_end - self.test_results.test_start
            ).total_seconds() / 3600
            
            self._analyze_results()
            
        return self.test_results
        
    async def _run_memory_leak_detection(self):
        """Test Case 1: Memory Leak Detection Under Sustained AI Agent Operations."""
        logger.info("Starting memory leak detection test")
        
        duration_hours = self.config["test_duration_hours"]
        agent_spawn_rate = self.config["agent_spawn_rate_per_minute"]
        
        total_duration = duration_hours * 3600
        spawn_interval = 60.0 / agent_spawn_rate
        
        start_time = time.time()
        while (time.time() - start_time) < total_duration:
            # Spawn batch of agents
            tasks = []
            for _ in range(10):  # Spawn 10 agents concurrently
                tasks.append(self.ai_agent_simulator.simulate_agent_lifecycle())
                
            await asyncio.gather(*tasks, return_exceptions=True)
            await asyncio.sleep(spawn_interval)
            
        logger.info("Memory leak detection test completed")
        
    async def _run_websocket_stress_test(self):
        """Test Case 2: WebSocket Connection Pool Exhaustion and Recovery."""
        logger.info("Starting WebSocket stress test")
        
        # Establish connections
        await self.websocket_stress.establish_persistent_connections(
            self.config["max_concurrent_connections"]
        )
        
        # Send periodic messages for test duration
        duration_hours = self.config["test_duration_hours"] * 0.75  # 75% of total test time
        message_task = asyncio.create_task(
            self.websocket_stress.send_periodic_messages(60)
        )
        
        await asyncio.sleep(duration_hours * 3600)
        message_task.cancel()
        
        # Cleanup
        await self.websocket_stress.cleanup_connections()
        
        logger.info("WebSocket stress test completed")
        
    async def _run_database_stress_test(self):
        """Test Case 3: Database Connection Pool Stability Under Continuous Load."""
        logger.info("Starting database stress test")
        
        await self.database_stress.execute_continuous_operations(
            self.config["database_ops_per_minute"],
            self.config["test_duration_hours"]
        )
        
        logger.info("Database stress test completed")
        
    async def _run_performance_degradation_analysis(self):
        """Test Case 5: Performance Degradation Curve Analysis."""
        logger.info("Starting performance degradation analysis")
        
        duration_hours = self.config["test_duration_hours"]
        benchmark_interval = 3600  # Run benchmark every hour
        
        for hour in range(int(duration_hours)):
            try:
                # Execute performance benchmark
                start_time = time.time()
                
                async with httpx.AsyncClient(timeout=30.0) as client:
                    # Test critical endpoints
                    await client.get(f"{self.config['backend_url']}/health")
                    await client.get(f"{self.config['auth_service_url']}/health")
                    
                    # Test AI processing endpoint
                    await client.post(f"{self.config['backend_url']}/agents", json={
                        "type": "benchmark",
                        "config": {"test": True}
                    })
                    
                end_time = time.time()
                
                metric = PerformanceMetrics(
                    operation="hourly_benchmark",
                    start_time=start_time,
                    end_time=end_time,
                    duration=end_time - start_time,
                    success=True
                )
                self.test_results.performance_metrics.append(metric)
                
                await asyncio.sleep(benchmark_interval)
                
            except Exception as e:
                logger.error(f"Performance benchmark failed at hour {hour}: {e}")
                
        logger.info("Performance degradation analysis completed")
        
    async def _run_cache_memory_management_test(self):
        """Test Case 6: Cache Memory Management and Eviction Policies."""
        logger.info("Starting cache memory management test")
        
        # Connect to Redis
        redis_client = redis.Redis.from_url(self.config["redis_url"], decode_responses=True)
        
        try:
            # Populate cache to near capacity
            for i in range(10000):
                await redis_client.set(f"soak_test_key_{i}", f"data_{i}" * 100)
                
                if i % 1000 == 0:
                    # Check cache stats
                    info = await redis_client.info("memory")
                    logger.info(f"Cache populated: {i} keys, memory: {info.get('used_memory_human')}")
                    
            # Sustain cache operations
            duration_hours = self.config["test_duration_hours"] * 0.5
            end_time = time.time() + (duration_hours * 3600)
            
            while time.time() < end_time:
                # Cache operations
                await redis_client.get(f"soak_test_key_{time.time() % 10000}")
                await redis_client.set(f"temp_key_{time.time()}", "temp_data")
                await asyncio.sleep(1)
                
        finally:
            # Cleanup
            await redis_client.flushdb()
            await redis_client.aclose()
            
        logger.info("Cache memory management test completed")
        
    async def _run_gc_impact_analysis(self):
        """Test Case 7: Garbage Collection Impact on System Responsiveness."""
        logger.info("Starting GC impact analysis")
        
        duration_hours = self.config["test_duration_hours"]
        end_time = time.time() + (duration_hours * 3600)
        
        while time.time() < end_time:
            # Create allocation pressure to trigger GC
            data = []
            for i in range(1000):
                data.append({"id": i, "data": "x" * 1000})
                
            # Force GC and measure impact
            start_time = time.time()
            gc.collect()
            gc_duration = time.time() - start_time
            
            if gc_duration > 0.05:  # Log GC events longer than 50ms
                logger.warning(f"Long GC cycle detected: {gc_duration:.3f}s")
                
            # Clear references
            del data
            
            await asyncio.sleep(10)
            
        logger.info("GC impact analysis completed")
        
    def _analyze_results(self):
        """Analyze test results and populate final metrics."""
        self.test_results.resource_snapshots = self.resource_monitor.snapshots
        
        # Analyze memory leaks
        leak_detected, leak_analysis = self.resource_monitor.analyze_memory_leaks()
        self.test_results.memory_leak_detected = leak_detected
        
        # Calculate performance metrics
        if self.test_results.performance_metrics:
            durations = [m.duration for m in self.test_results.performance_metrics if m.success]
            self.test_results.avg_response_time_ms = sum(durations) / len(durations) * 1000
            
            total_operations = len(self.test_results.performance_metrics)
            successful_operations = sum(1 for m in self.test_results.performance_metrics if m.success)
            self.test_results.success_rate = successful_operations / total_operations * 100
            self.test_results.error_count = total_operations - successful_operations
            
        # Calculate max memory usage
        if self.test_results.resource_snapshots:
            self.test_results.max_memory_usage_mb = max(
                s.memory_usage_mb for s in self.test_results.resource_snapshots
            )
            
        # GC efficiency
        self.test_results.gc_efficiency = self.resource_monitor._calculate_gc_efficiency()
        
        logger.info(f"Soak test analysis completed:")
        logger.info(f"  Duration: {self.test_results.total_duration_hours:.2f} hours")
        logger.info(f"  Memory leak detected: {self.test_results.memory_leak_detected}")
        logger.info(f"  Max memory usage: {self.test_results.max_memory_usage_mb:.2f} MB")
        logger.info(f"  Success rate: {self.test_results.success_rate:.2f}%")
        logger.info(f"  GC efficiency: {self.test_results.gc_efficiency:.2f}")


# Test implementations

@pytest.mark.e2e
@pytest.mark.soak
@pytest.mark.timeout(timeout=172800)  # 48 hours
async def test_memory_leak_detection_48h():
    """
    Test Case 1: Memory Leak Detection Under Sustained AI Agent Operations
    Duration: 48 hours
    """
    if not os.getenv("RUN_SOAK_TESTS", "false").lower() == "true":
        pytest.skip("Soak tests disabled (set RUN_SOAK_TESTS=true to enable)")
        
    orchestrator = SoakTestOrchestrator(SOAK_CONFIG)
    
    # Run memory leak detection specifically
    logger.info("Starting 48h memory leak detection test")
    
    resource_monitor = ResourceMonitor(60)  # Monitor every minute
    resource_monitor.start_monitoring()
    
    try:
        # Run for 48 hours with continuous agent operations
        await orchestrator._run_memory_leak_detection()
        
        # Analyze results
        leak_detected, analysis = resource_monitor.analyze_memory_leaks()
        
        # Assertions
        assert not leak_detected, f"Memory leak detected: {analysis}"
        assert analysis["growth_rate_mb_per_snapshot"] < 2.0, "Memory growth rate too high"
        assert analysis["gc_efficiency"] > 0.5, "GC efficiency too low"
        
        logger.info("Memory leak detection test PASSED")
        
    finally:
        resource_monitor.stop_monitoring()


@pytest.mark.e2e
@pytest.mark.soak
@pytest.mark.timeout(timeout=129600)  # 36 hours
async def test_websocket_connection_pool_exhaustion_36h():
    """
    Test Case 2: WebSocket Connection Pool Exhaustion and Recovery
    Duration: 36 hours
    """
    if not os.getenv("RUN_SOAK_TESTS", "false").lower() == "true":
        pytest.skip("Soak tests disabled (set RUN_SOAK_TESTS=true to enable)")
        
    websocket_stress = WebSocketStressTest(
        SOAK_CONFIG["websocket_url"],
        SOAK_CONFIG["max_concurrent_connections"]
    )
    
    try:
        # Establish connections
        await websocket_stress.establish_persistent_connections(500)
        
        # Run for 36 hours
        duration_hours = 36
        message_task = asyncio.create_task(
            websocket_stress.send_periodic_messages(60)
        )
        
        await asyncio.sleep(duration_hours * 3600)
        message_task.cancel()
        
        # Validate results
        assert len(websocket_stress.active_connections) > 450, "Too many connection failures"
        assert websocket_stress.connection_errors < 25, "Too many connection errors"
        
        logger.info("WebSocket stress test PASSED")
        
    finally:
        await websocket_stress.cleanup_connections()


@pytest.mark.e2e
@pytest.mark.soak
@pytest.mark.timeout(timeout=172800)  # 48 hours
async def test_database_connection_stability_48h():
    """
    Test Case 3: Database Connection Pool Stability Under Continuous Load
    Duration: 48 hours
    """
    if not os.getenv("RUN_SOAK_TESTS", "false").lower() == "true":
        pytest.skip("Soak tests disabled (set RUN_SOAK_TESTS=true to enable)")
        
    database_stress = DatabaseStressTest(SOAK_CONFIG["postgres_url"])
    
    # Run continuous database operations for 48 hours
    await database_stress.execute_continuous_operations(
        SOAK_CONFIG["database_ops_per_minute"],
        48.0
    )
    
    # Validate results
    error_rate = database_stress.error_count / database_stress.query_count * 100
    assert error_rate < 0.1, f"Database error rate too high: {error_rate:.2f}%"
    assert database_stress.query_count > 100000, "Insufficient query volume"
    
    logger.info(f"Database stress test PASSED: {database_stress.query_count} queries, {error_rate:.2f}% error rate")


@pytest.mark.e2e
@pytest.mark.soak
@pytest.mark.timeout(timeout=172800)  # 48 hours
async def test_log_file_growth_and_disk_management_48h():
    """
    Test Case 4: Log File Growth and Disk Space Management
    Duration: 48 hours
    """
    if not os.getenv("RUN_SOAK_TESTS", "false").lower() == "true":
        pytest.skip("Soak tests disabled (set RUN_SOAK_TESTS=true to enable)")
        
    # Monitor disk usage throughout test
    initial_disk_usage = psutil.disk_usage('/').percent
    
    duration_hours = 48
    end_time = time.time() + (duration_hours * 3600)
    
    while time.time() < end_time:
        # Generate high-volume logs
        for i in range(100):
            logger.info(f"Soak test log entry {i}: {time.time()}")
            
        # Check disk usage
        current_disk_usage = psutil.disk_usage('/').percent
        assert current_disk_usage < 90, f"Disk usage too high: {current_disk_usage}%"
        
        await asyncio.sleep(60)  # Check every minute
        
    final_disk_usage = psutil.disk_usage('/').percent
    disk_growth = final_disk_usage - initial_disk_usage
    
    assert disk_growth < 10, f"Excessive disk growth: {disk_growth}%"
    logger.info(f"Disk management test PASSED: {disk_growth:.1f}% growth")


@pytest.mark.e2e
@pytest.mark.soak
@pytest.mark.timeout(timeout=172800)  # 48 hours
async def test_performance_degradation_analysis_48h():
    """
    Test Case 5: Performance Degradation Curve Analysis
    Duration: 48 hours
    """
    if not os.getenv("RUN_SOAK_TESTS", "false").lower() == "true":
        pytest.skip("Soak tests disabled (set RUN_SOAK_TESTS=true to enable)")
        
    orchestrator = SoakTestOrchestrator(SOAK_CONFIG)
    
    # Run performance analysis
    await orchestrator._run_performance_degradation_analysis()
    
    # Analyze performance metrics
    benchmarks = [m for m in orchestrator.test_results.performance_metrics if m.operation == "hourly_benchmark"]
    
    if len(benchmarks) > 1:
        initial_duration = benchmarks[0].duration
        final_duration = benchmarks[-1].duration
        degradation = (final_duration - initial_duration) / initial_duration * 100
        
        assert degradation < 25, f"Performance degradation too high: {degradation:.1f}%"
        logger.info(f"Performance analysis PASSED: {degradation:.1f}% degradation over 48h")


@pytest.mark.e2e
@pytest.mark.soak
@pytest.mark.timeout(timeout=86400)  # 24 hours
async def test_cache_memory_management_24h():
    """
    Test Case 6: Cache Memory Management and Eviction Policies
    Duration: 24 hours
    """
    if not os.getenv("RUN_SOAK_TESTS", "false").lower() == "true":
        pytest.skip("Soak tests disabled (set RUN_SOAK_TESTS=true to enable)")
        
    orchestrator = SoakTestOrchestrator(SOAK_CONFIG)
    
    # Run cache management test
    await orchestrator._run_cache_memory_management_test()
    
    # Test passes if no exceptions occurred
    logger.info("Cache memory management test PASSED")


@pytest.mark.e2e
@pytest.mark.soak
@pytest.mark.timeout(timeout=129600)  # 36 hours
async def test_gc_impact_analysis_36h():
    """
    Test Case 7: Garbage Collection Impact on System Responsiveness
    Duration: 36 hours
    """
    if not os.getenv("RUN_SOAK_TESTS", "false").lower() == "true":
        pytest.skip("Soak tests disabled (set RUN_SOAK_TESTS=true to enable)")
        
    orchestrator = SoakTestOrchestrator(SOAK_CONFIG)
    
    # Run GC impact analysis
    await orchestrator._run_gc_impact_analysis()
    
    # Test passes if no critical GC pauses detected
    logger.info("GC impact analysis test PASSED")


@pytest.mark.e2e
@pytest.mark.soak
@pytest.mark.timeout(timeout=172800)  # 48 hours
async def test_complete_soak_test_suite_48h():
    """
    Complete Soak Test Suite - All scenarios running concurrently
    Duration: 48 hours
    
    This is the master soak test that runs all scenarios simultaneously
    to provide comprehensive long-term stability validation.
    """
    if not os.getenv("RUN_COMPLETE_SOAK_TEST", "false").lower() == "true":
        pytest.skip("Complete soak test disabled (set RUN_COMPLETE_SOAK_TEST=true to enable)")
        
    logger.info("Starting complete 48-hour soak test suite")
    
    orchestrator = SoakTestOrchestrator(SOAK_CONFIG)
    results = await orchestrator.run_complete_soak_test()
    
    # Comprehensive validation
    assert not results.memory_leak_detected, "Memory leak detected during soak test"
    assert results.success_rate > 99.0, f"Success rate too low: {results.success_rate:.2f}%"
    assert results.error_count < 100, f"Too many errors: {results.error_count}"
    assert results.max_memory_usage_mb < 2000, f"Memory usage too high: {results.max_memory_usage_mb:.2f}MB"
    assert results.gc_efficiency > 0.3, f"GC efficiency too low: {results.gc_efficiency:.2f}"
    
    logger.info("Complete soak test suite PASSED - System demonstrates long-term stability")
    
    # Generate detailed report
    report = {
        "test_duration_hours": results.total_duration_hours,
        "memory_leak_detected": results.memory_leak_detected,
        "max_memory_usage_mb": results.max_memory_usage_mb,
        "success_rate_percent": results.success_rate,
        "total_errors": results.error_count,
        "gc_efficiency": results.gc_efficiency,
        "total_snapshots": len(results.resource_snapshots),
        "total_operations": len(results.performance_metrics)
    }
    
    # Save detailed results for analysis
    with open("soak_test_results.json", "w") as f:
        json.dump(report, f, indent=2, default=str)
        
    return results