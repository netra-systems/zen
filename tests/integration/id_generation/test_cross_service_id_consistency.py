"""PHASE 2: CROSS-SERVICE ID CONSISTENCY VALIDATION TESTS

Issue #841: SSOT-ID-Generation-Incomplete-Migration-Authentication-WebSocket-Factories

INTEGRATION PRIORITY: These tests validate cross-service ID consistency after SSOT migration.
Tests should PASS after successful UnifiedIdGenerator implementation across all services.

Post-Migration Validation:
- Auth service and backend service use consistent ID patterns
- WebSocket and auth services maintain ID correlation
- Factory services generate compatible client IDs
- Audit trails maintain cross-service traceability

Business Value Protection: $500K+ ARR Golden Path cross-service integration
"""
import pytest
import re
import time
from unittest.mock import patch, MagicMock, AsyncMock
from typing import Dict, Any, List, Tuple, Optional
from test_framework.ssot.base_test_case import SSotBaseTestCase
from shared.id_generation.unified_id_generator import UnifiedIdGenerator

@pytest.mark.integration
class CrossServiceIdConsistencyTests(SSotBaseTestCase):
    """Integration tests validating cross-service ID consistency after SSOT migration"""

    def test_auth_service_backend_id_correlation_post_migration(self):
        """INTEGRATION: Verify auth service and backend maintain ID correlation

        This test validates that IDs generated by the auth service are properly
        correlated with backend service operations after SSOT migration.

        Expected Behavior: POST-MIGRATION SUCCESS
        Validates: Session IDs from auth service correlate with backend operations
        """
        unified_generator = UnifiedIdGenerator()
        auth_user_id = 'cross_service_user_123'
        auth_request_id = 'auth_request_456'
        auth_session_id = unified_generator.generate_session_id(user_id=auth_user_id, request_id=auth_request_id)
        backend_connection_id = unified_generator.generate_connection_id(user_id=auth_user_id, session_id=auth_session_id)
        backend_redis_client_id = unified_generator.generate_client_id(service_type='redis', user_id=auth_user_id, request_id=auth_request_id)

        def extract_user_context(id_string: str) -> str:
            """Extract user context for correlation analysis"""
            parts = id_string.split('_')
            if len(parts) >= 2:
                return parts[1]
            return 'unknown'
        auth_user_context = extract_user_context(auth_session_id)
        backend_conn_user_context = extract_user_context(backend_connection_id)
        backend_client_user_context = extract_user_context(backend_redis_client_id)
        assert auth_user_context == 'cross', f"AUTH USER CONTEXT ERROR: Expected 'cross' from user_id, got '{auth_user_context}'"
        assert backend_conn_user_context == 'cross', f"BACKEND CONNECTION CONTEXT ERROR: Expected 'cross', got '{backend_conn_user_context}'"
        assert backend_client_user_context == 'cross', f"BACKEND CLIENT CONTEXT ERROR: Expected 'cross', got '{backend_client_user_context}'"

        def extract_timestamp(id_string: str) -> int:
            parts = id_string.split('_')
            for part in parts:
                if part.isdigit() and len(part) >= 10:
                    return int(part)
            return 0
        auth_timestamp = extract_timestamp(auth_session_id)
        backend_conn_timestamp = extract_timestamp(backend_connection_id)
        backend_client_timestamp = extract_timestamp(backend_redis_client_id)
        assert auth_timestamp > 0, 'AUTH TIMESTAMP MISSING'
        assert backend_conn_timestamp > 0, 'BACKEND CONNECTION TIMESTAMP MISSING'
        assert backend_client_timestamp > 0, 'BACKEND CLIENT TIMESTAMP MISSING'
        max_timestamp = max(auth_timestamp, backend_conn_timestamp, backend_client_timestamp)
        min_timestamp = min(auth_timestamp, backend_conn_timestamp, backend_client_timestamp)
        timestamp_range = max_timestamp - min_timestamp
        assert timestamp_range <= 5, f'CROSS-SERVICE TIMESTAMP CORRELATION FAILURE: {timestamp_range}s range exceeds 5s limit'
        print(f'\n✅ AUTH-BACKEND ID CORRELATION SUCCESS:')
        print(f'   ✓ Auth Session:      {auth_session_id}')
        print(f'   ✓ Backend Connection: {backend_connection_id}')
        print(f'   ✓ Backend Client:     {backend_redis_client_id}')
        print(f'   ✓ User context consistent across all services')
        print(f'   ✓ Timestamp correlation within {timestamp_range}s')
        print(f'   Status: Cross-service ID correlation validated')

    def test_websocket_auth_integration_id_consistency_post_migration(self):
        """INTEGRATION: Verify WebSocket and auth services maintain ID consistency

        This test validates that WebSocket connection IDs properly integrate
        with auth service session IDs after SSOT migration.

        Expected Behavior: POST-MIGRATION SUCCESS
        Validates: WebSocket connection IDs correlate with auth session IDs
        """
        unified_generator = UnifiedIdGenerator()
        websocket_user_id = 'ws_integration_user_789'
        websocket_request_id = 'ws_request_012'
        auth_session_id = unified_generator.generate_session_id(user_id=websocket_user_id, request_id=websocket_request_id)
        websocket_connection_id = unified_generator.generate_connection_id(user_id=websocket_user_id, session_id=auth_session_id)
        websocket_audit_id = unified_generator.generate_audit_id(record_type='websocket', user_id=websocket_user_id, resource_id=websocket_connection_id)
        connection_parts = websocket_connection_id.split('_')
        session_referenced = False
        for part in connection_parts:
            if 'session' in part.lower() or auth_session_id.split('_')[-1] in part:
                session_referenced = True
                break

        def extract_user_prefix(id_string: str) -> str:
            parts = id_string.split('_')
            if len(parts) >= 2:
                return parts[1].split('-')[0]
            return 'unknown'
        auth_user_prefix = extract_user_prefix(auth_session_id)
        websocket_user_prefix = extract_user_prefix(websocket_connection_id)
        audit_user_prefix = extract_user_prefix(websocket_audit_id)
        assert auth_user_prefix == websocket_user_prefix, f"USER CONSISTENCY FAILURE: Auth '{auth_user_prefix}' != WebSocket '{websocket_user_prefix}'"
        assert websocket_user_prefix == audit_user_prefix, f"AUDIT CONSISTENCY FAILURE: WebSocket '{websocket_user_prefix}' != Audit '{audit_user_prefix}'"
        assert auth_session_id.startswith('sess_'), f'AUTH PREFIX ERROR: {auth_session_id}'
        assert websocket_connection_id.startswith('conn_'), f'WEBSOCKET PREFIX ERROR: {websocket_connection_id}'
        assert websocket_audit_id.startswith('audit_'), f'AUDIT PREFIX ERROR: {websocket_audit_id}'
        all_ids = [auth_session_id, websocket_connection_id, websocket_audit_id]
        unique_ids = set(all_ids)
        assert len(unique_ids) == 3, f'ID UNIQUENESS FAILURE: Generated {len(unique_ids)}/3 unique IDs'
        print(f'\n✅ WEBSOCKET-AUTH INTEGRATION CONSISTENCY SUCCESS:')
        print(f'   ✓ Auth Session:    {auth_session_id}')
        print(f'   ✓ WS Connection:   {websocket_connection_id}')
        print(f'   ✓ WS Audit:        {websocket_audit_id}')
        print(f"   ✓ User context consistent: '{auth_user_prefix}'")
        print(f'   ✓ Service prefixes correct')
        print(f'   ✓ All IDs unique')
        print(f'   Status: WebSocket-Auth integration consistency validated')

    def test_factory_services_client_id_coordination_post_migration(self):
        """INTEGRATION: Verify factory services generate coordinated client IDs

        This test validates that Redis and ClickHouse factory services generate
        client IDs that can be properly coordinated for the same user operations.

        Expected Behavior: POST-MIGRATION SUCCESS
        Validates: Factory client IDs enable proper resource coordination
        """
        unified_generator = UnifiedIdGenerator()
        factory_user_id = 'factory_coord_user_345'
        factory_request_id = 'factory_request_678'
        redis_client_id = unified_generator.generate_client_id(service_type='redis', user_id=factory_user_id, request_id=factory_request_id)
        clickhouse_client_id = unified_generator.generate_client_id(service_type='clickhouse', user_id=factory_user_id, request_id=factory_request_id)
        redis_cache_client_id = unified_generator.generate_client_id(service_type='redis', user_id=factory_user_id, request_id=f'{factory_request_id}_cache')
        clickhouse_analytics_client_id = unified_generator.generate_client_id(service_type='clickhouse', user_id=factory_user_id, request_id=f'{factory_request_id}_analytics')
        all_client_ids = [redis_client_id, clickhouse_client_id, redis_cache_client_id, clickhouse_analytics_client_id]
        client_pattern = re.compile('^client_[a-z]+_[a-zA-Z0-9_]+_[a-zA-Z0-9_]+_\\d+_[a-f0-9]{8}$')
        for client_id in all_client_ids:
            assert client_pattern.match(client_id), f"CLIENT FORMAT ERROR: '{client_id}' doesn't match SSOT pattern"

        def extract_service_type(client_id: str) -> str:
            parts = client_id.split('_')
            if len(parts) >= 2 and parts[0] == 'client':
                return parts[1]
            return 'unknown'
        service_types = [extract_service_type(cid) for cid in all_client_ids]
        expected_services = ['redis', 'clickhouse', 'redis', 'clickhouse']
        assert service_types == expected_services, f'SERVICE TYPE COORDINATION ERROR: Expected {expected_services}, got {service_types}'

        def extract_user_context(client_id: str) -> str:
            parts = client_id.split('_')
            if len(parts) >= 3 and parts[0] == 'client':
                return parts[2]
            return 'unknown'
        user_contexts = [extract_user_context(cid) for cid in all_client_ids]
        expected_user_context = 'factory'
        for user_context in user_contexts:
            assert user_context == expected_user_context, f"USER COORDINATION ERROR: Expected '{expected_user_context}', got '{user_context}'"

        def extract_request_info(client_id: str) -> str:
            parts = client_id.split('_')
            if len(parts) >= 4 and parts[0] == 'client':
                return parts[3]
            return 'unknown'
        request_infos = [extract_request_info(cid) for cid in all_client_ids]
        assert request_infos[0] == 'factory', f'REQUEST CORRELATION ERROR: {request_infos[0]}'
        assert request_infos[1] == 'factory', f'REQUEST CORRELATION ERROR: {request_infos[1]}'
        unique_client_ids = set(all_client_ids)
        assert len(unique_client_ids) == 4, f'CLIENT ID UNIQUENESS FAILURE: Generated {len(unique_client_ids)}/4 unique IDs'
        print(f'\n✅ FACTORY SERVICES COORDINATION SUCCESS:')
        print(f'   ✓ Redis Primary:    {redis_client_id}')
        print(f'   ✓ ClickHouse Primary: {clickhouse_client_id}')
        print(f'   ✓ Redis Cache:      {redis_cache_client_id}')
        print(f'   ✓ ClickHouse Analytics: {clickhouse_analytics_client_id}')
        print(f'   ✓ Service types: {service_types}')
        print(f"   ✓ User contexts consistent: '{expected_user_context}'")
        print(f'   ✓ All {len(unique_client_ids)} client IDs unique')
        print(f'   Status: Factory services coordination validated')

    def test_audit_trail_cross_service_traceability_post_migration(self):
        """INTEGRATION: Verify audit trails maintain cross-service traceability

        This test validates that audit records can trace operations across
        multiple services using consistent ID patterns after SSOT migration.

        Expected Behavior: POST-MIGRATION SUCCESS
        Validates: Audit trails enable cross-service operation tracing
        """
        unified_generator = UnifiedIdGenerator()
        trace_user_id = 'trace_user_901'
        trace_request_id = 'trace_request_234'
        auth_session_id = unified_generator.generate_session_id(user_id=trace_user_id, request_id=trace_request_id)
        auth_audit_id = unified_generator.generate_audit_id(record_type='auth', user_id=trace_user_id, resource_id=auth_session_id)
        websocket_connection_id = unified_generator.generate_connection_id(user_id=trace_user_id, session_id=auth_session_id)
        websocket_audit_id = unified_generator.generate_audit_id(record_type='websocket', user_id=trace_user_id, resource_id=websocket_connection_id)
        redis_client_id = unified_generator.generate_client_id(service_type='redis', user_id=trace_user_id, request_id=trace_request_id)
        clickhouse_client_id = unified_generator.generate_client_id(service_type='clickhouse', user_id=trace_user_id, request_id=trace_request_id)
        data_audit_id = unified_generator.generate_audit_id(record_type='data', user_id=trace_user_id, resource_id=f'{redis_client_id}|{clickhouse_client_id}')
        trace_chain = {'auth_session': auth_session_id, 'auth_audit': auth_audit_id, 'websocket_connection': websocket_connection_id, 'websocket_audit': websocket_audit_id, 'redis_client': redis_client_id, 'clickhouse_client': clickhouse_client_id, 'data_audit': data_audit_id}

        def extract_user_context(id_string: str) -> str:
            parts = id_string.split('_')
            if len(parts) >= 2:
                user_part = parts[1]
                return user_part.split('-')[0]
            return 'unknown'
        user_contexts = {}
        for service, id_string in trace_chain.items():
            user_context = extract_user_context(id_string)
            user_contexts[service] = user_context
        expected_user_context = 'trace'
        for service, user_context in user_contexts.items():
            assert user_context == expected_user_context, f"TRACEABILITY USER CONTEXT ERROR: {service} has '{user_context}', expected '{expected_user_context}'"

        def extract_timestamp(id_string: str) -> int:
            parts = id_string.split('_')
            for part in parts:
                if part.isdigit() and len(part) >= 10:
                    return int(part)
            return 0
        timestamps = {}
        for service, id_string in trace_chain.items():
            timestamp = extract_timestamp(id_string)
            timestamps[service] = timestamp
            assert timestamp > 0, f'TIMESTAMP MISSING: {service} - {id_string}'
        auth_time = timestamps['auth_session']
        websocket_time = timestamps['websocket_connection']
        data_time = timestamps['redis_client']
        time_range = max(timestamps.values()) - min(timestamps.values())
        assert time_range <= 30, f'TRACEABILITY TIME RANGE ERROR: {time_range}s exceeds 30s operation window'
        service_prefixes = {'auth_session': 'sess', 'auth_audit': 'audit', 'websocket_connection': 'conn', 'websocket_audit': 'audit', 'redis_client': 'client', 'clickhouse_client': 'client', 'data_audit': 'audit'}
        for service, id_string in trace_chain.items():
            expected_prefix = service_prefixes[service]
            actual_prefix = id_string.split('_')[0]
            assert actual_prefix == expected_prefix, f"SERVICE PREFIX ERROR: {service} has '{actual_prefix}', expected '{expected_prefix}'"
        all_trace_ids = list(trace_chain.values())
        unique_trace_ids = set(all_trace_ids)
        assert len(unique_trace_ids) == len(all_trace_ids), f'TRACE UNIQUENESS FAILURE: Generated {len(unique_trace_ids)}/{len(all_trace_ids)} unique IDs'
        print(f'\n✅ CROSS-SERVICE AUDIT TRACEABILITY SUCCESS:')
        print(f'   ✓ Operation sequence traced across {len(trace_chain)} services')
        for service, id_string in trace_chain.items():
            print(f'   ✓ {service:20} -> {id_string}')
        print(f"   ✓ User context '{expected_user_context}' consistent across all services")
        print(f'   ✓ Timestamp correlation within {time_range}s window')
        print(f'   ✓ All {len(unique_trace_ids)} trace IDs unique')
        print(f'   Status: Cross-service audit traceability validated')
if __name__ == '__main__':
    'MIGRATED: Use SSOT unified test runner'
    print('MIGRATION NOTICE: Please use SSOT unified test runner')
    print('Command: python tests/unified_test_runner.py --category <category>')