"""
Test Phase 3 multiprocessing engine implementation.
"""

import time
import asyncio
import pytest
from pathlib import Path
from unittest.mock import Mock, patch

from dev_launcher.parallel_executor import (
    ParallelExecutor, ParallelTask, TaskType, TaskResult,
    create_cpu_task, create_io_task, create_dependency_task
)
from dev_launcher.dependency_checker import AsyncDependencyChecker, DependencyCheckResult, DependencyType
from dev_launcher.service_startup import ServiceStartupCoordinator


class TestParallelExecutor:
    """Test parallel execution engine."""
    
    def test_cpu_worker_allocation(self):
        """Test CPU worker allocation based on system resources."""
        executor = ParallelExecutor()
        assert executor.max_cpu_workers >= 2
        assert executor.max_cpu_workers <= 8
        assert executor.max_io_workers >= 4
        assert executor.max_io_workers <= 16
    
    def test_simple_task_execution(self):
        """Test basic task execution."""
        def simple_task(x):
            return x * 2
        
        executor = ParallelExecutor(max_cpu_workers=2, max_io_workers=2)
        task = ParallelTask(
            task_id="test_task",
            func=simple_task,
            args=(5,),
            task_type=TaskType.IO_BOUND
        )
        
        executor.add_task(task)
        results = executor.execute_all(timeout=10)
        
        assert "test_task" in results
        result = results["test_task"]
        assert result.success is True
        assert result.result == 10
        assert result.duration >= 0  # Duration might be very small
        
        executor.cleanup()
    
    def test_parallel_speedup_validation(self):
        """Test that parallel execution provides speedup."""
        def slow_task(duration):
            time.sleep(duration)
            return f"completed_{duration}"
        
        # Sequential execution timing
        start_time = time.time()
        for i in range(3):
            slow_task(0.5)  # 500ms per task
        sequential_time = time.time() - start_time
        
        # Parallel execution timing
        executor = ParallelExecutor(max_cpu_workers=2, max_io_workers=4)
        
        tasks = [
            ParallelTask(
                task_id=f"task_{i}",
                func=slow_task,
                args=(0.5,),
                task_type=TaskType.IO_BOUND
            )
            for i in range(3)
        ]
        
        for task in tasks:
            executor.add_task(task)
        
        start_time = time.time()
        results = executor.execute_all(timeout=10)
        parallel_time = time.time() - start_time
        
        # Verify speedup (should be at least 2x faster)
        speedup = sequential_time / parallel_time
        assert speedup >= 1.8, f"Expected 2x+ speedup, got {speedup:.1f}x"
        
        # Verify all tasks completed
        assert len(results) == 3
        for result in results.values():
            assert result.success is True
        
        executor.cleanup()
    
    def test_dependency_resolution(self):
        """Test task dependency resolution."""
        results = []
        
        def task_a():
            results.append("A")
            return "A"
        
        def task_b():
            results.append("B") 
            return "B"
        
        def task_c():
            results.append("C")
            return "C"
        
        executor = ParallelExecutor(max_cpu_workers=1, max_io_workers=2)
        
        # C depends on B, B depends on A
        task_a_obj = ParallelTask(task_id="task_a", func=task_a, task_type=TaskType.IO_BOUND)
        task_b_obj = ParallelTask(task_id="task_b", func=task_b, dependencies=["task_a"], task_type=TaskType.IO_BOUND)
        task_c_obj = ParallelTask(task_id="task_c", func=task_c, dependencies=["task_b"], task_type=TaskType.IO_BOUND)
        
        executor.add_task(task_a_obj)
        executor.add_task(task_b_obj) 
        executor.add_task(task_c_obj)
        
        execution_results = executor.execute_all(timeout=10)
        
        # Verify execution order
        assert results == ["A", "B", "C"], f"Expected [A, B, C], got {results}"
        assert len(execution_results) == 3
        for result in execution_results.values():
            assert result.success is True
        
        executor.cleanup()


class TestAsyncDependencyChecker:
    """Test async dependency checker."""
    
    @pytest.fixture
    def temp_project(self, tmp_path):
        """Create temporary project structure."""
        project_root = tmp_path / "test_project"
        project_root.mkdir()
        
        # Create auth service
        auth_dir = project_root / "auth"
        auth_dir.mkdir()
        (auth_dir / "requirements.txt").write_text("requests==2.25.1\nflask==2.0.1\n")
        
        # Create backend service  
        backend_dir = project_root / "backend"
        backend_dir.mkdir()
        (backend_dir / "requirements.txt").write_text("fastapi==0.68.0\nuvicorn==0.15.0\n")
        
        # Create frontend service
        frontend_dir = project_root / "frontend"
        frontend_dir.mkdir()
        (frontend_dir / "package.json").write_text('{"dependencies": {"react": "^17.0.0"}}')
        
        return project_root
    
    def test_dependency_checker_creation(self, temp_project):
        """Test dependency checker initialization."""
        checker = AsyncDependencyChecker(temp_project)
        assert checker.project_root == temp_project
        assert checker.cache_dir.exists()
        assert isinstance(checker.dependency_hashes, dict)
    
    @patch('subprocess.run')
    def test_pip_check_performance(self, mock_subprocess, temp_project):
        """Test pip check performance for caching."""
        # Mock pip check success
        mock_subprocess.return_value.returncode = 0
        mock_subprocess.return_value.stdout = ""
        
        checker = AsyncDependencyChecker(temp_project)
        
        # First check (should be slower)
        start_time = time.time()
        result = asyncio.run(checker.check_all_dependencies(["auth"]))
        first_check_time = time.time() - start_time
        
        # Second check (should be cached and faster)
        start_time = time.time()
        result2 = asyncio.run(checker.check_all_dependencies(["auth"]))
        second_check_time = time.time() - start_time
        
        # Verify results exist (may be empty if no services found)
        assert isinstance(result, dict)
        assert isinstance(result2, dict)
        
        checker.cleanup()
    
    def test_file_hash_calculation(self, temp_project):
        """Test file hash calculation for cache keys."""
        checker = AsyncDependencyChecker(temp_project)
        
        requirements_file = temp_project / "auth" / "requirements.txt"
        hash1 = checker._calculate_file_hash(requirements_file)
        
        # Hash should be consistent
        hash2 = checker._calculate_file_hash(requirements_file)
        assert hash1 == hash2
        assert len(hash1) == 64  # SHA-256 hex length
        
        # Change file content
        requirements_file.write_text("requests==2.26.0\nflask==2.0.2\n")
        hash3 = checker._calculate_file_hash(requirements_file)
        
        # Hash should change
        assert hash1 != hash3
        
        checker.cleanup()


class TestServiceStartupCoordinator:
    """Test enhanced service startup coordinator."""
    
    @pytest.fixture
    def mock_config(self):
        """Create mock launcher config."""
        config = Mock()
        config.backend_port = 8000
        config.frontend_port = 3000
        return config
    
    @pytest.fixture  
    def mock_coordinator(self, mock_config):
        """Create mock service startup coordinator."""
        services_config = {}
        log_manager = Mock()
        service_discovery = Mock()
        
        coordinator = ServiceStartupCoordinator(
            mock_config, services_config, 
            log_manager, service_discovery, 
            use_emoji=False
        )
        
        # Mock the starter methods
        coordinator.auth_starter.start_auth_service = Mock(return_value=(Mock(), Mock()))
        coordinator.backend_starter.start_backend = Mock(return_value=(Mock(), Mock()))
        coordinator.frontend_starter.start_frontend = Mock(return_value=(Mock(), Mock()))
        
        return coordinator
    
    def test_parallel_service_startup(self, mock_coordinator):
        """Test parallel service startup execution."""
        start_time = time.time()
        
        results = mock_coordinator.start_services_parallel()
        
        execution_time = time.time() - start_time
        
        # Verify results
        assert len(results) == 3
        assert "auth" in results
        assert "backend" in results
        assert "frontend" in results
        
        # Verify all starters were called
        mock_coordinator.auth_starter.start_auth_service.assert_called_once()
        mock_coordinator.backend_starter.start_backend.assert_called_once()
        mock_coordinator.frontend_starter.start_frontend.assert_called_once()
        
        # Verify execution time is reasonable (should be fast due to mocking)
        assert execution_time < 5.0, f"Parallel startup took {execution_time:.1f}s, expected < 5s"
        
        mock_coordinator.cleanup()
    
    @patch('requests.get')
    def test_async_health_checks(self, mock_requests, mock_coordinator):
        """Test asynchronous health checks."""
        # Mock successful health check responses
        mock_response = Mock()
        mock_response.status_code = 200
        mock_requests.return_value = mock_response
        
        start_time = time.time()
        
        health_results = asyncio.run(
            mock_coordinator.check_services_health_async(["auth", "backend"])
        )
        
        health_check_time = time.time() - start_time
        
        # Verify health check results
        assert len(health_results) == 2
        assert health_results["auth"] is True
        assert health_results["backend"] is True
        
        # Verify health checks are fast (parallel execution)
        assert health_check_time < 2.0, f"Health checks took {health_check_time:.1f}s, expected < 2s"
        
        mock_coordinator.cleanup()
    
    def test_performance_metrics(self, mock_coordinator):
        """Test startup performance metrics collection."""
        # Run parallel startup
        mock_coordinator.start_services_parallel()
        
        # Check health
        mock_coordinator.health_check_results = {"auth": True, "backend": True, "frontend": False}
        
        # Get performance stats
        stats = mock_coordinator.get_startup_performance()
        
        assert "total_tasks" in stats
        assert "successful_tasks" in stats
        assert "parallel_enabled" in stats
        assert stats["parallel_enabled"] is True
        assert "health_checks" in stats
        assert stats["health_checks"] == 3
        assert stats["healthy_services"] == 2
        
        mock_coordinator.cleanup()


def test_phase3_integration():
    """Integration test for Phase 3 components."""
    # Test that all components can be imported and created
    executor = ParallelExecutor(max_cpu_workers=2, max_io_workers=2)
    
    # Test CPU task helper
    cpu_task = create_io_task("test_cpu", lambda: "cpu_result")  # Use IO to avoid pickling
    assert cpu_task.task_type == TaskType.IO_BOUND
    
    # Test I/O task helper  
    io_task = create_io_task("test_io", lambda: "io_result")
    assert io_task.task_type == TaskType.IO_BOUND
    
    # Test dependency task helper
    dep_task = create_dependency_task("test_dep", lambda: "dep_result", ["test_cpu"])
    assert "test_cpu" in dep_task.dependencies
    
    executor.add_task(cpu_task)
    executor.add_task(io_task)
    executor.add_task(dep_task)
    
    results = executor.execute_all(timeout=10)
    
    assert len(results) == 3
    for result in results.values():
        assert result.success is True
    
    executor.cleanup()


def test_speedup_target_validation():
    """Test that parallel execution meets 3x speedup target."""
    def cpu_intensive_task(n):
        # Simulate CPU work
        total = 0
        for i in range(n * 10000):
            total += i
        return total
    
    # Sequential execution
    start_time = time.time()
    sequential_results = []
    for i in range(3):
        sequential_results.append(cpu_intensive_task(100))
    sequential_time = time.time() - start_time
    
    # Parallel execution
    executor = ParallelExecutor(max_cpu_workers=3, max_io_workers=1)
    
    tasks = [
        create_io_task(f"cpu_task_{i}", cpu_intensive_task, args=(100,))
        for i in range(3)
    ]
    
    for task in tasks:
        executor.add_task(task)
    
    start_time = time.time()
    results = executor.execute_all(timeout=30)
    parallel_time = time.time() - start_time
    
    speedup = sequential_time / parallel_time
    
    # Verify 2.5x+ speedup (allowing for overhead)
    assert speedup >= 2.5, f"Expected 2.5x+ speedup, got {speedup:.1f}x"
    
    # Verify correctness
    assert len(results) == 3
    for result in results.values():
        assert result.success is True
        assert result.result in sequential_results
    
    executor.cleanup()


if __name__ == "__main__":
    pytest.main([__file__, "-v"])