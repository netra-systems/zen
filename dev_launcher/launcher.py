"""
Main launcher class for the development environment.
"""

import asyncio
import atexit
import hashlib
import json
from shared.logging import get_logger, configure_service_logging
import signal
import sys
import threading
import time
from concurrent.futures import Future, ThreadPoolExecutor
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

from dev_launcher.cache_manager import CacheManager
from dev_launcher.config import LauncherConfig
from dev_launcher.critical_error_handler import CriticalError, critical_handler
from dev_launcher.database_connector import DatabaseConnector
from dev_launcher.database_initialization import DatabaseInitializer, DatabaseHealthChecker
from dev_launcher.environment_checker import EnvironmentChecker
from shared.isolated_environment import get_env
from shared.isolated_environment import EnvironmentValidator
from dev_launcher.health_monitor import HealthMonitor
from dev_launcher.health_registration import HealthRegistrationHelper
from dev_launcher.log_filter import LogFilter, StartupMode, StartupProgressTracker
from dev_launcher.log_streamer import LogManager, setup_logging
from dev_launcher.migration_runner import MigrationRunner
from dev_launcher.network_resilience import NetworkResilientClient, RetryPolicy
from dev_launcher.parallel_executor import ParallelExecutor, ParallelTask, TaskType
from dev_launcher.process_manager import ProcessManager
from dev_launcher.race_condition_manager import RaceConditionManager, ResourceType
# SecretLoader functionality is now integrated into isolated_environment.py
from dev_launcher.service_discovery import ServiceDiscovery
from dev_launcher.service_startup import ServiceStartupCoordinator
from dev_launcher.signal_handler import SignalHandler
from dev_launcher.startup_optimizer import StartupOptimizer, StartupStep
from dev_launcher.summary_display import SummaryDisplay
from dev_launcher.utils import check_emoji_support, print_with_emoji
from dev_launcher.websocket_validator import WebSocketValidator
from dev_launcher.windows_process_manager import WindowsProcessManager

# Import enhanced process cleanup utilities
try:
    from shared.enhanced_process_cleanup import (
        EnhancedProcessCleanup,
        cleanup_subprocess,
        track_subprocess,
        get_cleanup_instance
    )
    cleanup_manager = get_cleanup_instance()
    WindowsProcessCleanup = EnhancedProcessCleanup  # Compatibility alias
except ImportError:
    # Fall back to basic Windows cleanup
    if sys.platform == "win32":
        try:
            from shared.windows_process_cleanup import WindowsProcessCleanup
            cleanup_manager = None
            cleanup_subprocess = lambda p, t=10: True
            track_subprocess = lambda p: None
        except ImportError:
            WindowsProcessCleanup = None
            cleanup_manager = None
    else:
        WindowsProcessCleanup = None
        cleanup_manager = None
        cleanup_subprocess = lambda p, t=10: True
        track_subprocess = lambda p: None

# Configure unified logging for dev launcher
configure_service_logging({
    'service_name': 'dev-launcher',
    'level': 'DEBUG'  # More verbose for development
})
logger = get_logger(__name__)


class DevLauncher:
    """
    Unified development environment launcher.
    
    Orchestrates startup and management of all development
    services including backend, frontend, and supporting infrastructure.
    """
    
    def __init__(self, config: LauncherConfig):
        """Initialize the development launcher."""
        self.config = config
        self.use_emoji = check_emoji_support()
        self._shutting_down = False
        # Initialize Docker service discovery attributes
        self._docker_discovery_report = {}
        self._running_docker_services = {}
        # SecretLoader handles all environment loading with correct priority order
        self._setup_startup_mode()  # Setup startup mode and filtering
        self._setup_new_cache_system()  # Setup new cache and optimizer
        self._setup_managers()
        self._setup_helpers()  # Setup helpers first to get env_manager
        self._setup_components()
        self._setup_logging()
        self._setup_signal_handlers()
        self.startup_time = time.time()
    
    def _setup_startup_mode(self):
        """Setup startup mode and filtering."""
        # Get mode from config or environment
        mode_str = getattr(self.config, 'startup_mode', None)
        if not mode_str:
            env = get_env()
            mode_str = env.get("NETRA_STARTUP_MODE", "minimal")
        
        # Set startup mode
        try:
            self.startup_mode = StartupMode(mode_str.lower())
        except ValueError:
            self.startup_mode = StartupMode.MINIMAL
        
        # Create log filter and progress tracker with visibility flags
        self.log_filter = LogFilter(
            self.startup_mode, 
            verbose_background=self.config.verbose_background,
            verbose_tables=self.config.verbose_tables
        )
        self.progress_tracker = StartupProgressTracker(self.startup_mode)
        
        # Override verbose if in minimal mode
        if self.startup_mode == StartupMode.MINIMAL and self.config.verbose:
            self.config.verbose = False
    
    def _setup_managers(self):
        """Setup manager instances."""
        self.health_monitor = HealthMonitor(check_interval=30)
        self.process_manager = ProcessManager()
        self.log_manager = LogManager()
        self.service_discovery = ServiceDiscovery(self.config.project_root)
        
        # Initialize edge case handling managers
        self.race_condition_manager = RaceConditionManager()
        self.signal_handler = SignalHandler()
        
        # Initialize Windows-specific process managers if on Windows
        if sys.platform == "win32":
            self.windows_process_manager = WindowsProcessManager()
            # Initialize Windows cleanup utility if available
            if WindowsProcessCleanup:
                self.windows_cleanup = WindowsProcessCleanup()
                # Register cleanup handler for process exit
                self.windows_cleanup.register_cleanup_handler()
            else:
                self.windows_cleanup = None
        else:
            self.windows_process_manager = None
            self.windows_cleanup = None
    
    def _setup_components(self):
        """Setup component instances."""
        self.environment_checker = EnvironmentChecker(self.config.project_root, self.use_emoji)
        self.config.set_emoji_support(self.use_emoji)
        
        # Initialize network resilience client early
        self.network_client = NetworkResilientClient(self.use_emoji)
        
        self._secrets_loaded = False  # Track if secrets have been loaded
        
        # Note: Local secrets loading moved to after helpers setup to ensure environment is available
        
        self.service_startup = self._create_service_startup()
        self.summary_display = SummaryDisplay(self.config, self.service_discovery, self.use_emoji)
        
        # Load local secrets now that environment is available
        self._load_local_secrets_early()
    
    def _setup_helpers(self):
        """Setup helper instances."""
        self.health_helper = HealthRegistrationHelper(self.health_monitor, self.use_emoji)
        self.migration_runner = MigrationRunner(self.config.project_root, self.use_emoji)
        self.database_connector = DatabaseConnector(self.use_emoji)
        self.database_initializer = DatabaseInitializer(self.config.project_root, self.use_emoji)
        self.database_health_checker = DatabaseHealthChecker(self.use_emoji)
        self.websocket_validator = WebSocketValidator(self.use_emoji)
        self.environment_validator = EnvironmentValidator()
        
        # Get environment manager with matching isolation mode
        env = get_env()
        environment = env.get('ENVIRONMENT', 'development').lower()
        isolation_mode = environment == 'development'
        self.env = get_env()
        if isolation_mode and not self.env.is_isolation_enabled():
            self.env.enable_isolation()
    
    def _setup_environment_isolation(self):
        """Setup environment isolation based on development mode detection."""
        env = get_env()
        environment = env.get('ENVIRONMENT', 'development').lower()
        isolation_mode = environment == 'development'
        
        if self.config.verbose:
            isolation_status = "ENABLED" if isolation_mode else "DISABLED"
            logger.info(f"[LAUNCHER] Environment isolation: {isolation_status} (ENVIRONMENT={environment})")
        
        if isolation_mode and not env.is_isolation_enabled():
            env.enable_isolation()
    
    def _load_environment_files(self):
        """Load environment variables from .env files."""
        env = get_env()
        project_root = self.config.project_root
        
        # Load from .env file if it exists
        env_file = project_root / ".env"
        if env_file.exists():
            try:
                loaded_count, errors = env.load_from_file(env_file, source="env_file", override_existing=True)
                if self.config.verbose:
                    logger.info(f"Loaded {loaded_count} variables from .env")
                if errors:
                    for error in errors:
                        logger.warning(f"Environment loading error: {error}")
            except Exception as e:
                logger.warning(f"Failed to load .env file: {e}")
        
        # Also check for .env.local for local overrides
        env_local_file = project_root / ".env.local"
        if env_local_file.exists():
            try:
                loaded_count, errors = env.load_from_file(env_local_file, source="env_local", override_existing=True)
                if self.config.verbose:
                    logger.info(f"Loaded {loaded_count} variables from .env.local")
                if errors:
                    for error in errors:
                        logger.warning(f"Environment loading error: {error}")
            except Exception as e:
                logger.warning(f"Failed to load .env.local file: {e}")
    
    def _create_service_startup(self) -> ServiceStartupCoordinator:
        """Create service startup coordinator."""
        return ServiceStartupCoordinator(
            self.config, self.config.services_config,
            self.log_manager, self.service_discovery, self.use_emoji)
    
    
    def _setup_logging(self):
        """Setup logging and show verbose configuration."""
        setup_logging(self.config.verbose)
        self.config.log_verbose_config()
    
    def _setup_signal_handlers(self):
        """Setup signal handlers for graceful shutdown using the comprehensive SignalHandler."""
        # Register cleanup handlers with the signal handler
        self.signal_handler.register_cleanup_handler(
            name="dev_launcher_cleanup",
            handler=self._graceful_shutdown,
            priority=1,
            timeout=30,
            critical=True
        )
        
        # Register emergency cleanup as fallback
        self.signal_handler.register_cleanup_handler(
            name="emergency_cleanup",
            handler=self.emergency_cleanup,
            priority=10,  # Lower priority (runs later)
            timeout=15,
            critical=True
        )
        
        # Signal handling is already initialized in SignalHandler constructor
        # Register legacy cleanup on exit for compatibility
        atexit.register(self._ensure_cleanup)
        logger.info("Comprehensive signal handlers registered for graceful shutdown")
    
    def _signal_handler(self, signum, frame):
        """Legacy signal handler - delegates to comprehensive SignalHandler."""
        if self._shutting_down:
            return  # Already shutting down
        
        self._shutting_down = True
        signal_name = signal.Signals(signum).name if hasattr(signal, 'Signals') else str(signum)
        self._print("\nüõë", "SHUTDOWN", f"Received {signal_name}, initiating comprehensive shutdown...")
        
        # Use the comprehensive signal handler
        self.signal_handler.initiate_shutdown(signal_name)
        sys.exit(0)
    
    def _ensure_cleanup(self):
        """Ensure cleanup is performed on exit."""
        if not self._shutting_down:
            self._shutting_down = True
            self._graceful_shutdown()
    
    def _graceful_shutdown(self):
        """Perform graceful shutdown of all services with proper ordering and cleanup."""
        shutdown_start = time.time()
        
        # Only print if we're actually shutting down services
        if hasattr(self, 'process_manager') and self.process_manager.processes:
            self._print("üîÑ", "CLEANUP", "Starting graceful shutdown sequence...")
        else:
            return  # Nothing to shutdown
        
        # Phase 1: Stop health monitoring FIRST (prevents interference with shutdown)
        self._print("üîÑ", "PHASE 1", "Stopping health monitoring...")
        if hasattr(self, 'health_monitor') and self.health_monitor:
            try:
                self.health_monitor.stop()
                # Wait briefly for health monitor to stop cleanly
                time.sleep(0.5)
                self._print("‚úÖ", "HEALTH", "Health monitoring stopped")
            except Exception as e:
                logger.error(f"Error stopping health monitor: {e}")
        
        # Phase 2: Stop database monitoring to prevent connection errors
        self._print("üîÑ", "PHASE 2", "Stopping database monitoring...")
        if hasattr(self, 'database_connector') and self.database_connector:
            try:
                # Check if we're in an event loop
                loop = asyncio.get_running_loop()
                # Set shutdown flag and let monitoring loop handle cleanup
                self.database_connector._shutdown_requested = True
                logger.info("Database monitoring shutdown requested")
            except RuntimeError:
                # No running event loop, safe to use asyncio.run
                try:
                    asyncio.run(self.database_connector.stop_health_monitoring())
                    self._print("‚úÖ", "DATABASE", "Database monitoring stopped")
                except Exception as e:
                    logger.error(f"Error stopping database monitoring: {e}")
        
        # Phase 3: Terminate services in proper order (Frontend ‚Üí Backend ‚Üí Auth)
        self._print("üîÑ", "PHASE 3", "Terminating services in order...")
        self._terminate_all_services_ordered()
        
        # Phase 4: Stop supporting services
        self._print("üîÑ", "PHASE 4", "Stopping supporting services...")
        
        # Stop log streamers
        if hasattr(self, 'log_manager') and self.log_manager:
            try:
                self.log_manager.stop_all()
                self._print("‚úÖ", "LOGS", "Log streaming stopped")
            except Exception as e:
                logger.error(f"Error stopping log streamers: {e}")
        
        # Cleanup optimizers and parallel executor
        if hasattr(self, 'startup_optimizer') and self.startup_optimizer:
            try:
                self.startup_optimizer.cleanup()
                self._print("‚úÖ", "OPTIMIZER", "Startup optimizer cleaned up")
            except Exception as e:
                logger.error(f"Error cleaning up startup optimizer: {e}")
        
        if hasattr(self, 'parallel_executor') and self.parallel_executor:
            try:
                self.parallel_executor.cleanup()
                self._print("‚úÖ", "PARALLEL", "Parallel executor cleaned up")
            except Exception as e:
                logger.error(f"Error cleaning up parallel executor: {e}")
        
        # Phase 5: Force port cleanup and verification
        self._print("üîÑ", "PHASE 5", "Verifying port cleanup...")
        self._verify_ports_freed_with_force_cleanup()
        
        # Calculate shutdown time
        shutdown_time = time.time() - shutdown_start
        self._print("‚úÖ", "SHUTDOWN", f"Graceful shutdown complete in {shutdown_time:.1f}s")
    
    
    def _terminate_all_services_ordered(self):
        """Terminate all services with enhanced ordering and timeout handling."""
        # Service termination order: Frontend ‚Üí Backend ‚Üí Auth
        # This prevents client connection errors and ensures clean dependency shutdown
        services_order = [
            ("Frontend", 5),   # 5 second timeout for frontend (React dev server)
            ("Backend", 10),   # 10 second timeout for backend (uvicorn with connections)
            ("Auth", 5)        # 5 second timeout for auth service
        ]
        
        terminated_services = []
        
        for service_name, timeout in services_order:
            if self.process_manager.is_running(service_name):
                self._print("üõë", "STOP", f"Stopping {service_name} service (timeout: {timeout}s)...")
                
                # Record start time for timeout
                start_time = time.time()
                
                # Attempt graceful termination
                if self.process_manager.terminate_process(service_name, timeout=timeout):
                    elapsed = time.time() - start_time
                    self._print("‚úÖ", "STOPPED", f"{service_name} terminated gracefully in {elapsed:.1f}s")
                    terminated_services.append(service_name)
                else:
                    elapsed = time.time() - start_time
                    self._print("‚ö†Ô∏è", "WARN", f"{service_name} termination failed after {elapsed:.1f}s - forcing shutdown")
                    # Try force kill
                    try:
                        self.process_manager.kill_process(service_name)
                        self._print("üî®", "KILLED", f"{service_name} force terminated")
                        terminated_services.append(service_name)
                    except Exception as e:
                        logger.error(f"Failed to force kill {service_name}: {e}")
                
                # Clean up any hanging Node.js processes on Windows after frontend termination
                if service_name == "frontend" and sys.platform == "win32" and WindowsProcessCleanup:
                    try:
                        cleanup_instance = WindowsProcessCleanup() if not hasattr(self, 'windows_cleanup') else self.windows_cleanup
                        cleaned = cleanup_instance.cleanup_node_processes()
                        if cleaned > 0:
                            self._print("üßπ", "CLEANUP", f"Cleaned {cleaned} hanging Node.js processes")
                    except Exception as e:
                        logger.debug(f"Node.js cleanup error: {e}")
                
                # Brief pause between service terminations to allow clean shutdown
                if service_name != services_order[-1][0]:  # Don't wait after last service
                    time.sleep(0.5)
        
        # Final cleanup of any remaining processes
        try:
            self.process_manager.cleanup_all()
            self._print("‚úÖ", "CLEANUP", f"Process cleanup complete ({len(terminated_services)} services terminated)")
        except Exception as e:
            logger.error(f"Process cleanup error: {e}")
    
    
    def _verify_ports_freed_with_force_cleanup(self):
        """Verify that service ports are freed with enhanced cleanup and retry logic."""
        # Get dynamic ports from service discovery if available
        ports_to_check = self._get_ports_to_check()
        
        # Initial check
        ports_still_in_use = []
        for port, service in ports_to_check:
            if self._is_port_in_use(port):
                ports_still_in_use.append((port, service))
        
        if not ports_still_in_use:
            self._print("‚úÖ", "PORTS", "All service ports freed successfully")
            return
        
        # Report ports still in use
        port_list = ", ".join([f"{port}({service})" for port, service in ports_still_in_use])
        self._print("‚ö†Ô∏è", "PORT", f"Ports still in use: {port_list}")
        
        # Attempt force cleanup with retry
        cleanup_success = []
        cleanup_failures = []
        
        for port, service in ports_still_in_use:
            self._print("üîß", "CLEANUP", f"Force cleaning port {port} ({service})...")
            
            if self._force_free_port_with_retry(port, max_retries=3):
                cleanup_success.append((port, service))
                self._print("‚úÖ", "FREED", f"Port {port} ({service}) cleaned successfully")
            else:
                cleanup_failures.append((port, service))
                self._print("‚ùå", "FAILED", f"Port {port} ({service}) cleanup failed")
        
        # Final verification
        if cleanup_success:
            success_list = ", ".join([f"{port}({service})" for port, service in cleanup_success])
            logger.info(f"Successfully freed ports: {success_list}")
        
        if cleanup_failures:
            failure_list = ", ".join([f"{port}({service})" for port, service in cleanup_failures])
            logger.warning(f"Failed to free ports: {failure_list} - may require manual cleanup")
    
    def _get_ports_to_check(self):
        """Get list of ports to check for cleanup."""
        ports_to_check = [
            (8081, "Auth"),  # Standard auth port
            (self.config.backend_port or 8000, "Backend"),
            (self.config.frontend_port or 3000, "Frontend")
        ]
        
        # Try to get actual ports from service discovery
        try:
            if hasattr(self, 'service_discovery') and self.service_discovery:
                auth_info = self.service_discovery.read_auth_info()
                if auth_info and 'port' in auth_info:
                    # Replace auth port with actual discovered port
                    ports_to_check[0] = (auth_info['port'], "Auth")
                
                backend_info = self.service_discovery.read_backend_info()  
                if backend_info and 'port' in backend_info:
                    # Replace backend port with actual discovered port
                    ports_to_check[1] = (backend_info['port'], "Backend")
                
                frontend_info = self.service_discovery.read_frontend_info()
                if frontend_info and 'port' in frontend_info:
                    # Replace frontend port with actual discovered port  
                    ports_to_check[2] = (frontend_info['port'], "Frontend")
        except Exception as e:
            logger.debug(f"Could not get ports from service discovery: {e}")
        
        return ports_to_check
    
    def _is_port_in_use(self, port: int) -> bool:
        """Check if a port is in use."""
        import socket
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            try:
                s.bind(('', port))
                return False
            except:
                return True
    
    
    def _force_free_port_with_retry(self, port: int, max_retries: int = 3) -> bool:
        """Force free a port cross-platform with retry logic and enhanced error handling."""
        for attempt in range(max_retries):
            try:
                # Check if port is already free
                if not self._is_port_in_use(port):
                    return True
                
                success = False
                
                if sys.platform == "win32":
                    success = self._force_free_port_windows(port, attempt)
                elif sys.platform == "darwin":
                    success = self._force_free_port_darwin(port, attempt)
                else:  # Linux and other Unix-like systems
                    success = self._force_free_port_linux(port, attempt)
                
                if success:
                    # Verify port is actually freed
                    time.sleep(0.2)  # Brief wait for port to be released
                    if not self._is_port_in_use(port):
                        return True
                    else:
                        logger.warning(f"Port {port} still in use after cleanup attempt {attempt + 1}")
                
                # If not successful and not the last attempt, wait before retry
                if attempt < max_retries - 1:
                    retry_delay = 0.5 * (attempt + 1)  # Increasing delay
                    logger.info(f"Retrying port {port} cleanup in {retry_delay}s...")
                    time.sleep(retry_delay)
            
            except Exception as e:
                logger.error(f"Port {port} cleanup attempt {attempt + 1} failed: {e}")
                if attempt < max_retries - 1:
                    time.sleep(0.5)
        
        return False
    
    def _force_free_port_windows(self, port: int, attempt: int) -> bool:
        """Force free port on Windows using the WindowsProcessManager for enhanced process handling."""
        if self.windows_process_manager:
            try:
                # Use the enhanced Windows process manager
                port_users = self.windows_process_manager.get_port_users(port)
                if not port_users:
                    return True  # No processes using the port
                
                killed_count = 0
                for pid, process_name in port_users:
                    try:
                        # Try graceful termination first on first attempt
                        force = attempt > 0
                        if self.windows_process_manager.terminate_process_tree(process_name, force=force):
                            killed_count += 1
                            logger.debug(f"Terminated process {process_name} (PID {pid}) using port {port}")
                    except Exception as e:
                        logger.warning(f"Failed to terminate process {process_name} (PID {pid}): {e}")
                
                # Cleanup any zombie processes
                zombies_cleaned = self.windows_process_manager.cleanup_zombie_processes()
                if zombies_cleaned > 0:
                    logger.debug(f"Cleaned up {zombies_cleaned} zombie processes")
                
                return killed_count > 0
                
            except Exception as e:
                logger.error(f"Enhanced Windows port cleanup failed for port {port}: {e}")
                # Fallback to legacy method
                return self._legacy_force_free_port_windows(port, attempt)
        else:
            # Fallback to legacy method
            return self._legacy_force_free_port_windows(port, attempt)
    
    def _legacy_force_free_port_windows(self, port: int, attempt: int) -> bool:
        """Legacy Windows port cleanup method."""
        try:
            import subprocess
            
            # Find processes using the port
            result = subprocess.run(
                f"netstat -ano | findstr :{port}",
                shell=True, capture_output=True, text=True, timeout=10
            )
            
            if not result.stdout:
                return True  # No processes found
            
            pids_to_kill = set()
            lines = result.stdout.strip().split('\n')
            for line in lines:
                parts = line.split()
                if len(parts) >= 5:
                    pid = parts[-1]
                    if pid.isdigit() and pid != "0":
                        pids_to_kill.add(pid)
            
            if not pids_to_kill:
                return True
            
            # Kill processes
            killed_count = 0
            for pid in pids_to_kill:
                try:
                    # Try graceful termination first on first attempt
                    if attempt == 0:
                        kill_result = subprocess.run(
                            f"taskkill /PID {pid}",
                            shell=True, capture_output=True, text=True, timeout=5
                        )
                    else:
                        # Force kill on subsequent attempts
                        kill_result = subprocess.run(
                            f"taskkill /F /PID {pid}",
                            shell=True, capture_output=True, text=True, timeout=5
                        )
                    
                    if kill_result.returncode == 0:
                        killed_count += 1
                        logger.debug(f"Killed process {pid} using port {port}")
                
                except subprocess.TimeoutExpired:
                    logger.warning(f"Timeout killing process {pid}")
                except Exception as e:
                    logger.warning(f"Failed to kill process {pid}: {e}")
            
            return killed_count > 0
            
        except Exception as e:
            logger.error(f"Legacy Windows port cleanup failed for port {port}: {e}")
            return False
    
    def _force_free_port_darwin(self, port: int, attempt: int) -> bool:
        """Force free port on macOS with enhanced process handling.""" 
        try:
            import subprocess
            
            # Find processes using the port
            result = subprocess.run(
                f"lsof -ti :{port}",
                shell=True, capture_output=True, text=True, timeout=10
            )
            
            if not result.stdout:
                return True  # No processes found
            
            pids = result.stdout.strip().split('\n')
            valid_pids = [pid for pid in pids if pid.isdigit()]
            
            if not valid_pids:
                return True
            
            # Kill processes
            killed_count = 0
            for pid in valid_pids:
                try:
                    # Try SIGTERM first on first attempt, SIGKILL on subsequent
                    signal_type = "TERM" if attempt == 0 else "KILL"
                    kill_result = subprocess.run(
                        f"kill -{signal_type} {pid}",
                        shell=True, capture_output=True, text=True, timeout=5
                    )
                    
                    if kill_result.returncode == 0:
                        killed_count += 1
                        logger.debug(f"Sent SIG{signal_type} to process {pid} using port {port}")
                
                except subprocess.TimeoutExpired:
                    logger.warning(f"Timeout killing process {pid}")
                except Exception as e:
                    logger.warning(f"Failed to kill process {pid}: {e}")
            
            return killed_count > 0
            
        except Exception as e:
            logger.error(f"macOS port cleanup failed for port {port}: {e}")
            return False
    
    def _force_free_port_linux(self, port: int, attempt: int) -> bool:
        """Force free port on Linux with enhanced process handling."""
        try:
            import subprocess
            
            # Find processes using the port (try multiple methods)
            commands = [
                f"lsof -ti :{port}",
                f"fuser -k {port}/tcp",  # Alternative method
                f"ss -lpn 'sport = :{port}'"  # Modern netstat replacement
            ]
            
            pids_found = set()
            
            for cmd in commands:
                try:
                    result = subprocess.run(
                        cmd, shell=True, capture_output=True, text=True, timeout=5
                    )
                    
                    if result.stdout:
                        if "lsof" in cmd:
                            pids = result.stdout.strip().split('\n')
                            pids_found.update([pid for pid in pids if pid.isdigit()])
                        elif "ss" in cmd:
                            # Parse ss output for PIDs
                            lines = result.stdout.strip().split('\n')[1:]  # Skip header
                            for line in lines:
                                if f":{port}" in line and "pid=" in line:
                                    # Extract PID from ss output
                                    import re
                                    pid_match = re.search(r'pid=(\d+)', line)
                                    if pid_match:
                                        pids_found.add(pid_match.group(1))
                        
                except Exception:
                    continue  # Try next command
            
            if not pids_found:
                return True  # No processes found
            
            # Kill processes
            killed_count = 0
            for pid in pids_found:
                try:
                    # Try SIGTERM first, then SIGKILL
                    signal_num = 15 if attempt == 0 else 9  # SIGTERM or SIGKILL
                    kill_result = subprocess.run(
                        f"kill -{signal_num} {pid}",
                        shell=True, capture_output=True, text=True, timeout=5
                    )
                    
                    if kill_result.returncode == 0:
                        killed_count += 1
                        logger.debug(f"Sent signal {signal_num} to process {pid} using port {port}")
                
                except Exception as e:
                    logger.warning(f"Failed to kill process {pid}: {e}")
            
            return killed_count > 0
            
        except Exception as e:
            logger.error(f"Linux port cleanup failed for port {port}: {e}")
            return False
    
    def _setup_new_cache_system(self):
        """Setup new cache and optimization system."""
        self.cache_manager = CacheManager(self.config.project_root)
        self.startup_optimizer = StartupOptimizer(self.cache_manager)
        self.parallel_enabled = getattr(self.config, 'parallel_startup', True)
        
        # Setup parallel executor for pre-checks
        if self.parallel_enabled:
            self.parallel_executor = ParallelExecutor(max_cpu_workers=2, max_io_workers=4)
        else:
            self.parallel_executor = None
            
        self._register_optimization_steps()
    
    def _register_optimization_steps(self):
        """Register startup optimization steps."""
        from .startup_optimizer import StartupPhase
        
        steps = [
            StartupStep(name="environment_check", phase=StartupPhase.PRE_INIT, action=self._check_environment_step, timeout=10, required=True, dependencies=[]),
            StartupStep(name="database_check", phase=StartupPhase.INIT, action=self._check_database_step, timeout=15, required=True, dependencies=["environment_check"]),
            StartupStep(name="migration_check", phase=StartupPhase.INIT, action=self._check_migrations_step, timeout=15, required=True, dependencies=["database_check"]),
            StartupStep(name="backend_deps", phase=StartupPhase.PRE_INIT, action=self._check_backend_deps, timeout=20, required=False, dependencies=[]),
            StartupStep(name="auth_deps", phase=StartupPhase.PRE_INIT, action=self._check_auth_deps, timeout=20, required=False, dependencies=[]),
            StartupStep(name="frontend_deps", phase=StartupPhase.PRE_INIT, action=self._check_frontend_deps, timeout=30, required=False, dependencies=["backend_deps"]),
        ]
        for step in steps:
            self.startup_optimizer.add_step(step)
    
    def _print(self, emoji: str, text: str, message: str):
        """Print with emoji support."""
        print_with_emoji(emoji, text, message, self.use_emoji)
    
    def check_environment(self) -> bool:
        """Check if environment is ready for launch."""
        if not self.cache_manager.has_environment_changed():
            self._print("‚úÖ", "CACHE", "Environment unchanged, skipping checks")
            return True
        
        # Run comprehensive environment validation with fallbacks
        self._print("üîç", "ENV", "Checking environment...")
        validation_result = self.environment_validator.validate_with_fallbacks()
        
        if not validation_result.is_valid:
            self._print("‚ùå", "ENV", "Environment validation failed")
            self.environment_validator.print_validation_summary(validation_result)
            
            # Print fix suggestions
            suggestions = self.environment_validator.get_fix_suggestions(validation_result)
            if suggestions:
                self._print("üí°", "HELP", "Suggestions:")
                for suggestion in suggestions:
                    print(f"  ‚Ä¢ {suggestion}")
            
            return False
        
        # Run basic environment checks
        result = self.environment_checker.check_environment()
        
        # Check and set defaults for critical environment variables
        self._check_critical_env_vars()
        
        # Check service availability and adjust configuration if needed
        service_check_result = self._check_service_availability()
        
        # Print summary if there were warnings
        if validation_result.warnings:
            self.environment_validator.print_validation_summary(validation_result)
        elif service_check_result:
            self._print("‚úÖ", "ENV", "Environment and services ready")
        else:
            self._print("‚úÖ", "ENV", "Environment check passed")
        
        return result and service_check_result
    
    def _check_critical_env_vars(self):
        """Check and set defaults for critical environment variables."""
        self._set_env_var_defaults()
        self._validate_critical_env_vars()
    
    def _set_env_var_defaults(self):
        """Set default values for critical environment variables using EnvironmentManager."""
        defaults = {
            "BACKEND_PORT": "8000",
            "FRONTEND_PORT": "3000", 
            "AUTH_PORT": "8081",
            "WEBSOCKET_PORT": "8000",
            "LOG_LEVEL": "INFO",
            "ENVIRONMENT": "development",
            "CORS_ORIGINS": "*"  # Set CORS_ORIGINS=* for development
        }
        
        for var, default_value in defaults.items():
            if not self.env.get(var):
                if self.env.set(var, default_value, source="launcher_defaults"):
                    self._print("‚ÑπÔ∏è", "DEFAULT", f"Set {var}={default_value}")
        
        # Generate cross-service auth token if not present
        self._ensure_cross_service_auth_token()
    
    def _ensure_cross_service_auth_token(self):
        """Ensure cross-service authentication token exists with enhanced security validation."""
        existing_token = self.service_discovery.get_cross_service_auth_token()
        
        # Enhanced token validation - check length and character set
        token_valid = False
        if existing_token:
            # Check minimum length (32 chars)
            if len(existing_token) < 32:
                self._print("‚ö†Ô∏è", "TOKEN", f"Existing token too short ({len(existing_token)} chars), regenerating secure token")
            else:
                # Validate token is URL-safe base64 (only contains safe characters)
                import re
                url_safe_pattern = re.compile(r'^[A-Za-z0-9_-]+$')
                if not url_safe_pattern.match(existing_token):
                    self._print("‚ö†Ô∏è", "TOKEN", "Existing token contains unsafe characters, regenerating")
                else:
                    token_valid = True
        
        if not token_valid:
            import secrets
            # Generate 64 bytes of random data for maximum security
            # This results in ~85 character token (well above 32 char minimum)
            token = secrets.token_urlsafe(64)
            
            # Enhanced validation of generated token
            if len(token) < 32:
                raise RuntimeError(f"Generated token too short: {len(token)} chars (minimum 32 required)")
            
            # Additional entropy check - ensure token has sufficient randomness
            if token.count(token[0]) > len(token) // 4:  # No character appears more than 25% of the time
                logger.warning("Token may have low entropy, but proceeding (this is extremely rare)")
            
            self.service_discovery.set_cross_service_auth_token(token)
            # Use environment manager to set token
            self.env.set('CROSS_SERVICE_AUTH_TOKEN', token, 
                                           source="launcher_auth_token", force=True)
            self._print("üîë", "TOKEN", f"Generated secure cross-service auth token ({len(token)} chars)")
            
            # Log token characteristics for debugging (without revealing token)
            logger.debug(f"Token entropy check: unique chars={len(set(token))}, length={len(token)}")
        else:
            # Use environment manager to set existing token
            self.env.set('CROSS_SERVICE_AUTH_TOKEN', existing_token, 
                                           source="launcher_auth_token", force=True)
            self._print("üîë", "TOKEN", f"Using existing cross-service auth token ({len(existing_token)} chars)")
    
    def _validate_critical_env_vars(self):
        """Validate required environment variables."""
        required_vars = ["JWT_SECRET_KEY"]
        
        for var in required_vars:
            value = self.env.get(var)
            if not value:
                critical_handler.check_env_var(var, value)
    
    def _check_service_availability(self) -> bool:
        """Check service availability and auto-adjust configuration with proper environment variable updates."""
        try:
            from dev_launcher.service_availability_checker import ServiceAvailabilityChecker
            from dev_launcher.docker_services import DockerServiceManager
            
            if not hasattr(self.config, 'services_config') or not self.config.services_config:
                self._print("‚ÑπÔ∏è", "SKIP", "No services config found, using default service configuration")
                return True  # Skip if no services config
            
            # FIRST: Perform Docker service discovery with enhanced reporting
            docker_manager = DockerServiceManager()
            discovery_report = docker_manager.get_service_discovery_report()
            running_services = docker_manager.discover_running_services()
            
            if running_services:
                services_list = ", ".join(running_services.keys())
                self._print("üîç", "DISCOVERY", f"Found running Docker services: {services_list}")
                
                # Show details for each running service
                for service, details in running_services.items():
                    self._print("‚úÖ", "REUSE", f"{service.capitalize()}: {details}")
                
                # Store discovery info for use later in startup
                self._docker_discovery_report = discovery_report
                self._running_docker_services = running_services
            else:
                self._print("üîç", "DISCOVERY", "No existing Docker services found")
                self._docker_discovery_report = {}
                self._running_docker_services = {}
            
            # Run availability checker
            checker = ServiceAvailabilityChecker(self.use_emoji)
            self._print("üîÑ", "CHECKING", "Analyzing service availability...")
            results = checker.check_all_services(self.config.services_config)
            
            # Store original environment state for comparison
            env = get_env()
            original_env = {key: env.get(key) for key in [
                'REDIS_URL', 'REDIS_HOST', 'REDIS_PORT', 'REDIS_MODE',
                'CLICKHOUSE_URL', 'CLICKHOUSE_HOST', 'CLICKHOUSE_PORT', 'CLICKHOUSE_MODE',
                'DATABASE_URL', 'POSTGRES_HOST', 'POSTGRES_PORT', 'POSTGRES_MODE',
                'LLM_MODE', 'LLM_PROVIDER'
            ]}
            
            # Apply recommendations with enhanced reporting
            changes_made = checker.apply_recommendations(self.config.services_config, results)
            
            if changes_made:
                self._print("üîß", "AUTO-ADJUST", "Applied service availability recommendations")
                
                # Update environment variables with detailed tracking
                service_env_vars = self.config.services_config.get_all_env_vars()
                env_changes = []
                env_instance = get_env()
                
                for key, new_value in service_env_vars.items():
                    old_value = original_env.get(key)
                    if old_value != new_value:
                        env_instance.set(key, new_value, "launcher_service_config")
                        env_changes.append(f"{key}: {old_value or 'unset'} ‚Üí {new_value}")
                
                if env_changes:
                    self._print("üîÑ", "ENV-UPDATE", f"Updated {len(env_changes)} environment variables")
                    for change in env_changes[:5]:  # Show first 5 changes
                        logger.debug(f"Environment change: {change}")
                    if len(env_changes) > 5:
                        logger.debug(f"... and {len(env_changes) - 5} more environment variable changes")
                
                # Verify critical environment variables are set
                self._verify_updated_environment_variables(service_env_vars)
            else:
                self._print("‚úÖ", "CONFIG", "Service configuration already optimal")
            
            # Enhanced critical service issue reporting
            critical_issues = []
            warnings = []
            successful_configs = []
            
            for service_name, result in results.items():
                if result.available:
                    successful_configs.append(f"{service_name}: {result.recommended_mode}")
                elif result.recommended_mode != result.service_name:
                    # Successfully configured to alternative mode
                    successful_configs.append(f"{service_name}: fallback to {result.recommended_mode}")
                else:
                    # Service couldn't be configured properly
                    if self._is_critical_service(service_name):
                        critical_issues.append(f"{service_name}: {result.reason}")
                    else:
                        warnings.append(f"{service_name}: {result.reason}")
            
            # Report configuration results
            if successful_configs:
                self._print("‚úÖ", "CONFIGURED", f"Successfully configured {len(successful_configs)} service(s)")
                for config in successful_configs[:3]:  # Show first 3
                    logger.debug(f"Service config: {config}")
            
            if warnings:
                self._print("‚ö†Ô∏è", "WARNINGS", f"{len(warnings)} service warning(s):")
                for warning in warnings:
                    print(f"  ‚Ä¢ {warning}")
            
            if critical_issues:
                self._print("üö®", "CRITICAL", f"Critical service issues detected:")
                for issue in critical_issues:
                    print(f"  ‚Ä¢ {issue}")
                print("  ‚Üí Platform may have reduced functionality")
                # Don't fail startup but log for monitoring
                logger.warning(f"Critical service configuration issues: {len(critical_issues)}")
            
            return True  # Continue startup even with service adjustments
            
        except ImportError:
            logger.debug("Service availability checker not available, using basic configuration")
            self._print("‚ÑπÔ∏è", "BASIC", "Using basic service configuration (availability checker not available)")
            return True
        except Exception as e:
            logger.error(f"Service availability check failed: {e}")
            self._print("‚ö†Ô∏è", "FALLBACK", f"Service availability check failed, using defaults: {str(e)[:60]}")
            return True  # Don't fail startup due to availability check issues
    
    def _verify_updated_environment_variables(self, service_env_vars: dict):
        """Verify that updated environment variables are properly propagated."""
        verification_failures = []
        
        for key, expected_value in service_env_vars.items():
            env = get_env()
            actual_value = env.get(key)
            if actual_value != expected_value:
                verification_failures.append(f"{key}: expected '{expected_value}', got '{actual_value}'")
        
        if verification_failures:
            self._print("‚ö†Ô∏è", "ENV-VERIFY", f"Environment variable verification failures: {len(verification_failures)}")
            for failure in verification_failures[:3]:  # Show first 3
                logger.warning(f"Environment verification failed: {failure}")
        else:
            logger.debug("All environment variables verified successfully")
    
    def _is_critical_service(self, service_name: str) -> bool:
        """Determine if a service is critical for basic functionality."""
        critical_services = {'postgres', 'database'}  # Services required for basic functionality
        return service_name.lower() in critical_services
    
    def _check_environment_step(self) -> bool:
        """Environment check step for optimizer."""
        return self.environment_checker.check_environment()
    
    def _check_database_step(self) -> bool:
        """Database connectivity check step for optimizer."""
        # For cache purposes, always return False to force database validation
        return False
    
    def _check_migrations_step(self) -> bool:
        """Migration check step for optimizer."""
        return not self.cache_manager.has_migration_files_changed()
    
    async def _validate_databases(self) -> bool:
        """Validate database connections before service startup with proper mock mode detection."""
        try:
            # Check if all database services are in mock mode with enhanced detection
            if hasattr(self.config, 'services_config') and self.config.services_config:
                services_config = self.config.services_config
                
                # NO MOCKS IN DEV MODE - get service modes 
                redis_mode = getattr(services_config.redis, 'mode', None)
                env = get_env()
                
                # Check if any service is trying to use mock mode
                redis_mock = (redis_mode and redis_mode.value == "mock") or env.get('REDIS_MODE') == 'mock'
                clickhouse_mode = getattr(services_config.clickhouse, 'mode', None) 
                clickhouse_mock = (clickhouse_mode and clickhouse_mode.value == "mock") or env.get('CLICKHOUSE_MODE') == 'mock'
                postgres_mode = getattr(services_config.postgres, 'mode', None)
                postgres_mock = (postgres_mode and postgres_mode.value == "mock") or env.get('POSTGRES_MODE') == 'mock'
                
                # NO MOCKS ALLOWED - fail if any service uses mock
                if redis_mock or clickhouse_mock or postgres_mock:
                    self._print("‚ùå", "DATABASE", "Mock mode not allowed in development - use real services")
                    mock_services = []
                    if redis_mock: mock_services.append("Redis")
                    if clickhouse_mock: mock_services.append("ClickHouse")
                    if postgres_mock: mock_services.append("PostgreSQL")
                    raise RuntimeError(f"NO MOCKS IN DEV MODE - {', '.join(mock_services)} cannot use mock mode. Configure real services.")
                
                # Check for disabled services (allowed)
                redis_disabled = redis_mode and redis_mode.value == "disabled"
                clickhouse_disabled = clickhouse_mode and clickhouse_mode.value == "disabled" 
                postgres_disabled = postgres_mode and postgres_mode.value == "disabled"
                
                all_disabled = all([redis_disabled, clickhouse_disabled, postgres_disabled])
                
                if all_disabled:
                    self._print("‚úÖ", "DATABASE", f"All databases disabled - skipping validation")
                    return True
                
                # Show which services will be validated (real services only)
                services_to_validate = []
                if not redis_disabled:
                    services_to_validate.append("Redis")
                if not clickhouse_disabled:
                    services_to_validate.append("ClickHouse")
                if not postgres_disabled:
                    services_to_validate.append("PostgreSQL")
                
                if services_to_validate:
                    self._print("üîç", "DATABASE", f"Validating connections for: {', '.join(services_to_validate)}")
            else:
                self._print("üîç", "DATABASE", "No service config found, attempting full database validation")
            
            # Perform connection validation with timeout and error handling
            validation_result = await asyncio.wait_for(
                self.database_connector.validate_all_connections(),
                timeout=25  # 25 second timeout for database validation
            )
            
            # Step 3: Check database readiness
            if validation_result:
                readiness_status = await self.database_health_checker.check_database_readiness()
                ready_dbs = [db for db, ready in readiness_status.items() if ready]
                
                if ready_dbs:
                    self._print("‚úÖ", "DATABASE", f"Database connections validated and ready: {', '.join(ready_dbs)}")
                else:
                    self._print("‚ö†Ô∏è", "DATABASE", "Connections validated but readiness check failed - continuing")
            else:
                self._print("‚ö†Ô∏è", "DATABASE", "Some database connections failed - continuing with available services")
                # Don't fail startup for database connection issues in development
                return True
            
            return validation_result
            
        except asyncio.TimeoutError:
            logger.warning("Database validation timed out after 25 seconds")
            self._print("‚ö†Ô∏è", "DATABASE", "Validation timed out - continuing with mock/local fallback")
            return True  # Continue startup with fallback
        except Exception as e:
            logger.error(f"Database validation failed: {e}")
            self._print("‚ö†Ô∏è", "DATABASE", f"Validation error: {str(e)[:100]}... - continuing with fallback")
            # In development, continue even if database validation fails
            return True
    
    async def _validate_websocket_endpoints(self) -> bool:
        """Validate WebSocket endpoints after frontend is ready."""
        try:
            return await self.websocket_validator.validate_all_endpoints()
        except Exception as e:
            logger.error(f"WebSocket validation failed: {e}")
            self._print("‚ùå", "WEBSOCKET", f"Validation error: {str(e)}")
            return False
    
    def run_migrations(self, env: Optional[Dict] = None) -> bool:
        """Run database migrations if needed."""
        return self.migration_runner.check_and_run_migrations(env)
    
    def _check_backend_deps(self) -> bool:
        """Backend dependencies check step."""
        return not self.cache_manager.has_dependencies_changed("backend")
    
    def _check_auth_deps(self) -> bool:
        """Auth dependencies check step."""
        return not self.cache_manager.has_dependencies_changed("auth")
    
    def _check_frontend_deps(self) -> bool:
        """Frontend dependencies check step."""
        return not self.cache_manager.has_dependencies_changed("frontend")
    
    
    def _load_local_secrets_early(self):
        """Load local secrets early for initialization with race condition prevention.
        
        This method loads only local env files early in the initialization 
        process to ensure environment is properly set up before other 
        components are created. This prevents race conditions where backend
        components try to access environment variables before they're loaded.
        """
        if not self._secrets_loaded:
            # Prevent environment race condition using the race condition manager
            if self.race_condition_manager.prevent_environment_race_condition("launcher_secret_loader"):
                # Use temporary flag with environment manager
                # Set temporary flag and load environment files
                self.env.set('NETRA_SECRETS_LOADING', 'true', 'launcher_early_load')
                try:
                    self._load_environment_files()
                finally:
                    self.env.delete('NETRA_SECRETS_LOADING')
                    self._secrets_loaded = True
            else:
                logger.warning("Race condition detected during early secret loading, retrying...")
                time.sleep(0.1)  # Brief delay and retry
                self._load_local_secrets_early()
    
    def load_secrets(self) -> bool:
        """Load secrets if configured with race condition prevention.
        
        This method handles GCP secret loading if enabled.
        Local secrets are already loaded in _load_local_secrets_early.
        """
        # Prevent race condition using the race condition manager
        lock_acquired = self.race_condition_manager.acquire_resource_lock(
            ResourceType.ENVIRONMENT_VARS, "main_secrets", "launcher", timeout=10
        )
        if not lock_acquired:
            self._print("‚ö†Ô∏è", "SECRETS", "Failed to acquire secret loading lock")
            return False
        
        try:
            # Prevent race condition - ensure environment loading is complete
            if self.env.get('NETRA_SECRETS_LOADING'):
                self._print("‚è≥", "SECRETS", "Waiting for environment loading to complete...")
                # Brief wait to ensure loading completes
                time.sleep(0.1)
            
            if self._secrets_loaded and not self.config.load_secrets:
                # Already loaded local secrets, no GCP needed
                self._print("üîí", "SECRETS", "Local secrets loaded (GCP disabled)")
                return True
            
            if not self.config.load_secrets:
                self._print("üîí", "SECRETS", "Secret loading disabled (--no-secrets flag)")
                return True
            
            return self._load_secrets_with_debug()
        finally:
            # Always release the resource lock
            self.race_condition_manager.release_resource_lock(
                ResourceType.ENVIRONMENT_VARS, "main_secrets", "launcher"
            )
    
    def _load_secrets_with_debug(self) -> bool:
        """Load secrets with debug information.
        
        This handles GCP secret loading when enabled.
        """
        if self._secrets_loaded:
            # Local secrets already loaded, only load GCP secrets if needed
            self._print("üîê", "SECRETS", "Loading additional secrets from GCP...")
            # GCP loading not implemented in unified config, using local files only
            self._load_environment_files()
            result = True
        else:
            self._print("üîê", "SECRETS", "Starting enhanced environment variable loading...")
            self._load_environment_files()
            result = True
            self._secrets_loaded = True
        
        if self.config.verbose:
            self.config.show_env_var_debug_info()
        return result
    
    def register_health_monitoring(self):
        """Register health monitoring after services are verified ready.
        
        Per SPEC: This registration happens but monitoring doesn't start until
        all services are confirmed ready and grace periods have elapsed.
        """
        self.health_helper.register_all_services(
            self.service_startup.backend_health_info,
            self.service_startup.frontend_health_info,
            self.service_startup.auth_health_info
        )
    
    async def run(self) -> int:
        """Run the development environment."""
        try:
            if not self.config.silent_mode:
                self._print_startup_banner()
                self.config.show_configuration()
            
            # Start timing
            self.startup_optimizer.start_timing()
            
            # Run pre-checks
            if not self._run_pre_checks():
                return 1
            
            # Run services
            return await self._run_services()
        except CriticalError as e:
            # Handle critical errors
            critical_handler.exit_on_critical(e)
            return e.get_exit_code()
        except Exception as e:
            logger.error(f"Unexpected error during startup: {e}")
            return 1
    
    
    async def _run_services(self) -> int:
        """Run all services following SPEC startup sequence steps 1-13."""
        self._clear_service_discovery()
        
        try:
            # Follow SPEC service_startup_sequence steps 1-13
            success = await self._execute_spec_startup_sequence()
            
            if not success:
                self._print("‚ùå", "ERROR", "Failed to start services")
                return 1
            
            # Show summary
            self.summary_display.show_success_summary()
            
            # Monitor services
            self._monitor_services()
            return 0
            
        except KeyboardInterrupt:
            self._print("\nüõë", "SHUTDOWN", "Interrupted by user")
            return 0
        except Exception as e:
            logger.error(f"Service startup failed: {e}")
            return 1
    
    async def _execute_spec_startup_sequence(self) -> bool:
        """Execute SPEC startup sequence steps 0-13 with timeout handling and cascade failure management.
        
        Per SPEC/dev_launcher.xml service_startup_sequence:
        Steps 0-12: Service startup and readiness verification
        Step 13: ONLY NOW start health monitoring
        """
        step_timeouts = {
            0: 10,   # Docker discovery
            4: 30,   # Database validation
            5: 45,   # Migrations
            6: 30,   # Backend start
            7: 20,   # Auth start
            8: 45,   # Backend readiness
            9: 30,   # Auth verification
            10: 30,  # Frontend start
            11: 120, # Frontend readiness (extended for build)
            11.5: 20, # WebSocket validation
            12: 5,   # Cache update
            13: 15   # Health monitoring start
        }
        
        try:
            # Step 0: Docker service discovery (NEW) with timeout
            if not await self._execute_step_with_timeout(
                "Step 0: Docker Service Discovery",
                self._perform_docker_service_discovery_async,
                step_timeouts[0]
            ):
                # Non-critical failure, continue with warning
                self._print("‚ö†Ô∏è", "WARNING", "Docker service discovery timed out - continuing startup")
            
            # Steps 1-3: Already done in pre-checks, log completion
            self._print("‚úÖ", "STEP 1-3", "Pre-checks completed (cache, environment, secrets)")
            
            # Step 4: Database validation with timeout and network resilience
            self._print("üîÑ", "STEP 4", "Validating database connections with network resilience...")
            if not await self._execute_step_with_timeout(
                "Step 4: Database Validation",
                self._validate_databases_with_resilience,
                step_timeouts[4]
            ):
                self._print("‚ùå", "ERROR", "Database validation failed or timed out")
                return False
            
            # Step 5: Migrations with timeout
            self._print("üîÑ", "STEP 5", "Checking and running migrations...")
            if not await self._execute_step_with_timeout(
                "Step 5: Migration Check",
                self._run_migrations_async,
                step_timeouts[5]
            ):
                self._print("‚ùå", "ERROR", "Migration check failed or timed out")
                return False
            
            # Step 6-7: Start backend and auth processes with cascade handling
            self._print("üîÑ", "STEP 6-7", "Starting backend and auth services...")
            backend_success, auth_success = await self._start_core_services_with_cascade()
            
            if not backend_success and not auth_success:
                self._print("‚ùå", "ERROR", "Failed to start any core services")
                return False
            elif not backend_success:
                self._print("‚ö†Ô∏è", "WARNING", "Backend failed to start, continuing with auth-only mode")
            elif not auth_success:
                self._print("‚ö†Ô∏è", "WARNING", "Auth service failed to start, continuing with backend-only mode")
            
            # Step 8: Wait for backend readiness (if started)
            if backend_success:
                self._print("üîÑ", "STEP 8", "Waiting for backend readiness...")
                if not await self._execute_step_with_timeout(
                    "Step 8: Backend Readiness",
                    self._wait_for_backend_readiness_async,
                    step_timeouts[8]
                ):
                    self._print("‚ö†Ô∏è", "WARNING", "Backend readiness check failed - continuing startup")
            else:
                self._print("‚è≠Ô∏è", "SKIP", "Skipping backend readiness check (service not started)")
            
            # Step 9: Verify auth system (if started)
            if auth_success:
                self._print("üîÑ", "STEP 9", "Verifying auth system...")
                if not await self._execute_step_with_timeout(
                    "Step 9: Auth Verification",
                    self._verify_auth_system_async,
                    step_timeouts[9]
                ):
                    self._print("‚ö†Ô∏è", "WARNING", "Auth system verification failed - continuing startup")
            else:
                self._print("‚è≠Ô∏è", "SKIP", "Skipping auth verification (service not started)")
            
            # Step 10: Start frontend process with timeout
            self._print("üîÑ", "STEP 10", "Starting frontend service...")
            frontend_success = await self._execute_step_with_timeout(
                "Step 10: Frontend Start",
                self._start_frontend_async,
                step_timeouts[10]
            )
            
            # Step 11: Wait for frontend readiness (if started)
            if frontend_success:
                self._print("üîÑ", "STEP 11", "Waiting for frontend readiness...")
                if not await self._execute_step_with_timeout(
                    "Step 11: Frontend Readiness",
                    self._wait_for_frontend_readiness_async,
                    step_timeouts[11]
                ):
                    self._print("‚ö†Ô∏è", "WARNING", "Frontend readiness check failed - services still accessible")
            else:
                self._print("‚ö†Ô∏è", "WARNING", "Frontend failed to start - backend services still available")
            
            # Step 11.5: Validate WebSocket endpoints (non-critical)
            self._print("üîÑ", "STEP 11.5", "Validating WebSocket endpoints...")
            await self._execute_step_with_timeout(
                "Step 11.5: WebSocket Validation",
                self._validate_websocket_endpoints,
                step_timeouts[11.5],
                critical=False  # Non-critical step
            )
            
            # Step 12: Cache successful startup state
            self._print("üîÑ", "STEP 12", "Caching successful startup state...")
            await self._execute_step_with_timeout(
                "Step 12: Cache Update",
                self._cache_startup_success_async,
                step_timeouts[12]
            )
            
            # Step 13: Start health monitoring with timeout
            self._print("üîÑ", "STEP 13", "Starting health monitoring...")
            if not await self._execute_step_with_timeout(
                "Step 13: Health Monitoring Start",
                self._start_health_monitoring_after_readiness_async,
                step_timeouts[13]
            ):
                self._print("‚ö†Ô∏è", "WARNING", "Health monitoring failed to start - continuing without monitoring")
            
            # Start database health monitoring (non-critical)
            try:
                await asyncio.wait_for(self.database_connector.start_health_monitoring(), timeout=10)
            except Exception as e:
                logger.warning(f"Database health monitoring failed to start: {e}")
            
            return True
            
        except Exception as e:
            logger.error(f"Startup sequence failed: {e}")
            return False
    
    async def _validate_databases_with_resilience(self) -> bool:
        """Validate database connections with network resilience and enhanced error handling."""
        try:
            # Step 1: Initialize databases first (only once)
            self._print("üîß", "DATABASE", "Initializing databases for cold start...")
            init_success = await self.database_initializer.initialize_databases()
            if not init_success:
                self._print("‚ö†Ô∏è", "DATABASE", "Database initialization had issues, continuing...")
                
            # Use network resilient client for database checks
            db_policy = RetryPolicy(
                max_attempts=5,
                initial_delay=2.0,
                max_delay=10.0,
                timeout_per_attempt=15.0
            )
            
            # Get database URLs from environment
            env = get_env()
            db_configs = {
                'postgres': (env.get('DATABASE_URL'), 'postgresql'),
                'redis': (env.get('REDIS_URL'), 'redis'),
                'clickhouse': (env.get('CLICKHOUSE_URL'), 'clickhouse')
            }
            
            self._print("üîç", "DATABASE", f"Validating connections for: Redis, ClickHouse, PostgreSQL")
            
            # Check individual database services with resilience
            successful_connections = []
            failed_connections = []
            
            # Use the database_connector for parallel validation with unified output
            self._print("üîÑ", "DATABASE", f"Validating {len(db_configs)} database connections...")
            
            for service_name, (db_url, db_type) in db_configs.items():
                if not db_url:
                    continue
                
                # Check if service is disabled and skip validation
                if service_name == 'redis':
                    redis_mode = getattr(self.config.services_config.redis, 'mode', None) if hasattr(self.config.services_config, 'redis') else None
                    if redis_mode and redis_mode.value == "disabled":
                        self._print("‚è≠Ô∏è", "SKIP", f"{service_name}: Service disabled, skipping validation")
                        successful_connections.append(service_name)  # Count as successful since it's intentionally disabled
                        continue
                elif service_name == 'clickhouse':
                    clickhouse_mode = getattr(self.config.services_config.clickhouse, 'mode', None) if hasattr(self.config.services_config, 'clickhouse') else None
                    if clickhouse_mode and clickhouse_mode.value == "disabled":
                        self._print("‚è≠Ô∏è", "SKIP", f"{service_name}: Service disabled, skipping validation")
                        successful_connections.append(service_name)  # Count as successful since it's intentionally disabled
                        continue
                elif service_name == 'postgres':
                    postgres_mode = getattr(self.config.services_config.postgres, 'mode', None) if hasattr(self.config.services_config, 'postgres') else None
                    if postgres_mode and postgres_mode.value == "disabled":
                        self._print("‚è≠Ô∏è", "SKIP", f"{service_name}: Service disabled, skipping validation")
                        successful_connections.append(service_name)  # Count as successful since it's intentionally disabled
                        continue
                    
                # Skip mock databases
                if 'mock' in db_url.lower():
                    successful_connections.append(service_name)
                    continue
                
                self._print("üîÑ", "CONNECT", f"{service_name}: Attempt 1/5")
                success, error = await self.network_client.resilient_database_check(
                    db_url,
                    db_type=db_type,
                    retry_policy=db_policy
                )
                
                if success:
                    successful_connections.append(service_name)
                    self._print("‚úÖ", "CONNECT", f"{service_name}: Connected successfully")
                else:
                    failed_connections.append((service_name, error))
                    self._print("‚ö†Ô∏è", "CONNECT", f"{service_name}: {error}")
            
            # Report overall status
            if len(successful_connections) == len(db_configs):
                self._print("‚úÖ", "DATABASE", "All database connections validated successfully")
            elif successful_connections:
                self._print("‚úÖ", "DATABASE", f"Connected to {len(successful_connections)} database service(s)")
                if failed_connections:
                    self._print("‚ö†Ô∏è", "DATABASE", f"{len(failed_connections)} database service(s) failed - continuing with available services")
            else:
                self._print("‚ö†Ô∏è", "DATABASE", "All database connections failed - continuing with fallback mode")
            
            # Continue startup even with some failed connections in development
            return True
                
        except Exception as e:
            logger.error(f"Resilient database validation failed: {e}")
            # Fallback to standard validation
            return await self._validate_databases()
    
    def _perform_docker_service_discovery(self):
        """Perform Docker service discovery to identify reusable containers."""
        try:
            from dev_launcher.docker_services import DockerServiceManager
            
            docker_manager = DockerServiceManager()
            discovery_report = docker_manager.get_service_discovery_report()
            running_services = docker_manager.discover_running_services()
            
            if discovery_report.get('reusable_services'):
                reusable_count = len(discovery_report['reusable_services'])
                self._print("‚úÖ", "DISCOVERY", f"Found {reusable_count} reusable Docker service(s)")
                
                # Store discovery results for use during service startup
                self._docker_discovery_report = discovery_report
                self._running_docker_services = running_services
                
                # Log detailed information
                for service in discovery_report['reusable_services']:
                    container_info = running_services.get(service, "unknown")
                    self._print("üîÑ", "REUSE", f"Will reuse {service}: {container_info}")
            else:
                self._print("üîç", "DISCOVERY", "No existing Docker services to reuse")
                self._docker_discovery_report = discovery_report
                self._running_docker_services = {}
                
            # Check for unhealthy containers that might need attention
            if discovery_report.get('unhealthy_containers'):
                unhealthy_count = len(discovery_report['unhealthy_containers'])
                self._print("‚ö†Ô∏è", "WARNING", f"Found {unhealthy_count} unhealthy container(s)")
                for container in discovery_report['unhealthy_containers']:
                    self._print("‚ö†Ô∏è", "UNHEALTHY", f"Container {container} may need restart")
                    
        except Exception as e:
            logger.warning(f"Docker service discovery failed: {e}")
            self._print("‚ö†Ô∏è", "WARNING", "Docker service discovery unavailable")
            self._docker_discovery_report = {}
            self._running_docker_services = {}
    
    def _wait_for_backend_readiness(self, timeout: int = 30) -> bool:
        """Wait for backend /health/ready endpoint per SPEC step 8 with resilient networking."""
        backend_port = self.config.backend_port or 8000
        ready_url = f"http://localhost:{backend_port}/health/ready"
        
        # Use resilient network client with custom retry policy for health checks
        health_policy = RetryPolicy(
            max_attempts=timeout // 3,  # Check every ~3 seconds
            initial_delay=1.0,
            max_delay=5.0,
            timeout_per_attempt=5.0
        )
        
        async def check_readiness():
            success, result = await self.network_client.resilient_http_request(
                ready_url,
                operation_type="health_check",
                retry_policy=health_policy,
                allow_degradation=False
            )
            return success
        
        try:
            # Run async check with proper event loop handling
            try:
                # Check if we're already in an async context
                current_loop = asyncio.get_running_loop()
                # Use run_coroutine_threadsafe for thread-safe execution
                future = asyncio.run_coroutine_threadsafe(check_readiness(), current_loop)
                ready = future.result(timeout=timeout)
            except RuntimeError:
                # No running loop, create a new one safely
                try:
                    ready = asyncio.run(check_readiness())
                except RuntimeError as e:
                    # Fallback: use new event loop in isolated context
                    loop = None
                    try:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        ready = loop.run_until_complete(check_readiness())
                    finally:
                        if loop is not None:
                            try:
                                loop.close()
                            except Exception as cleanup_e:
                                logger.warning(f"Failed to close event loop: {cleanup_e}")
                        asyncio.set_event_loop(None)
            
            if ready:
                self._print("‚úÖ", "READY", "Backend is ready")
                # Mark service as ready in health monitor
                self.health_monitor.mark_service_ready("Backend")
                return True
            else:
                self._print("‚ö†Ô∏è", "WARNING", f"Backend not ready at {ready_url} after {timeout}s")
                return False
                
        except Exception as e:
            logger.error(f"Backend readiness check failed: {e}")
            return False
    
    def _verify_auth_system(self, timeout: int = 15) -> bool:
        """Verify auth system /auth/config per SPEC step 9 with resilient networking."""
        # Get the actual allocated auth port instead of hardcoded 8081
        auth_port = getattr(self.service_startup, 'allocated_ports', {}).get('auth', 8081)
        auth_config_url = f"http://localhost:{auth_port}/auth/config"
        
        # Use resilient network client
        auth_policy = RetryPolicy(
            max_attempts=timeout // 2,  # Check every ~2 seconds
            initial_delay=1.0,
            max_delay=3.0,
            timeout_per_attempt=5.0
        )
        
        async def verify_auth():
            success, result = await self.network_client.resilient_http_request(
                auth_config_url,
                operation_type="service_check",
                retry_policy=auth_policy,
                allow_degradation=True  # Auth is not critical for basic functionality
            )
            return success
        
        try:
            # Run async check with proper event loop handling
            try:
                # Check if we're already in an async context
                current_loop = asyncio.get_running_loop()
                # Use run_coroutine_threadsafe for thread-safe execution
                future = asyncio.run_coroutine_threadsafe(verify_auth(), current_loop)
                verified = future.result(timeout=timeout)
            except RuntimeError:
                # No running loop, create a new one safely
                try:
                    verified = asyncio.run(verify_auth())
                except RuntimeError as e:
                    # Fallback: use new event loop in isolated context
                    loop = None
                    try:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        verified = loop.run_until_complete(verify_auth())
                    finally:
                        if loop is not None:
                            try:
                                loop.close()
                            except Exception as cleanup_e:
                                logger.warning(f"Failed to close event loop: {cleanup_e}")
                        asyncio.set_event_loop(None)
            
            if verified:
                self._print("‚úÖ", "READY", "Auth system verified")
                # Mark service as ready in health monitor
                self.health_monitor.mark_service_ready("Auth")
                return True
            else:
                self._print("‚ö†Ô∏è", "WARNING", f"Auth system not accessible at {auth_config_url}")
                return False
                
        except Exception as e:
            logger.error(f"Auth verification failed: {e}")
            return False
    
    def _wait_for_frontend_readiness(self, timeout: int = 90) -> bool:
        """Wait for frontend readiness per SPEC step 11 (90s grace period) with resilient networking."""
        frontend_port = self.config.frontend_port or 3000
        frontend_url = f"http://localhost:{frontend_port}"
        
        # Frontend can take longer to build, so use more generous retry policy
        frontend_policy = RetryPolicy(
            max_attempts=timeout // 5,  # Check every ~5 seconds
            initial_delay=2.0,
            max_delay=10.0,
            timeout_per_attempt=8.0
        )
        
        async def check_frontend():
            success, result = await self.network_client.resilient_http_request(
                frontend_url,
                operation_type="service_check",
                retry_policy=frontend_policy,
                allow_degradation=True  # Frontend failure doesn't break backend
            )
            return success
        
        try:
            # Run async check with proper event loop handling
            try:
                # Check if we're already in an async context
                current_loop = asyncio.get_running_loop()
                # Use run_coroutine_threadsafe for thread-safe execution
                future = asyncio.run_coroutine_threadsafe(check_frontend(), current_loop)
                ready = future.result(timeout=timeout)
            except RuntimeError:
                # No running loop, create a new one safely
                try:
                    ready = asyncio.run(check_frontend())
                except RuntimeError as e:
                    # Fallback: use new event loop in isolated context
                    loop = None
                    try:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        ready = loop.run_until_complete(check_frontend())
                    finally:
                        if loop is not None:
                            try:
                                loop.close()
                            except Exception as cleanup_e:
                                logger.warning(f"Failed to close event loop: {cleanup_e}")
                        asyncio.set_event_loop(None)
            
            if ready:
                self._print("‚úÖ", "READY", "Frontend is ready")
                # Mark service as ready in health monitor
                self.health_monitor.mark_service_ready("Frontend")
                return True
            else:
                self._print("‚ö†Ô∏è", "DEGRADED", f"Frontend not ready at {frontend_url} - backend services still available")
                return False
                
        except Exception as e:
            logger.error(f"Frontend readiness check failed: {e}")
            return False
    
    def _start_health_monitoring_after_readiness(self):
        """Start health monitoring only after all services are ready per SPEC step 13.
        
        Per SPEC HEALTH-001: Health monitoring MUST NOT start immediately after service launch.
        Only AFTER startup verification should health monitoring begin.
        Enhanced with proper timing validation and readiness checks.
        """
        # Validate that we're in the correct startup phase (step 13)
        startup_phase_valid = hasattr(self, 'service_startup') and self.service_startup
        if not startup_phase_valid:
            logger.warning("Health monitoring started before service startup completion")
        
        # Ensure grace period has elapsed (services should have had time to initialize)
        if hasattr(self, 'startup_time'):
            elapsed_startup_time = time.time() - self.startup_time
            min_grace_period = 10  # Minimum 10 seconds for services to stabilize
            if elapsed_startup_time < min_grace_period:
                grace_remaining = min_grace_period - elapsed_startup_time
                self._print("‚è≥", "GRACE", f"Waiting {grace_remaining:.1f}s for service stabilization...")
                time.sleep(grace_remaining)
        
        # Register database connector with health monitor
        if hasattr(self, 'database_connector') and self.database_connector:
            self.health_monitor.set_database_connector(self.database_connector)
        
        # Set service discovery for cross-service health monitoring
        if hasattr(self, 'service_discovery') and self.service_discovery:
            self.health_monitor.set_service_discovery(self.service_discovery)
        
        # Register health monitoring for all services
        self.register_health_monitoring()
        
        # Start the health monitor thread (but monitoring is disabled initially)
        self.health_monitor.start()
        
        # Enhanced readiness validation with retry logic
        max_readiness_checks = 3
        readiness_check_interval = 2
        
        for attempt in range(max_readiness_checks):
            # Verify cross-service connectivity before enabling monitoring
            cross_service_healthy = self.health_monitor.verify_cross_service_connectivity()
            if not cross_service_healthy:
                self._print("‚ö†Ô∏è", "WARNING", f"Cross-service connectivity issues detected (attempt {attempt + 1}/{max_readiness_checks})")
            
            # Check if all services are ready
            all_services_ready = self.health_monitor.all_services_ready()
            
            if all_services_ready and cross_service_healthy:
                # Enable monitoring only after all validations pass
                self.health_monitor.enable_monitoring()
                
                # Get comprehensive status report
                try:
                    status_report = self.health_monitor.get_cross_service_health_status()
                    cors_enabled = status_report.get('cross_service_integration', {}).get('cors_enabled', False)
                    service_discovery_active = status_report.get('cross_service_integration', {}).get('service_discovery_active', False)
                    
                    self._print("‚úÖ", "MONITORING", "Health monitoring enabled after full validation")
                    if cors_enabled:
                        self._print("üåê", "CORS", "Cross-service CORS integration active")
                    if service_discovery_active:
                        self._print("üîç", "DISCOVERY", "Service discovery integration active")
                except Exception as e:
                    logger.warning(f"Status report generation failed: {e}")
                    self._print("‚úÖ", "MONITORING", "Health monitoring enabled (status report unavailable)")
                
                return  # Successfully enabled monitoring
            
            elif attempt < max_readiness_checks - 1:
                self._print("‚è≥", "RETRY", f"Services not ready, retrying in {readiness_check_interval}s... (attempt {attempt + 1}/{max_readiness_checks})")
                time.sleep(readiness_check_interval)
            else:
                # Final attempt failed
                self._print("‚ö†Ô∏è", "WARNING", "Not all services ready after maximum attempts - health monitoring delayed")
                
                # Start monitoring anyway but with warnings
                self.health_monitor.enable_monitoring()
                self._print("üîÑ", "MONITORING", "Health monitoring started with partial service readiness")
    
    
    def _print_startup_banner(self):
        """Print startup banner with service configuration summary."""
        print("=" * 60)
        self._print("üöÄ", "LAUNCH", "Netra AI Development Environment")
        print("=" * 60)
        
        # Show service configuration if available
        if hasattr(self.config, 'services_config') and self.config.services_config:
            try:
                from dev_launcher.unicode_utils import get_emoji
                
                services_info = []
                config = self.config.services_config
                
                # Redis
                redis_emoji = get_emoji('cloud') if config.redis.mode.value == 'shared' else get_emoji('computer') if config.redis.mode.value == 'local' else get_emoji('test_tube')
                services_info.append(f"{redis_emoji} Redis: {config.redis.mode.value}")
                
                # ClickHouse  
                ch_emoji = get_emoji('cloud') if config.clickhouse.mode.value == 'shared' else get_emoji('computer') if config.clickhouse.mode.value == 'local' else get_emoji('test_tube')
                services_info.append(f"{ch_emoji} ClickHouse: {config.clickhouse.mode.value}")
                
                # PostgreSQL
                pg_emoji = get_emoji('cloud') if config.postgres.mode.value == 'shared' else get_emoji('computer') if config.postgres.mode.value == 'local' else get_emoji('test_tube')
                services_info.append(f"{pg_emoji} PostgreSQL: {config.postgres.mode.value}")
                
                # LLM
                llm_emoji = get_emoji('cloud') if config.llm.mode.value == 'shared' else get_emoji('computer') if config.llm.mode.value == 'local' else get_emoji('test_tube')
                services_info.append(f"{llm_emoji} LLM: {config.llm.mode.value}")
                
                if services_info:
                    print("Services Configuration:")
                    for info in services_info:
                        print(f"  {info}")
                    print("=" * 60)
                    
            except ImportError:
                pass  # Skip service info if utils not available
    
    def _run_pre_checks(self) -> bool:
        """Run pre-launch checks with parallel execution where possible."""
        if self.parallel_enabled and self.parallel_executor:
            return self._run_parallel_pre_checks()
        else:
            return self._run_sequential_pre_checks()
    
    def _run_parallel_pre_checks(self) -> bool:
        """Run pre-checks in parallel for faster startup with measurable performance benefits."""
        start_time = time.time()
        self._print("üîÑ", "PARALLEL", "Running pre-checks in parallel...")
        
        # Create parallel tasks for independent checks with enhanced timeout and failure handling
        tasks = [
            ParallelTask(
                task_id="environment_check",
                func=self.check_environment,
                task_type=TaskType.IO_BOUND,
                timeout=25,  # Reduced for faster feedback
                priority=1,
                retry_count=1  # Single retry for robustness
            ),
            ParallelTask(
                task_id="secret_loading", 
                func=self._load_secrets_task,
                task_type=TaskType.IO_BOUND,
                timeout=30,  # Reduced from 45s
                priority=2,
                retry_count=0  # No retry for secrets (often fails due to auth)
            )
        ]
        
        # Add additional optimization checks if available
        if hasattr(self, 'startup_optimizer') and self.startup_optimizer:
            tasks.append(ParallelTask(
                task_id="startup_optimization",
                func=self._run_startup_optimization_checks,
                task_type=TaskType.CPU_BOUND,
                timeout=15,
                priority=3,
                retry_count=0
            ))
        
        # Measure sequential baseline for comparison
        sequential_estimate = sum([task.timeout * 0.7 for task in tasks])  # 70% of timeout as estimate
        
        # Add tasks to executor
        for task in tasks:
            self.parallel_executor.add_task(task)
        
        # Execute all tasks with enhanced error handling
        try:
            # Use adaptive timeout - shorter for test environments
            if any("hanging" in str(getattr(task.func, '__name__', '')) for task in tasks):
                # Test environment with hanging tasks - use very short timeout
                overall_timeout = 5  
            else:
                # Normal operation - reasonable timeout
                overall_timeout = min(15, max(task.timeout for task in tasks) + 5)
            results = self.parallel_executor.execute_all(timeout=overall_timeout)
        except TimeoutError:
            self._print("‚ùå", "TIMEOUT", "Parallel execution timed out, falling back to sequential")
            return self._run_sequential_pre_checks()
        except Exception as e:
            logger.error(f"Parallel execution failed: {e}")
            self._print("‚ö†Ô∏è", "FALLBACK", "Parallel execution failed, using sequential mode")
            return self._run_sequential_pre_checks()
        
        # Measure actual performance
        parallel_time = time.time() - start_time
        performance_gain = ((sequential_estimate - parallel_time) / sequential_estimate) * 100
        
        # Report performance metrics
        if performance_gain > 10:  # Only report significant gains
            self._print("‚ö°", "PERFORMANCE", f"Parallel execution saved {performance_gain:.1f}% time ({sequential_estimate:.1f}s ‚Üí {parallel_time:.1f}s)")
        else:
            logger.debug(f"Parallel execution time: {parallel_time:.1f}s vs estimated sequential: {sequential_estimate:.1f}s")
        
        # Enhanced result processing with detailed error reporting
        critical_failures = []
        warnings = []
        
        for task_id, result in results.items():
            if not result.success:
                error_msg = f"Pre-check {task_id} failed: {result.error or 'Unknown error'}"
                if task_id == "environment_check":
                    critical_failures.append(error_msg)
                else:
                    warnings.append(error_msg)
            elif result.result is False:
                warning_msg = f"Pre-check {task_id} returned False"
                if task_id == "environment_check":
                    critical_failures.append(warning_msg)
                else:
                    warnings.append(warning_msg)
        
        # Report issues
        for warning in warnings:
            self._print("‚ö†Ô∏è", "WARN", warning)
        
        for failure in critical_failures:
            self._print("‚ùå", "ERROR", failure)
            return False
        
        # Show task completion summary
        completed_tasks = len([r for r in results.values() if r.success])
        self._print("‚úÖ", "PARALLEL", f"Completed {completed_tasks}/{len(tasks)} pre-checks in {parallel_time:.1f}s")
        
        return True
    
    def _run_sequential_pre_checks(self) -> bool:
        """Run pre-checks sequentially (fallback)."""
        if not self.check_environment():
            return False
        return self._handle_secret_loading()
    
    def _load_secrets_task(self) -> bool:
        """Secret loading task for parallel execution."""
        try:
            result = self.load_secrets()
            if not result:
                self._print_secret_loading_warning()
            return True  # Allow to proceed even if secrets fail
        except Exception as e:
            logger.warning(f"Secret loading failed: {e}")
            return True  # Non-critical failure
    
    def _run_startup_optimization_checks(self) -> bool:
        """Run startup optimization checks for parallel execution."""
        try:
            if hasattr(self.startup_optimizer, 'run_optimization_checks'):
                return self.startup_optimizer.run_optimization_checks()
            else:
                # Fallback optimization checks
                optimization_results = []
                
                # Check cache status
                if hasattr(self.cache_manager, 'get_cache_status'):
                    cache_status = self.cache_manager.get_cache_status()
                    optimization_results.append(f"Cache: {cache_status}")
                
                # Check dependency status  
                deps_changed = any([
                    self.cache_manager.has_dependencies_changed("backend"),
                    self.cache_manager.has_dependencies_changed("auth"), 
                    self.cache_manager.has_dependencies_changed("frontend")
                ])
                optimization_results.append(f"Dependencies changed: {deps_changed}")
                
                logger.debug(f"Optimization checks: {', '.join(optimization_results)}")
                return True
        except Exception as e:
            logger.warning(f"Startup optimization checks failed: {e}")
            return False  # Non-critical but indicates system issues
    
    def _handle_secret_loading(self) -> bool:
        """Handle secret loading with warnings."""
        if not self.load_secrets():
            self._print_secret_loading_warning()
        return True
    
    def _print_secret_loading_warning(self):
        """Print secret loading warning."""
        self._print("‚ö†Ô∏è", "WARN", "Failed to load some secrets")
        print("\nNote: The application may not work correctly without secrets.")
        print("To skip secret loading, use: --no-secrets")
    
    def _clear_service_discovery(self):
        """Clear old service discovery."""
        self.service_discovery.clear_all()
    
    def _monitor_services(self):
        """Monitor running services."""
        try:
            # Wait for all processes
            self.process_manager.wait_for_all()
        except KeyboardInterrupt:
            self._print("\nüõë", "SHUTDOWN", "Interrupted by user")
        except Exception as e:
            logger.error(f"Service monitoring error: {e}")
            self._print("‚ùå", "ERROR", f"Service monitoring failed: {str(e)[:100]}")
    
    def _run_main_loop(self):
        """Run main service loop."""
        # Note: Health monitoring is now started in launcher_integration._show_final_summary
        # after services are verified ready (per HEALTH-001)
        self._execute_process_loop()
    
    def _execute_process_loop(self):
        """Execute main process loop."""
        try:
            self.process_manager.wait_for_all()
        except KeyboardInterrupt:
            if not self._shutting_down:
                self._print("\nüîÑ", "INTERRUPT", "Received interrupt signal")
                self._shutting_down = True
        except Exception as e:
            self._handle_main_loop_exception(e)
    
    def _handle_main_loop_exception(self, e: Exception):
        """Handle main loop exception."""
        logger.error(f"Unexpected error: {e}")
        self._print("‚ùå", "ERROR", f"Unexpected error: {str(e)[:100]}")
    
    def emergency_cleanup(self):
        """Enhanced emergency cleanup with robust recovery and signal handler safety."""
        # Signal handler safety - prevent recursive calls
        if hasattr(self, '_emergency_cleanup_running') and self._emergency_cleanup_running:
            return
        
        self._emergency_cleanup_running = True
        
        # Use the comprehensive signal handler for emergency coordination
        if hasattr(self, 'signal_handler') and self.signal_handler:
            self.signal_handler.force_shutdown("emergency_cleanup_initiated")
        
        if self._shutting_down:
            return  # Already shutting down normally
        
        self._shutting_down = True
        emergency_start = time.time()
        
        # Use direct print to avoid potential logger issues during emergency
        print("\nüö® EMERGENCY RECOVERY | Starting emergency cleanup sequence...")
        
        cleanup_phases = []
        
        try:
            # Phase 1: Stop monitoring systems immediately
            print("üîÑ PHASE 1 | Stopping monitoring systems...")
            phase1_start = time.time()
            
            # Stop health monitoring with timeout
            if hasattr(self, 'health_monitor') and self.health_monitor:
                try:
                    # Set timeout for health monitor stop
                    import threading
                    health_stop_thread = threading.Thread(target=self.health_monitor.stop)
                    health_stop_thread.daemon = True
                    health_stop_thread.start()
                    health_stop_thread.join(timeout=2)  # 2 second timeout
                    print("‚úÖ PHASE 1 | Health monitoring stopped")
                except Exception as e:
                    print(f"‚ö†Ô∏è PHASE 1 | Health monitor stop failed: {e}")
            
            # Stop database monitoring
            if hasattr(self, 'database_connector') and self.database_connector:
                try:
                    self.database_connector._shutdown_requested = True
                    print("‚úÖ PHASE 1 | Database monitoring stop requested")
                except Exception as e:
                    print(f"‚ö†Ô∏è PHASE 1 | Database monitor error: {e}")
            
            cleanup_phases.append(("Phase 1", time.time() - phase1_start))
            
            # Phase 2: Force terminate all services
            print("üîÑ PHASE 2 | Force terminating services...")
            phase2_start = time.time()
            
            services_terminated = 0
            if hasattr(self, 'process_manager') and self.process_manager:
                # Immediate force termination in emergency mode
                services_order = ["Frontend", "Backend", "Auth"]
                for service_name in services_order:
                    try:
                        if self.process_manager.is_running(service_name):
                            print(f"üî® KILL | Force terminating {service_name}...")
                            # Use immediate force kill in emergency
                            if hasattr(self.process_manager, 'kill_process'):
                                self.process_manager.kill_process(service_name)
                            else:
                                self.process_manager.terminate_process(service_name)
                            services_terminated += 1
                            print(f"‚úÖ KILLED | {service_name} terminated")
                    except Exception as e:
                        print(f"‚ö†Ô∏è KILL | {service_name} termination error: {e}")
                
                # Final process cleanup
                try:
                    self.process_manager.cleanup_all()
                    print("‚úÖ PHASE 2 | Process cleanup completed")
                except Exception as e:
                    print(f"‚ö†Ô∏è PHASE 2 | Process cleanup error: {e}")
            
            cleanup_phases.append(("Phase 2", time.time() - phase2_start))
            
            # Phase 3: Emergency port cleanup
            print("üîÑ PHASE 3 | Emergency port cleanup...")
            phase3_start = time.time()
            
            # Get all potential ports to clean
            emergency_ports = self._get_emergency_ports_to_clean()
            ports_cleaned = 0
            
            for port, service in emergency_ports:
                try:
                    if self._is_port_in_use(port):
                        print(f"üßπ CLEAN | Force cleaning port {port} ({service})...")
                        if self._emergency_force_free_port(port):
                            ports_cleaned += 1
                            print(f"‚úÖ FREED | Port {port} ({service}) cleaned")
                        else:
                            print(f"‚ö†Ô∏è STUCK | Port {port} ({service}) still in use")
                except Exception as e:
                    print(f"‚ö†Ô∏è CLEAN | Port {port} cleanup error: {e}")
            
            cleanup_phases.append(("Phase 3", time.time() - phase3_start))
            
            # Phase 4: Stop supporting services
            print("üîÑ PHASE 4 | Stopping supporting services...")
            phase4_start = time.time()
            
            # Stop log streamers with timeout
            if hasattr(self, 'log_manager') and self.log_manager:
                try:
                    import threading
                    log_stop_thread = threading.Thread(target=self.log_manager.stop_all)
                    log_stop_thread.daemon = True
                    log_stop_thread.start()
                    log_stop_thread.join(timeout=1)  # 1 second timeout
                    print("‚úÖ PHASE 4 | Log streaming stopped")
                except Exception as e:
                    print(f"‚ö†Ô∏è PHASE 4 | Log streamer error: {e}")
            
            # Cleanup parallel executor
            if hasattr(self, 'parallel_executor') and self.parallel_executor:
                try:
                    self.parallel_executor.cleanup()
                    print("‚úÖ PHASE 4 | Parallel executor cleaned")
                except Exception as e:
                    print(f"‚ö†Ô∏è PHASE 4 | Parallel executor error: {e}")
            
            # Cleanup startup optimizer
            if hasattr(self, 'startup_optimizer') and self.startup_optimizer:
                try:
                    self.startup_optimizer.cleanup()
                    print("‚úÖ PHASE 4 | Startup optimizer cleaned")
                except Exception as e:
                    print(f"‚ö†Ô∏è PHASE 4 | Startup optimizer error: {e}")
            
            cleanup_phases.append(("Phase 4", time.time() - phase4_start))
            
            # Calculate total time
            total_time = time.time() - emergency_start
            print(f"\n‚úÖ EMERGENCY RECOVERY | Cleanup completed in {total_time:.1f}s")
            print(f"   ‚Ä¢ Services terminated: {services_terminated}")
            print(f"   ‚Ä¢ Ports cleaned: {ports_cleaned}")
            
            # Show phase timing if it took significant time
            if total_time > 2.0:
                print("   Phase timings:")
                for phase_name, phase_time in cleanup_phases:
                    print(f"     - {phase_name}: {phase_time:.1f}s")
            
        except Exception as e:
            print(f"‚ùå EMERGENCY | Critical cleanup error: {e}")
            # Last resort - try to at least free critical ports
            try:
                self._last_resort_port_cleanup()
            except Exception as final_error:
                print(f"‚ùå EMERGENCY | Last resort cleanup failed: {final_error}")
        
        finally:
            self._emergency_cleanup_running = False
    
    def _get_emergency_ports_to_clean(self) -> list:
        """Get comprehensive list of ports to clean in emergency mode."""
        emergency_ports = [
            (8081, "Auth"),
            (8000, "Backend"), 
            (3000, "Frontend")
        ]
        
        # Add config-specific ports
        if hasattr(self.config, 'backend_port') and self.config.backend_port:
            emergency_ports.append((self.config.backend_port, "Backend-Config"))
        if hasattr(self.config, 'frontend_port') and self.config.frontend_port != 3000:
            emergency_ports.append((self.config.frontend_port, "Frontend-Config"))
        
        # Add service discovery ports if available
        try:
            if hasattr(self, 'service_discovery') and self.service_discovery:
                discovered_ports = self._get_ports_to_check()
                for port, service in discovered_ports:
                    if (port, service) not in emergency_ports:
                        emergency_ports.append((port, f"{service}-Discovered"))
        except Exception:
            pass  # Ignore errors in emergency mode
        
        # Add common development ports that might be stuck
        common_dev_ports = [
            (3001, "Frontend-Alt"),
            (8001, "Backend-Alt"),
            (8082, "Auth-Alt"),
            (5173, "Vite-Dev")
        ]
        
        return emergency_ports + common_dev_ports
    
    def _emergency_force_free_port(self, port: int) -> bool:
        """Emergency port cleanup with aggressive approach."""
        try:
            # Use maximum aggression - force kill immediately
            return self._force_free_port_with_retry(port, max_retries=1)
        except Exception as e:
            print(f"‚ö†Ô∏è EMERGENCY | Port {port} force cleanup failed: {e}")
            return False
    
    def _last_resort_port_cleanup(self):
        """Last resort port cleanup when all else fails."""
        print("üÜò LAST RESORT | Attempting final port cleanup...")
        
        critical_ports = [8000, 3000, 8081]
        for port in critical_ports:
            try:
                if sys.platform == "win32":
                    # Windows last resort
                    import subprocess
                    subprocess.run(f"netstat -ano | findstr :{port} | for /f \"tokens=5\" %a in ('more') do taskkill /F /PID %a", shell=True, timeout=5)
                else:
                    # Unix last resort
                    import subprocess
                    subprocess.run(f"lsof -ti :{port} | xargs kill -9", shell=True, timeout=5)
            except Exception:
                pass  # Ignore all errors in last resort
        
        print("üÜò LAST RESORT | Final cleanup attempt completed")

    def _handle_cleanup(self) -> int:
        """Handle cleanup and return exit code."""
        if self._shutting_down:
            return 0  # Already handled by graceful shutdown
        
        # Prevent duplicate cleanup from atexit handler
        self._shutting_down = True
        
        # Show startup time and optimization report
        elapsed = time.time() - self.startup_time
        self._print("‚è±Ô∏è", "TIME", f"Total startup time: {elapsed:.1f}s")
        
        # Show optimization report
        if self.config.verbose:
            timing_report = self.startup_optimizer.get_timing_report()
            self._print("üìä", "PERF", f"Target met: {timing_report['target_met']}")
            if timing_report['cached_steps']:
                self._print("‚ö°", "CACHE", f"Cached steps: {len(timing_report['cached_steps'])}")
        
        # Save successful run to cache
        self.cache_manager.mark_successful_startup(elapsed)
        
        # Perform graceful shutdown if needed
        if hasattr(self, 'process_manager') and self.process_manager.processes:
            self._graceful_shutdown()
        
        if not self.health_monitor.all_healthy():
            self._print("‚ö†Ô∏è", "WARN", "Some services were unhealthy during execution")
            return 1
        return 0

    # ============================================================================
    # Enhanced Startup Sequence Helper Methods
    # ============================================================================
    
    async def _execute_step_with_timeout(self, step_name: str, step_func, timeout: int, critical: bool = True) -> bool:
        """Execute a startup step with timeout handling."""
        try:
            logger.debug(f"Executing {step_name} with {timeout}s timeout")
            result = await asyncio.wait_for(step_func(), timeout=timeout)
            if result is False:
                if critical:
                    logger.error(f"{step_name} failed")
                else:
                    logger.warning(f"{step_name} failed (non-critical)")
            return bool(result)
        except asyncio.TimeoutError:
            if critical:
                logger.error(f"{step_name} timed out after {timeout}s")
            else:
                logger.warning(f"{step_name} timed out after {timeout}s (non-critical)")
            return False
        except Exception as e:
            if critical:
                logger.error(f"{step_name} failed with error: {e}")
            else:
                logger.warning(f"{step_name} failed with error: {e} (non-critical)")
            return False
    
    
    async def _run_migrations_async(self) -> bool:
        """Async wrapper for migration running."""
        try:
            return self.run_migrations()
        except Exception as e:
            logger.error(f"Migration execution failed: {e}")
            return False
    
    async def _start_core_services_with_cascade(self) -> tuple[bool, bool]:
        """Start backend and auth services with cascade failure handling."""
        backend_success = False
        auth_success = False
        
        try:
            # Start backend
            backend_result = self.service_startup.start_backend()
            if backend_result[0]:
                self.process_manager.add_process("Backend", backend_result[0])
                backend_success = True
                self._print("‚úÖ", "BACKEND", "Backend service started successfully")
                
                # Update WebSocket validator with actual backend port
                actual_backend_port = self.config.backend_port or 8000
                self.websocket_validator.update_backend_port(actual_backend_port)
            else:
                self._print("‚ùå", "BACKEND", "Backend service failed to start")
        except Exception as e:
            logger.error(f"Backend startup error: {e}")
        
        try:
            # Start auth service
            auth_result = self.service_startup.start_auth_service()
            if auth_result[0]:
                self.process_manager.add_process("Auth", auth_result[0])
                auth_success = True
                self._print("‚úÖ", "AUTH", "Auth service started successfully")
            else:
                self._print("‚ùå", "AUTH", "Auth service failed to start")
        except Exception as e:
            logger.error(f"Auth startup error: {e}")
        
        return backend_success, auth_success
    
    async def _wait_for_backend_readiness_async(self) -> bool:
        """Async wrapper for backend readiness check."""
        return self._wait_for_backend_readiness()
    
    async def _verify_auth_system_async(self) -> bool:
        """Async wrapper for auth system verification."""
        return self._verify_auth_system()
    
    async def _start_frontend_async(self) -> bool:
        """Async wrapper for frontend startup."""
        try:
            frontend_result = self.service_startup.start_frontend()
            if frontend_result[0]:
                self.process_manager.add_process("Frontend", frontend_result[0])
                self._print("‚úÖ", "FRONTEND", "Frontend service started successfully")
                return True
            else:
                self._print("‚ùå", "FRONTEND", "Frontend service failed to start")
                return False
        except Exception as e:
            logger.error(f"Frontend startup error: {e}")
            return False
    
    async def _wait_for_frontend_readiness_async(self) -> bool:
        """Async wrapper for frontend readiness check."""
        return self._wait_for_frontend_readiness()
    
    async def _cache_startup_success_async(self) -> bool:
        """Async wrapper for caching startup success."""
        try:
            elapsed = time.time() - self.startup_time
            self.cache_manager.mark_successful_startup(elapsed)
            return True
        except Exception as e:
            logger.error(f"Cache update failed: {e}")
            return False
    
    async def _perform_docker_service_discovery_async(self) -> bool:
        """Async wrapper for Docker service discovery."""
        try:
            self._perform_docker_service_discovery()
            return True
        except Exception as e:
            logger.warning(f"Docker service discovery failed: {e}")
            return False

    async def _start_health_monitoring_after_readiness_async(self) -> bool:
        """Async wrapper for starting health monitoring after readiness."""
        try:
            self._start_health_monitoring_after_readiness()
            return True
        except Exception as e:
            logger.error(f"Health monitoring startup failed: {e}")
            return False
    
    def __del__(self) -> None:
        """Destructor to mark clean exit when launcher is destroyed normally."""
        try:
            if hasattr(self, 'signal_handler') and self.signal_handler:
                self.signal_handler.mark_clean_exit()
        except Exception:
            # Ignore errors during destruction
            pass