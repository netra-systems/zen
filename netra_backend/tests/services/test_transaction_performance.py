"""
Focused tests for transaction performance under various load conditions
Tests high concurrency, scaling, and performance metrics
MODULAR VERSION: <300 lines, all functions â‰¤8 lines
"""

import pytest
import asyncio
import uuid
from datetime import datetime, UTC
from typing import Dict, List, Any, Optional
from unittest.mock import AsyncMock, MagicMock
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.exc import IntegrityError, SQLAlchemyError, DisconnectionError

# Add project root to path
from netra_backend.tests.test_utils import setup_test_path
setup_test_path()

from netra_backend.app.services.database.base_repository import BaseRepository
from netra_backend.app.core.exceptions_base import NetraException

# Add project root to path


class MockDatabaseModel:
    """Mock database model for testing"""
    
    def __init__(self, id: str = None, name: str = None, **kwargs):
        self.id = id or str(uuid.uuid4())
        self.name = name
        self.created_at = datetime.now(UTC)
        self.updated_at = datetime.now(UTC)
        
        # Set other attributes
        for key, value in kwargs.items():
            setattr(self, key, value)


class MockRepository(BaseRepository[MockDatabaseModel]):
    """Mock repository for testing transaction behavior"""
    
    def __init__(self):
        super().__init__(MockDatabaseModel)
        self.operation_log = []  # Track operations for testing
    
    async def create(self, db: Optional[AsyncSession] = None, **kwargs) -> Optional[MockDatabaseModel]:
        """Override create to log operations"""
        self.operation_log.append(('create', kwargs))
        
        if not db:
            return None
            
        try:
            # Create mock entity directly without calling super()
            entity = MockDatabaseModel(**kwargs)
            db.add(entity)
            await db.flush()  # Use flush instead of commit to match BaseRepository
            return entity
        except (IntegrityError, SQLAlchemyError):
            await db.rollback()
            return None
        except asyncio.TimeoutError:
            raise
        except Exception:
            await db.rollback()
            return None
    
    async def find_by_user(self, db: AsyncSession, user_id: str) -> List[MockDatabaseModel]:
        """Implementation of abstract method find_by_user"""
        self.operation_log.append(('find_by_user', user_id))
        return []
    
    def clear_log(self):
        """Clear operation log"""
        self.operation_log.clear()


class TransactionTestManager:
    """Manages transaction test scenarios"""
    
    def __init__(self):
        self.transaction_states = {}
        self.rollback_counts = 0
        self.commit_counts = 0
        self.deadlock_simulations = 0
        
    def simulate_deadlock(self, session: AsyncSession):
        """Simulate database deadlock"""
        self.deadlock_simulations += 1
        raise SQLAlchemyError("deadlock detected")
    
    def simulate_connection_loss(self, session: AsyncSession):
        """Simulate connection loss"""
        raise DisconnectionError("connection lost", None, None)
    
    def track_transaction_state(self, transaction_id: str, state: str):
        """Track transaction state changes"""
        self.transaction_states[transaction_id] = state
    
    def increment_rollback(self):
        """Track rollback operations"""
        self.rollback_counts += 1
    
    def increment_commit(self):
        """Track commit operations"""
        self.commit_counts += 1


class TestTransactionPerformanceAndScaling:
    """Test transaction performance under various load conditions"""
    
    @pytest.fixture
    def performance_repository(self):
        """Repository for performance testing"""
        repo = MockRepository()
        return repo
    
    @pytest.fixture
    def transaction_manager(self):
        """Create transaction test manager"""
        return TransactionTestManager()
    
    def _create_concurrent_sessions(self, num_concurrent):
        """Create mock sessions for concurrency test"""
        sessions = []
        for i in range(num_concurrent):
            session = AsyncMock(spec=AsyncSession)
            session.add = MagicMock()
            session.flush = AsyncMock()
            session.rollback = AsyncMock()
            session.refresh = AsyncMock()
            sessions.append(session)
        return sessions

    async def _create_concurrent_entity(self, performance_repository, session, index):
        """Create entity for concurrent testing"""
        return await performance_repository.create(session, name=f'Concurrent Entity {index}')

    def _create_concurrent_tasks(self, performance_repository, sessions, num_concurrent):
        """Create concurrent tasks for testing"""
        return [self._create_concurrent_entity(performance_repository, sessions[i], i) for i in range(num_concurrent)]

    def _assert_concurrency_performance(self, execution_time, results, num_concurrent):
        """Assert concurrency performance metrics"""
        assert execution_time < 2.0
        assert len(results) == num_concurrent
        successful = sum(1 for r in results if not isinstance(r, Exception))
        assert successful == num_concurrent

    def _assert_all_sessions_used(self, sessions):
        """Assert all sessions were used correctly"""
        for session in sessions:
            session.add.assert_called_once()
            session.flush.assert_called_once()
    async def test_high_concurrency_transactions(self, performance_repository):
        """Test transaction handling under high concurrency"""
        num_concurrent = 50
        sessions = self._create_concurrent_sessions(num_concurrent)
        tasks = self._create_concurrent_tasks(performance_repository, sessions, num_concurrent)
        start_time = asyncio.get_event_loop().time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        end_time = asyncio.get_event_loop().time()
        execution_time = end_time - start_time
        self._assert_concurrency_performance(execution_time, results, num_concurrent)
        self._assert_all_sessions_used(sessions)
    async def test_transaction_deadlock_recovery(self, performance_repository, transaction_manager):
        """Test transaction recovery from deadlock scenarios"""
        session = AsyncMock(spec=AsyncSession)
        session.add = MagicMock()
        session.flush = MagicMock(side_effect=transaction_manager.simulate_deadlock)
        session.rollback = AsyncMock()
        
        result = await performance_repository.create(session, name='Deadlock Test Entity')
        
        assert result == None
        assert transaction_manager.deadlock_simulations == 1
        session.rollback.assert_called_once()
    async def test_connection_loss_handling(self, performance_repository, transaction_manager):
        """Test handling of connection loss during transactions"""
        session = AsyncMock(spec=AsyncSession)
        session.add = MagicMock(side_effect=transaction_manager.simulate_connection_loss)
        session.rollback = AsyncMock()
        
        result = await performance_repository.create(session, name='Connection Loss Test')
        
        assert result == None
        session.rollback.assert_called_once()

    def _create_stress_test_sessions(self, num_sessions):
        """Create sessions for stress testing"""
        return [AsyncMock(spec=AsyncSession) for _ in range(num_sessions)]

    def _setup_stress_test_session(self, session):
        """Setup individual session for stress testing"""
        session.add = MagicMock()
        session.flush = AsyncMock()
        session.rollback = AsyncMock()
        session.refresh = AsyncMock()
    async def test_stress_test_transaction_volume(self, performance_repository):
        """Test handling of high volume transactions"""
        num_transactions = 100
        sessions = self._create_stress_test_sessions(num_transactions)
        
        for session in sessions:
            self._setup_stress_test_session(session)
        
        tasks = [
            performance_repository.create(sessions[i], name=f'Stress Entity {i}')
            for i in range(num_transactions)
        ]
        
        start_time = asyncio.get_event_loop().time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        end_time = asyncio.get_event_loop().time()
        
        execution_time = end_time - start_time
        assert execution_time < 5.0  # Should complete within 5 seconds
        assert len(results) == num_transactions
    async def test_transaction_state_tracking(self, performance_repository, transaction_manager):
        """Test transaction state tracking under load"""
        num_concurrent = 20
        sessions = self._create_concurrent_sessions(num_concurrent)
        
        # Track states for each transaction
        for i in range(num_concurrent):
            transaction_manager.track_transaction_state(f'tx_{i}', 'started')
        
        tasks = self._create_concurrent_tasks(performance_repository, sessions, num_concurrent)
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Verify state tracking
        assert len(transaction_manager.transaction_states) == num_concurrent
        for i in range(num_concurrent):
            assert f'tx_{i}' in transaction_manager.transaction_states
    async def test_memory_efficiency_under_load(self, performance_repository):
        """Test memory efficiency during high concurrent load"""
        num_concurrent = 75
        sessions = self._create_concurrent_sessions(num_concurrent)
        
        # Test memory efficiency by ensuring operations complete without excessive memory growth
        initial_log_size = len(performance_repository.operation_log)
        
        tasks = self._create_concurrent_tasks(performance_repository, sessions, num_concurrent)
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Verify memory usage patterns
        final_log_size = len(performance_repository.operation_log)
        assert final_log_size == initial_log_size + num_concurrent
        assert len(results) == num_concurrent