"""
Multi-Constraint Optimization Test Module
Tests complex multi-objective optimization scenarios.
Maximum 300 lines, functions â‰¤8 lines.
"""

# Add project root to path
import sys
from pathlib import Path

from netra_backend.tests.test_utils import setup_test_path

PROJECT_ROOT = Path(__file__).parent.parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

setup_test_path()

from typing import Dict, List

import pytest

# Add project root to path
from netra_backend.tests.e2e.multi_constraint_test_helpers import (
    build_multi_constraint_setup,
    # Add project root to path
    create_agent_instances,
    create_quality_cost_latency_state,
    create_triple_constraint_state,
    execute_multi_constraint_workflow,
    validate_basic_workflow_execution,
    validate_completed_or_fallback_states,
    validate_compromise_recommendations,
    validate_constraint_conflict_identification,
    validate_multi_objective_analysis,
)


@pytest.fixture(scope="function")
def multi_constraint_setup(real_llm_manager, real_websocket_manager, real_tool_dispatcher):
    """Setup real agent environment for multi-constraint optimization testing."""
    agents = create_agent_instances(real_llm_manager, real_tool_dispatcher)
    return build_multi_constraint_setup(agents, real_llm_manager, real_websocket_manager)


class TestComplexMultiObjectiveOptimization:
    """Test complex multi-objective optimization scenarios."""
    
    async def test_triple_constraint_optimization(self, multi_constraint_setup):
        """Test optimization with three competing constraints."""
        setup = multi_constraint_setup
        state = create_triple_constraint_state()
        results = await execute_multi_constraint_workflow(setup, state)
        validate_triple_constraint_results(results, state)
    
    async def test_quality_cost_latency_tradeoff(self, multi_constraint_setup):
        """Test quality vs cost vs latency tradeoff analysis."""
        setup = multi_constraint_setup
        state = create_quality_cost_latency_state()
        results = await execute_multi_constraint_workflow(setup, state)
        validate_quality_cost_latency_results(results)
    
    async def test_constraint_conflict_resolution(self, multi_constraint_setup):
        """Test resolution of conflicting constraints."""
        setup = multi_constraint_setup
        state = create_triple_constraint_state()
        state.metadata.update({'conflict_resolution': 'weighted_priority'})
        results = await execute_multi_constraint_workflow(setup, state)
        validate_conflict_resolution_results(results, state)
    
    async def test_pareto_frontier_analysis(self, multi_constraint_setup):
        """Test Pareto frontier optimization analysis."""
        setup = multi_constraint_setup
        state = create_quality_cost_latency_state()
        state.metadata.update({'analysis_type': 'pareto_frontier'})
        results = await execute_multi_constraint_workflow(setup, state)
        validate_pareto_analysis_results(results, state)
    
    async def test_weighted_optimization_objectives(self, multi_constraint_setup):
        """Test optimization with weighted objectives."""
        setup = multi_constraint_setup
        state = create_triple_constraint_state()
        state.metadata.update({
            'weights': {'cost': 0.5, 'quality': 0.3, 'latency': 0.2}
        })
        results = await execute_multi_constraint_workflow(setup, state)
        validate_weighted_optimization_results(results, state)


def validate_triple_constraint_results(results: List[Dict], state) -> None:
    """Validate triple constraint optimization results."""
    validate_basic_workflow_execution(results)
    validate_constraint_conflict_identification(results[0], state)
    validate_multi_objective_analysis(results[2], state)
    validate_compromise_recommendations(results[3], state)


def validate_quality_cost_latency_results(results: List[Dict]) -> None:
    """Validate quality vs cost vs latency tradeoff results."""
    validate_basic_workflow_execution(results)
    completed_results = [r for r in results if r['agent_state'].name == 'COMPLETED']
    assert len(completed_results) >= 3, "Core workflow should complete"


def validate_conflict_resolution_results(results: List[Dict], state) -> None:
    """Validate constraint conflict resolution results."""
    validate_basic_workflow_execution(results)
    assert state.metadata.get('conflict_resolution') == 'weighted_priority'
    validate_completed_or_fallback_states(results)


def validate_pareto_analysis_results(results: List[Dict], state) -> None:
    """Validate Pareto frontier analysis results."""
    validate_basic_workflow_execution(results)
    assert state.metadata.get('analysis_type') == 'pareto_frontier'
    validate_completed_or_fallback_states(results)


def validate_weighted_optimization_results(results: List[Dict], state) -> None:
    """Validate weighted optimization results."""
    validate_basic_workflow_execution(results)
    weights = state.metadata.get('weights', {})
    assert abs(sum(weights.values()) - 1.0) < 0.01, "Weights should sum to 1.0"
    validate_completed_or_fallback_states(results)