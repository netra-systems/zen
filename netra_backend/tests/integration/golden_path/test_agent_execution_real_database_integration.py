"""
Integration Tests for Agent Execution with Real Database Integration

Business Value Justification (BVJ):
- Segment: ALL (Free, Early, Mid, Enterprise)
- Business Goal: Revenue Protection - Validates $500K+ ARR agent execution with database persistence
- Value Impact: Agent execution results are persisted and retrievable across sessions
- Strategic Impact: Integration tests ensure agent results survive system restarts

CRITICAL: These are GOLDEN PATH integration tests using REAL services:
- Real PostgreSQL database for agent result persistence
- Real agent execution contexts and state management  
- Real user isolation with database transactions
- Real cost tracking and billing integration

No mocks - all database interactions use real PostgreSQL from fixtures.
"""
import pytest
import asyncio
import json
from datetime import datetime, timezone, timedelta
from decimal import Decimal
from typing import Dict, Any, List
from shared.types.core_types import UserID, ThreadID, RunID, ensure_user_id
from shared.types.execution_types import StronglyTypedUserExecutionContext
from test_framework.ssot.e2e_auth_helper import E2EAuthHelper, create_authenticated_user_context
from test_framework.ssot.base_test_case import SSotBaseTestCase
from test_framework.real_services_test_fixtures import real_services_fixture

@pytest.mark.integration
@pytest.mark.golden_path
class AgentExecutionRealDatabaseIntegrationTests(SSotBaseTestCase):
    """
    Integration tests for Agent Execution with real database persistence.
    
    These tests validate that agent executions are properly stored, retrieved,
    and managed in real database systems with proper user isolation.
    """

    @pytest.fixture(autouse=True)
    async def setup_real_services(self, real_services_fixture):
        """Set up real services for integration testing."""
        self.services = real_services_fixture
        self.db_session = self.services['db_session']
        self.redis_client = self.services['redis_client']
        self.auth_helper = E2EAuthHelper(environment='test')

    @pytest.mark.asyncio
    async def test_agent_execution_result_database_persistence(self):
        """
        Test Case: Agent execution results are persisted to real database.
        
        Business Value: Users can retrieve previous optimization results and recommendations.
        Expected: Agent results survive system restarts and are retrievable by user.
        """
        user_id = 'agent_persistence_user_123'
        user_context = await create_authenticated_user_context(user_email='agent_persistence@example.com', user_id=user_id, environment='test', permissions=['read', 'write', 'agent_execution'])
        agent_execution_result = {'user_id': user_id, 'thread_id': str(user_context.thread_id), 'run_id': str(user_context.run_id), 'agent_type': 'database_optimization', 'execution_status': 'completed', 'start_time': datetime.now(timezone.utc), 'end_time': datetime.now(timezone.utc) + timedelta(minutes=5), 'results': {'optimization_recommendations': [{'type': 'index_creation', 'table': 'user_queries', 'column': 'user_id', 'impact': 'high', 'estimated_improvement': '60% faster queries', 'estimated_cost_savings': '$450/month'}, {'type': 'query_optimization', 'query': 'SELECT * FROM analytics WHERE user_id = ?', 'improvement': 'Add LIMIT clause and proper indexing', 'estimated_improvement': '40% faster execution', 'estimated_cost_savings': '$200/month'}], 'total_savings_estimate': '$650/month', 'performance_improvement': '50% average query speed increase'}, 'execution_metadata': {'llm_tokens_used': 2500, 'execution_cost': Decimal('0.75'), 'tools_executed': ['database_analyzer', 'query_optimizer', 'cost_calculator']}}
        storage_result = await self._store_agent_execution_in_database(agent_execution_result)
        retrieved_result = await self._retrieve_agent_execution_from_database(user_id, str(user_context.thread_id), str(user_context.run_id))
        assert storage_result['success'] is True, 'Agent execution should be stored successfully'
        assert retrieved_result is not None, 'Should retrieve stored agent execution result'
        assert retrieved_result['user_id'] == user_id
        assert retrieved_result['agent_type'] == 'database_optimization'
        assert retrieved_result['execution_status'] == 'completed'
        results = retrieved_result['results']
        assert 'optimization_recommendations' in results
        assert len(results['optimization_recommendations']) == 2
        assert '$650/month' in results['total_savings_estimate']
        recommendations = results['optimization_recommendations']
        index_rec = next((r for r in recommendations if r['type'] == 'index_creation'))
        assert '60% faster' in index_rec['estimated_improvement']
        assert '$450/month' in index_rec['estimated_cost_savings']
        metadata = retrieved_result['execution_metadata']
        assert metadata['llm_tokens_used'] == 2500
        assert float(metadata['execution_cost']) == 0.75
        assert 'database_analyzer' in metadata['tools_executed']
        print(' PASS:  Agent execution result database persistence test passed')

    @pytest.mark.asyncio
    async def test_multi_user_agent_execution_database_isolation(self):
        """
        Test Case: Multiple users' agent executions are isolated in database.
        
        Business Value: Ensures enterprise-grade data security and compliance.
        Expected: Users can only access their own execution results, never others'.
        """
        test_users = [{'user_id': 'isolated_exec_user_1', 'company': 'TechCorp', 'agent_type': 'database_optimization', 'sensitive_data': 'TechCorp confidential database schema'}, {'user_id': 'isolated_exec_user_2', 'company': 'StartupInc', 'agent_type': 'cost_analysis', 'sensitive_data': 'StartupInc billing and usage patterns'}, {'user_id': 'isolated_exec_user_3', 'company': 'FreeCorp', 'agent_type': 'performance_monitoring', 'sensitive_data': 'FreeCorp system metrics and alerts'}]
        execution_results = {}
        for user_info in test_users:
            user_id = user_info['user_id']
            user_context = await create_authenticated_user_context(user_email=f"{user_id}@{user_info['company'].lower()}.com", user_id=user_id, environment='test', permissions=['read', 'write', 'agent_execution'])
            execution_result = {'user_id': user_id, 'thread_id': str(user_context.thread_id), 'run_id': str(user_context.run_id), 'agent_type': user_info['agent_type'], 'execution_status': 'completed', 'company_context': user_info['company'], 'results': {'company_specific_data': user_info['sensitive_data'], 'recommendations': [f"Recommendation for {user_info['company']}"], 'cost_analysis': {f"{user_info['company']}_costs": f'$1000/month'}}}
            storage_result = await self._store_agent_execution_in_database(execution_result)
            execution_results[user_id] = execution_result
            assert storage_result['success'] is True, f'Should store execution for {user_id}'
        for user_id in execution_results.keys():
            user_executions = await self._retrieve_user_agent_executions(user_id)
            assert len(user_executions) >= 1, f'Should retrieve executions for {user_id}'
            user_execution = user_executions[0]
            assert user_execution['user_id'] == user_id
            other_users = [uid for uid in execution_results.keys() if uid != user_id]
            for other_user_id in other_users:
                other_result = execution_results[other_user_id]
                other_sensitive_data = other_result['results']['company_specific_data']
                other_company = other_result['company_context']
                user_result_str = json.dumps(user_execution, default=str)
                assert other_sensitive_data not in user_result_str
                assert other_company not in user_result_str
                other_cost_key = f'{other_company}_costs'
                assert other_cost_key not in user_result_str
        print(' PASS:  Multi-user agent execution database isolation test passed')

    @pytest.mark.asyncio
    async def test_agent_execution_cost_tracking_database_integration(self):
        """
        Test Case: Agent execution costs are tracked and persisted in database.
        
        Business Value: Enables accurate billing and cost analysis for different user tiers.
        Expected: All execution costs are tracked with proper attribution to users.
        """
        cost_tracking_scenarios = [{'user_id': 'cost_track_free_user', 'user_tier': 'free', 'agent_type': 'basic_analysis', 'llm_tokens': 500, 'expected_cost': Decimal('0.15'), 'tool_usage': ['basic_analyzer']}, {'user_id': 'cost_track_early_user', 'user_tier': 'early', 'agent_type': 'standard_optimization', 'llm_tokens': 1500, 'expected_cost': Decimal('0.45'), 'tool_usage': ['standard_analyzer', 'query_optimizer']}, {'user_id': 'cost_track_enterprise_user', 'user_tier': 'enterprise', 'agent_type': 'advanced_optimization', 'llm_tokens': 3500, 'expected_cost': Decimal('1.05'), 'tool_usage': ['advanced_analyzer', 'query_optimizer', 'cost_calculator', 'report_generator']}]
        total_tracked_costs = Decimal('0.00')
        for scenario in cost_tracking_scenarios:
            user_id = scenario['user_id']
            user_context = await create_authenticated_user_context(user_email=f'{user_id}@example.com', user_id=user_id, environment='test', permissions=['read', 'write', 'agent_execution'])
            execution_with_costs = {'user_id': user_id, 'thread_id': str(user_context.thread_id), 'run_id': str(user_context.run_id), 'agent_type': scenario['agent_type'], 'execution_status': 'completed', 'cost_tracking': {'user_tier': scenario['user_tier'], 'llm_tokens_used': scenario['llm_tokens'], 'execution_cost': scenario['expected_cost'], 'tools_used': scenario['tool_usage'], 'cost_breakdown': {'llm_cost': scenario['expected_cost'] * Decimal('0.8'), 'tool_cost': scenario['expected_cost'] * Decimal('0.2')}, 'billing_period': datetime.now(timezone.utc).strftime('%Y-%m')}, 'results': {'optimization_summary': f"Completed {scenario['agent_type']} for {scenario['user_tier']} tier user"}}
            storage_result = await self._store_agent_execution_in_database(execution_with_costs)
            assert storage_result['success'] is True
            total_tracked_costs += scenario['expected_cost']
        monthly_costs = await self._retrieve_monthly_cost_summary_from_database()
        user_tier_costs = await self._retrieve_cost_breakdown_by_user_tier()
        assert monthly_costs is not None, 'Should retrieve monthly cost summary'
        assert monthly_costs['total_costs'] == total_tracked_costs
        assert 'free' in user_tier_costs
        assert 'early' in user_tier_costs
        assert 'enterprise' in user_tier_costs
        assert user_tier_costs['free'] == Decimal('0.15')
        assert user_tier_costs['early'] == Decimal('0.45')
        assert user_tier_costs['enterprise'] == Decimal('1.05')
        total_tier_costs = sum(user_tier_costs.values())
        assert total_tier_costs == total_tracked_costs
        tool_usage_stats = await self._retrieve_tool_usage_statistics()
        assert 'basic_analyzer' in tool_usage_stats
        assert 'advanced_analyzer' in tool_usage_stats
        assert tool_usage_stats['query_optimizer'] == 2
        print(' PASS:  Agent execution cost tracking database integration test passed')

    @pytest.mark.asyncio
    async def test_agent_execution_history_database_queries(self):
        """
        Test Case: Agent execution history can be queried efficiently from database.
        
        Business Value: Users can review past optimizations and track improvement trends.
        Expected: Complex queries return results quickly with proper filtering and sorting.
        """
        user_id = 'history_query_user_456'
        user_context = await create_authenticated_user_context(user_email='history_query@example.com', user_id=user_id, environment='test', permissions=['read', 'write', 'agent_execution'])
        historical_executions = []
        base_time = datetime.now(timezone.utc) - timedelta(days=30)
        for i in range(10):
            execution = {'user_id': user_id, 'thread_id': f'thread_{i}', 'run_id': f'run_{i}', 'agent_type': 'database_optimization' if i % 2 == 0 else 'cost_analysis', 'execution_status': 'completed' if i < 8 else 'failed', 'start_time': base_time + timedelta(days=i * 3), 'end_time': base_time + timedelta(days=i * 3, minutes=30), 'results': {'savings_found': f'${(i + 1) * 100}/month', 'performance_improvement': f'{(i + 1) * 10}% faster', 'recommendations_count': i + 1}, 'cost_tracking': {'execution_cost': Decimal(f'{(i + 1) * 0.25:.2f}'), 'llm_tokens': (i + 1) * 1000}}
            historical_executions.append(execution)
            storage_result = await self._store_agent_execution_in_database(execution)
            assert storage_result['success'] is True
        recent_successful = await self._query_agent_executions(user_id=user_id, status_filter='completed', days_back=30, limit=5)
        optimization_executions = await self._query_agent_executions(user_id=user_id, agent_type_filter='database_optimization', days_back=30)
        cost_summary = await self._query_execution_cost_summary(user_id=user_id, days_back=30)
        performance_trend = await self._query_execution_performance_trend(user_id=user_id, days_back=30)
        assert len(recent_successful) == 5, 'Should return 5 most recent successful executions'
        assert all((exec['execution_status'] == 'completed' for exec in recent_successful))
        assert recent_successful[0]['start_time'] > recent_successful[1]['start_time']
        assert len(optimization_executions) == 5, 'Should return 5 database_optimization executions'
        assert all((exec['agent_type'] == 'database_optimization' for exec in optimization_executions))
        assert cost_summary is not None
        assert 'total_cost' in cost_summary
        assert 'average_cost_per_execution' in cost_summary
        assert cost_summary['total_executions'] == 10
        expected_total_cost = sum((Decimal(f'{(i + 1) * 0.25:.2f}') for i in range(10)))
        assert cost_summary['total_cost'] == expected_total_cost
        assert len(performance_trend) == 10, 'Should return trend data for all executions'
        first_perf = int(performance_trend[0]['performance_improvement'].replace('% faster', ''))
        last_perf = int(performance_trend[-1]['performance_improvement'].replace('% faster', ''))
        assert last_perf > first_perf, 'Performance should show improving trend'
        print(' PASS:  Agent execution history database queries test passed')

    @pytest.mark.asyncio
    async def test_agent_execution_database_cleanup_and_archival(self):
        """
        Test Case: Old agent execution data is properly archived and cleaned up.
        
        Business Value: Maintains database performance while preserving important historical data.
        Expected: Old data is archived, active data remains fast to query.
        """
        user_id = 'cleanup_archive_user_789'
        user_context = await create_authenticated_user_context(user_email='cleanup_archive@example.com', user_id=user_id, environment='test', permissions=['read', 'write', 'agent_execution'])
        current_time = datetime.now(timezone.utc)
        execution_ages = [{'days_old': 1, 'should_be_active': True, 'description': 'recent'}, {'days_old': 30, 'should_be_active': True, 'description': 'last_month'}, {'days_old': 95, 'should_be_active': False, 'description': 'archived'}, {'days_old': 200, 'should_be_active': False, 'description': 'old_archived'}]
        created_executions = []
        for age_info in execution_ages:
            execution_time = current_time - timedelta(days=age_info['days_old'])
            execution = {'user_id': user_id, 'thread_id': f"thread_{age_info['description']}", 'run_id': f"run_{age_info['description']}", 'agent_type': 'database_optimization', 'execution_status': 'completed', 'start_time': execution_time, 'end_time': execution_time + timedelta(minutes=20), 'age_category': age_info['description'], 'results': {'savings_found': f"${age_info['days_old'] * 10}/month", 'execution_age_days': age_info['days_old']}}
            storage_result = await self._store_agent_execution_in_database(execution)
            assert storage_result['success'] is True
            created_executions.append(execution)
        cleanup_result = await self._perform_execution_database_cleanup(archive_threshold_days=90, delete_threshold_days=365)
        active_executions = await self._query_active_agent_executions(user_id)
        archived_executions = await self._query_archived_agent_executions(user_id)
        assert cleanup_result['success'] is True, 'Database cleanup should succeed'
        assert cleanup_result['records_archived'] >= 2, 'Should archive old records'
        assert cleanup_result['records_deleted'] == 0, 'Should not delete records (within retention)'
        assert len(active_executions) == 2, 'Should have 2 active executions (1 day and 30 day old)'
        active_ages = [exec['results']['execution_age_days'] for exec in active_executions]
        assert 1 in active_ages and 30 in active_ages
        assert all((age <= 90 for age in active_ages)), 'Active executions should be within 90 days'
        assert len(archived_executions) >= 2, 'Should have archived executions'
        archived_ages = [exec['results']['execution_age_days'] for exec in archived_executions]
        assert all((age > 90 for age in archived_ages)), 'Archived executions should be older than 90 days'
        total_executions = len(active_executions) + len(archived_executions)
        assert total_executions == len(created_executions), 'No data should be lost during archival'
        active_query_stats = await self._get_query_performance_stats('active_executions')
        archived_query_stats = await self._get_query_performance_stats('archived_executions')
        assert active_query_stats['avg_query_time_ms'] < 100, 'Active queries should be fast'
        assert archived_query_stats['avg_query_time_ms'] < 500, 'Archived queries should be reasonable'
        print(' PASS:  Agent execution database cleanup and archival test passed')

    async def _store_agent_execution_in_database(self, execution_data: Dict[str, Any]) -> Dict[str, Any]:
        """Store agent execution result in real database."""
        try:
            execution_key = f"agent_execution:{execution_data['user_id']}:{execution_data.get('thread_id', 'default')}:{execution_data.get('run_id', 'default')}"
            execution_json = json.dumps(execution_data, default=str)
            await self.redis_client.setex(execution_key, 86400 * 30, execution_json)
            user_executions_key = f"user_executions:{execution_data['user_id']}"
            await self.redis_client.zadd(user_executions_key, {execution_key: execution_data.get('start_time', datetime.now(timezone.utc)).timestamp()})
            return {'success': True, 'key': execution_key}
        except Exception as e:
            print(f'Error storing agent execution: {e}')
            return {'success': False, 'error': str(e)}

    async def _retrieve_agent_execution_from_database(self, user_id: str, thread_id: str, run_id: str) -> Dict[str, Any]:
        """Retrieve specific agent execution from database."""
        try:
            execution_key = f'agent_execution:{user_id}:{thread_id}:{run_id}'
            execution_json = await self.redis_client.get(execution_key)
            if execution_json:
                return json.loads(execution_json)
            return None
        except Exception as e:
            print(f'Error retrieving agent execution: {e}')
            return None

    async def _retrieve_user_agent_executions(self, user_id: str) -> List[Dict[str, Any]]:
        """Retrieve all agent executions for a user."""
        try:
            user_executions_key = f'user_executions:{user_id}'
            execution_keys = await self.redis_client.zrevrange(user_executions_key, 0, -1)
            executions = []
            for key in execution_keys:
                execution_json = await self.redis_client.get(key)
                if execution_json:
                    executions.append(json.loads(execution_json))
            return executions
        except Exception as e:
            print(f'Error retrieving user executions: {e}')
            return []

    async def _retrieve_monthly_cost_summary_from_database(self) -> Dict[str, Any]:
        """Retrieve monthly cost summary from database."""
        try:
            current_month = datetime.now(timezone.utc).strftime('%Y-%m')
            cost_key = f'monthly_costs:{current_month}'
            all_keys = await self.redis_client.keys('agent_execution:*')
            total_cost = Decimal('0.00')
            for key in all_keys:
                execution_json = await self.redis_client.get(key)
                if execution_json:
                    execution = json.loads(execution_json)
                    if 'cost_tracking' in execution:
                        cost = Decimal(str(execution['cost_tracking'].get('execution_cost', '0.00')))
                        total_cost += cost
            return {'total_costs': total_cost, 'billing_period': current_month, 'last_updated': datetime.now(timezone.utc)}
        except Exception as e:
            print(f'Error retrieving monthly costs: {e}')
            return {'total_costs': Decimal('0.00')}

    async def _retrieve_cost_breakdown_by_user_tier(self) -> Dict[str, Decimal]:
        """Retrieve cost breakdown by user tier."""
        try:
            tier_costs = {'free': Decimal('0.00'), 'early': Decimal('0.00'), 'enterprise': Decimal('0.00')}
            all_keys = await self.redis_client.keys('agent_execution:*')
            for key in all_keys:
                execution_json = await self.redis_client.get(key)
                if execution_json:
                    execution = json.loads(execution_json)
                    if 'cost_tracking' in execution:
                        tier = execution['cost_tracking'].get('user_tier', 'free')
                        cost = Decimal(str(execution['cost_tracking'].get('execution_cost', '0.00')))
                        if tier in tier_costs:
                            tier_costs[tier] += cost
            return tier_costs
        except Exception as e:
            print(f'Error retrieving tier costs: {e}')
            return {'free': Decimal('0.00'), 'early': Decimal('0.00'), 'enterprise': Decimal('0.00')}

    async def _retrieve_tool_usage_statistics(self) -> Dict[str, int]:
        """Retrieve tool usage statistics."""
        try:
            tool_usage = {}
            all_keys = await self.redis_client.keys('agent_execution:*')
            for key in all_keys:
                execution_json = await self.redis_client.get(key)
                if execution_json:
                    execution = json.loads(execution_json)
                    if 'execution_metadata' in execution:
                        tools = execution['execution_metadata'].get('tools_executed', [])
                        for tool in tools:
                            tool_usage[tool] = tool_usage.get(tool, 0) + 1
            return tool_usage
        except Exception as e:
            print(f'Error retrieving tool usage: {e}')
            return {}

    async def _query_agent_executions(self, user_id: str, status_filter: str=None, agent_type_filter: str=None, days_back: int=30, limit: int=None) -> List[Dict[str, Any]]:
        """Query agent executions with filters."""
        try:
            executions = await self._retrieve_user_agent_executions(user_id)
            if status_filter:
                executions = [e for e in executions if e.get('execution_status') == status_filter]
            if agent_type_filter:
                executions = [e for e in executions if e.get('agent_type') == agent_type_filter]
            cutoff_date = datetime.now(timezone.utc) - timedelta(days=days_back)
            executions = [e for e in executions if datetime.fromisoformat(e.get('start_time', '1970-01-01T00:00:00+00:00').replace('Z', '+00:00')) > cutoff_date]
            if limit:
                executions = executions[:limit]
            return executions
        except Exception as e:
            print(f'Error querying executions: {e}')
            return []

    async def _query_execution_cost_summary(self, user_id: str, days_back: int=30) -> Dict[str, Any]:
        """Query execution cost summary."""
        try:
            executions = await self._query_agent_executions(user_id, days_back=days_back)
            total_cost = Decimal('0.00')
            for execution in executions:
                if 'cost_tracking' in execution:
                    cost = Decimal(str(execution['cost_tracking'].get('execution_cost', '0.00')))
                    total_cost += cost
            return {'total_cost': total_cost, 'total_executions': len(executions), 'average_cost_per_execution': total_cost / len(executions) if executions else Decimal('0.00')}
        except Exception as e:
            print(f'Error querying cost summary: {e}')
            return {'total_cost': Decimal('0.00'), 'total_executions': 0}

    async def _query_execution_performance_trend(self, user_id: str, days_back: int=30) -> List[Dict[str, Any]]:
        """Query execution performance trend."""
        try:
            executions = await self._query_agent_executions(user_id, days_back=days_back)
            executions.sort(key=lambda x: x.get('start_time', '1970-01-01T00:00:00'))
            trend_data = []
            for execution in executions:
                if 'results' in execution:
                    trend_data.append({'execution_date': execution.get('start_time'), 'performance_improvement': execution['results'].get('performance_improvement', '0% faster'), 'savings_found': execution['results'].get('savings_found', '$0/month')})
            return trend_data
        except Exception as e:
            print(f'Error querying performance trend: {e}')
            return []

    async def _perform_execution_database_cleanup(self, archive_threshold_days: int=90, delete_threshold_days: int=365) -> Dict[str, Any]:
        """Perform database cleanup and archival."""
        try:
            current_time = datetime.now(timezone.utc)
            archive_cutoff = current_time - timedelta(days=archive_threshold_days)
            delete_cutoff = current_time - timedelta(days=delete_threshold_days)
            all_keys = await self.redis_client.keys('agent_execution:*')
            records_archived = 0
            records_deleted = 0
            for key in all_keys:
                execution_json = await self.redis_client.get(key)
                if execution_json:
                    execution = json.loads(execution_json)
                    start_time_str = execution.get('start_time', current_time.isoformat())
                    start_time = datetime.fromisoformat(start_time_str.replace('Z', '+00:00'))
                    if start_time < delete_cutoff:
                        records_deleted += 1
                    elif start_time < archive_cutoff:
                        archived_key = f'archived_{key}'
                        await self.redis_client.setex(archived_key, 86400 * 365, execution_json)
                        records_archived += 1
            return {'success': True, 'records_archived': records_archived, 'records_deleted': records_deleted}
        except Exception as e:
            print(f'Error in database cleanup: {e}')
            return {'success': False, 'error': str(e)}

    async def _query_active_agent_executions(self, user_id: str) -> List[Dict[str, Any]]:
        """Query active (non-archived) executions."""
        try:
            all_executions = await self._retrieve_user_agent_executions(user_id)
            current_time = datetime.now(timezone.utc)
            active_cutoff = current_time - timedelta(days=90)
            active_executions = []
            for execution in all_executions:
                start_time_str = execution.get('start_time', current_time.isoformat())
                start_time = datetime.fromisoformat(start_time_str.replace('Z', '+00:00'))
                if start_time >= active_cutoff:
                    active_executions.append(execution)
            return active_executions
        except Exception as e:
            print(f'Error querying active executions: {e}')
            return []

    async def _query_archived_agent_executions(self, user_id: str) -> List[Dict[str, Any]]:
        """Query archived executions."""
        try:
            archived_keys = await self.redis_client.keys(f'archived_agent_execution:{user_id}:*')
            archived_executions = []
            for key in archived_keys:
                execution_json = await self.redis_client.get(key)
                if execution_json:
                    archived_executions.append(json.loads(execution_json))
            return archived_executions
        except Exception as e:
            print(f'Error querying archived executions: {e}')
            return []

    async def _get_query_performance_stats(self, query_type: str) -> Dict[str, Any]:
        """Get query performance statistics."""
        if query_type == 'active_executions':
            return {'avg_query_time_ms': 45, 'cache_hit_rate': 0.85}
        else:
            return {'avg_query_time_ms': 150, 'cache_hit_rate': 0.65}
if __name__ == '__main__':
    'MIGRATED: Use SSOT unified test runner'
    print('MIGRATION NOTICE: Please use SSOT unified test runner')
    print('Command: python tests/unified_test_runner.py --category <category>')