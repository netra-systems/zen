"""Unit tests for cost limit enforcement in LLM manager."""

import pytest

# All required dependencies are now available - no skip needed

from decimal import Decimal
from datetime import datetime
from enum import Enum
from netra_backend.app.llm.llm_defaults import LLMModel, LLMConfig


from netra_backend.app.llm.llm_manager import LLMManager
from netra_backend.app.services.cost_calculator import TokenUsage
from netra_backend.app.schemas.llm_types import LLMProvider
import asyncio


class RequestStatus(Enum):
    """Status of an LLM request."""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"


class TestCostLimitEnforcement:
    """Test suite for cost limit enforcement functionality."""

    @pytest.fixture
    def llm_manager(self):
        """Create LLM manager with small budget for testing."""
        # TODO: Initialize real service
        return LLMManager(daily_budget=Decimal("1.00"))  # $1 daily budget

    @pytest.mark.asyncio
    async def test_cost_limit_blocks_expensive_request(self, llm_manager):
        """Test that requests exceeding cost limit are blocked."""
        # Initialize the manager
        await llm_manager.initialize()
        
        # Create an expensive request (simulate large prompt)
        # With gpt-4, this will be 10000 * 3 = 30000 estimated tokens
        large_prompt = "test " * 10000  # Very large prompt
        request_id = await llm_manager.create_request(
            prompt=large_prompt,
            model=LLMModel.GEMINI_2_5_FLASH.value
        )
        
        # Process the request - should be blocked
        result = await llm_manager.process_request(request_id)

        assert result is not None
        assert result.status == RequestStatus.FAILED
        assert "Cost limit exceeded" in result.error
        assert ("unbounded API costs" in result.error or "estimated tokens" in result.error)

    @pytest.mark.asyncio
    async def test_cost_limit_allows_cheap_request(self, llm_manager):
        """Test that requests within cost limit are allowed."""
        # Initialize the manager
        await llm_manager.initialize()
        
        # Create a cheap request
        small_prompt = "Hello, world!"
        request_id = await llm_manager.create_request(
            prompt=small_prompt,
            model=LLMModel.GEMINI_2_5_FLASH.value
        )
        
        # Process the request - should succeed
        result = await llm_manager.process_request(request_id)
        
        assert result is not None
        assert result.status == RequestStatus.COMPLETED
        assert result.error is None
        assert result.response is not None
    
    @pytest.mark.asyncio
    async def test_cost_limit_can_be_disabled(self, llm_manager):
        """Test that cost limit enforcement can be disabled."""
        # Initialize the manager
        await llm_manager.initialize()
        
        # Disable cost limit enforcement
        llm_manager.cost_limit_enforced = False
        
        # Create an expensive request
        large_prompt = "test " * 10000
        request_id = await llm_manager.create_request(
            prompt=large_prompt,
            model=LLMModel.GEMINI_2_5_FLASH.value
        )
        
        # Process the request - should succeed even though it's expensive
        result = await llm_manager.process_request(request_id)
        
        assert result is not None
        assert result.status == RequestStatus.COMPLETED
        assert result.error is None
    
    @pytest.mark.asyncio
    async def test_budget_tracking_across_requests(self, llm_manager):
        """Test that budget is tracked across multiple requests."""
        # Initialize the manager
        await llm_manager.initialize()
        
        initial_budget = llm_manager.budget_manager.get_remaining_budget()
        assert initial_budget == Decimal("1.00")
        
        # Process several small requests
        for i in range(3):
            request_id = await llm_manager.create_request(
                prompt=f"Request {i}",
                model=LLMModel.GEMINI_2_5_FLASH.value
            )
            await llm_manager.process_request(request_id)
        
            # Check that budget tracking is working (may be minimal cost)
            remaining_budget = llm_manager.budget_manager.get_remaining_budget()
            assert remaining_budget <= initial_budget  # Should be less than or equal
            assert remaining_budget >= Decimal("0")
    
    @pytest.mark.asyncio
    async def test_health_check_includes_budget_info(self, llm_manager):
        """Test that health check includes budget information."""
        # Initialize the manager
        await llm_manager.initialize()
        
        # Get health check
        health = await llm_manager.health_check()
        
        assert "cost_limit_enforced" in health
        assert health["cost_limit_enforced"] is True
        assert "remaining_budget" in health
        assert health["remaining_budget"] == 1.0
        assert "daily_budget" in health
        assert health["daily_budget"] == 1.0
    
    def test_check_cost_limit_method(self, llm_manager):
        """Test the internal cost limit checking method."""
        # Test that the method exists and returns a boolean
        result = llm_manager._check_cost_limit(LLMModel.GEMINI_2_5_FLASH.value, 100)
        assert isinstance(result, bool)
        
        # Test with different token count
        result = llm_manager._check_cost_limit(LLMModel.GEMINI_2_5_FLASH.value, 10000000)
        assert isinstance(result, bool)
    
    def test_record_usage_method(self, llm_manager):
        """Test the internal usage recording method."""
        initial_spending = llm_manager.budget_manager.current_spending
        
        # Record some usage
        llm_manager._record_usage(LLMModel.GEMINI_2_5_FLASH.value, 1000)
        
        # Check that spending tracking is working (may be minimal cost)
        assert llm_manager.budget_manager.current_spending >= initial_spending
    
    @pytest.mark.asyncio
    async def test_budget_reset(self, llm_manager):
        """Test that budget can be reset."""
        # Initialize and use some budget
        await llm_manager.initialize()
        
        request_id = await llm_manager.create_request(
            prompt="Test request",
            model=LLMModel.GEMINI_2_5_FLASH.value
        )
        await llm_manager.process_request(request_id)
        
        # Check budget tracking is working (may be minimal cost)
        assert llm_manager.budget_manager.current_spending >= Decimal("0")
        
        # Reset budget
        llm_manager.budget_manager.reset_daily_spending()
        
        # Check budget is reset
        assert llm_manager.budget_manager.current_spending == Decimal("0")
        assert llm_manager.budget_manager.get_remaining_budget() == Decimal("1.00")