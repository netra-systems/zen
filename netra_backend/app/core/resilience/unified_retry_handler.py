"""
Unified Retry and Timeout Handler

Business Value Justification (BVJ):
- Segment: Platform/Internal
- Business Goal: Eliminate retry/timeout logic duplication across all services
- Value Impact: Consistent resilience patterns, standardized backoff strategies, unified error handling
- Strategic Impact: Improved system reliability, consistent SLA behavior, reduced operational complexity

This module provides unified retry and timeout handling that can be used across:
- Database connections (PostgreSQL, ClickHouse, Redis)
- HTTP requests (API calls, health checks, webhooks)
- File operations (with retries on temporary failures)
- Service startup and initialization

Key functionality:
- Configurable retry strategies (exponential backoff, linear, custom)
- Circuit breaker pattern integration
- Timeout management with escalation
- Async and sync support
- Comprehensive error classification
- Metrics integration for monitoring

Replaces 10+ duplicate retry/timeout implementations with a single unified handler.
Each function ≤25 lines, class ≤300 lines total.
"""

import asyncio
import logging
import time
import random
from dataclasses import dataclass, field
from enum import Enum
from functools import wraps
from typing import Any, Awaitable, Callable, Dict, List, Optional, Type, Union, Tuple
from datetime import datetime, timedelta, timezone

from shared.isolated_environment import IsolatedEnvironment
from netra_backend.app.core.resilience.unified_circuit_breaker import (
    UnifiedCircuitBreaker,
    UnifiedCircuitConfig,
    get_unified_circuit_breaker_manager
)
import psycopg2
import sqlalchemy.exc
import urllib.error
import httpx

logger = logging.getLogger(__name__)


class RetryStrategy(Enum):
    """Retry strategy types."""
    FIXED = "fixed"
    LINEAR = "linear"
    EXPONENTIAL = "exponential"
    EXPONENTIAL_JITTER = "exponential_jitter"
    FIBONACCI = "fibonacci"
    ADAPTIVE = "adaptive"
    CUSTOM = "custom"


class RetryDecision(Enum):
    """Retry decision outcomes."""
    RETRY = "retry"
    STOP = "stop"
    ESCALATE = "escalate"


@dataclass
class RetryConfig:
    """Configuration for retry behavior."""
    max_attempts: int = 3
    base_delay: float = 1.0
    max_delay: float = 60.0
    strategy: RetryStrategy = RetryStrategy.EXPONENTIAL
    backoff_multiplier: float = 2.0
    jitter_range: float = 0.1
    timeout_seconds: Optional[float] = None
    retryable_exceptions: Tuple[Type[Exception], ...] = field(default_factory=lambda: (Exception,))
    non_retryable_exceptions: Tuple[Type[Exception], ...] = field(default_factory=tuple)
    circuit_breaker_enabled: bool = False
    circuit_breaker_failure_threshold: int = 5
    circuit_breaker_recovery_timeout: float = 30.0
    metrics_enabled: bool = True
    
    
@dataclass 
class RetryAttempt:
    """Information about a retry attempt."""
    attempt_number: int
    delay_before: float
    exception: Optional[Exception]
    timestamp: datetime
    elapsed_time: float


class RetryResult:
    """Result of a retry operation."""
    def __init__(self, success: bool, result: Any = None, attempts: List[RetryAttempt] = None, final_exception: Exception = None):
        self.success = success
        self.result = result
        self.attempts = attempts or []
        self.final_exception = final_exception
        self.total_attempts = len(self.attempts)
        self.total_time = sum(attempt.elapsed_time for attempt in self.attempts)


class UnifiedRetryHandler:
    """
    Unified retry handler for consistent resilience patterns across all services.
    
    Provides standardized retry logic with configurable strategies, timeouts,
    and error handling for both synchronous and asynchronous operations.
    """
    
    def __init__(self, service_name: str = "unknown", config: Optional[RetryConfig] = None):
        self.service_name = service_name
        self.config = config or RetryConfig()
        self.env = IsolatedEnvironment()
        self._load_config_from_env()
        self._circuit_breaker: Optional[UnifiedCircuitBreaker] = None
        self._setup_circuit_breaker()
    
    def _load_config_from_env(self) -> None:
        """Load retry configuration from environment."""
        # Override config with environment variables if present
        self.config.max_attempts = int(self.env.get("RETRY_MAX_ATTEMPTS", str(self.config.max_attempts)))
        self.config.base_delay = float(self.env.get("RETRY_BASE_DELAY", str(self.config.base_delay)))
        self.config.max_delay = float(self.env.get("RETRY_MAX_DELAY", str(self.config.max_delay)))
        self.config.backoff_multiplier = float(self.env.get("RETRY_BACKOFF_MULTIPLIER", str(self.config.backoff_multiplier)))
        self.config.jitter_range = float(self.env.get("RETRY_JITTER_RANGE", str(self.config.jitter_range)))
        
        # Set timeout from environment
        timeout_env = self.env.get("RETRY_TIMEOUT_SECONDS")
        if timeout_env:
            self.config.timeout_seconds = float(timeout_env)
        
        # Set strategy from environment
        strategy_env = self.env.get("RETRY_STRATEGY", "").lower()
        if strategy_env:
            try:
                self.config.strategy = RetryStrategy(strategy_env)
            except ValueError:
                logger.warning(f"Unknown retry strategy '{strategy_env}', using default")
    
    def _calculate_delay(self, attempt_number: int) -> float:
        """Calculate delay before retry attempt."""
        if self.config.strategy == RetryStrategy.FIXED:
            delay = self.config.base_delay
        elif self.config.strategy == RetryStrategy.LINEAR:
            delay = self.config.base_delay * attempt_number
        elif self.config.strategy == RetryStrategy.EXPONENTIAL:
            delay = self.config.base_delay * (self.config.backoff_multiplier ** (attempt_number - 1))
        elif self.config.strategy == RetryStrategy.EXPONENTIAL_JITTER:
            delay = self.config.base_delay * (self.config.backoff_multiplier ** (attempt_number - 1))
            # Add jitter to prevent thundering herd
            jitter = delay * self.config.jitter_range * (random.random() * 2 - 1)
            delay += jitter
        elif self.config.strategy == RetryStrategy.FIBONACCI:
            delay = self._fibonacci_delay(attempt_number)
        elif self.config.strategy == RetryStrategy.ADAPTIVE:
            delay = self._adaptive_delay(attempt_number)
        else:  # CUSTOM - subclasses can override this method
            delay = self.config.base_delay
            
        # Cap delay at maximum
        return min(delay, self.config.max_delay)
    
    def _fibonacci_delay(self, attempt_number: int) -> float:
        """Calculate Fibonacci-based delay."""
        if attempt_number <= 1:
            return self.config.base_delay
        
        # Generate fibonacci sequence up to attempt_number
        fib_a, fib_b = 1, 1
        for _ in range(attempt_number - 2):
            fib_a, fib_b = fib_b, fib_a + fib_b
        
        return self.config.base_delay * fib_b
    
    def _adaptive_delay(self, attempt_number: int) -> float:
        """Calculate adaptive delay based on recent success patterns."""
        # For now, use exponential backoff but could be enhanced with historical data
        return self.config.base_delay * (self.config.backoff_multiplier ** (attempt_number - 1))
    
    def _should_retry(self, exception: Exception, attempt_number: int) -> RetryDecision:
        """Determine if operation should be retried."""
        # Check attempt limits
        if attempt_number >= self.config.max_attempts:
            return RetryDecision.STOP
            
        # Check non-retryable exceptions first
        for exc_type in self.config.non_retryable_exceptions:
            if isinstance(exception, exc_type):
                return RetryDecision.STOP
                
        # Check retryable exceptions
        for exc_type in self.config.retryable_exceptions:
            if isinstance(exception, exc_type):
                return RetryDecision.RETRY
                
        # Default decision
        return RetryDecision.STOP
    
    def execute_with_retry(self, func: Callable[[], Any], *args, **kwargs) -> RetryResult:
        """
        Execute function with retry logic.
        
        Args:
            func: Function to execute
            *args: Function arguments
            **kwargs: Function keyword arguments
            
        Returns:
            RetryResult with outcome and attempt information
        """
        # Check circuit breaker if enabled
        if self._circuit_breaker and not self._circuit_breaker.can_execute():
            return RetryResult(
                success=False, 
                attempts=[], 
                final_exception=Exception("Circuit breaker is open")
            )
        
        attempts = []
        start_time = time.time()
        
        for attempt_num in range(1, self.config.max_attempts + 1):
            attempt_start = time.time()
            
            try:
                # Check overall timeout
                if self.config.timeout_seconds:
                    elapsed = time.time() - start_time
                    if elapsed >= self.config.timeout_seconds:
                        raise TimeoutError(f"Overall timeout exceeded: {elapsed:.2f}s >= {self.config.timeout_seconds}s")
                
                # Execute function
                result = func(*args, **kwargs)
                
                # Success - record attempt and return
                attempt_time = time.time() - attempt_start
                attempts.append(RetryAttempt(
                    attempt_number=attempt_num,
                    delay_before=0.0,
                    exception=None,
                    timestamp=datetime.now(timezone.utc),
                    elapsed_time=attempt_time
                ))
                
                # Record success in circuit breaker
                if self._circuit_breaker:
                    self._circuit_breaker.record_success()
                
                logger.debug(f"Operation succeeded on attempt {attempt_num}")
                return RetryResult(success=True, result=result, attempts=attempts)
                
            except Exception as e:
                attempt_time = time.time() - attempt_start
                
                # Record failure in circuit breaker
                if self._circuit_breaker:
                    self._circuit_breaker.record_failure(type(e).__name__)
                
                # Decide whether to retry
                retry_decision = self._should_retry(e, attempt_num)
                
                if retry_decision == RetryDecision.STOP:
                    attempts.append(RetryAttempt(
                        attempt_number=attempt_num,
                        delay_before=0.0,
                        exception=e,
                        timestamp=datetime.now(timezone.utc),
                        elapsed_time=attempt_time
                    ))
                    logger.debug(f"Stopping retries after attempt {attempt_num}: {e}")
                    return RetryResult(success=False, attempts=attempts, final_exception=e)
                
                # Calculate delay for next attempt
                delay = self._calculate_delay(attempt_num) if attempt_num < self.config.max_attempts else 0.0
                
                attempts.append(RetryAttempt(
                    attempt_number=attempt_num,
                    delay_before=delay,
                    exception=e,
                    timestamp=datetime.now(timezone.utc),
                    elapsed_time=attempt_time
                ))
                
                logger.debug(f"Attempt {attempt_num} failed: {e}. Retrying in {delay:.2f}s")
                
                if delay > 0 and attempt_num < self.config.max_attempts:
                    time.sleep(delay)
        
        # Should not reach here, but handle edge case
        final_exception = attempts[-1].exception if attempts else Exception("Unknown error")
        return RetryResult(success=False, attempts=attempts, final_exception=final_exception)
    
    async def execute_with_retry_async(self, func: Callable[[], Awaitable[Any]], *args, **kwargs) -> RetryResult:
        """
        Execute async function with retry logic.
        
        Args:
            func: Async function to execute
            *args: Function arguments
            **kwargs: Function keyword arguments
            
        Returns:
            RetryResult with outcome and attempt information
        """
        # Check circuit breaker if enabled
        if self._circuit_breaker and not self._circuit_breaker.can_execute():
            return RetryResult(
                success=False, 
                attempts=[], 
                final_exception=Exception("Circuit breaker is open")
            )
        
        attempts = []
        start_time = time.time()
        
        for attempt_num in range(1, self.config.max_attempts + 1):
            attempt_start = time.time()
            
            try:
                # Check overall timeout
                if self.config.timeout_seconds:
                    elapsed = time.time() - start_time
                    if elapsed >= self.config.timeout_seconds:
                        raise TimeoutError(f"Overall timeout exceeded: {elapsed:.2f}s >= {self.config.timeout_seconds}s")
                
                # Execute async function
                if self.config.timeout_seconds:
                    remaining_time = self.config.timeout_seconds - elapsed
                    result = await asyncio.wait_for(func(*args, **kwargs), timeout=remaining_time)
                else:
                    result = await func(*args, **kwargs)
                
                # Success - record attempt and return
                attempt_time = time.time() - attempt_start
                attempts.append(RetryAttempt(
                    attempt_number=attempt_num,
                    delay_before=0.0,
                    exception=None,
                    timestamp=datetime.now(timezone.utc),
                    elapsed_time=attempt_time
                ))
                
                # Record success in circuit breaker
                if self._circuit_breaker:
                    self._circuit_breaker.record_success()
                
                logger.debug(f"Async operation succeeded on attempt {attempt_num}")
                return RetryResult(success=True, result=result, attempts=attempts)
                
            except Exception as e:
                attempt_time = time.time() - attempt_start
                
                # Record failure in circuit breaker
                if self._circuit_breaker:
                    self._circuit_breaker.record_failure(type(e).__name__)
                
                # Decide whether to retry
                retry_decision = self._should_retry(e, attempt_num)
                
                if retry_decision == RetryDecision.STOP:
                    attempts.append(RetryAttempt(
                        attempt_number=attempt_num,
                        delay_before=0.0,
                        exception=e,
                        timestamp=datetime.now(timezone.utc),
                        elapsed_time=attempt_time
                    ))
                    logger.debug(f"Stopping async retries after attempt {attempt_num}: {e}")
                    return RetryResult(success=False, attempts=attempts, final_exception=e)
                
                # Calculate delay for next attempt
                delay = self._calculate_delay(attempt_num) if attempt_num < self.config.max_attempts else 0.0
                
                attempts.append(RetryAttempt(
                    attempt_number=attempt_num,
                    delay_before=delay,
                    exception=e,
                    timestamp=datetime.now(timezone.utc),
                    elapsed_time=attempt_time
                ))
                
                logger.debug(f"Async attempt {attempt_num} failed: {e}. Retrying in {delay:.2f}s")
                
                if delay > 0 and attempt_num < self.config.max_attempts:
                    await asyncio.sleep(delay)
        
        # Should not reach here, but handle edge case
        final_exception = attempts[-1].exception if attempts else Exception("Unknown error")
        return RetryResult(success=False, attempts=attempts, final_exception=final_exception)
    
    def with_timeout(self, timeout_seconds: float) -> 'UnifiedRetryHandler':
        """Create a new handler with specified timeout."""
        new_config = RetryConfig(**self.config.__dict__)
        new_config.timeout_seconds = timeout_seconds
        return UnifiedRetryHandler(self.service_name, new_config)
    
    def with_max_attempts(self, max_attempts: int) -> 'UnifiedRetryHandler':
        """Create a new handler with specified max attempts."""
        new_config = RetryConfig(**self.config.__dict__)
        new_config.max_attempts = max_attempts
        return UnifiedRetryHandler(self.service_name, new_config)
    
    def _setup_circuit_breaker(self) -> None:
        """Setup circuit breaker if enabled."""
        if not self.config.circuit_breaker_enabled:
            return
        
        circuit_config = UnifiedCircuitConfig(
            name=f"{self.service_name}_retry_circuit",
            failure_threshold=self.config.circuit_breaker_failure_threshold,
            recovery_timeout=self.config.circuit_breaker_recovery_timeout,
            timeout_seconds=self.config.timeout_seconds or 30.0
        )
        
        manager = get_unified_circuit_breaker_manager()
        self._circuit_breaker = manager.create_circuit_breaker(circuit_config.name, circuit_config)
    
    def with_circuit_breaker(self, enabled: bool = True, failure_threshold: int = 5, recovery_timeout: float = 30.0) -> 'UnifiedRetryHandler':
        """Create a new handler with circuit breaker configuration."""
        new_config = RetryConfig(**self.config.__dict__)
        new_config.circuit_breaker_enabled = enabled
        new_config.circuit_breaker_failure_threshold = failure_threshold
        new_config.circuit_breaker_recovery_timeout = recovery_timeout
        return UnifiedRetryHandler(self.service_name, new_config)
    
    def get_circuit_breaker_status(self) -> Optional[Dict[str, Any]]:
        """Get circuit breaker status if enabled."""
        if self._circuit_breaker:
            return self._circuit_breaker.get_status()
        return None
    
    def retry_context(self, func: Callable, *args, **kwargs) -> 'RetryContext':
        """Create a retry context manager."""
        return RetryContext(self, func, *args, **kwargs)
    
    def __call__(self, func: Callable) -> Callable:
        """Make the handler callable as a decorator."""
        if asyncio.iscoroutinefunction(func):
            @wraps(func)
            async def async_wrapper(*args, **kwargs):
                result = await self.execute_with_retry_async(func, *args, **kwargs)
                if result.success:
                    return result.result
                else:
                    raise result.final_exception
            return async_wrapper
        else:
            @wraps(func)
            def sync_wrapper(*args, **kwargs):
                result = self.execute_with_retry(func, *args, **kwargs)
                if result.success:
                    return result.result
                else:
                    raise result.final_exception
            return sync_wrapper


# Decorator functions for easy retry application
def retry_on_exception(max_attempts: int = 3, base_delay: float = 1.0, 
                      strategy: RetryStrategy = RetryStrategy.EXPONENTIAL,
                      retryable_exceptions: Tuple[Type[Exception], ...] = (Exception,)):
    """Decorator to add retry behavior to functions."""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            config = RetryConfig(
                max_attempts=max_attempts,
                base_delay=base_delay,
                strategy=strategy,
                retryable_exceptions=retryable_exceptions
            )
            handler = UnifiedRetryHandler(func.__name__, config)
            result = handler.execute_with_retry(func, *args, **kwargs)
            if result.success:
                return result.result
            else:
                raise result.final_exception
        return wrapper
    return decorator


def async_retry_on_exception(max_attempts: int = 3, base_delay: float = 1.0,
                            strategy: RetryStrategy = RetryStrategy.EXPONENTIAL,
                            retryable_exceptions: Tuple[Type[Exception], ...] = (Exception,)):
    """Decorator to add retry behavior to async functions."""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            config = RetryConfig(
                max_attempts=max_attempts,
                base_delay=base_delay,
                strategy=strategy,
                retryable_exceptions=retryable_exceptions
            )
            handler = UnifiedRetryHandler(func.__name__, config)
            result = await handler.execute_with_retry_async(func, *args, **kwargs)
            if result.success:
                return result.result
            else:
                raise result.final_exception
        return wrapper
    return decorator


# Domain-specific decorators
def database_retry(max_attempts: Optional[int] = None, base_delay: Optional[float] = None):
    """Decorator for database operations with retry."""
    def decorator(func: Callable) -> Callable:
        config = DATABASE_RETRY_POLICY
        if max_attempts is not None or base_delay is not None:
            config = RetryConfig(**DATABASE_RETRY_POLICY.__dict__)
            if max_attempts is not None:
                config.max_attempts = max_attempts
            if base_delay is not None:
                config.base_delay = base_delay
        
        handler = UnifiedRetryHandler(func.__name__, config)
        return handler(func)
    return decorator


def llm_retry(max_attempts: Optional[int] = None, base_delay: Optional[float] = None):
    """Decorator for LLM operations with retry."""
    def decorator(func: Callable) -> Callable:
        config = LLM_RETRY_POLICY
        if max_attempts is not None or base_delay is not None:
            config = RetryConfig(**LLM_RETRY_POLICY.__dict__)
            if max_attempts is not None:
                config.max_attempts = max_attempts
            if base_delay is not None:
                config.base_delay = base_delay
        
        handler = UnifiedRetryHandler(func.__name__, config)
        return handler(func)
    return decorator


def agent_retry(max_attempts: Optional[int] = None, base_delay: Optional[float] = None):
    """Decorator for agent operations with retry."""
    def decorator(func: Callable) -> Callable:
        config = AGENT_RETRY_POLICY
        if max_attempts is not None or base_delay is not None:
            config = RetryConfig(**AGENT_RETRY_POLICY.__dict__)
            if max_attempts is not None:
                config.max_attempts = max_attempts
            if base_delay is not None:
                config.base_delay = base_delay
        
        handler = UnifiedRetryHandler(func.__name__, config)
        return handler(func)
    return decorator


def api_retry(max_attempts: Optional[int] = None, base_delay: Optional[float] = None):
    """Decorator for API operations with retry."""
    def decorator(func: Callable) -> Callable:
        config = API_RETRY_POLICY
        if max_attempts is not None or base_delay is not None:
            config = RetryConfig(**API_RETRY_POLICY.__dict__)
            if max_attempts is not None:
                config.max_attempts = max_attempts
            if base_delay is not None:
                config.base_delay = base_delay
        
        handler = UnifiedRetryHandler(func.__name__, config)
        return handler(func)
    return decorator


# Domain-Specific Retry Policies

# Database Retry Policy
DATABASE_RETRY_POLICY = RetryConfig(
    max_attempts=5,
    base_delay=0.5,
    max_delay=30.0,
    strategy=RetryStrategy.EXPONENTIAL_JITTER,
    backoff_multiplier=2.0,
    jitter_range=0.1,
    timeout_seconds=60.0,
    retryable_exceptions=(
        psycopg2.OperationalError,
        sqlalchemy.exc.DisconnectionError,
        sqlalchemy.exc.TimeoutError,
        ConnectionError,
        TimeoutError,
        OSError,  # Network-related errors
    ),
    non_retryable_exceptions=(
        psycopg2.ProgrammingError,  # SQL syntax errors
        psycopg2.IntegrityError,    # Constraint violations
        sqlalchemy.exc.IntegrityError,  # SQLAlchemy constraint violations
        sqlalchemy.exc.DataError,   # Data conversion errors
        ValueError,  # Parameter validation errors
    ),
    circuit_breaker_enabled=True,
    circuit_breaker_failure_threshold=5,
    circuit_breaker_recovery_timeout=60.0
)

# LLM Retry Policy
LLM_RETRY_POLICY = RetryConfig(
    max_attempts=4,
    base_delay=2.0,
    max_delay=120.0,
    strategy=RetryStrategy.EXPONENTIAL_JITTER,
    backoff_multiplier=2.5,
    jitter_range=0.15,
    timeout_seconds=300.0,  # 5 minutes for LLM calls
    retryable_exceptions=(
        TimeoutError,
        ConnectionError,
        httpx.TimeoutException,
        httpx.ConnectError,
        httpx.ReadError,
        OSError,
    ),
    non_retryable_exceptions=(
        ValueError,  # Invalid parameters
        TypeError,   # Type errors
        httpx.HTTPStatusError,  # HTTP 4xx errors (don't retry client errors)
    ),
    circuit_breaker_enabled=True,
    circuit_breaker_failure_threshold=3,
    circuit_breaker_recovery_timeout=180.0  # 3 minutes
)

# Agent Retry Policy
AGENT_RETRY_POLICY = RetryConfig(
    max_attempts=3,
    base_delay=1.0,
    max_delay=60.0,
    strategy=RetryStrategy.EXPONENTIAL,
    backoff_multiplier=2.0,
    jitter_range=0.1,
    timeout_seconds=120.0,
    retryable_exceptions=(
        ConnectionError,
        TimeoutError,
        OSError,
        RuntimeError,  # Runtime issues that might be transient
    ),
    non_retryable_exceptions=(
        ValueError,
        TypeError,
        AttributeError,
        ImportError,
    ),
    circuit_breaker_enabled=False,  # Agents handle their own circuit breaking
    metrics_enabled=True
)

# API Retry Policy
API_RETRY_POLICY = RetryConfig(
    max_attempts=3,
    base_delay=1.0,
    max_delay=30.0,
    strategy=RetryStrategy.EXPONENTIAL_JITTER,
    backoff_multiplier=2.0,
    jitter_range=0.1,
    timeout_seconds=30.0,
    retryable_exceptions=(
        ConnectionError,
        TimeoutError,
        urllib.error.URLError,
        urllib.error.HTTPError,
        httpx.TimeoutException,
        httpx.ConnectError,
        httpx.ReadError,
        OSError,
    ),
    non_retryable_exceptions=(
        ValueError,  # Invalid parameters
        TypeError,   # Type errors
    ),
    circuit_breaker_enabled=True,
    circuit_breaker_failure_threshold=3,
    circuit_breaker_recovery_timeout=30.0
)

# WebSocket Retry Policy
WEBSOCKET_RETRY_POLICY = RetryConfig(
    max_attempts=2,  # Quick retry for WebSocket
    base_delay=0.5,
    max_delay=5.0,
    strategy=RetryStrategy.EXPONENTIAL,
    backoff_multiplier=2.0,
    jitter_range=0.05,
    timeout_seconds=10.0,
    retryable_exceptions=(
        ConnectionError,
        TimeoutError,
        OSError,
    ),
    non_retryable_exceptions=(
        ValueError,
        TypeError,
    ),
    circuit_breaker_enabled=False,  # WebSocket connections managed separately
    metrics_enabled=True
)

# File Operation Retry Policy
FILE_RETRY_POLICY = RetryConfig(
    max_attempts=3,
    base_delay=0.2,
    max_delay=2.0,
    strategy=RetryStrategy.EXPONENTIAL,
    backoff_multiplier=1.5,
    jitter_range=0.05,
    timeout_seconds=30.0,
    retryable_exceptions=(
        OSError,
        IOError,
        FileNotFoundError,  # Might be transient in distributed systems
        PermissionError,    # Might be transient
    ),
    non_retryable_exceptions=(
        ValueError,
        TypeError,
        IsADirectoryError,
    ),
    circuit_breaker_enabled=False,
    metrics_enabled=True
)


# Convenience functions for common retry patterns
def retry_database_operation(func: Callable, max_attempts: int = 5, base_delay: float = 0.5) -> Any:
    """Retry database operations with appropriate settings."""
    config = DATABASE_RETRY_POLICY
    if max_attempts != 5 or base_delay != 0.5:
        # Override defaults if specified
        config = RetryConfig(**DATABASE_RETRY_POLICY.__dict__)
        config.max_attempts = max_attempts
        config.base_delay = base_delay
    
    handler = UnifiedRetryHandler("database", config)
    result = handler.execute_with_retry(func)
    if result.success:
        return result.result
    else:
        raise result.final_exception


def retry_http_request(func: Callable, max_attempts: int = 3, base_delay: float = 1.0) -> Any:
    """Retry HTTP requests with appropriate settings."""
    config = API_RETRY_POLICY
    if max_attempts != 3 or base_delay != 1.0:
        # Override defaults if specified
        config = RetryConfig(**API_RETRY_POLICY.__dict__)
        config.max_attempts = max_attempts
        config.base_delay = base_delay
    
    handler = UnifiedRetryHandler("http", config)
    result = handler.execute_with_retry(func)
    if result.success:
        return result.result
    else:
        raise result.final_exception


def retry_llm_request(func: Callable, max_attempts: int = 4, base_delay: float = 2.0) -> Any:
    """Retry LLM requests with appropriate settings."""
    config = LLM_RETRY_POLICY
    if max_attempts != 4 or base_delay != 2.0:
        # Override defaults if specified
        config = RetryConfig(**LLM_RETRY_POLICY.__dict__)
        config.max_attempts = max_attempts
        config.base_delay = base_delay
    
    handler = UnifiedRetryHandler("llm", config)
    result = handler.execute_with_retry(func)
    if result.success:
        return result.result
    else:
        raise result.final_exception


def retry_agent_operation(func: Callable, max_attempts: int = 3, base_delay: float = 1.0) -> Any:
    """Retry agent operations with appropriate settings."""
    config = AGENT_RETRY_POLICY
    if max_attempts != 3 or base_delay != 1.0:
        # Override defaults if specified
        config = RetryConfig(**AGENT_RETRY_POLICY.__dict__)
        config.max_attempts = max_attempts
        config.base_delay = base_delay
    
    handler = UnifiedRetryHandler("agent", config)
    result = handler.execute_with_retry(func)
    if result.success:
        return result.result
    else:
        raise result.final_exception


def retry_websocket_operation(func: Callable, max_attempts: int = 2, base_delay: float = 0.5) -> Any:
    """Retry WebSocket operations with appropriate settings."""
    config = WEBSOCKET_RETRY_POLICY
    if max_attempts != 2 or base_delay != 0.5:
        # Override defaults if specified
        config = RetryConfig(**WEBSOCKET_RETRY_POLICY.__dict__)
        config.max_attempts = max_attempts
        config.base_delay = base_delay
    
    handler = UnifiedRetryHandler("websocket", config)
    result = handler.execute_with_retry(func)
    if result.success:
        return result.result
    else:
        raise result.final_exception


def retry_file_operation(func: Callable, max_attempts: int = 3, base_delay: float = 0.2) -> Any:
    """Retry file operations with appropriate settings."""
    config = FILE_RETRY_POLICY
    if max_attempts != 3 or base_delay != 0.2:
        # Override defaults if specified
        config = RetryConfig(**FILE_RETRY_POLICY.__dict__)
        config.max_attempts = max_attempts
        config.base_delay = base_delay
    
    handler = UnifiedRetryHandler("file", config)
    result = handler.execute_with_retry(func)
    if result.success:
        return result.result
    else:
        raise result.final_exception


# Context Manager Support
class RetryContext:
    """Context manager for retry operations."""
    
    def __init__(self, handler: UnifiedRetryHandler, func: Callable, *args, **kwargs):
        self.handler = handler
        self.func = func
        self.args = args
        self.kwargs = kwargs
        self.result: Optional[RetryResult] = None
    
    def __enter__(self) -> 'RetryContext':
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        # Context manager cleanup if needed
        pass
    
    async def __aenter__(self) -> 'RetryContext':
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        # Async context manager cleanup if needed
        pass
    
    def execute(self) -> Any:
        """Execute the function with retry logic."""
        self.result = self.handler.execute_with_retry(self.func, *self.args, **self.kwargs)
        if self.result.success:
            return self.result.result
        else:
            raise self.result.final_exception
    
    async def execute_async(self) -> Any:
        """Execute the async function with retry logic."""
        self.result = await self.handler.execute_with_retry_async(self.func, *self.args, **self.kwargs)
        if self.result.success:
            return self.result.result
        else:
            raise self.result.final_exception


# Global instances for common service patterns with domain-specific policies
database_retry_handler = UnifiedRetryHandler("database", DATABASE_RETRY_POLICY)
llm_retry_handler = UnifiedRetryHandler("llm", LLM_RETRY_POLICY)
agent_retry_handler = UnifiedRetryHandler("agent", AGENT_RETRY_POLICY)
api_retry_handler = UnifiedRetryHandler("api", API_RETRY_POLICY)
websocket_retry_handler = UnifiedRetryHandler("websocket", WEBSOCKET_RETRY_POLICY)
file_retry_handler = UnifiedRetryHandler("file", FILE_RETRY_POLICY)

# Legacy compatibility instances
auth_retry_handler = UnifiedRetryHandler("auth_service", API_RETRY_POLICY)
backend_retry_handler = UnifiedRetryHandler("netra_backend", API_RETRY_POLICY)
launcher_retry_handler = UnifiedRetryHandler("dev_launcher", API_RETRY_POLICY)
default_retry_handler = UnifiedRetryHandler("default")


# Backoff strategy functions
def exponential_backoff(attempt: int, base_delay: float = 1.0, multiplier: float = 2.0, max_delay: float = 60.0) -> float:
    """Calculate exponential backoff delay."""
    delay = base_delay * (multiplier ** (attempt - 1))
    return min(delay, max_delay)


def linear_backoff(attempt: int, base_delay: float = 1.0, increment: float = 1.0, max_delay: float = 60.0) -> float:
    """Calculate linear backoff delay."""
    delay = base_delay + (increment * (attempt - 1))
    return min(delay, max_delay)