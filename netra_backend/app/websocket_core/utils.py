"""
WebSocket Utilities

Business Value Justification:
- Segment: Platform/Internal
- Business Goal: Development Velocity & Code Reuse
- Value Impact: Shared utilities, eliminates duplication across 20+ files
- Strategic Impact: DRY principle, consistent utility functions

Consolidated utility functions from scattered WebSocket implementation files.
All functions  <= 25 lines as per CLAUDE.md requirements.
"""

import asyncio
import json
import time
import uuid
from datetime import datetime, timezone
from typing import Any, AsyncGenerator, Dict, List, Optional, Union
from contextlib import asynccontextmanager

# Import UnifiedIdGenerator for SSOT ID generation
from shared.id_generation.unified_id_generator import UnifiedIdGenerator
# Import ID migration bridge for pattern-agnostic matching (PHASE 1 SSOT REMEDIATION)
from netra_backend.app.core.id_migration_bridge import get_migration_bridge, validate_id_compatibility

from fastapi import WebSocket
from starlette.websockets import WebSocketState, WebSocketDisconnect

from netra_backend.app.logging_config import central_logger
from netra_backend.app.websocket_core.types import (
    WebSocketMessage,
    ServerMessage,
    ErrorMessage,
    ConnectionInfo,
    MessageType,
    create_standard_message,
    create_error_message,
    create_server_message
)
from shared.types.core_types import (
    UserID, ConnectionID, WebSocketID,
    ensure_user_id, ensure_websocket_id
)
# No separate imports needed - using UnifiedIdGenerator directly

logger = central_logger.get_logger(__name__)


def _safe_websocket_state_for_logging(state) -> str:
    """
    Safely convert WebSocketState enum to string for GCP Cloud Run structured logging.
    
    CRITICAL FIX: GCP Cloud Run structured logging cannot serialize Starlette WebSocketState
    enum objects directly. This causes "Object of type WebSocketState is not JSON serializable"
    errors that manifest as 1011 internal server errors.
    
    Args:
        state: WebSocketState enum or any object that needs safe logging
        
    Returns:
        String representation safe for JSON serialization in structured logs
    """
    try:
        # Handle Starlette/FastAPI WebSocketState enums
        if hasattr(state, 'name') and hasattr(state, 'value'):
            return str(state.name).lower()  # CONNECTED -> "connected"
        
        # Handle other enum-like objects
        if hasattr(state, '__class__') and hasattr(state.__class__, '__name__'):
            if 'State' in state.__class__.__name__:
                return str(state)
        
        # Fallback to string representation
        return str(state)
        
    except Exception as e:
        # Ultimate fallback - prevent logging failures
        logger.debug(f"Error serializing state for logging: {e}")
        return "<serialization_error>"


def generate_connection_id(user_id: Union[str, UserID], prefix: str = "ws_conn") -> ConnectionID:
    """Generate unique connection ID with type safety.
    
    Args:
        user_id: User ID (accepts both str and UserID)
        prefix: Prefix for connection ID (should be ws_conn for consistency)
        
    Returns:
        Strongly typed ConnectionID
    """
    # Ensure user_id is validated
    validated_user_id = ensure_user_id(user_id)
    
    # Use UnifiedIdGenerator for SSOT ID generation
    connection_id = UnifiedIdGenerator.generate_websocket_connection_id(str(validated_user_id))
    
    return ConnectionID(connection_id)


def generate_message_id() -> str:
    """Generate unique message ID using UnifiedIdGenerator."""
    return UnifiedIdGenerator.generate_base_id("uid", include_random=True, random_length=8)


def get_current_timestamp() -> float:
    """Get current timestamp in seconds."""
    return time.time()


def get_current_iso_timestamp() -> str:
    """Get current timestamp in ISO format."""
    return datetime.now(timezone.utc).isoformat()


def is_websocket_connected(websocket: WebSocket) -> bool:
    """
    Check if WebSocket is connected.
    
    CRITICAL FIX: Enhanced state checking to prevent "Need to call accept first" errors
    with staging-optimized connection validation.
    """
    try:
        # Check multiple conditions to determine if WebSocket is connected
        # 1. Check if WebSocket has client_state (Starlette WebSocket attribute)
        if hasattr(websocket, 'client_state'):
            client_state = websocket.client_state
            is_connected = client_state == WebSocketState.CONNECTED
            
            # CRITICAL FIX: If client state indicates disconnected or not yet connected, return False
            if client_state in [WebSocketState.DISCONNECTED, WebSocketState.CONNECTING]:
                logger.debug(f"WebSocket client_state not connected: {_safe_websocket_state_for_logging(client_state)}")
                return False
            
            if is_connected:
                logger.debug(f"WebSocket connected via client_state: {_safe_websocket_state_for_logging(client_state)}")
            return is_connected
        
        # 2. Fallback to application_state if available
        if hasattr(websocket, 'application_state'):
            app_state = websocket.application_state
            is_connected = app_state == WebSocketState.CONNECTED
            
            # CRITICAL FIX: If application state indicates disconnected or not yet connected, return False
            if app_state in [WebSocketState.DISCONNECTED, WebSocketState.CONNECTING]:
                logger.debug(f"WebSocket application_state not connected: {_safe_websocket_state_for_logging(app_state)}")
                return False
                
            if is_connected:
                logger.debug(f"WebSocket connected via application_state: {_safe_websocket_state_for_logging(app_state)}")
            return is_connected
        
        # 3. Check if the websocket has been properly initialized
        if not hasattr(websocket, '_receive') and not hasattr(websocket, 'receive'):
            logger.debug("WebSocket state check: WebSocket not properly initialized")
            return False
        
        # 4. CRITICAL FIX: Enhanced Cloud Run environment detection and state validation
        # Root cause: is_websocket_connected() incorrectly returns False in GCP Cloud Run
        from shared.isolated_environment import get_env_var
        environment = get_env_var("ENVIRONMENT", "development").lower()
        
        # GCP Cloud Run specific WebSocket state validation
        if environment in ["staging", "production"]:
            # ENHANCED FIX: Try additional Cloud Run specific checks
            try:
                # Check if WebSocket has Cloud Run specific attributes
                if hasattr(websocket, '_send_queue') and hasattr(websocket, '_receive_queue'):
                    logger.debug(f"Cloud Run WebSocket queues detected - connection appears active")
                    return True
                
                # Check for Cloud Run WebSocket proxy attributes
                if hasattr(websocket, 'scope') and websocket.scope:
                    scope_type = websocket.scope.get('type', '')
                    if scope_type == 'websocket':
                        logger.debug(f"Cloud Run WebSocket scope confirmed - connection active")
                        return True
                
                # Check if we can access basic WebSocket methods without error
                if hasattr(websocket, 'send_json') and callable(websocket.send_json):
                    logger.debug(f"Cloud Run WebSocket send methods available - connection likely active")
                    return True
                    
            except Exception as cloud_check_error:
                logger.debug(f"Cloud Run WebSocket check failed: {cloud_check_error}")
            
            # Cloud environments - be conservative but not overly restrictive
            logger.debug(f"WebSocket state check: Could not confirm connection in {environment}, assuming disconnected for safety")
            return False
        else:
            # Development - more permissive but with better validation
            try:
                # Even in development, try to validate WebSocket is actually usable
                if hasattr(websocket, 'send_json') and callable(websocket.send_json):
                    logger.debug("Development WebSocket methods confirmed - assuming connected")
                    return True
            except Exception:
                pass
                
            logger.debug("Development WebSocket fallback - defaulting to connected=True")
            return True
        
    except Exception as e:
        # CRITICAL FIX: Enhanced error handling for connection state validation issues
        # Root cause: Connection churning causes resource accumulation
        import traceback
        from shared.isolated_environment import get_env_var

        environment = get_env_var("ENVIRONMENT", "development").lower()
        
        # Enhanced error context for debugging connection issues
        error_context = {
            "error_type": type(e).__name__,
            "error_message": str(e),
            "environment": environment,
            "websocket_type": type(websocket).__name__ if websocket else "None"
        }
        
        # Environment-specific error handling
        if environment in ["staging", "production"]:
            logger.warning(f" ALERT:  WebSocket state check failed in {environment}: {error_context['error_type']} - {error_context['error_message']}")
            logger.debug(f"WebSocket state check error context: {error_context}")
            # In cloud environments, connection check failures indicate real issues
            return False
        else:
            logger.debug(f"WebSocket state check error in development: {error_context}")
            # In development, be more forgiving of connection check errors
            return False  # Still return False for safety, but with less aggressive logging


def is_websocket_connected_and_ready(websocket: WebSocket, connection_id: Optional[str] = None) -> bool:
    """
    Enhanced connection validation with application state integration and race condition detection.
    CRITICAL: Combines WebSocket transport state with application-level readiness and race condition prevention.
    
    RACE CONDITION FIX: This function now properly separates transport readiness from application readiness.
    WebSocket.accept() completion (transport ready) != ready to process messages (application ready).
    
    This function ensures that:
    1. WebSocket is in CONNECTED state (transport level)
    2. Handshake is complete and validated
    3. Application-level connection state is ready (REQUIRED for message processing)
    4. Bidirectional communication is ready
    5. Race condition patterns are detected and logged
    
    Args:
        websocket: WebSocket connection to check
        connection_id: Optional connection ID for state machine lookup
    
    Returns:
        True only when WebSocket is fully operational for message handling
    """
    try:
        # First check basic connection state
        if not is_websocket_connected(websocket):
            logger.debug("WebSocket not connected - basic state check failed")
            return False
        
        # PHASE 1: WebSocket Transport Validation
        # Check if websocket has been accepted
        if hasattr(websocket, 'client_state'):
            client_state = websocket.client_state
            if client_state != WebSocketState.CONNECTED:
                logger.debug(f"WebSocket handshake not complete: {_safe_websocket_state_for_logging(client_state)}")
                return False
        
        # Check if websocket has proper receive/send capabilities
        if not hasattr(websocket, 'receive') or not hasattr(websocket, 'send'):
            logger.debug("WebSocket missing receive/send methods - handshake not complete")
            return False
        
        # PHASE 2: Application State Validation (CRITICAL FIX)
        # RACE CONDITION FIX: Always check connection state machine when connection_id is provided
        if connection_id:
            try:
                # Import here to avoid circular imports
                from netra_backend.app.websocket_core.connection_state_machine import get_connection_state_machine
                state_machine = get_connection_state_machine(connection_id)
                
                if state_machine:
                    # Use application-level readiness check - THIS IS THE KEY FIX
                    app_ready = state_machine.can_process_messages()
                    current_state = state_machine.current_state
                    logger.debug(f"Connection {connection_id} application state: {current_state}, ready: {app_ready}")
                    
                    # CRITICAL FIX: Application must be ready for message processing
                    if not app_ready:
                        logger.debug(f"Application not ready for {connection_id} (state: {current_state}) - transport may be ready but application setup incomplete")
                        return False
                    
                    # Application is ready - connection is fully operational
                    logger.debug(f"Connection {connection_id} fully operational - transport and application ready")
                else:
                    # REGRESSION FIX: Allow staging connections to proceed without state machine during initialization
                    # The state machine is created asynchronously and may not exist yet for valid connections
                    logger.debug(f"No state machine found for connection {connection_id} - allowing connection to proceed")
                    # In production environments, we still need to be conservative but not block valid connections
                    from shared.isolated_environment import get_env_var
                    environment = get_env_var("ENVIRONMENT", "development").lower()
                    
                    if environment in ["staging", "production"]:
                        # CRITICAL REGRESSION FIX: Don't block connections that are legitimately establishing
                        # State machines are created asynchronously, so missing state machine doesn't mean invalid connection
                        logger.debug(f"Cloud environment {environment}: proceeding without state machine - will be created asynchronously")
                        # Still proceed but log for monitoring
                        log_race_condition_pattern(
                            "missing_state_machine_during_connection_validation",
                            "info",  # Reduced from warning since this is expected during setup
                            {"connection_id": connection_id, "environment": environment}
                        )
                    else:
                        # Development - be more permissive and log the issue
                        logger.debug(f"Development environment: proceeding despite missing state machine for {connection_id}")
                        
            except ImportError:
                # State machine not available - fall back to transport-only validation
                logger.debug("ConnectionStateMachine not available, using transport-only validation")
            except Exception as e:
                # Error accessing state machine - this indicates a problem
                logger.warning(f"Error accessing state machine for {connection_id}: {e}")
                # In production, treat state machine errors as not ready
                from shared.isolated_environment import get_env_var
                environment = get_env_var("ENVIRONMENT", "development").lower()
                
                if environment in ["staging", "production"]:
                    logger.debug(f"Cloud environment {environment}: state machine error indicates not ready")
                    return False
        else:
            # REGRESSION FIX: No connection_id means we fall back to transport-only validation
            # This is common during initial connection establishment before connection_id assignment
            logger.debug("No connection_id provided - using transport-only validation")
            # In production environments, log but don't block connections during legitimate setup
            from shared.isolated_environment import get_env_var
            environment = get_env_var("ENVIRONMENT", "development").lower()
            
            if environment in ["staging", "production"]:
                logger.debug(f"Cloud environment {environment}: proceeding with transport validation - connection_id not yet assigned")
                # Log pattern for monitoring but allow connection to proceed
                log_race_condition_pattern(
                    "connection_validation_without_id",
                    "info", 
                    {"environment": environment, "reason": "connection_setup_phase"}
                )
        
        # PHASE 3: WebSocket Transport Readiness Validation
        # Additional validation: Check if websocket is in a state ready for messaging
        # This prevents "Need to call accept first" errors by ensuring accept() was called
        try:
            # Try to access websocket state attributes that are only available after accept()
            if hasattr(websocket, '_send_queue') or hasattr(websocket, '_receive_queue'):
                # These attributes indicate the websocket internal queues are initialized
                logger.debug("WebSocket internal queues confirmed - handshake complete")
            elif hasattr(websocket, 'send_json'):
                # send_json is available - indicates websocket is properly initialized
                logger.debug("WebSocket send_json available - handshake complete")
            else:
                logger.debug("WebSocket attributes suggest handshake may not be complete")
        except Exception as e:
            logger.debug(f"WebSocket state introspection failed: {e}")
            # Fall through to environment-specific logic
        
        # PHASE 4: Environment-Specific Validation with Race Condition Detection
        from shared.isolated_environment import get_env_var
        environment = get_env_var("ENVIRONMENT", "development").lower()
        
        # Initialize race condition detector for pattern tracking
        try:
            from netra_backend.app.websocket_core.race_condition_prevention import RaceConditionDetector
            race_detector = RaceConditionDetector(environment=environment)
        except ImportError:
            # Fallback if race condition prevention not available
            race_detector = None
        
        if environment in ["staging", "production"]:
            # CRITICAL FIX: In cloud environments, be very conservative about readiness
            # We've already validated application state above, so if we get here, we're ready
            logger.debug(f"Cloud environment {environment}: transport and application validation passed")
            
            # Log successful validation pattern
            if race_detector:
                race_detector.add_detected_pattern(
                    "cloud_environment_successful_validation",
                    "info",
                    details={
                        "environment": environment,
                        "connection_id": connection_id,
                        "reason": "transport_and_application_state_validated"
                    }
                )
            
            return True  # Both transport and application validated successfully
        else:
            # Development environment - if all checks passed, assume ready
            logger.debug("Development environment: transport and application validation passed")
            return True
        
    except Exception as e:
        logger.warning(f"WebSocket readiness check error: {e}, assuming not ready")
        
        # Log error pattern if race detector is available
        try:
            from netra_backend.app.websocket_core.race_condition_prevention import RaceConditionDetector
            from shared.isolated_environment import get_env_var
            environment = get_env_var("ENVIRONMENT", "development").lower()
            
            race_detector = RaceConditionDetector(environment=environment)
            race_detector.add_detected_pattern(
                "websocket_readiness_check_error",
                "critical",
                details={
                    "error": str(e),
                    "connection_id": connection_id,
                    "environment": environment
                }
            )
        except Exception:
            # Fallback - don't let race condition logging break the main function
            pass
        
        return False


async def validate_websocket_handshake_completion(websocket: WebSocket, timeout_seconds: float = 1.0) -> bool:
    """
    Validate WebSocket handshake is complete with bidirectional communication test.
    CRITICAL: This prevents race conditions in Cloud Run environments.
    
    This function performs a comprehensive handshake validation by:
    1. Checking WebSocket state attributes
    2. Performing a bidirectional communication test (ping/pong)
    3. Validating message sending/receiving capabilities
    
    Args:
        websocket: WebSocket connection to validate
        timeout_seconds: Maximum time to wait for handshake validation
        
    Returns:
        True if handshake is complete and bidirectional communication works
    """
    try:
        # Environment-specific timeout configuration
        from shared.isolated_environment import get_env_var
        environment = get_env_var("ENVIRONMENT", "development").lower()
        
        # Cloud environments need longer validation due to network latency
        if environment in ["staging", "production"]:
            timeout_seconds = max(timeout_seconds, 2.0)  # At least 2 seconds for cloud
        
        logger.debug(f"Starting WebSocket handshake validation (timeout: {timeout_seconds}s)")
        
        # Step 1: Basic state validation
        if not is_websocket_connected(websocket):
            logger.debug("Handshake validation failed: WebSocket not connected")
            return False
        
        # Step 2: Check if accept() was called by examining websocket state
        if hasattr(websocket, 'client_state'):
            client_state = websocket.client_state
            if client_state != WebSocketState.CONNECTED:
                logger.debug(f"Handshake validation failed: client_state not CONNECTED: {_safe_websocket_state_for_logging(client_state)}")
                return False
        
        # Step 3: Bidirectional communication test
        # Send a test ping and wait for capability confirmation
        test_start_time = time.time()
        
        try:
            # Create a test message that doesn't interfere with normal operations
            test_message = {
                "type": "handshake_validation",
                "timestamp": test_start_time,
                "validation_id": f"test_{int(test_start_time * 1000)}"
            }
            
            # Try to send test message - this will fail if handshake isn't complete
            await asyncio.wait_for(
                websocket.send_json(test_message),
                timeout=timeout_seconds / 2  # Use half timeout for send
            )
            
            logger.debug("WebSocket send test successful - handshake appears complete")
            
            # If we can send successfully, handshake is likely complete
            # Note: We don't wait for a response since this is a validation ping
            # The ability to send without "Need to call accept first" confirms handshake
            return True
            
        except asyncio.TimeoutError:
            logger.debug("WebSocket handshake validation timeout")
            return False
        except RuntimeError as e:
            error_message = str(e)
            if "Need to call 'accept' first" in error_message:
                logger.debug(f"Handshake validation confirmed incomplete: {error_message}")
                return False
            elif "WebSocket is not connected" in error_message:
                logger.debug(f"Handshake validation failed - WebSocket disconnected: {error_message}")
                return False
            else:
                logger.debug(f"WebSocket handshake validation error: {error_message}")
                return False
        except Exception as e:
            logger.debug(f"WebSocket handshake validation failed with error: {e}")
            return False
        
    except Exception as e:
        logger.warning(f"WebSocket handshake validation critical error: {e}")
        return False


async def safe_websocket_send(websocket: WebSocket, data: Union[Dict[str, Any], str],
                            retry_count: int = 2) -> bool:
    """
    Safely send data to WebSocket with retry logic.
    
    CRITICAL FIX: Enhanced error handling for connection state issues with
    staging-optimized retry logic and exponential backoff.
    """
    if not is_websocket_connected(websocket):
        logger.debug("WebSocket not connected, skipping send")
        return False
    
    # CRITICAL FIX: Environment-aware retry configuration
    from shared.isolated_environment import get_env_var
    environment = get_env_var("ENVIRONMENT", "development").lower()
    
    # Staging/production needs more aggressive retry logic due to network latency
    if environment in ["staging", "production"]:
        retry_count = max(retry_count, 3)  # At least 3 retries for cloud environments
        max_backoff = 2.0  # Longer max backoff for staging
    else:
        max_backoff = 1.0  # Shorter backoff for development
    
    for attempt in range(retry_count + 1):
        try:
            if isinstance(data, str):
                await websocket.send_text(data)
            else:
                # CRITICAL FIX: Use safe serialization to handle WebSocketState enums and other complex objects
                from netra_backend.app.websocket_core.unified_manager import _serialize_message_safely
                safe_data = _serialize_message_safely(data)
                await websocket.send_json(safe_data)
            
            if attempt > 0:
                logger.info(f"WebSocket send succeeded on attempt {attempt + 1}")
            return True
            
        except WebSocketDisconnect:
            logger.info("WebSocket disconnected during send")
            return False
        except RuntimeError as e:
            # CRITICAL FIX: Handle "WebSocket is not connected" and "Need to call accept first" errors
            error_message = str(e)
            if "Need to call 'accept' first" in error_message or "WebSocket is not connected" in error_message:
                logger.error(f"WebSocket connection state error during send: {error_message}")
                return False
            else:
                logger.warning(f"WebSocket send runtime error attempt {attempt + 1}/{retry_count + 1}: {e}")
                if attempt < retry_count:
                    backoff_delay = min(0.1 * (2 ** attempt), max_backoff)  # Exponential backoff with cap
                    await asyncio.sleep(backoff_delay)
                else:
                    logger.error(f"WebSocket send failed after {retry_count + 1} attempts")
                    return False
        except Exception as e:
            logger.warning(f"WebSocket send attempt {attempt + 1}/{retry_count + 1} failed: {e}")
            if attempt < retry_count:
                backoff_delay = min(0.1 * (2 ** attempt), max_backoff)  # Exponential backoff with cap
                logger.debug(f"Retrying WebSocket send in {backoff_delay:.2f}s")
                await asyncio.sleep(backoff_delay)
            else:
                logger.error(f"WebSocket send failed after {retry_count + 1} attempts")
                return False
    
    return False


async def safe_websocket_close(websocket: WebSocket, code: int = 1000,
                             reason: str = "Normal closure") -> None:
    """
    Safely close WebSocket connection with enhanced production state validation.

    CRITICAL FIX: Enhanced error handling for connection state issues during close.
    Addresses Issue #335: WebSocket "send after close" runtime errors with comprehensive
    state validation and production-specific race condition handling.
    """
    # Enhanced state validation before attempting close
    connection_already_closed = False
    close_attempted = False

    try:
        # PRODUCTION FIX: Comprehensive pre-close state validation
        # Check multiple state indicators to determine if connection is already closed
        if hasattr(websocket, 'client_state'):
            client_state = websocket.client_state
            if client_state == WebSocketState.DISCONNECTED:
                logger.debug(f"WebSocket already disconnected (client_state: {_safe_websocket_state_for_logging(client_state)}), skipping close")
                connection_already_closed = True
            elif client_state == WebSocketState.CONNECTING:
                logger.debug(f"WebSocket still connecting (client_state: {_safe_websocket_state_for_logging(client_state)}), attempting graceful close")

        # Additional application state check for Cloud Run environments
        if hasattr(websocket, 'application_state') and not connection_already_closed:
            app_state = websocket.application_state
            if app_state == WebSocketState.DISCONNECTED:
                logger.debug(f"WebSocket already disconnected (application_state: {_safe_websocket_state_for_logging(app_state)}), skipping close")
                connection_already_closed = True

        # Skip close attempt if we've determined the connection is already closed
        if connection_already_closed:
            logger.debug(f"Skipping WebSocket close operation - connection already closed")
            return

        # PRODUCTION FIX: Try close with enhanced error categorization
        close_attempted = True
        await websocket.close(code=code, reason=reason)
        logger.debug(f"WebSocket closed successfully with code {code}, reason: {reason}")

    except RuntimeError as e:
        # CRITICAL FIX: Enhanced RuntimeError handling for production edge cases
        error_message = str(e)

        # Known recoverable state errors that indicate connection already closed
        recoverable_errors = [
            "Need to call 'accept' first",
            "WebSocket is not connected",
            "Connection is already closed",
            "Cannot send to a closing connection",
            "Cannot send to a closed connection"
        ]

        if any(error_text in error_message for error_text in recoverable_errors):
            logger.debug(f"WebSocket close skipped - connection already in closed state: {error_message}")
        else:
            # Unknown RuntimeError - log as warning for production debugging
            logger.warning(f"Unexpected RuntimeError during WebSocket close (code: {code}): {error_message}")

    except WebSocketDisconnect as e:
        # PRODUCTION FIX: Handle WebSocketDisconnect during close attempts
        # This can happen in Cloud Run when connection drops during close
        logger.debug(f"WebSocket disconnected during close attempt (code: {code}): {e}")

    except ConnectionError as e:
        # PRODUCTION FIX: Handle network-level connection errors
        # Common in Cloud Run environments with timeout/infrastructure issues
        logger.debug(f"Connection error during WebSocket close (code: {code}): {e}")

    except Exception as e:
        # PRODUCTION FIX: Enhanced general exception handling with better context
        error_type = type(e).__name__
        logger.warning(f"Unexpected {error_type} during WebSocket close (code: {code}, attempted: {close_attempted}): {e}")

        # Additional context for production debugging
        if hasattr(websocket, 'client_state'):
            try:
                current_state = _safe_websocket_state_for_logging(websocket.client_state)
                logger.debug(f"WebSocket client_state during error: {current_state}")
            except Exception as state_error:
                logger.debug(f"Could not read WebSocket state during error: {state_error}")


class WebSocketMessageQueue:
    """Queue for managing WebSocket messages."""
    
    def __init__(self, max_size: int = 1000):
        self.queue: asyncio.Queue = asyncio.Queue(maxsize=max_size)
        self.stats = {
            "enqueued": 0,
            "dequeued": 0,
            "dropped": 0,
            "errors": 0
        }
    
    async def enqueue(self, message: Union[WebSocketMessage, Dict[str, Any]]) -> bool:
        """Add message to queue."""
        try:
            # Convert to dict if needed
            if hasattr(message, 'model_dump'):
                message_dict = message.model_dump()
            else:
                message_dict = message
            
            self.queue.put_nowait(message_dict)
            self.stats["enqueued"] += 1
            return True
            
        except asyncio.QueueFull:
            self.stats["dropped"] += 1
            logger.warning("Message queue is full, dropping message")
            return False
        except Exception as e:
            self.stats["errors"] += 1
            logger.error(f"Error enqueueing message: {e}")
            return False
    
    async def dequeue(self, timeout: Optional[float] = None) -> Optional[Dict[str, Any]]:
        """Get message from queue."""
        try:
            if timeout:
                message = await asyncio.wait_for(self.queue.get(), timeout=timeout)
            else:
                message = await self.queue.get()
            
            self.stats["dequeued"] += 1
            return message
            
        except asyncio.TimeoutError:
            return None
        except Exception as e:
            self.stats["errors"] += 1
            logger.error(f"Error dequeuing message: {e}")
            return None
    
    def size(self) -> int:
        """Get queue size."""
        return self.queue.qsize()
    
    def is_empty(self) -> bool:
        """Check if queue is empty."""
        return self.queue.empty()
    
    def clear(self) -> None:
        """Clear all messages from queue."""
        while not self.queue.empty():
            try:
                self.queue.get_nowait()
            except asyncio.QueueEmpty:
                break
    
    def get_stats(self) -> Dict[str, Any]:
        """Get queue statistics."""
        return {
            **self.stats,
            "current_size": self.queue.qsize(),
            "max_size": self.queue.maxsize
        }


class WebSocketHeartbeat:
    """Manages WebSocket heartbeat/ping mechanism."""
    
    def __init__(self, interval: float = 45.0, timeout: float = 10.0):
        self.interval = interval
        self.timeout = timeout
        self.running = False
        self.last_pong: Optional[float] = None
        self.heartbeat_task: Optional[asyncio.Task] = None
    
    async def start(self, websocket: WebSocket) -> None:
        """Start heartbeat monitoring."""
        if self.running:
            return
        
        self.running = True
        self.last_pong = time.time()
        self.heartbeat_task = asyncio.create_task(self._heartbeat_loop(websocket))
    
    async def stop(self) -> None:
        """Stop heartbeat monitoring."""
        self.running = False
        if self.heartbeat_task:
            self.heartbeat_task.cancel()
            try:
                await self.heartbeat_task
            except asyncio.CancelledError:
                pass
    
    def on_pong_received(self) -> None:
        """Called when pong is received."""
        self.last_pong = time.time()
    
    async def _heartbeat_loop(self, websocket: WebSocket) -> None:
        """Main heartbeat loop."""
        try:
            while self.running and is_websocket_connected_and_ready(websocket):
                current_time = time.time()
                
                # Check if we missed a pong
                if self.last_pong and (current_time - self.last_pong) > (self.interval + self.timeout):
                    logger.warning("WebSocket heartbeat timeout")
                    break
                
                # Send ping
                ping_message = create_server_message(
                    MessageType.PING,
                    {"timestamp": current_time}
                )
                
                if not await safe_websocket_send(websocket, ping_message.model_dump()):
                    logger.warning("Failed to send heartbeat ping")
                    break
                
                await asyncio.sleep(self.interval)
                
        except asyncio.CancelledError:
            pass
        except Exception as e:
            logger.error(f"Heartbeat loop error: {e}")
        finally:
            self.running = False


class WebSocketConnectionMonitor:
    """Monitors WebSocket connection health and statistics with type safety."""
    
    def __init__(self):
        self.connections: Dict[str, Dict[str, Any]] = {}
        self.global_stats = {
            "total_connections": 0,
            "active_connections": 0,
            "messages_processed": 0,
            "errors_occurred": 0,
            "start_time": time.time()
        }
        # Initialize monitoring coverage tracking
        self.monitoring_coverage = {
            "total_checks": 0,
            "successful_checks": 0,
            "failed_checks": 0,
            "check_results": []
        }
    
    def register_connection(self, connection_id: Union[str, ConnectionID], user_id: Union[str, UserID],
                          websocket: WebSocket) -> None:
        """Register connection for monitoring with type safety.
        
        Args:
            connection_id: Connection ID (accepts both str and ConnectionID)
            user_id: User ID (accepts both str and UserID)
            websocket: WebSocket instance to monitor
        """
        # Validate typed IDs
        validated_user_id = ensure_user_id(user_id)
        validated_connection_id = str(connection_id)
        
        self.connections[validated_connection_id] = {
            "user_id": validated_user_id,
            "websocket": websocket,
            "connected_at": datetime.now(timezone.utc),
            "last_activity": datetime.now(timezone.utc),
            "messages_sent": 0,
            "messages_received": 0,
            "errors": 0,
            "is_healthy": True
        }
        
        self.global_stats["total_connections"] += 1
        self.global_stats["active_connections"] += 1
    
    def unregister_connection(self, connection_id: Union[str, ConnectionID]) -> None:
        """Unregister connection with type safety.
        
        Args:
            connection_id: Connection ID to unregister (accepts both str and ConnectionID)
        """
        validated_connection_id = str(connection_id)
        if validated_connection_id in self.connections:
            del self.connections[validated_connection_id]
            self.global_stats["active_connections"] -= 1
    
    def update_activity(self, connection_id: Union[str, ConnectionID], activity_type: str = "message") -> None:
        """Update connection activity with type safety.
        
        Args:
            connection_id: Connection ID to update (accepts both str and ConnectionID)
            activity_type: Type of activity to record
        """
        validated_connection_id = str(connection_id)
        if validated_connection_id in self.connections:
            conn = self.connections[validated_connection_id]
            conn["last_activity"] = datetime.now(timezone.utc)
            
            if activity_type == "message_sent":
                conn["messages_sent"] += 1
            elif activity_type == "message_received":
                conn["messages_received"] += 1
            elif activity_type == "error":
                conn["errors"] += 1
                self.global_stats["errors_occurred"] += 1
            
            self.global_stats["messages_processed"] += 1
    
    def get_connection_health(self, connection_id: Union[str, ConnectionID]) -> Dict[str, Any]:
        """Get health status for specific connection with type safety.
        
        Args:
            connection_id: Connection ID to check (accepts both str and ConnectionID)
            
        Returns:
            Dictionary with connection health information
        """
        validated_connection_id = str(connection_id)
        if validated_connection_id not in self.connections:
            return {"status": "not_found"}
        
        conn = self.connections[validated_connection_id]
        websocket = conn["websocket"]
        current_time = datetime.now(timezone.utc)
        last_activity = conn["last_activity"]
        
        # Calculate activity metrics
        inactive_seconds = (current_time - last_activity).total_seconds()
        is_stale = inactive_seconds > 300  # 5 minutes
        is_connected = is_websocket_connected(websocket)
        
        return {
            "connection_id": validated_connection_id,
            "user_id": conn["user_id"],
            "is_connected": is_connected,
            "is_stale": is_stale,
            "inactive_seconds": inactive_seconds,
            "messages_sent": conn["messages_sent"],
            "messages_received": conn["messages_received"],
            "error_count": conn["errors"],
            "connected_duration": (current_time - conn["connected_at"]).total_seconds()
        }
    
    def get_global_stats(self) -> Dict[str, Any]:
        """Get global connection statistics."""
        uptime = time.time() - self.global_stats["start_time"]
        
        return {
            **self.global_stats,
            "uptime_seconds": uptime,
            "connections_by_user": self._get_connections_by_user(),
            "health_summary": self._get_health_summary()
        }
    
    def _get_connections_by_user(self) -> Dict[str, int]:
        """Get connection count by user."""
        user_counts = {}
        for conn in self.connections.values():
            user_id = conn["user_id"]
            user_counts[user_id] = user_counts.get(user_id, 0) + 1
        return user_counts
    
    def _get_health_summary(self) -> Dict[str, Any]:
        """Get health summary of all connections."""
        healthy_count = 0
        stale_count = 0
        
        for connection_id in self.connections:
            health = self.get_connection_health(connection_id)
            if health.get("is_connected") and not health.get("is_stale"):
                healthy_count += 1
            elif health.get("is_stale"):
                stale_count += 1
        
        return {
            "healthy_connections": healthy_count,
            "stale_connections": stale_count,
            "total_monitored": len(self.connections)
        }
    
    async def _check_performance_thresholds(self) -> None:
        """Run all performance threshold checks."""
        check_methods = [
            self._check_response_time_threshold,
            self._check_memory_threshold,
            self._check_error_rate_threshold,
            self._check_throughput_threshold,
            self._check_cpu_threshold
        ]
        
        check_names = [
            "response_time",
            "memory",
            "error_rate", 
            "throughput",
            "cpu"
        ]
        
        # Run checks concurrently and collect results
        tasks = []
        for check_method in check_methods:
            tasks.append(asyncio.create_task(self._run_check_safely(check_method)))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Handle results
        await self._handle_check_results(check_names, results)
    
    async def _run_check_safely(self, check_method) -> Any:
        """Run a check method safely, catching exceptions."""
        try:
            if asyncio.iscoroutinefunction(check_method):
                return await check_method()
            else:
                return check_method()
        except Exception as e:
            return e
    
    async def _handle_check_results(self, check_names, results):
        """Handle the results of performance checks."""
        for check_name, result in zip(check_names, results):
            self.monitoring_coverage["total_checks"] += 1
            
            if isinstance(result, Exception):
                self.monitoring_coverage["failed_checks"] += 1
                await self._handle_check_failure(check_name, result)
            else:
                self.monitoring_coverage["successful_checks"] += 1
                self._record_check_success(check_name)
    
    def _record_check_success(self, check_name: str) -> None:
        """Record a successful check."""
        self.monitoring_coverage["check_results"].append({
            "timestamp": get_current_iso_timestamp(),
            "check_name": check_name,
            "success": True,
            "error": None
        })
    
    async def _handle_check_failure(self, check_name: str, error: Exception) -> None:
        """Handle a failed check."""
        self.monitoring_coverage["check_results"].append({
            "timestamp": get_current_iso_timestamp(),
            "check_name": check_name,
            "success": False,
            "error": str(error)
        })
    
    def _get_monitoring_coverage_summary(self) -> Dict[str, Any]:
        """Get monitoring coverage summary."""
        total = self.monitoring_coverage["total_checks"]
        successful = self.monitoring_coverage["successful_checks"]
        
        coverage_percentage = (successful / total * 100) if total > 0 else 0.0
        
        return {
            "coverage_percentage": coverage_percentage,
            "recent_failures": self._count_recent_failures()
        }
    
    def _count_recent_failures(self) -> int:
        """Count recent failures within 5 minutes."""
        from datetime import datetime, timezone, timedelta
        
        cutoff_time = datetime.now(timezone.utc) - timedelta(minutes=5)
        recent_failures = 0
        
        for result in self.monitoring_coverage["check_results"]:
            if not result["success"]:
                result_time = datetime.fromisoformat(result["timestamp"].replace("Z", "+00:00"))
                if result_time > cutoff_time:
                    recent_failures += 1
                    
        return recent_failures
    
    def get_current_performance_summary(self) -> Dict[str, Any]:
        """Get current performance summary including monitoring coverage."""
        return {
            **self.get_global_stats(),
            "monitoring_coverage": self._get_monitoring_coverage_summary()
        }
    
    def reset_metrics(self) -> None:
        """Reset all monitoring metrics."""
        self.monitoring_coverage = {
            "total_checks": 0,
            "successful_checks": 0,
            "failed_checks": 0,
            "check_results": []
        }
    
    # Stub implementations of performance check methods
    async def _check_response_time_threshold(self) -> None:
        """Check response time threshold."""
        pass
    
    async def _check_memory_threshold(self) -> None:
        """Check memory threshold.""" 
        pass
    
    async def _check_error_rate_threshold(self) -> None:
        """Check error rate threshold."""
        pass
    
    async def _check_throughput_threshold(self) -> None:
        """Check throughput threshold."""
        pass
    
    async def _check_cpu_threshold(self) -> None:
        """Check CPU threshold."""
        pass


# Utility functions for message processing

def parse_websocket_message(raw_data: Union[str, bytes]) -> Optional[Dict[str, Any]]:
    """Parse raw WebSocket message data."""
    try:
        if isinstance(raw_data, bytes):
            raw_data = raw_data.decode('utf-8')
        
        return json.loads(raw_data)
    except (json.JSONDecodeError, UnicodeDecodeError) as e:
        logger.error(f"Failed to parse WebSocket message: {e}")
        return None


def validate_message_structure(message: Dict[str, Any]) -> bool:
    """Validate basic message structure."""
    required_fields = ["type"]
    
    if not isinstance(message, dict):
        return False
    
    for field in required_fields:
        if field not in message:
            return False
    
    return True


def extract_user_info_from_message(message: Dict[str, Any]) -> Optional[Dict[str, str]]:
    """Extract user information from message with type validation.
    
    Args:
        message: Message dictionary to extract info from
        
    Returns:
        Dictionary with validated user info or None if no info found
    """
    user_info = {}
    
    if "user_id" in message:
        try:
            # Validate user_id if present
            validated_user_id = ensure_user_id(message["user_id"])
            user_info["user_id"] = validated_user_id
        except ValueError as e:
            logger.warning(f"Invalid user_id in message: {message['user_id']}: {e}")
            return None
    
    if "thread_id" in message:
        user_info["thread_id"] = str(message["thread_id"])
    
    return user_info if user_info else None


async def broadcast_to_websockets(websockets: List[WebSocket], 
                                message: Union[Dict[str, Any], str],
                                exclude_websockets: Optional[List[WebSocket]] = None) -> int:
    """Broadcast message to multiple WebSockets."""
    exclude_websockets = exclude_websockets or []
    successful_sends = 0
    
    # Filter out excluded WebSockets
    target_websockets = [ws for ws in websockets if ws not in exclude_websockets]
    
    # Send to all targets concurrently
    send_tasks = []
    for websocket in target_websockets:
        if is_websocket_connected(websocket):
            task = safe_websocket_send(websocket, message)
            send_tasks.append(task)
    
    if send_tasks:
        results = await asyncio.gather(*send_tasks, return_exceptions=True)
        successful_sends = sum(1 for result in results if result is True)
    
    return successful_sends


def format_websocket_error_response(error_code: str, error_message: str,
                                  request_id: Optional[str] = None) -> Dict[str, Any]:
    """Format standardized WebSocket error response."""
    error_response = {
        "type": "error",
        "error": {
            "code": error_code,
            "message": error_message,
            "timestamp": time.time()
        }
    }
    
    if request_id:
        error_response["request_id"] = request_id
    
    return error_response


def create_connection_info(connection_id: Union[str, ConnectionID], user_id: Union[str, UserID],
                         thread_id: Optional[str] = None) -> ConnectionInfo:
    """Create connection info object with type safety.
    
    Args:
        connection_id: Connection ID (accepts both str and ConnectionID)
        user_id: User ID (accepts both str and UserID) 
        thread_id: Optional thread ID
        
    Returns:
        ConnectionInfo object with validated IDs
    """
    # Validate the typed IDs
    validated_user_id = ensure_user_id(user_id)
    validated_connection_id = str(connection_id) if connection_id else None
    
    return ConnectionInfo(
        connection_id=validated_connection_id,
        user_id=validated_user_id,
        thread_id=thread_id,
        connected_at=datetime.now(timezone.utc),
        last_activity=datetime.now(timezone.utc),
        message_count=0,
        is_healthy=True
    )


# Global utilities instances
_connection_monitor: Optional[WebSocketConnectionMonitor] = None

def get_connection_monitor() -> WebSocketConnectionMonitor:
    """Get global connection monitor."""
    global _connection_monitor
    if _connection_monitor is None:
        _connection_monitor = WebSocketConnectionMonitor()
    return _connection_monitor


@asynccontextmanager
async def websocket_message_queue_context(max_size: int = 1000) -> AsyncGenerator[WebSocketMessageQueue, None]:
    """Context manager for WebSocket message queue."""
    queue = WebSocketMessageQueue(max_size=max_size)
    try:
        yield queue
    finally:
        queue.clear()


@asynccontextmanager  
async def websocket_heartbeat_context(websocket: WebSocket, interval: float = 45.0) -> AsyncGenerator[WebSocketHeartbeat, None]:
    """Context manager for WebSocket heartbeat."""
    heartbeat = WebSocketHeartbeat(interval=interval)
    try:
        await heartbeat.start(websocket)
        yield heartbeat
    finally:
        await heartbeat.stop()


def check_rate_limit(client_id: Union[str, UserID], max_requests: int = 60, window_seconds: int = 60) -> bool:
    """
    Utility function for backward compatibility with rate limiting.
    
    This function creates a temporary RateLimiter instance to check rate limits.
    For production use, prefer using RateLimiter class directly from auth module.
    
    Args:
        client_id: Client/User ID (accepts both str and UserID)
        max_requests: Maximum requests allowed
        window_seconds: Time window for rate limiting
        
    Returns:
        True if request is allowed, False if rate limited
    """
    # Import here to avoid circular imports
    from netra_backend.app.websocket_core.rate_limiter import AdaptiveRateLimiter
    
    # Validate client_id
    try:
        validated_client_id = ensure_user_id(client_id) if isinstance(client_id, (str, UserID)) else str(client_id)
    except ValueError:
        logger.warning(f"Invalid client_id for rate limiting: {client_id}")
        return False
    
    # Create temporary rate limiter with specified limits
    rate_limiter = AdaptiveRateLimiter(base_rate=max_requests, window_seconds=window_seconds)
    allowed = rate_limiter.is_allowed(validated_client_id)
    return allowed


# Compression utility functions (stub implementations for backward compatibility)

def compress(data: Union[str, bytes]) -> bytes:
    """
    Stub compression function for backward compatibility.
    
    Currently returns data as-is (no compression).
    Can be extended with actual compression logic when needed.
    """
    if isinstance(data, str):
        return data.encode('utf-8')
    return data


def decompress(data: bytes) -> str:
    """
    Stub decompression function for backward compatibility.
    
    Currently returns data as-is (no decompression).
    Can be extended with actual decompression logic when needed.
    """
    if isinstance(data, bytes):
        return data.decode('utf-8')
    return data


# Race condition prevention utility functions

def create_race_condition_detector(environment: Optional[str] = None):
    """
    Create a RaceConditionDetector instance for WebSocket operations.
    
    Args:
        environment: Target environment, defaults to detected environment
    
    Returns:
        RaceConditionDetector instance or None if not available
    """
    try:
        from netra_backend.app.websocket_core.race_condition_prevention import RaceConditionDetector
        return RaceConditionDetector(environment=environment)
    except ImportError:
        logger.warning("Race condition prevention not available - using fallback mode")
        return None


def create_handshake_coordinator(environment: Optional[str] = None):
    """
    Create a HandshakeCoordinator instance for WebSocket operations.
    
    Args:
        environment: Target environment, defaults to detected environment
    
    Returns:
        HandshakeCoordinator instance or None if not available
    """
    try:
        from netra_backend.app.websocket_core.race_condition_prevention import HandshakeCoordinator
        return HandshakeCoordinator(environment=environment)
    except ImportError:
        logger.warning("Handshake coordination not available - using fallback mode")
        return None


async def validate_connection_with_race_detection(websocket: WebSocket, connection_id: Optional[str] = None) -> bool:
    """
    Validate WebSocket connection with integrated race condition detection.
    
    This function combines traditional connection validation with race condition
    pattern detection and logging for comprehensive connection safety.
    
    Args:
        websocket: WebSocket connection to validate
        connection_id: Optional connection ID for tracking
    
    Returns:
        True if connection is ready and no race conditions detected
    """
    try:
        # Get environment for race condition detection
        from shared.isolated_environment import get_env_var
        environment = get_env_var("ENVIRONMENT", "development").lower()
        
        # Create race condition detector
        race_detector = create_race_condition_detector(environment)
        handshake_coordinator = create_handshake_coordinator(environment)
        
        # Basic connection validation
        is_connected = is_websocket_connected_and_ready(websocket, connection_id)
        
        if not is_connected and race_detector:
            race_detector.add_detected_pattern(
                "connection_validation_failed",
                "warning",
                details={
                    "connection_id": connection_id,
                    "environment": environment
                }
            )
        
        # If handshake coordinator is available, use it for additional validation
        if handshake_coordinator and is_connected:
            # For existing connections, we can't coordinate the handshake again
            # but we can validate the current state
            logger.debug("Connection passed basic validation and race condition checks")
            return True
        
        return is_connected
        
    except Exception as e:
        logger.error(f"Error during connection validation with race detection: {e}")
        return False


def log_race_condition_pattern(pattern_type: str, severity: str = "warning", 
                             details: Optional[Dict] = None, 
                             environment: Optional[str] = None):
    """
    Utility function to log race condition patterns from WebSocket utils.
    
    Args:
        pattern_type: Type of race condition pattern
        severity: Severity level (warning, critical, fatal)
        details: Additional context about the pattern
        environment: Environment where pattern occurred
    """
    try:
        race_detector = create_race_condition_detector(environment)
        if race_detector:
            race_detector.add_detected_pattern(pattern_type, severity, details)
        else:
            # Fallback logging if race detection not available
            logger.warning(f"Race condition pattern detected: {pattern_type} ({severity}) - {details}")
    except Exception as e:
        logger.error(f"Error logging race condition pattern: {e}")


def get_progressive_delay(attempt: int, environment: Optional[str] = None) -> float:
    """
    Get progressive delay for retry operations with race condition prevention.
    
    Args:
        attempt: Attempt number (0-based)
        environment: Target environment for timing calculation
    
    Returns:
        Delay in seconds appropriate for the environment and attempt
    """
    try:
        race_detector = create_race_condition_detector(environment)
        if race_detector:
            return race_detector.calculate_progressive_delay(attempt)
        else:
            # Fallback timing if race detection not available
            if environment in ["staging", "production"]:
                return 0.025 * (attempt + 1)  # 25ms, 50ms, 75ms
            elif environment == "testing":
                return 0.005  # 5ms for tests
            else:
                return 0.01  # 10ms for development
    except Exception as e:
        logger.error(f"Error calculating progressive delay: {e}")
        return 0.01  # Safe fallback


# Stub functions for backward compatibility with legacy tests
# These functions were previously imported from websocket routes but are no longer needed

def _get_rate_limit_for_environment(environment: Optional[str] = None) -> Dict[str, Any]:
    """
    Stub function for backward compatibility with legacy tests.
    
    Returns rate limiting configuration for the specified environment.
    This is a minimal implementation for test compatibility.
    """
    from shared.isolated_environment import get_env_var

    if environment is None:
        environment = get_env_var("ENVIRONMENT", "development").lower()
    
    # Return basic rate limiting configuration
    if environment in ["staging", "production"]:
        return {
            "max_requests_per_minute": 60,
            "max_concurrent_connections": 10,
            "rate_limit_window_seconds": 60
        }
    elif environment == "testing":
        return {
            "max_requests_per_minute": 1000,  # Higher for tests
            "max_concurrent_connections": 100,
            "rate_limit_window_seconds": 60
        }
    else:  # development
        return {
            "max_requests_per_minute": 120,
            "max_concurrent_connections": 20,
            "rate_limit_window_seconds": 60
        }


def _get_staging_optimized_timeouts(environment: Optional[str] = None) -> Dict[str, Any]:
    """
    Stub function for backward compatibility with legacy tests.
    
    Returns timeout configuration optimized for the specified environment.
    This is a minimal implementation for test compatibility.
    """
    from shared.isolated_environment import get_env_var

    if environment is None:
        environment = get_env_var("ENVIRONMENT", "development").lower()
    
    # Return environment-specific timeout configuration
    if environment == "staging":
        return {
            "connection_timeout_seconds": 300,  # 5 minutes
            "heartbeat_timeout_seconds": 90,
            "message_timeout_seconds": 60,
            "handshake_timeout_seconds": 30,
            "close_timeout_seconds": 10
        }
    elif environment == "production":
        return {
            "connection_timeout_seconds": 600,  # 10 minutes
            "heartbeat_timeout_seconds": 120,
            "message_timeout_seconds": 90,
            "handshake_timeout_seconds": 45,
            "close_timeout_seconds": 15
        }
    elif environment == "testing":
        return {
            "connection_timeout_seconds": 30,   # Shorter for tests
            "heartbeat_timeout_seconds": 10,
            "message_timeout_seconds": 5,
            "handshake_timeout_seconds": 2,
            "close_timeout_seconds": 1
        }
    else:  # development
        return {
            "connection_timeout_seconds": 120,  # 2 minutes
            "heartbeat_timeout_seconds": 45,
            "message_timeout_seconds": 30,
            "handshake_timeout_seconds": 10,
            "close_timeout_seconds": 5
        }


# Heartbeat timeout constant for backward compatibility
HEARTBEAT_TIMEOUT_SECONDS = 45  # Default heartbeat timeout


# WebSocket Manager Factory Function - Compatibility Wrapper
# PHASE 1 SSOT REMEDIATION - Resource Cleanup Utilities

def find_matching_resources(target_id: str, resource_pool: Dict[str, Any]) -> List[str]:
    """Find resources that match target ID for cleanup operations.
    
    PHASE 1 SSOT REMEDIATION: This function enables WebSocket resource cleanup
    to work correctly despite ID pattern mismatches by using pattern-agnostic
    matching instead of exact string equality.
    
    Args:
        target_id: ID to find matches for
        resource_pool: Dictionary of resource_id -> resource mappings
        
    Returns:
        List of resource IDs that match the target
    """
    if not target_id or not resource_pool:
        return []
    
    # Use migration bridge for pattern-agnostic matching
    bridge = get_migration_bridge()
    candidate_ids = list(resource_pool.keys())
    
    return bridge.find_matching_ids(target_id, candidate_ids)


def cleanup_resources_by_pattern(target_pattern: str, resource_pools: Dict[str, Dict[str, Any]], 
                                logger_context: Optional[str] = None) -> int:
    """Clean up resources matching a pattern across multiple resource pools.
    
    PHASE 1 SSOT REMEDIATION: This function enables comprehensive resource cleanup
    that works with both legacy and SSOT ID patterns.
    
    Args:
        target_pattern: Pattern to match (thread_id, run_id, etc.)
        resource_pools: Dict of pool_name -> {resource_id -> resource} mappings
        logger_context: Optional context for logging
        
    Returns:
        Number of resources cleaned up
    """
    cleaned_count = 0
    context_msg = f" [{logger_context}]" if logger_context else ""
    
    for pool_name, pool in resource_pools.items():
        if not pool:
            continue
        
        # Find matching resources in this pool
        matching_ids = find_matching_resources(target_pattern, pool)
        
        for resource_id in matching_ids:
            try:
                del pool[resource_id]
                cleaned_count += 1
                logger.debug(f"Cleaned up resource {resource_id} from {pool_name}{context_msg}")
            except Exception as e:
                logger.warning(f"Failed to clean up resource {resource_id} from {pool_name}{context_msg}: {e}")
    
    if cleaned_count > 0:
        logger.info(f"Pattern cleanup{context_msg}: removed {cleaned_count} resources matching {target_pattern}")
    
    return cleaned_count


def normalize_connection_id(connection_id: str, user_id: str) -> str:
    """Normalize connection ID to SSOT format for consistent resource management.
    
    PHASE 1 SSOT REMEDIATION: This function ensures connection IDs are in
    SSOT-compliant format to prevent cleanup mismatches.
    
    Args:
        connection_id: Connection ID to normalize
        user_id: User ID for context
        
    Returns:
        Normalized connection ID
    """
    try:
        # Use migration bridge for normalization
        bridge = get_migration_bridge()
        result = bridge.translate_id(connection_id)
        return result.translated_id
    except Exception as e:
        logger.warning(f"Failed to normalize connection ID {connection_id} for user {user_id}: {e}")
        return connection_id


def validate_resource_compatibility(resource_id: str, context_ids: List[str]) -> bool:
    """Validate that a resource is compatible with context IDs for cleanup.
    
    PHASE 1 SSOT REMEDIATION: This function prevents cleanup errors by
    validating ID compatibility before attempting resource operations.
    
    Args:
        resource_id: Resource ID to validate
        context_ids: List of context IDs (thread_id, run_id, etc.)
        
    Returns:
        True if resource is compatible with any context ID
    """
    if not resource_id or not context_ids:
        return False
    
    for context_id in context_ids:
        if validate_id_compatibility(resource_id, context_id):
            return True
    
    return False


def get_cleanup_priority(id_string: str) -> int:
    """Get cleanup priority for an ID based on its pattern.
    
    PHASE 1 SSOT REMEDIATION: This function helps prioritize cleanup operations
    to prevent resource conflicts during migration.
    
    Args:
        id_string: ID to assess
        
    Returns:
        Priority level (higher = more urgent)
    """
    try:
        bridge = get_migration_bridge()
        format_info, confidence = bridge.detect_id_format(id_string)
        
        # SSOT format gets highest priority
        if format_info.name == 'SSOT' and confidence > 0.9:
            return 100
        
        # Legacy formats get medium priority
        if 'LEGACY' in format_info.name:
            return 50
        
        # Unknown formats get low priority
        return 10
        
    except Exception as e:
        logger.debug(f"Error assessing cleanup priority for {id_string}: {e}")
        return 1  # Default low priority


async def create_websocket_manager(user_context=None, user_id=None):
    """
    Create WebSocket manager instance - Compatibility wrapper.
    
    COMPATIBILITY: This function provides backward compatibility for tests
    that import create_websocket_manager from utils. New code should use
    the function directly from websocket_manager_factory.
    
    Args:
        user_context: User execution context (optional)
        user_id: User ID for manager scoping (optional)
        
    Returns:
        WebSocketManager instance configured for the user context
    """
    from netra_backend.app.services.user_execution_context import create_defensive_user_execution_context as factory_create

    logger.debug(f"COMPATIBILITY: Creating WebSocket manager via utils.py wrapper (user_id: {user_id})")
    return await factory_create(user_context)