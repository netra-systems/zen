"""Modernized Query Builder with standardized execution patterns."""

import time
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional

from abc import ABC, abstractmethod
from netra_backend.app.agents.base.interface import (
    ExecutionContext,
)
from netra_backend.app.schemas.core_enums import ExecutionStatus
from netra_backend.app.schemas.agent_models import DeepAgentState, UserExecutionContextAdapter
from netra_backend.app.services.user_execution_context import UserExecutionContext

# Local result structure since ExecutionResult may not be available
@dataclass
class ExecutionResult:
    success: bool
    status: ExecutionStatus
    result: Optional[Any] = None
    error: Optional[str] = None  
    execution_time_ms: float = 0.0
from netra_backend.app.logging_config import central_logger as logger


@dataclass
class QueryExecutionRequest:
    """Request parameters for query execution."""
    query_type: str
    user_id: int
    parameters: Dict[str, Any]
    execution_timeout: float = 30.0


@dataclass 
class QueryExecutionMetrics:
    """Query execution performance metrics."""
    query_build_time_ms: float = 0.0
    query_validation_time_ms: float = 0.0
    total_execution_time_ms: float = 0.0
    query_complexity_score: int = 0


class QueryBuilder(ABC):
    """Build optimized ClickHouse queries with modern execution patterns."""
    
    # Marker to identify queries from this builder
    QUERY_SOURCE_MARKER = "/* Generated by Netra QueryBuilder */"
    
    def __init__(self, websocket_manager: Optional[Any] = None):
        """Initialize modernized query builder."""
        # Using single inheritance pattern for simplicity
        self.agent_name = "QueryBuilder"
        self.websocket_manager = websocket_manager
        self._init_query_registry()
        self._init_performance_tracking()
        
    def _init_query_registry(self) -> None:
        """Initialize query type registry for validation."""
        self.supported_query_types = {
            'performance_metrics', 'anomaly_detection', 
            'correlation_analysis', 'usage_patterns'
        }
        
    def _init_performance_tracking(self) -> None:
        """Initialize performance tracking components."""
        self.query_metrics = QueryExecutionMetrics()
        self.execution_history: List[Dict[str, Any]] = []
        
    async def execute_core_logic(self, context: ExecutionContext) -> Dict[str, Any]:
        """Execute query building with performance tracking."""
        start_time = time.time()
        request = self._extract_request_from_context(context)
        await self.send_status_update(context, "building", "Building optimized query")
        query = await self._build_query_with_tracking(request, context)
        execution_time_ms = (time.time() - start_time) * 1000
        return self._create_execution_result(query, request, execution_time_ms)
        
    async def validate_preconditions(self, context: ExecutionContext) -> bool:
        """Validate query execution preconditions."""
        try:
            request = self._extract_request_from_context(context)
            return self._validate_query_request(request)
        except Exception as e:
            logger.error(f"Precondition validation failed: {e}")
            return False
            
    def _extract_request_from_context(self, context: ExecutionContext) -> QueryExecutionRequest:
        """Extract query request from execution context."""
        state_dict = context.metadata.get('request', {})
        return QueryExecutionRequest(
            query_type=state_dict.get('query_type', 'performance_metrics'),
            user_id=int(state_dict.get('user_id', context.user_id or 0)),
            parameters=state_dict.get('parameters', {}),
            execution_timeout=state_dict.get('timeout', 30.0)
        )
        
    def _validate_query_request(self, request: QueryExecutionRequest) -> bool:
        """Validate query request parameters."""
        if request.query_type not in self.supported_query_types:
            return False
        return request.user_id > 0 and request.parameters is not None
        
    async def _build_query_with_tracking(self, request: QueryExecutionRequest, 
                                       context: ExecutionContext) -> str:
        """Build query with performance tracking."""
        build_start = time.time()
        query = self._route_query_building(request)
        self.query_metrics.query_build_time_ms = (time.time() - build_start) * 1000
        await self.send_status_update(context, "built", f"Query built for {request.query_type}")
        return query
        
    def _route_query_building(self, request: QueryExecutionRequest) -> str:
        """Route to appropriate query building method."""
        params = request.parameters
        if request.query_type == 'performance_metrics':
            return self._build_performance_query(request.user_id, params)
        elif request.query_type == 'anomaly_detection':
            return self._build_anomaly_query(request.user_id, params)
        elif request.query_type == 'correlation_analysis':
            return self._build_correlation_query(request.user_id, params)
        elif request.query_type == 'usage_patterns':
            return self._build_usage_query(request.user_id, params)
        else:
            raise ValueError(f"Unsupported query type: {request.query_type}")
            
    def _create_execution_result(self, query: str, request: QueryExecutionRequest,
                               execution_time_ms: float) -> Dict[str, Any]:
        """Create standardized execution result."""
        self._update_execution_history(request, execution_time_ms)
        return {
            'query': query,
            'query_type': request.query_type,
            'user_id': request.user_id,
            'execution_time_ms': execution_time_ms,
            'complexity_score': self._calculate_complexity_score(query),
            'build_metrics': self.query_metrics.__dict__
        }
        
    def _update_execution_history(self, request: QueryExecutionRequest,
                                execution_time_ms: float) -> None:
        """Update query execution history."""
        history_entry = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'query_type': request.query_type,
            'user_id': request.user_id,
            'execution_time_ms': execution_time_ms
        }
        self.execution_history.append(history_entry)
        self._trim_execution_history()
        
    def _trim_execution_history(self) -> None:
        """Trim execution history to last 100 entries."""
        if len(self.execution_history) > 100:
            self.execution_history = self.execution_history[-100:]
            
    def _calculate_complexity_score(self, query: str) -> int:
        """Calculate query complexity score for performance tracking."""
        score = 0
        complexity_indicators = ['WITH', 'GROUP BY', 'ORDER BY', 'LIMIT', 'JOIN']
        for indicator in complexity_indicators:
            score += query.upper().count(indicator)
        return min(score, 10)  # Cap at 10
        
    def _build_performance_query(self, user_id: int, params: Dict[str, Any]) -> str:
        """Build performance metrics query from parameters."""
        # Create a simple default query for now since data_sub_agent was removed
        return f"""
        {self.QUERY_SOURCE_MARKER}
        SELECT 
            toStartOfMinute(timestamp) as time_bucket,
            avg(latency_ms) as avg_latency,
            count() as request_count
        FROM metrics_table 
        WHERE user_id = {user_id}
        AND timestamp >= now() - INTERVAL 1 HOUR
        GROUP BY time_bucket
        ORDER BY time_bucket
        """
        
    def _build_anomaly_query(self, user_id: int, params: Dict[str, Any]) -> str:
        """Build anomaly detection query from parameters."""
        metric_name = params.get('metric_name', 'latency_ms')
        threshold = params.get('z_score_threshold', 2.0)
        return f"""
        {self.QUERY_SOURCE_MARKER}
        WITH stats AS (
            SELECT 
                avg({metric_name}) as mean_val,
                stddevPop({metric_name}) as std_val
            FROM metrics_table
            WHERE user_id = {user_id}
            AND timestamp >= now() - INTERVAL 24 HOUR
        )
        SELECT 
            timestamp,
            {metric_name},
            abs({metric_name} - stats.mean_val) / stats.std_val as z_score
        FROM metrics_table, stats
        WHERE user_id = {user_id}
        AND abs({metric_name} - stats.mean_val) / stats.std_val > {threshold}
        ORDER BY timestamp DESC
        """
        
    def _build_correlation_query(self, user_id: int, params: Dict[str, Any]) -> str:
        """Build correlation analysis query from parameters."""
        metric1 = params.get('metric1', 'latency_ms')
        metric2 = params.get('metric2', 'throughput')
        return f"""
        {self.QUERY_SOURCE_MARKER}
        SELECT 
            corr({metric1}, {metric2}) as correlation_coefficient,
            count() as sample_size
        FROM metrics_table
        WHERE user_id = {user_id}
        AND timestamp >= now() - INTERVAL 24 HOUR
        """
        
    def _build_usage_query(self, user_id: int, params: Dict[str, Any]) -> str:
        """Build usage patterns query from parameters."""
        days_back = params.get('days_back', 30)
        return f"""
        {self.QUERY_SOURCE_MARKER}
        SELECT 
            toDate(timestamp) as date,
            count() as daily_requests,
            uniq(session_id) as unique_sessions
        FROM metrics_table
        WHERE user_id = {user_id}
        AND timestamp >= now() - INTERVAL {days_back} DAY
        GROUP BY date
        ORDER BY date
        """
        
    async def execute_with_reliability(self, request: QueryExecutionRequest) -> ExecutionResult:
        """Execute query building with reliability patterns and proper user isolation.
        
        PHASE 1 MIGRATION: Now uses UserExecutionContext for enhanced user isolation
        and database session management, preventing cross-user data contamination.
        """
        # PHASE 1 MIGRATION: Create UserExecutionContext for proper isolation
        try:
            # Generate secure IDs for this execution
            from shared.id_generation.unified_id_generator import UnifiedIdGenerator
            
            user_context = UserExecutionContext(
                user_id=str(request.user_id),
                thread_id=UnifiedIdGenerator.generate_base_id("query_thread"),
                run_id=f"query_{int(time.time() * 1000)}",
                agent_context={
                    'operation_name': 'query_building',
                    'query_type': request.query_type,
                    'parameters': request.parameters,
                    'execution_timeout': request.execution_timeout
                },
                audit_metadata={
                    'component': 'QueryBuilder',
                    'request_params': request.__dict__,
                    'migration_phase': 'phase_1'
                }
            )
            
            # Create backward compatible ExecutionContext using adapter
            deep_state = UserExecutionContextAdapter.create_deep_state_from_user_context(user_context)
            
            context = ExecutionContext(
                run_id=user_context.run_id,
                agent_name=self.agent_name,
                state=deep_state,
                user_id=user_context.user_id,
                metadata={'request': request.__dict__, 'user_context': user_context}
            )
            
        except Exception as e:
            logger.error(f"Failed to create secure execution context: {e}")
            # Fallback to legacy pattern for Phase 1 compatibility
            context = ExecutionContext(
                run_id=f"query_{int(time.time() * 1000)}",
                agent_name=self.agent_name,
                state=DeepAgentState(),
                user_id=str(request.user_id),
                metadata={'request': request.__dict__}
            )
        
        try:
            if not await self.validate_preconditions(context):
                return ExecutionResult(
                    success=False,
                    status=ExecutionStatus.FAILED,
                    error="Precondition validation failed"
                )
                
            result_data = await self.execute_core_logic(context)
            return ExecutionResult(
                success=True,
                status=ExecutionStatus.COMPLETED,
                result=result_data,
                execution_time_ms=result_data.get('execution_time_ms', 0)
            )
            
        except Exception as e:
            logger.error(f"Query execution failed: {e}")
            return ExecutionResult(
                success=False,
                status=ExecutionStatus.FAILED,
                error=str(e)
            )
    
    @staticmethod
    def build_performance_metrics_query(
        user_id: int,
        workload_id: Optional[str],
        start_time: datetime,
        end_time: datetime,
        aggregation_level: str = "minute"
    ) -> str:
        """Build query for performance metrics - backward compatibility."""
        # Simplified version since original query_operations is not available
        time_format = "toStartOfMinute" if aggregation_level == "minute" else "toStartOfHour"
        workload_filter = f"AND workload_id = '{workload_id}'" if workload_id else ""
        
        return f"""
        /* Generated by Netra QueryBuilder */
        SELECT 
            {time_format}(timestamp) as time_bucket,
            avg(latency_ms) as avg_latency,
            count() as request_count,
            max(latency_ms) as max_latency
        FROM metrics_table 
        WHERE user_id = {user_id}
        AND timestamp >= '{start_time.isoformat()}'
        AND timestamp <= '{end_time.isoformat()}'
        {workload_filter}
        GROUP BY time_bucket
        ORDER BY time_bucket
        """
    
    @staticmethod
    def build_anomaly_detection_query(
        user_id: int,
        metric_name: str,
        start_time: datetime,
        end_time: datetime,
        z_score_threshold: float = 2.0
    ) -> str:
        """Build query for anomaly detection - backward compatibility."""
        return f"""
        /* Generated by Netra QueryBuilder */
        WITH stats AS (
            SELECT 
                avg({metric_name}) as mean_val,
                stddevPop({metric_name}) as std_val
            FROM metrics_table
            WHERE user_id = {user_id}
            AND timestamp >= '{start_time.isoformat()}'
            AND timestamp <= '{end_time.isoformat()}'
        )
        SELECT 
            timestamp,
            {metric_name},
            abs({metric_name} - stats.mean_val) / stats.std_val as z_score
        FROM metrics_table, stats
        WHERE user_id = {user_id}
        AND timestamp >= '{start_time.isoformat()}'
        AND timestamp <= '{end_time.isoformat()}'
        AND abs({metric_name} - stats.mean_val) / stats.std_val > {z_score_threshold}
        ORDER BY timestamp DESC
        """
    
    @staticmethod
    def build_correlation_analysis_query(
        user_id: int,
        metric1: str,
        metric2: str,
        start_time: datetime,
        end_time: datetime
    ) -> str:
        """Build query for correlation analysis - backward compatibility."""
        return f"""
        /* Generated by Netra QueryBuilder */
        SELECT 
            corr({metric1}, {metric2}) as correlation_coefficient,
            count() as sample_size,
            avg({metric1}) as avg_{metric1},
            avg({metric2}) as avg_{metric2}
        FROM metrics_table
        WHERE user_id = {user_id}
        AND timestamp >= '{start_time.isoformat()}'
        AND timestamp <= '{end_time.isoformat()}'
        """
    
    @staticmethod
    def build_usage_patterns_query(
        user_id: int,
        days_back: int = 30
    ) -> str:
        """Build query for usage pattern analysis - backward compatibility."""
        return f"""
        /* Generated by Netra QueryBuilder */
        SELECT 
            toDate(timestamp) as date,
            count() as daily_requests,
            uniq(session_id) as unique_sessions,
            avg(latency_ms) as avg_latency
        FROM metrics_table
        WHERE user_id = {user_id}
        AND timestamp >= now() - INTERVAL {days_back} DAY
        GROUP BY date
        ORDER BY date
        """
        
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Get query builder performance metrics."""
        recent_executions = self.execution_history[-10:] if self.execution_history else []
        avg_execution_time = sum(e.get('execution_time_ms', 0) for e in recent_executions) / max(len(recent_executions), 1)
        return {
            'total_queries_built': len(self.execution_history),
            'average_build_time_ms': avg_execution_time,
            'supported_query_types': list(self.supported_query_types),
            'recent_executions_count': len(recent_executions),
            'current_metrics': self.query_metrics.__dict__
        }
        
    def get_health_status(self) -> Dict[str, Any]:
        """Get health status for monitoring."""
        performance = self.get_performance_metrics()
        return {
            'status': 'healthy' if performance['total_queries_built'] >= 0 else 'unknown',
            'uptime_queries': performance['total_queries_built'],
            'avg_performance_ms': performance['average_build_time_ms'],
            'last_updated': datetime.now(timezone.utc).isoformat()
        }

    async def send_status_update(self, context: ExecutionContext, status: str, message: str) -> None:
        """Send status update via WebSocket if available."""
        # Placeholder for WebSocket status updates
        logger.info(f"QueryBuilder {status}: {message}")