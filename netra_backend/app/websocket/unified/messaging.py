"""Unified WebSocket Messaging - Message processing, validation, and sending.

Consolidates all message handling into a unified system with:
- Zero-loss message queuing with retry logic
- Comprehensive message validation and sanitization  
- Rate limiting with graceful degradation
- Real-time message tracking and telemetry
- Agent and tool communication support

Business Value: Ensures reliable message delivery for superior UX
All functions â‰¤8 lines as per CLAUDE.md requirements.
"""

import asyncio
import time
from typing import Any, Dict, List, Literal, Optional, Union

from fastapi import WebSocket

from netra_backend.app.logging_config import central_logger
from netra_backend.app.schemas.registry import WebSocketMessage
from netra_backend.app.schemas.websocket_message_types import ServerMessage
from netra_backend.app.websocket.connection import ConnectionInfo
from netra_backend.app.websocket.large_message_handler import (
    CompressionAlgorithm,
    get_large_message_handler,
)

from netra_backend.app.websocket.unified.message_handlers import MessageBuilder, MessageHandler, MessageProcessor
from netra_backend.app.websocket.unified.message_queue import MessageQueue

logger = central_logger.get_logger(__name__)


class UnifiedMessagingManager:
    """Unified messaging manager with zero-loss guarantee."""
    
    def __init__(self, manager) -> None:
        """Initialize with reference to unified manager."""
        self.manager = manager
        self.user_queues: Dict[str, MessageQueue] = {}
        self._queue_processor_started = False
        self._init_message_components()
    
    def _init_message_components(self) -> None:
        """Initialize message handling components."""
        self.message_handler = MessageHandler(self.manager)
        self.message_processor = MessageProcessor(self.manager, self.message_handler)
        self.message_builder = MessageBuilder()
        self.large_message_handler = get_large_message_handler()
    
    def _ensure_queue_processor_started(self) -> None:
        """Lazily start queue processor when first needed."""
        if not self._queue_processor_started:
            try:
                asyncio.create_task(self._process_queues_continuously())
                self._queue_processor_started = True
            except RuntimeError:
                # No event loop running yet, will start later
                pass

    async def _process_queues_continuously(self) -> None:
        """Continuously process message queues for reliable delivery."""
        while True:
            await self._process_all_user_queues()
            await asyncio.sleep(0.1)  # 100ms processing interval

    async def _process_all_user_queues(self) -> None:
        """Process queues for all users."""
        for user_id, queue in list(self.user_queues.items()):
            await self._process_user_queue(user_id, queue)

    async def _process_user_queue(self, user_id: str, queue: MessageQueue) -> None:
        """Process messages in user's queue."""
        message = queue.get_next_message()
        if message:
            success = await self._attempt_direct_send(user_id, message)
            if not success:
                queue.add_failed_message(message)

    def _get_or_create_user_queue(self, user_id: str) -> MessageQueue:
        """Get or create message queue for user."""
        if user_id not in self.user_queues:
            self.user_queues[user_id] = MessageQueue(user_id, max_size=1000)
        return self.user_queues[user_id]

    async def send_to_user(self, user_id: str, 
                          message: Union[WebSocketMessage, ServerMessage, Dict[str, Any]], 
                          retry: bool = True,
                          compression: CompressionAlgorithm = CompressionAlgorithm.NONE) -> bool:
        """Send message to user with zero-loss guarantee and transactional patterns."""
        self._ensure_queue_processor_started()
        validated_message = self.message_handler.prepare_and_validate_message(message)
        if not validated_message:
            return False
        
        # Implement transactional pattern as per websocket_reliability.xml
        return await self._send_with_transactional_guarantee(user_id, validated_message, retry, compression)

    async def _send_with_transactional_guarantee(self, user_id: str, message: Dict[str, Any], 
                                               retry: bool, compression: CompressionAlgorithm) -> bool:
        """Send message with transactional guarantee following websocket_reliability.xml patterns."""
        # Step 1: Mark message as 'sending' in-place (NEVER remove from queue before confirmation)
        message_id = f"tx_{user_id}_{int(time.time() * 1000000)}"
        queue = self._get_or_create_user_queue(user_id)
        
        try:
            # Step 2: Mark as sending and attempt transmission
            queue.mark_message_sending(message_id, message)
            
            # Step 3: Attempt send operation with retry logic
            success = await self._send_with_large_message_support(user_id, message, retry, compression)
            
            if success:
                # Step 4: Only remove on confirmed success
                queue.confirm_message_sent(message_id)
                return True
            else:
                # Step 5: Revert to 'pending' on failure (transactional pattern)
                queue.revert_to_pending(message_id)
                return False
                
        except Exception as e:
            # Step 5: Revert to 'pending' on exception (transactional pattern)
            queue.revert_to_pending(message_id)
            logger.error(f"Transactional send failed for user {user_id}: {e}")
            if retry:
                # Add to retry queue for later processing
                queue.add_failed_message(message)
            raise

    async def _send_with_large_message_support(self, user_id: str, message: Dict[str, Any], 
                                             retry: bool, compression: CompressionAlgorithm) -> bool:
        """Send message with large message and compression support."""
        try:
            # Prepare message for transmission (handles chunking and compression)
            prepared_messages = await self.large_message_handler.prepare_message(
                message, compression=compression
            )
            
            # Send all prepared messages
            all_sent = True
            for prepared_msg in prepared_messages:
                sent = await self._send_with_queue_fallback(user_id, prepared_msg, retry)
                if not sent:
                    all_sent = False
            
            return all_sent
            
        except Exception as e:
            logger.error(f"Error in large message handling: {e}")
            # Fall back to standard send
            return await self._send_with_queue_fallback(user_id, message, retry)

    async def _send_with_queue_fallback(self, user_id: str, message: Dict[str, Any], retry: bool) -> bool:
        """Send message with queue fallback for zero-loss delivery."""
        direct_success = await self._attempt_direct_send(user_id, message)
        if direct_success:
            self.message_processor.update_send_stats(True)
            return True
        if retry:
            self._queue_message_for_retry(user_id, message)
        self.message_processor.update_send_stats(False)
        return False

    async def _attempt_direct_send(self, user_id: str, message: Dict[str, Any]) -> bool:
        """Attempt direct message delivery to user connections."""
        connections = self.manager.connection_manager.get_user_connections(user_id)
        if not connections:
            return False
        return await self._send_to_all_user_connections(connections, message)

    async def _send_to_all_user_connections(self, connections: List[ConnectionInfo], message: Dict[str, Any]) -> bool:
        """Send message to all user connections."""
        success_count = 0
        for conn_info in connections:
            if await self.message_handler.send_to_single_connection(conn_info, message):
                success_count += 1
        return success_count > 0

    def _queue_message_for_retry(self, user_id: str, message: Dict[str, Any]) -> None:
        """Queue message for retry delivery."""
        if user_id not in self.user_queues:
            self.user_queues[user_id] = MessageQueue()
        self.user_queues[user_id].add_message(message)

    async def handle_incoming_message(self, user_id: str, websocket: WebSocket, 
                                    message: Dict[str, Any]) -> bool:
        """Handle incoming WebSocket message with large message support and rate limiting."""
        conn_info = await self.manager.connection_manager.find_connection(user_id, websocket)
        if not conn_info:
            logger.warning(f"Connection not found for user {user_id}")
            return False
        
        # Check if this is a large message
        message_type = message.get("message_type")
        if message_type:
            # Process large message
            processed_message = await self.large_message_handler.process_incoming_message(message)
            if processed_message is None:
                # Message incomplete (chunking in progress)
                return True
            
            # Send progress updates for chunked messages
            if isinstance(processed_message, dict) and processed_message.get("message_type") == "upload_progress":
                await self.send_to_user(user_id, processed_message, retry=False)
                return True
            
            # Continue processing the assembled message
            message = processed_message if isinstance(processed_message, dict) else {"data": processed_message}
        
        # Handle state synchronization messages
        msg_type = message.get("type", "")
        state_sync_types = {
            "get_current_state", "state_update", "partial_state_update", "client_state_update"
        }
        
        if msg_type in state_sync_types:
            connection_id = conn_info.connection_id
            return await self.message_handler.handle_state_sync_message(
                user_id, connection_id, websocket, message
            )
        
        return await self.message_processor.process_with_rate_limiting(conn_info, message)

    # Agent and tool communication methods
    async def send_error_message(self, user_id: str, error_message: str, 
                               sub_agent_name: str = "System") -> bool:
        """Send error message to user."""
        error_msg = self.message_builder.create_error_message(error_message, sub_agent_name)
        return await self.send_to_user(user_id, error_msg)

    async def send_agent_log(self, user_id: str, log_level: Literal["debug", "info", "warning", "error", "critical"], 
                           message: str, sub_agent_name: Optional[str] = None) -> None:
        """Send agent log message for real-time monitoring."""
        log_msg = self.message_builder.create_agent_log_message(log_level, message, sub_agent_name)
        await self.send_to_user(user_id, log_msg)

    async def send_tool_call(self, user_id: str, tool_name: str, tool_args: Dict[str, Any], 
                           sub_agent_name: Optional[str] = None) -> None:
        """Send tool call update message."""
        tool_msg = self.message_builder.create_tool_call_message(tool_name, tool_args, sub_agent_name)
        await self.send_to_user(user_id, tool_msg)

    async def send_tool_result(self, user_id: str, tool_name: str, 
                             result: Union[str, Dict[str, Any], List[Any]], 
                             sub_agent_name: Optional[str] = None) -> None:
        """Send tool result update message."""
        result_msg = self.message_builder.create_tool_result_message(tool_name, result, sub_agent_name)
        await self.send_to_user(user_id, result_msg)

    async def send_sub_agent_update(self, user_id: str, sub_agent_name: str, state: Dict[str, Any]) -> None:
        """Send sub-agent status update message."""
        update_msg = self.message_builder.create_sub_agent_update_message(sub_agent_name, state)
        await self.send_to_user(user_id, update_msg)

    # Large message convenience methods
    async def send_large_message(self, user_id: str, message: Union[Dict[str, Any], bytes],
                                compression: CompressionAlgorithm = CompressionAlgorithm.GZIP) -> bool:
        """Send large message with automatic compression."""
        return await self.send_to_user(user_id, message, retry=True, compression=compression)
    
    async def send_binary_data(self, user_id: str, data: bytes, 
                              compression: CompressionAlgorithm = CompressionAlgorithm.LZ4) -> bool:
        """Send binary data with optimal compression."""
        return await self.send_to_user(user_id, data, retry=True, compression=compression)
    
    def negotiate_compression(self, client_algorithms: List[str]) -> CompressionAlgorithm:
        """Negotiate compression algorithm with client."""
        return self.large_message_handler.negotiate_compression(client_algorithms)

    def get_messaging_stats(self) -> Dict[str, Any]:
        """Get comprehensive messaging statistics."""
        queue_stats = self._get_all_queue_stats()
        compression_stats = self.large_message_handler.get_compression_stats()
        assembly_stats = self.large_message_handler.get_assembly_stats()
        
        return {
            "message_stats": self.message_processor.get_stats(),
            "queue_stats": queue_stats,
            "compression_stats": compression_stats,
            "assembly_stats": assembly_stats,
            "active_users": len(self.user_queues)
        }

    def _get_all_queue_stats(self) -> Dict[str, Any]:
        """Get statistics for all user queues."""
        total_stats = {"total_queued": 0, "total_failed": 0, "users_with_queues": 0}
        for user_id, queue in self.user_queues.items():
            stats = queue.get_stats()
            total_stats["total_queued"] += stats["total_queued"]
            total_stats["total_failed"] += stats["failed_queue_size"]
            if stats["total_queued"] > 0:
                total_stats["users_with_queues"] += 1
        return total_stats


# Re-export classes for backward compatibility
from netra_backend.app.websocket.unified.message_handlers import MessageBuilder, MessageHandler, MessageProcessor
from netra_backend.app.websocket.unified.message_queue import MessageQueue

__all__ = [
    "UnifiedMessagingManager", "MessageQueue", "MessageHandler", 
    "MessageBuilder", "MessageProcessor"
]