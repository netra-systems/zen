"""Modernized Query Builder with standardized execution patterns."""

import time
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional

from abc import ABC, abstractmethod
from netra_backend.app.agents.base.interface import (
    ExecutionContext,
    ExecutionResult,
    WebSocketManagerProtocol,
)
from netra_backend.app.schemas.core_enums import ExecutionStatus
from netra_backend.app.agents.state import DeepAgentState
from netra_backend.app.logging_config import central_logger as logger


@dataclass
class QueryExecutionRequest:
    """Request parameters for query execution."""
    query_type: str
    user_id: int
    parameters: Dict[str, Any]
    execution_timeout: float = 30.0


@dataclass 
class QueryExecutionMetrics:
    """Query execution performance metrics."""
    query_build_time_ms: float = 0.0
    query_validation_time_ms: float = 0.0
    total_execution_time_ms: float = 0.0
    query_complexity_score: int = 0


class QueryBuilder(ABC):
    """Build optimized ClickHouse queries with modern execution patterns."""
    
    # Marker to identify queries from this builder
    QUERY_SOURCE_MARKER = "/* Generated by Netra QueryBuilder */"
    
    def __init__(self, websocket_manager: Optional[WebSocketManagerProtocol] = None):
        """Initialize modernized query builder."""
        # Using single inheritance pattern for simplicity
        self.agent_name = "QueryBuilder"
        self._init_query_registry()
        self._init_performance_tracking()
        
    def _init_query_registry(self) -> None:
        """Initialize query type registry for validation."""
        self.supported_query_types = {
            'performance_metrics', 'anomaly_detection', 
            'correlation_analysis', 'usage_patterns'
        }
        
    def _init_performance_tracking(self) -> None:
        """Initialize performance tracking components."""
        self.query_metrics = QueryExecutionMetrics()
        self.execution_history: List[Dict[str, Any]] = []
        
    async def execute_core_logic(self, context: ExecutionContext) -> Dict[str, Any]:
        """Execute query building with performance tracking."""
        start_time = time.time()
        request = self._extract_request_from_context(context)
        await self.send_status_update(context, "building", "Building optimized query")
        query = await self._build_query_with_tracking(request, context)
        execution_time_ms = (time.time() - start_time) * 1000
        return self._create_execution_result(query, request, execution_time_ms)
        
    async def validate_preconditions(self, context: ExecutionContext) -> bool:
        """Validate query execution preconditions."""
        try:
            request = self._extract_request_from_context(context)
            return self._validate_query_request(request)
        except Exception as e:
            logger.error(f"Precondition validation failed: {e}")
            return False
            
    def _extract_request_from_context(self, context: ExecutionContext) -> QueryExecutionRequest:
        """Extract query request from execution context."""
        state_dict = context.metadata.get('request', {})
        return QueryExecutionRequest(
            query_type=state_dict.get('query_type', 'performance_metrics'),
            user_id=int(state_dict.get('user_id', context.user_id or 0)),
            parameters=state_dict.get('parameters', {}),
            execution_timeout=state_dict.get('timeout', 30.0)
        )
        
    def _validate_query_request(self, request: QueryExecutionRequest) -> bool:
        """Validate query request parameters."""
        if request.query_type not in self.supported_query_types:
            return False
        return request.user_id > 0 and request.parameters is not None
        
    async def _build_query_with_tracking(self, request: QueryExecutionRequest, 
                                       context: ExecutionContext) -> str:
        """Build query with performance tracking."""
        build_start = time.time()
        query = self._route_query_building(request)
        self.query_metrics.query_build_time_ms = (time.time() - build_start) * 1000
        await self.send_status_update(context, "built", f"Query built for {request.query_type}")
        return query
        
    def _route_query_building(self, request: QueryExecutionRequest) -> str:
        """Route to appropriate query building method."""
        params = request.parameters
        if request.query_type == 'performance_metrics':
            return self._build_performance_query(request.user_id, params)
        elif request.query_type == 'anomaly_detection':
            return self._build_anomaly_query(request.user_id, params)
        elif request.query_type == 'correlation_analysis':
            return self._build_correlation_query(request.user_id, params)
        elif request.query_type == 'usage_patterns':
            return self._build_usage_query(request.user_id, params)
        else:
            raise ValueError(f"Unsupported query type: {request.query_type}")
            
    def _create_execution_result(self, query: str, request: QueryExecutionRequest,
                               execution_time_ms: float) -> Dict[str, Any]:
        """Create standardized execution result."""
        self._update_execution_history(request, execution_time_ms)
        return {
            'query': query,
            'query_type': request.query_type,
            'user_id': request.user_id,
            'execution_time_ms': execution_time_ms,
            'complexity_score': self._calculate_complexity_score(query),
            'build_metrics': self.query_metrics.__dict__
        }
        
    def _update_execution_history(self, request: QueryExecutionRequest,
                                execution_time_ms: float) -> None:
        """Update query execution history."""
        history_entry = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'query_type': request.query_type,
            'user_id': request.user_id,
            'execution_time_ms': execution_time_ms
        }
        self.execution_history.append(history_entry)
        self._trim_execution_history()
        
    def _trim_execution_history(self) -> None:
        """Trim execution history to last 100 entries."""
        if len(self.execution_history) > 100:
            self.execution_history = self.execution_history[-100:]
            
    def _calculate_complexity_score(self, query: str) -> int:
        """Calculate query complexity score for performance tracking."""
        score = 0
        complexity_indicators = ['WITH', 'GROUP BY', 'ORDER BY', 'LIMIT', 'JOIN']
        for indicator in complexity_indicators:
            score += query.upper().count(indicator)
        return min(score, 10)  # Cap at 10
        
    def _build_performance_query(self, user_id: int, params: Dict[str, Any]) -> str:
        """Build performance metrics query from parameters."""
        from netra_backend.app.agents.data_sub_agent.query_operations import QueryOperations
        return QueryOperations.build_performance_metrics_query(
            user_id=user_id,
            workload_id=params.get('workload_id'),
            start_time=params.get('start_time'),
            end_time=params.get('end_time'),
            aggregation_level=params.get('aggregation_level', 'minute')
        )
        
    def _build_anomaly_query(self, user_id: int, params: Dict[str, Any]) -> str:
        """Build anomaly detection query from parameters."""
        from netra_backend.app.agents.data_sub_agent.query_operations import QueryOperations
        return QueryOperations.build_anomaly_detection_query(
            user_id=user_id,
            metric_name=params.get('metric_name', 'latency_ms'),
            start_time=params.get('start_time'),
            end_time=params.get('end_time'),
            z_score_threshold=params.get('z_score_threshold', 2.0)
        )
        
    def _build_correlation_query(self, user_id: int, params: Dict[str, Any]) -> str:
        """Build correlation analysis query from parameters."""
        from netra_backend.app.agents.data_sub_agent.query_operations import QueryOperations
        return QueryOperations.build_correlation_analysis_query(
            user_id=user_id,
            metric1=params.get('metric1', 'latency_ms'),
            metric2=params.get('metric2', 'throughput'),
            start_time=params.get('start_time'),
            end_time=params.get('end_time')
        )
        
    def _build_usage_query(self, user_id: int, params: Dict[str, Any]) -> str:
        """Build usage patterns query from parameters."""
        from netra_backend.app.agents.data_sub_agent.query_operations import QueryOperations
        return QueryOperations.build_usage_patterns_query(
            user_id=user_id,
            days_back=params.get('days_back', 30)
        )
        
    async def execute_with_reliability(self, request: QueryExecutionRequest) -> ExecutionResult:
        """Execute query building with reliability patterns."""
        context = ExecutionContext(
            run_id=f"query_{int(time.time() * 1000)}",
            agent_name=self.agent_name,
            state=DeepAgentState(),
            user_id=str(request.user_id),
            metadata={'request': request.__dict__}
        )
        
        try:
            if not await self.validate_preconditions(context):
                return ExecutionResult(
                    success=False,
                    status=ExecutionStatus.FAILED,
                    error="Precondition validation failed"
                )
                
            result_data = await self.execute_core_logic(context)
            return ExecutionResult(
                success=True,
                status=ExecutionStatus.COMPLETED,
                result=result_data,
                execution_time_ms=result_data.get('execution_time_ms', 0)
            )
            
        except Exception as e:
            logger.error(f"Query execution failed: {e}")
            return ExecutionResult(
                success=False,
                status=ExecutionStatus.FAILED,
                error=str(e)
            )
    
    @staticmethod
    def build_performance_metrics_query(
        user_id: int,
        workload_id: Optional[str],
        start_time: datetime,
        end_time: datetime,
        aggregation_level: str = "minute"
    ) -> str:
        """Build query for performance metrics - backward compatibility."""
        from netra_backend.app.agents.data_sub_agent.query_operations import QueryOperations
        return QueryOperations.build_performance_metrics_query(
            user_id, workload_id, start_time, end_time, aggregation_level
        )
    
    @staticmethod
    def build_anomaly_detection_query(
        user_id: int,
        metric_name: str,
        start_time: datetime,
        end_time: datetime,
        z_score_threshold: float = 2.0
    ) -> str:
        """Build query for anomaly detection - backward compatibility."""
        from netra_backend.app.agents.data_sub_agent.query_operations import QueryOperations
        return QueryOperations.build_anomaly_detection_query(
            user_id, metric_name, start_time, end_time, z_score_threshold
        )
    
    @staticmethod
    def build_correlation_analysis_query(
        user_id: int,
        metric1: str,
        metric2: str,
        start_time: datetime,
        end_time: datetime
    ) -> str:
        """Build query for correlation analysis - backward compatibility."""
        from netra_backend.app.agents.data_sub_agent.query_operations import QueryOperations
        return QueryOperations.build_correlation_analysis_query(
            user_id, metric1, metric2, start_time, end_time
        )
    
    @staticmethod
    def build_usage_patterns_query(
        user_id: int,
        days_back: int = 30
    ) -> str:
        """Build query for usage pattern analysis - backward compatibility."""
        from netra_backend.app.agents.data_sub_agent.query_operations import QueryOperations
        return QueryOperations.build_usage_patterns_query(
            user_id, days_back
        )
        
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Get query builder performance metrics."""
        recent_executions = self.execution_history[-10:] if self.execution_history else []
        avg_execution_time = sum(e.get('execution_time_ms', 0) for e in recent_executions) / max(len(recent_executions), 1)
        return {
            'total_queries_built': len(self.execution_history),
            'average_build_time_ms': avg_execution_time,
            'supported_query_types': list(self.supported_query_types),
            'recent_executions_count': len(recent_executions),
            'current_metrics': self.query_metrics.__dict__
        }
        
    def get_health_status(self) -> Dict[str, Any]:
        """Get health status for monitoring."""
        performance = self.get_performance_metrics()
        return {
            'status': 'healthy' if performance['total_queries_built'] >= 0 else 'unknown',
            'uptime_queries': performance['total_queries_built'],
            'avg_performance_ms': performance['average_build_time_ms'],
            'last_updated': datetime.now(timezone.utc).isoformat()
        }