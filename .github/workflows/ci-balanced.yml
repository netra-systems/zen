name: CI - Balanced

on:
  pull_request:
    types: [opened, synchronize, reopened]
  push:
    branches: [main, develop, staging]
  workflow_dispatch:
    inputs:
      skip_non_critical:
        description: 'Skip non-critical tests'
        required: false
        type: boolean
        default: false

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'
  # Real services for testing per CLAUDE.md requirements
  TEST_DATABASE_URL: postgresql://test_user:test_password@localhost:5432/netra_test
  TEST_REDIS_URL: redis://localhost:6379/0
  NETRA_ENV: test
  CI: true

permissions:
  contents: read
  pull-requests: write
  statuses: write
  checks: write

concurrency:
  group: ci-balanced-${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  # ==========================================
  # PHASE 1: Critical Checks (Parallel)
  # ==========================================
  
  mission-critical:
    name: Mission Critical Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      passed: ${{ steps.test.outputs.passed }}
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: netra_test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run mission critical tests
        id: test
        run: |
          python tests/mission_critical/test_websocket_agent_events_suite.py
          echo "passed=true" >> $GITHUB_OUTPUT
      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mission-critical-results
          path: test-results/mission-critical/
          
  architecture-compliance:
    name: Architecture & Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      compliant: ${{ steps.check.outputs.compliant }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install ruff black mypy
      - name: Install Node dependencies
        working-directory: ./frontend
        run: npm ci
      - name: Check architecture compliance
        id: check
        run: |
          python scripts/check_architecture_compliance.py
          echo "compliant=true" >> $GITHUB_OUTPUT
      - name: Python linting
        run: |
          ruff check .
          black --check .
      - name: Python type checking
        run: |
          mypy netra_backend --ignore-missing-imports
      - name: Frontend linting
        working-directory: ./frontend
        run: |
          npm run lint
          npm run typecheck
      - name: Upload compliance report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: compliance-report
          path: reports/compliance/

  # ==========================================
  # PHASE 2: Unit Tests (Parallel, after critical)
  # ==========================================
  
  backend-unit-tests:
    name: Backend Unit Tests
    needs: [mission-critical, architecture-compliance]
    if: |
      always() &&
      needs.mission-critical.result == 'success' &&
      needs.architecture-compliance.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run backend unit tests
        run: |
          python unified_test_runner.py --category unit --service backend --fast-fail
      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-unit-results
          path: test-results/backend-unit/

  frontend-unit-tests:
    name: Frontend Unit Tests
    needs: [mission-critical, architecture-compliance]
    if: |
      always() &&
      needs.mission-critical.result == 'success' &&
      needs.architecture-compliance.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      - name: Install dependencies
        working-directory: ./frontend
        run: npm ci
      - name: Run frontend tests
        working-directory: ./frontend
        run: |
          npm run test:unit
          npm run test:components
      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: frontend-unit-results
          path: frontend/coverage/

  auth-service-tests:
    name: Auth Service Tests
    needs: [mission-critical, architecture-compliance]
    if: |
      always() &&
      needs.mission-critical.result == 'success' &&
      needs.architecture-compliance.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: netra_test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r auth_service/requirements.txt
      - name: Run auth service tests
        run: |
          cd auth_service && python -m pytest tests/ -v

  # ==========================================
  # PHASE 3: Integration Tests (After unit tests)
  # ==========================================
  
  backend-integration-tests:
    name: Backend Integration Tests
    needs: [backend-unit-tests, auth-service-tests]
    if: |
      always() &&
      needs.backend-unit-tests.result == 'success' &&
      needs.auth-service-tests.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 20
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: netra_test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run integration tests
        run: |
          python unified_test_runner.py --category integration --real-services
      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-integration-results
          path: test-results/backend-integration/

  database-tests:
    name: Database & Migration Tests
    needs: [backend-unit-tests]
    if: |
      always() &&
      needs.backend-unit-tests.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: netra_test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Test migrations
        run: |
          python unified_test_runner.py --category database --real-services

  # ==========================================
  # PHASE 4: E2E Tests (After integration)
  # ==========================================
  
  e2e-tests:
    name: End-to-End Tests
    needs: [backend-integration-tests, frontend-unit-tests]
    if: |
      always() &&
      needs.backend-integration-tests.result == 'success' &&
      needs.frontend-unit-tests.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: netra_test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      - name: Install backend dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Install frontend dependencies
        working-directory: ./frontend
        run: npm ci
      - name: Start services
        run: |
          # Start backend
          python -m uvicorn netra_backend.app.main:app --host 0.0.0.0 --port 8000 &
          sleep 5
          # Start frontend
          cd frontend && npm run dev &
          sleep 5
      - name: Run E2E tests
        run: |
          python unified_test_runner.py --category e2e --real-services
      - name: Upload E2E results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-results
          path: test-results/e2e/

  # ==========================================
  # PHASE 5: Security & Performance (Optional)
  # ==========================================
  
  security-scan:
    name: Security Scan
    needs: [backend-integration-tests]
    if: |
      always() &&
      needs.backend-integration-tests.result == 'success' &&
      inputs.skip_non_critical != true
    runs-on: ubuntu-latest
    timeout-minutes: 10
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install safety bandit
      - name: Run security checks
        run: |
          safety check || true
          bandit -r netra_backend -f json -o security-report.json
      - name: Upload security report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-report
          path: security-report.json

  # ==========================================
  # PHASE 6: Final Report
  # ==========================================
  
  generate-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [
      mission-critical,
      architecture-compliance,
      backend-unit-tests,
      frontend-unit-tests,
      auth-service-tests,
      backend-integration-tests,
      database-tests,
      e2e-tests,
      security-scan
    ]
    if: always()
    steps:
      - name: Check test results
        id: check-results
        run: |
          # Determine overall status
          FAILED=false
          CRITICAL_FAILED=false
          
          # Check critical tests
          if [[ "${{ needs.mission-critical.result }}" != "success" ]]; then
            CRITICAL_FAILED=true
            FAILED=true
          fi
          
          if [[ "${{ needs.architecture-compliance.result }}" != "success" ]]; then
            FAILED=true
          fi
          
          # Check other tests
          for result in "${{ needs.backend-unit-tests.result }}" "${{ needs.frontend-unit-tests.result }}" "${{ needs.backend-integration-tests.result }}" "${{ needs.e2e-tests.result }}"; do
            if [[ "$result" == "failure" ]]; then
              FAILED=true
            fi
          done
          
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "critical_failed=$CRITICAL_FAILED" >> $GITHUB_OUTPUT
          
      - name: Generate summary
        run: |
          echo "## 🔄 CI Balanced - Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Phase 1: Critical Checks ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Mission Critical: **${{ needs.mission-critical.result }}**" >> $GITHUB_STEP_SUMMARY
          echo "- Architecture Compliance: **${{ needs.architecture-compliance.result }}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Phase 2: Unit Tests" >> $GITHUB_STEP_SUMMARY
          echo "- Backend Unit: **${{ needs.backend-unit-tests.result }}**" >> $GITHUB_STEP_SUMMARY
          echo "- Frontend Unit: **${{ needs.frontend-unit-tests.result }}**" >> $GITHUB_STEP_SUMMARY
          echo "- Auth Service: **${{ needs.auth-service-tests.result }}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Phase 3: Integration Tests" >> $GITHUB_STEP_SUMMARY
          echo "- Backend Integration: **${{ needs.backend-integration-tests.result }}**" >> $GITHUB_STEP_SUMMARY
          echo "- Database Tests: **${{ needs.database-tests.result }}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Phase 4: E2E Tests" >> $GITHUB_STEP_SUMMARY
          echo "- E2E Tests: **${{ needs.e2e-tests.result }}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Phase 5: Security & Quality" >> $GITHUB_STEP_SUMMARY
          echo "- Security Scan: **${{ needs.security-scan.result }}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ steps.check-results.outputs.critical_failed }}" == "true" ]]; then
            echo "❌ **CRITICAL FAILURE: Mission critical tests failed!**" >> $GITHUB_STEP_SUMMARY
          elif [[ "${{ steps.check-results.outputs.failed }}" == "true" ]]; then
            echo "⚠️ **Some tests failed. Please review the results.**" >> $GITHUB_STEP_SUMMARY
          else
            echo "✅ **All tests passed successfully!**" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: test-results/
          
      - name: Comment PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const failed = '${{ steps.check-results.outputs.failed }}' === 'true';
            const criticalFailed = '${{ steps.check-results.outputs.critical_failed }}' === 'true';
            
            let status = '✅ All Checks Passed';
            if (criticalFailed) {
              status = '❌ Critical Tests Failed';
            } else if (failed) {
              status = '⚠️ Some Tests Failed';
            }
            
            const comment = `
            ## 🔄 CI Balanced Pipeline Results
            
            **Status:** ${status}
            **Strategy:** Balanced parallelization with smart dependencies
            
            ### Test Phases
            1. **Critical Checks** - ${criticalFailed ? '❌' : '✅'}
            2. **Unit Tests** - Running in parallel after critical checks
            3. **Integration Tests** - Running after unit tests pass
            4. **E2E Tests** - Final validation after integration
            5. **Security Scan** - Optional quality checks
            
            [View Full Results](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            `;
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
            
      - name: Exit with appropriate code
        if: steps.check-results.outputs.failed == 'true'
        run: exit 1