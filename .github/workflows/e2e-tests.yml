
# NOTE: This workflow has been identified for PR comment update
# To prevent comment spam, update PR comment sections to use:
# uses: ./.github/actions/pr-comment
# with:
#   comment-identifier: 'netra-e2e-tests'
#   comment-body: |
#     Your comment content here

name: E2E Test Suite with CI/CD Integration

# BUSINESS VALUE JUSTIFICATION (BVJ):
# 1. Segment: All segments - protects entire user funnel
# 2. Business Goal: Prevent production failures and revenue loss  
# 3. Value Impact: 99.9% uptime protection, prevents $100K+ MRR loss
# 4. Revenue Impact: Protects complete customer acquisition pipeline

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'app/**'
      - 'auth_service/**'  
      - 'frontend/**'
      - 'tests/**'
      - '.github/workflows/**'
  push:
    branches: [main, staging]
  workflow_dispatch:
    inputs:
      test_level:
        description: 'E2E test level'
        required: false
        default: 'standard'
        type: choice
        options:
          - 'smoke'
          - 'standard'  
          - 'comprehensive'
      parallel_workers:
        description: 'Number of parallel test workers'
        required: false
        default: '4'
        type: string
      skip_services:
        description: 'Skip service startup (assume running)'
        required: false
        default: false
        type: boolean

env:
  # Performance and resource limits
  MAX_TEST_DURATION: 300  # 5 minutes max
  PARALLEL_WORKERS: ${{ github.event.inputs.parallel_workers || '4' }}
  
  # Service configuration
  POSTGRES_URL: postgresql://test_user:test_pass@localhost:5432/test_db
  REDIS_URL: redis://localhost:6379
  CLICKHOUSE_URL: http://localhost:8123
  
  # Test environment
  E2E_TESTING: true
  NETRA_REAL_LLM_ENABLED: true  # CRITICAL: Real LLM testing required per CLAUDE.md
  ENABLE_REAL_LLM_TESTING: true  # Legacy support - real LLM testing enabled
  USE_REAL_LLM: true             # Legacy support - real LLM testing enabled
  TEST_USE_REAL_LLM: true        # Legacy support - real LLM testing enabled
  TEST_TIMEOUT: 30
  PYTEST_TIMEOUT: 60

permissions:
  contents: read
  pull-requests: write
  issues: write
  checks: write

jobs:
  setup-matrix:
    name: Setup Test Matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.setup.outputs.matrix }}
      total_shards: ${{ steps.setup.outputs.total_shards }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup test matrix
        id: setup
        run: |
          # Define test shards for parallel execution
          if [ "${{ github.event.inputs.test_level || 'standard' }}" = "smoke" ]; then
            matrix='{"shard": [1], "include": [{"shard": 1, "name": "smoke", "pattern": "test_*e2e*smoke* or test_critical*"}]}'
            total_shards=1
          elif [ "${{ github.event.inputs.test_level || 'standard' }}" = "comprehensive" ]; then
            matrix='{"shard": [1, 2, 3, 4], "include": [
              {"shard": 1, "name": "auth-flow", "pattern": "test_*auth* or test_*login* or test_*signup*"},
              {"shard": 2, "name": "user-journey", "pattern": "test_*user* or test_*chat* or test_*real*"},  
              {"shard": 3, "name": "websocket", "pattern": "test_*websocket* or test_*ws* or test_*connection*"},
              {"shard": 4, "name": "integration", "pattern": "test_*integration* or test_*e2e*"}
            ]}'
            total_shards=4
          else
            # Standard level
            matrix='{"shard": [1, 2], "include": [
              {"shard": 1, "name": "core-flow", "pattern": "test_real_* or test_*e2e*"},
              {"shard": 2, "name": "integration", "pattern": "test_*integration* or test_*websocket*"}
            ]}'
            total_shards=2
          fi
          
          echo "matrix=$matrix" >> $GITHUB_OUTPUT
          echo "total_shards=$total_shards" >> $GITHUB_OUTPUT

  service-health:
    name: Service Health Check
    runs-on: ubuntu-latest
    if: ${{ !github.event.inputs.skip_services }}
    outputs:
      services_ready: ${{ steps.health.outputs.ready }}
      
    services:
      postgres:
        image: postgres:17.6
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_pass
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Service health check
        id: health
        run: |
          echo "Checking service health..."
          
          # Check PostgreSQL
          if pg_isready -h localhost -p 5432 -U test_user; then
            echo "✅ PostgreSQL ready"
          else
            echo "❌ PostgreSQL not ready"
            exit 1
          fi
          
          # Check Redis  
          if redis-cli -h localhost -p 6379 ping | grep -q "PONG"; then
            echo "✅ Redis ready"
          else
            echo "❌ Redis not ready"
            exit 1
          fi
          
          echo "ready=true" >> $GITHUB_OUTPUT

  e2e-tests:
    name: E2E Tests (Shard ${{ matrix.shard }})
    runs-on: ubuntu-latest
    needs: [setup-matrix, service-health]
    if: always() && (needs.service-health.result == 'success' || github.event.inputs.skip_services)
    timeout-minutes: 15  # Hard limit for CI efficiency
    
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.setup-matrix.outputs.matrix) }}
    
    services:
      postgres:
        image: postgres:17.6
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_pass
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for change detection
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          pip install pytest-xdist pytest-timeout pytest-html
      
      - name: Install Node.js dependencies
        run: |
          cd frontend
          npm ci
      
      - name: Configure test environment
        run: |
          echo "SHARD_NUMBER=${{ matrix.shard }}" >> $GITHUB_ENV
          echo "SHARD_NAME=${{ matrix.name }}" >> $GITHUB_ENV
          echo "TEST_PATTERN=${{ matrix.pattern }}" >> $GITHUB_ENV
          
          # Database setup
          echo "DATABASE_URL=${POSTGRES_URL}" >> $GITHUB_ENV
          echo "TEST_DATABASE_URL=${POSTGRES_URL}" >> $GITHUB_ENV
          
          # Service URLs
          echo "AUTH_SERVICE_URL=http://localhost:8081" >> $GITHUB_ENV
          echo "BACKEND_SERVICE_URL=http://localhost:8000" >> $GITHUB_ENV
          echo "FRONTEND_URL=http://localhost:3000" >> $GITHUB_ENV
          
          # Test configuration
          echo "TEST_PARALLEL_WORKERS=${{ env.PARALLEL_WORKERS }}" >> $GITHUB_ENV
          echo "PYTEST_CURRENT_TEST=true" >> $GITHUB_ENV
      
      - name: Setup test database
        run: |
          # Create test database schema
          python -c "
          import asyncio
          import asyncpg
          import os
          
          async def setup_db():
              conn = await asyncpg.connect(os.environ['POSTGRES_URL'])
              try:
                  await conn.execute('CREATE SCHEMA IF NOT EXISTS test_schema')
                  print('✅ Test database ready')
              finally:
                  await conn.close()
          
          asyncio.run(setup_db())
          "
      
      - name: Start application services
        id: services
        if: ${{ !github.event.inputs.skip_services }}
        run: |
          echo "Starting application services for E2E testing..."
          
          # Start auth service
          cd auth_service
          python main.py &
          AUTH_PID=$!
          echo "AUTH_SERVICE_PID=$AUTH_PID" >> $GITHUB_ENV
          
          # Wait for auth service
          sleep 5
          
          # Start backend service  
          cd ../app
          python main.py &
          BACKEND_PID=$!
          echo "BACKEND_SERVICE_PID=$BACKEND_PID" >> $GITHUB_ENV
          
          # Wait for backend service
          sleep 5
          
          # Health check services
          max_attempts=30
          attempt=0
          
          while [ $attempt -lt $max_attempts ]; do
            if curl -f -s http://localhost:8001/health > /dev/null 2>&1 && \
               curl -f -s http://localhost:8000/health > /dev/null 2>&1; then
              echo "✅ Services ready"
              break
            fi
            
            echo "Waiting for services... ($((attempt + 1))/$max_attempts)"
            sleep 2
            attempt=$((attempt + 1))
          done
          
          if [ $attempt -eq $max_attempts ]; then
            echo "❌ Services failed to start"
            exit 1
          fi
          
          echo "services_ready=true" >> $GITHUB_OUTPUT
      
      - name: Run E2E tests
        id: tests
        run: |
          echo "Running E2E tests for shard ${{ matrix.shard }}: ${{ matrix.name }}"
          
          # Use our custom E2E runner
          python tests/unified/e2e/run_e2e_tests.py \
            --parallel \
            --workers ${{ env.PARALLEL_WORKERS }} \
            --ci \
            ${{ github.event.inputs.skip_services && '--no-services' || '' }}
        
        timeout-minutes: 10
      
      - name: Generate test report
        id: report
        if: always()
        run: |
          echo "Generating test report for shard ${{ matrix.shard }}"
          
          if [ -f test_reports/e2e_test_results.json ]; then
            # Extract key metrics for GitHub Actions
            python -c "
            import json
            with open('test_reports/e2e_test_results.json') as f:
                data = json.load(f)
            
            print(f'TESTS_TOTAL={data.get(\"total_tests\", 0)}')
            print(f'TESTS_PASSED={data.get(\"passed_tests\", 0)}')
            print(f'TESTS_FAILED={data.get(\"failed_tests\", 0)}')
            print(f'SUCCESS_RATE={data.get(\"success_rate\", 0):.1f}')
            print(f'DURATION={data.get(\"total_duration\", 0):.1f}')
            print(f'BASELINE_MET={data.get(\"performance_baseline_met\", False)}')
            " >> $GITHUB_ENV
            
            echo "report_available=true" >> $GITHUB_OUTPUT
          else
            echo "report_available=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-results-shard-${{ matrix.shard }}
          path: |
            test_reports/
            pytest-html-report.html
            .pytest_cache/
          retention-days: 7
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request' && steps.report.outputs.report_available == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const shard = '${{ matrix.shard }}';
            const shardName = '${{ matrix.name }}';
            const testsTotal = '${{ env.TESTS_TOTAL }}';
            const testsPassed = '${{ env.TESTS_PASSED }}';
            const testsFailed = '${{ env.TESTS_FAILED }}';
            const successRate = '${{ env.SUCCESS_RATE }}';
            const duration = '${{ env.DURATION }}';
            const baselineMet = '${{ env.BASELINE_MET }}' === 'True';
            
            const emoji = testsFailed === '0' ? '✅' : '❌';
            const baselineEmoji = baselineMet ? '⚡' : '🐌';
            
            const body = `
            ## ${emoji} E2E Test Results - Shard ${shard} (${shardName})
            
            | Metric | Value |
            |--------|-------|
            | Tests Run | ${testsTotal} |
            | Passed | ${testsPassed} |  
            | Failed | ${testsFailed} |
            | Success Rate | ${successRate}% |
            | Duration | ${duration}s |
            | Performance | ${baselineEmoji} ${baselineMet ? 'Baseline Met' : 'Over Baseline'} |
            
            ${testsFailed !== '0' ? '🚨 **E2E tests failed - revenue protection at risk**' : '💰 **$100K+ MRR protected by E2E validation**'}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
      
      - name: Stop services
        if: always() && steps.services.outputs.services_ready == 'true'
        run: |
          echo "Stopping application services..."
          
          # Stop services gracefully
          if [ -n "$BACKEND_SERVICE_PID" ]; then
            kill $BACKEND_SERVICE_PID || true
            echo "Backend service stopped"
          fi
          
          if [ -n "$AUTH_SERVICE_PID" ]; then
            kill $AUTH_SERVICE_PID || true
            echo "Auth service stopped"  
          fi
          
          # Wait for cleanup
          sleep 2

  aggregate-results:
    name: Aggregate E2E Results  
    runs-on: ubuntu-latest
    needs: [setup-matrix, e2e-tests]
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: test-artifacts/
      
      - name: Aggregate results
        id: aggregate
        run: |
          echo "Aggregating results from ${{ needs.setup-matrix.outputs.total_shards }} shards"
          
          total_tests=0
          total_passed=0
          total_failed=0
          total_duration=0
          
          for shard in test-artifacts/e2e-test-results-shard-*/test_reports/e2e_test_results.json; do
            if [ -f "$shard" ]; then
              echo "Processing: $shard"
              
              # Extract metrics using Python
              metrics=$(python3 -c "
              import json
              with open('$shard') as f:
                  data = json.load(f)
              print(f\"{data.get('total_tests', 0)} {data.get('passed_tests', 0)} {data.get('failed_tests', 0)} {data.get('total_duration', 0)}\")
              ")
              
              read tests passed failed duration <<< "$metrics"
              total_tests=$((total_tests + tests))
              total_passed=$((total_passed + passed))
              total_failed=$((total_failed + failed))
              total_duration=$(echo "$total_duration + $duration" | bc)
            fi
          done
          
          success_rate=0
          if [ $total_tests -gt 0 ]; then
            success_rate=$(echo "scale=1; $total_passed * 100 / $total_tests" | bc)
          fi
          
          baseline_met=$(echo "$total_duration < 300" | bc)  # 5 minutes
          
          echo "TOTAL_TESTS=$total_tests" >> $GITHUB_ENV
          echo "TOTAL_PASSED=$total_passed" >> $GITHUB_ENV  
          echo "TOTAL_FAILED=$total_failed" >> $GITHUB_ENV
          echo "SUCCESS_RATE=$success_rate" >> $GITHUB_ENV
          echo "TOTAL_DURATION=$total_duration" >> $GITHUB_ENV
          echo "BASELINE_MET=$baseline_met" >> $GITHUB_ENV
          
          # Set exit code for workflow
          if [ $total_failed -eq 0 ]; then
            echo "exit_code=0" >> $GITHUB_OUTPUT
          else
            echo "exit_code=1" >> $GITHUB_OUTPUT
          fi
      
      - name: Create final PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const totalTests = '${{ env.TOTAL_TESTS }}';
            const totalPassed = '${{ env.TOTAL_PASSED }}';
            const totalFailed = '${{ env.TOTAL_FAILED }}';
            const successRate = '${{ env.SUCCESS_RATE }}';
            const duration = '${{ env.TOTAL_DURATION }}';
            const baselineMet = '${{ env.BASELINE_MET }}' === '1';
            
            const overallEmoji = totalFailed === '0' ? '🎉' : '💥';
            const performanceEmoji = baselineMet ? '⚡' : '🐌';
            
            const body = `
            ## ${overallEmoji} E2E Test Suite Complete
            
            ### 📊 Overall Results
            | Metric | Value |
            |--------|--------|
            | **Total Tests** | ${totalTests} |
            | **✅ Passed** | ${totalPassed} |
            | **❌ Failed** | ${totalFailed} |
            | **📈 Success Rate** | ${successRate}% |
            | **⏱️ Duration** | ${duration}s |
            | **${performanceEmoji} Performance** | ${baselineMet ? '< 5min (✅ Baseline Met)' : '> 5min (⚠️ Over Baseline)'} |
            
            ### 💰 Business Impact
            ${totalFailed === '0' 
              ? '✅ **$100K+ MRR Protected** - All E2E tests passed\n✅ **Production Ready** - User funnel validated\n✅ **Revenue Safe** - No critical path failures'
              : '🚨 **Revenue at Risk** - E2E test failures detected\n🚨 **User Experience Impact** - Critical paths may be broken\n🚨 **Production Blocked** - Fix required before merge'
            }
            
            ### 🔍 Test Coverage
            - User authentication flow
            - Chat functionality end-to-end  
            - WebSocket connections
            - Service integrations
            - Performance validations
            
            ${totalFailed !== '0' ? '\n⚠️ **Action Required**: Review failed tests and fix issues before merging.' : ''}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,  
              repo: context.repo.repo,
              body: body
            });
      
      - name: Set workflow status
        run: |
          if [ "${{ steps.aggregate.outputs.exit_code }}" = "0" ]; then
            echo "🎉 All E2E tests passed - $100K+ MRR protected"
            exit 0
          else
            echo "💥 E2E tests failed - revenue at risk"
            exit 1
          fi