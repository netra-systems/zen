name: Reusable Test Runner

on:
  workflow_call:
    inputs:
      test_level:
        description: 'Test level: smoke, unit, integration, e2e, comprehensive'
        required: false
        type: string
        default: 'unit'
      changed_areas:
        description: 'JSON string of changed areas from determine-strategy'
        required: false
        type: string
        default: '{}'
      act_mode:
        description: 'Whether running in ACT mode'
        required: false
        type: string
        default: 'false'
      runner_type:
        description: 'Runner type to use'
        required: false
        type: string
        default: 'warp-custom-default'
      strategy:
        description: 'Test strategy: series, parallel, matrix'
        required: false
        type: string
        default: 'series'
      timeout_minutes:
        description: 'Test timeout in minutes'
        required: false
        type: number
        default: 30
      retry_failed:
        description: 'Retry failed tests'
        required: false
        type: boolean
        default: true
      max_retries:
        description: 'Maximum retry attempts'
        required: false
        type: number
        default: 2
      python_version:
        description: 'Python version to use'
        required: false
        type: string
        default: '3.11'
      node_version:
        description: 'Node.js version to use'
        required: false
        type: string
        default: '20'
    outputs:
      test_status:
        description: 'Overall test status'
        value: ${{ jobs.test-runner.outputs.test_status }}
      coverage_percentage:
        description: 'Test coverage percentage'
        value: ${{ jobs.test-runner.outputs.coverage_percentage }}
      test_duration:
        description: 'Test execution duration'
        value: ${{ jobs.test-runner.outputs.test_duration }}

permissions:
  contents: read
  pull-requests: write
  issues: write
  statuses: write

env:
  ACT: 'false'
  IS_ACT: 'false'

jobs:
  test-runner:
    runs-on: ${{ inputs.runner_type }}
    timeout-minutes: ${{ inputs.timeout_minutes }}
    outputs:
      test_status: ${{ steps.final-status.outputs.test_status }}
      coverage_percentage: ${{ steps.coverage.outputs.percentage }}
      test_duration: ${{ steps.final-status.outputs.duration }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ inputs.python_version }}
          cache: 'pip'
          
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ inputs.node_version }}
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'
          
      - name: Start test timer
        id: timer-start
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
        
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Install frontend dependencies
        working-directory: ./frontend
        run: npm ci
        
      - name: ACT Mode Detection
        id: act-detect
        run: |
          if [[ "${{ inputs.act_mode }}" == "true" ]]; then
            echo "🧪 Test runner in ACT mode"
            echo "ACT_MODE=true" >> $GITHUB_ENV
          else
            echo "☁️ Test runner in GitHub Actions"
            echo "ACT_MODE=false" >> $GITHUB_ENV
          fi
          
      - name: Run smoke tests
        id: smoke-tests
        if: ${{ inputs.test_level == 'smoke' || inputs.test_level == 'comprehensive' }}
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 5
          max_attempts: ${{ inputs.retry_failed && inputs.max_retries || 1 }}
          retry_wait_seconds: 30
          command: |
            if [[ "${{ env.ACT_MODE }}" == "true" ]]; then
              echo "🧪 ACT: Running mock smoke tests"
              echo "✅ Smoke tests passed (mock)"
            else
              python test_runner.py --level smoke
            fi
            
      - name: Run unit tests
        id: unit-tests
        if: ${{ inputs.test_level == 'unit' || inputs.test_level == 'comprehensive' }}
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 15
          max_attempts: ${{ inputs.retry_failed && inputs.max_retries || 1 }}
          retry_wait_seconds: 30
          command: |
            if [[ "${{ env.ACT_MODE }}" == "true" ]]; then
              echo "🧪 ACT: Running mock unit tests"
              echo "✅ Unit tests passed (mock)"
              # Create mock coverage file
              mkdir -p test-results
              echo '<coverage line-rate="0.85"></coverage>' > coverage.xml
            else
              python test_runner.py --level unit --coverage
            fi
            
      - name: Run integration tests
        id: integration-tests
        if: ${{ inputs.test_level == 'integration' || inputs.test_level == 'comprehensive' }}
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 20
          max_attempts: ${{ inputs.retry_failed && inputs.max_retries || 1 }}
          retry_wait_seconds: 30
          command: |
            if [[ "${{ env.ACT_MODE }}" == "true" ]]; then
              echo "🧪 ACT: Running mock integration tests"
              echo "✅ Integration tests passed (mock)"
            else
              python test_runner.py --level integration
            fi
            
      - name: Run E2E tests
        id: e2e-tests
        if: ${{ inputs.test_level == 'e2e' || inputs.test_level == 'comprehensive' }}
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 25
          max_attempts: ${{ inputs.retry_failed && inputs.max_retries || 1 }}
          retry_wait_seconds: 30
          command: |
            if [[ "${{ env.ACT_MODE }}" == "true" ]]; then
              echo "🧪 ACT: Running mock E2E tests"
              echo "✅ E2E tests passed (mock)"
            else
              python test_runner.py --level e2e
            fi
            
      - name: Collect coverage
        id: coverage
        if: always()
        run: |
          if [ -f coverage.xml ]; then
            coverage_pct=$(python -c "
            import xml.etree.ElementTree as ET
            tree = ET.parse('coverage.xml')
            root = tree.getroot()
            print(root.attrib.get('line-rate', '0'))
            ")
            coverage_pct=$(echo "$coverage_pct * 100" | bc)
            echo "percentage=${coverage_pct%.*}" >> $GITHUB_OUTPUT
          else
            echo "percentage=0" >> $GITHUB_OUTPUT
          fi
          
      - name: Calculate test duration
        id: final-status
        if: always()
        run: |
          start_time=${{ steps.timer-start.outputs.start_time }}
          end_time=$(date +%s)
          duration=$((end_time - start_time))
          
          # Determine overall status
          if [ "${{ steps.smoke-tests.outcome }}" = "failure" ] || \
             [ "${{ steps.unit-tests.outcome }}" = "failure" ] || \
             [ "${{ steps.integration-tests.outcome }}" = "failure" ] || \
             [ "${{ steps.e2e-tests.outcome }}" = "failure" ]; then
            status="failure"
          elif [ "${{ steps.smoke-tests.outcome }}" = "cancelled" ] || \
               [ "${{ steps.unit-tests.outcome }}" = "cancelled" ] || \
               [ "${{ steps.integration-tests.outcome }}" = "cancelled" ] || \
               [ "${{ steps.e2e-tests.outcome }}" = "cancelled" ]; then
            status="cancelled"
          else
            status="success"
          fi
          
          echo "test_status=$status" >> $GITHUB_OUTPUT
          echo "duration=${duration}s" >> $GITHUB_OUTPUT
          
      - name: Update commit status
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const status = '${{ steps.final-status.outputs.test_status }}';
            const coverage = '${{ steps.coverage.outputs.percentage }}';
            const duration = '${{ steps.final-status.outputs.duration }}';
            
            const state = status === 'success' ? 'success' : 
                         status === 'cancelled' ? 'error' : 'failure';
            
            const description = `Tests ${status} - Coverage: ${coverage}% - Duration: ${duration}`;
            
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: state,
              description: description,
              context: 'tests/${{ inputs.test_level }}'
            });
            
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ inputs.test_level }}-${{ github.run_id }}
          path: |
            test-results/
            coverage.xml
            pytest.xml
          retention-days: 7
          
      - name: Cleanup on failure
        if: failure()
        run: |
          echo "Cleaning up after test failure..."
          # Kill any hanging processes
          pkill -f "python.*test" || true
          # Clean up test databases
          python scripts/cleanup_test_resources.py || true