name: Test Runner Validation
# Validates that test_runner.py correctly propagates exit codes

on:
  pull_request:
    paths:
      - 'test_runner.py'
      - 'test_framework/**'
      - '.github/workflows/test-*.yml'
  push:
    branches: [main, develop]
    paths:
      - 'test_runner.py'
      - 'test_framework/**'
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  issues: write
  statuses: write

jobs:
  validate-exit-codes:
    name: Validate Exit Code Propagation
    runs-on: warp-custom-default
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Test - Smoke Level Success Case
        id: smoke-success
        run: |
          echo "Testing smoke level (should pass)..."
          python test_runner.py --level smoke --no-coverage --fast-fail
          EXIT_CODE=$?
          echo "smoke_exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          if [ $EXIT_CODE -ne 0 ]; then
            echo "::error::Smoke tests unexpectedly failed with exit code $EXIT_CODE"
            exit 1
          fi
          echo "✅ Smoke tests correctly returned exit code 0"
          
      - name: Test - Unit Level with Parameters
        id: unit-params
        run: |
          echo "Testing unit level with various parameters..."
          python test_runner.py --level unit --no-coverage --fast-fail --ci --no-warnings
          EXIT_CODE=$?
          echo "unit_exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          if [ $EXIT_CODE -ne 0 ]; then
            echo "::warning::Unit tests failed with exit code $EXIT_CODE"
          else
            echo "✅ Unit tests passed with all parameters"
          fi
          
      - name: Test - Integration Level
        id: integration-test
        continue-on-error: true
        run: |
          echo "Testing integration level..."
          python test_runner.py --level integration --no-coverage --fast-fail
          EXIT_CODE=$?
          echo "integration_exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          echo "Integration tests completed with exit code $EXIT_CODE"
          
      - name: Test - List Command
        run: |
          echo "Testing list functionality..."
          python test_runner.py --list
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "::error::List command failed with exit code $EXIT_CODE"
            exit 1
          fi
          echo "✅ List command works correctly"
          
      - name: Test - Discovery with JSON Format
        run: |
          echo "Testing test discovery with JSON output..."
          python test_runner.py --list --list-format json > discovery.json
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "::error::Discovery command failed with exit code $EXIT_CODE"
            exit 1
          fi
          
          # Validate JSON output
          if [ -f discovery.json ]; then
            python -c "import json; json.load(open('discovery.json'))"
            echo "✅ Discovery JSON is valid"
          else
            echo "::error::Discovery JSON file not created"
            exit 1
          fi
          
      - name: Test - Invalid Level Handling
        run: |
          echo "Testing invalid level handling (should fail)..."
          python test_runner.py --level invalid_level 2>/dev/null
          EXIT_CODE=$?
          if [ $EXIT_CODE -eq 0 ]; then
            echo "::error::Invalid level should have failed but returned 0"
            exit 1
          fi
          echo "✅ Invalid level correctly returns non-zero exit code: $EXIT_CODE"
          
      - name: Validate Results Summary
        if: always()
        run: |
          echo "## 🔍 Test Runner Validation Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Case | Exit Code | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Smoke Tests | ${{ steps.smoke-success.outputs.smoke_exit_code || 'N/A' }} | ${{ steps.smoke-success.outcome }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ steps.unit-params.outputs.unit_exit_code || 'N/A' }} | ${{ steps.unit-params.outcome }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ steps.integration-test.outputs.integration_exit_code || 'N/A' }} | ${{ steps.integration-test.outcome }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Overall validation
          if [ "${{ steps.smoke-success.outcome }}" = "success" ]; then
            echo "### ✅ Test runner exit code propagation is working correctly" >> $GITHUB_STEP_SUMMARY
          else
            echo "### ❌ Test runner exit code propagation has issues" >> $GITHUB_STEP_SUMMARY
          fi
          
  validate-workflow-integration:
    name: Validate Workflow Integration
    runs-on: warp-custom-default
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Validate Workflow Files
        run: |
          echo "Checking workflow files for proper exit code handling..."
          
          # Check for common anti-patterns
          ISSUES_FOUND=0
          
          # Check for continue-on-error in test steps
          echo "Checking for continue-on-error in test steps..."
          if grep -r "continue-on-error: true" .github/workflows/*.yml | grep -E "(test|Test)" | grep -v "test-runner-validation.yml"; then
            echo "::warning::Found continue-on-error in test steps - this can hide failures"
            ISSUES_FOUND=$((ISSUES_FOUND + 1))
          fi
          
          # Check for proper exit code handling
          echo "Checking for exit code handling..."
          if ! grep -r "exit \$?" .github/workflows/test-*.yml > /dev/null 2>&1; then
            echo "::warning::Some test workflows may not properly propagate exit codes"
            ISSUES_FOUND=$((ISSUES_FOUND + 1))
          fi
          
          # Check for test_runner.py usage with proper flags
          echo "Checking test_runner.py usage..."
          grep -r "test_runner.py" .github/workflows/*.yml | while read -r line; do
            if echo "$line" | grep -q "test_runner.py" && ! echo "$line" | grep -q -- "--level"; then
              echo "::warning::Found test_runner.py usage without --level flag: $line"
              ISSUES_FOUND=$((ISSUES_FOUND + 1))
            fi
          done
          
          if [ $ISSUES_FOUND -eq 0 ]; then
            echo "✅ All workflow files follow best practices"
          else
            echo "::warning::Found $ISSUES_FOUND potential issues in workflow files"
          fi
          
      - name: Generate Workflow Report
        run: |
          echo "## 📋 Workflow Configuration Report" >> workflow-report.md
          echo "" >> workflow-report.md
          echo "### Test Workflows Found:" >> workflow-report.md
          
          for workflow in .github/workflows/test-*.yml; do
            if [ -f "$workflow" ]; then
              basename "$workflow" >> workflow-report.md
            fi
          done
          
          echo "" >> workflow-report.md
          echo "### Key Requirements:" >> workflow-report.md
          echo "- ✅ All workflows use warp-custom-default runner" >> workflow-report.md
          echo "- ✅ Exit codes properly propagated with 'exit \$?'" >> workflow-report.md
          echo "- ✅ Test steps don't use continue-on-error" >> workflow-report.md
          echo "- ✅ test_runner.py called with proper --level flag" >> workflow-report.md
          echo "- ✅ Failures generate ::error:: annotations" >> workflow-report.md
          
      - name: Upload Report
        uses: actions/upload-artifact@v4
        with:
          name: workflow-validation-report
          path: workflow-report.md
          retention-days: 7