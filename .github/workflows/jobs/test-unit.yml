name: Unit Test Execution

on:
  workflow_call:
    inputs:
      python_version:
        description: 'Python version to use'
        required: false
        type: string
        default: '3.11'
      test_path:
        description: 'Path to test directory or specific test files'
        required: false
        type: string
        default: 'app/tests/unit'
      coverage_threshold:
        description: 'Minimum coverage threshold percentage'
        required: false
        type: number
        default: 85
      timeout_minutes:
        description: 'Test execution timeout in minutes'
        required: false
        type: number
        default: 30
      skip_condition:
        description: 'Skip condition for conditional execution'
        required: false
        type: string
        default: 'false'
    outputs:
      coverage_percentage:
        description: 'Test coverage percentage'
        value: ${{ jobs.unit-tests.outputs.coverage_percentage }}
      test_results:
        description: 'Test execution results summary'
        value: ${{ jobs.unit-tests.outputs.test_results }}
      status:
        description: 'Job completion status'
        value: ${{ jobs.unit-tests.outputs.status }}

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  unit-tests:
    runs-on: warp-custom-default
    if: ${{ inputs.skip_condition != 'true' }}
    timeout-minutes: ${{ inputs.timeout_minutes }}
    outputs:
      coverage_percentage: ${{ steps.coverage.outputs.percentage }}
      test_results: ${{ steps.results.outputs.summary }}
      status: ${{ steps.final.outputs.status }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ inputs.python_version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-xdist pytest-html

      - name: Setup test environment
        run: |
          # Create test environment variables
          echo "TESTING=true" >> $GITHUB_ENV
          echo "DATABASE_URL=postgresql://test:test@localhost:5432/test_db" >> $GITHUB_ENV
          echo "LOG_LEVEL=WARNING" >> $GITHUB_ENV

      - name: Start test dependencies
        run: |
          # Start any required services for tests (e.g., test database)
          echo "Setting up test dependencies..."
          # Note: Add actual dependency setup here if needed

      - name: Run unit tests with coverage
        id: test
        run: |
          pytest ${{ inputs.test_path }} \
            --cov=app \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --cov-fail-under=${{ inputs.coverage_threshold }} \
            --junit-xml=test-results.xml \
            --html=test-report.html \
            --self-contained-html \
            -v \
            -x \
            --tb=short

      - name: Extract coverage percentage
        id: coverage
        if: always()
        run: |
          if [ -f coverage.xml ]; then
            coverage_pct=$(python -c "
            import xml.etree.ElementTree as ET
            tree = ET.parse('coverage.xml')
            root = tree.getroot()
            coverage = root.attrib.get('line-rate', '0')
            print(f'{float(coverage) * 100:.1f}')
            ")
            echo "percentage=$coverage_pct" >> $GITHUB_OUTPUT
            echo "Coverage: $coverage_pct%"
          else
            echo "percentage=0" >> $GITHUB_OUTPUT
            echo "Coverage file not found"
          fi

      - name: Generate test results summary
        id: results
        if: always()
        run: |
          if [ -f test-results.xml ]; then
            summary=$(python -c "
            import xml.etree.ElementTree as ET
            tree = ET.parse('test-results.xml')
            root = tree.getroot()
            tests = root.attrib.get('tests', '0')
            failures = root.attrib.get('failures', '0')
            errors = root.attrib.get('errors', '0')
            skipped = root.attrib.get('skipped', '0')
            passed = int(tests) - int(failures) - int(errors) - int(skipped)
            print(f'Tests: {tests}, Passed: {passed}, Failed: {failures}, Errors: {errors}, Skipped: {skipped}')
            ")
            echo "summary=$summary" >> $GITHUB_OUTPUT
          else
            echo "summary=Test results not available" >> $GITHUB_OUTPUT
          fi

      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: |
            coverage.xml
            htmlcov/
            test-report.html
          retention-days: 30

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: test-results.xml
          retention-days: 30

      - name: Handle test failures
        if: failure()
        run: |
          echo "Unit tests failed"
          echo "Test path: ${{ inputs.test_path }}"
          echo "Python version: ${{ inputs.python_version }}"
          echo "Coverage threshold: ${{ inputs.coverage_threshold }}%"
          if [ -f test-results.xml ]; then
            echo "Test results available in artifacts"
          fi
          exit 1

      - name: Final status
        id: final
        if: always()
        run: |
          echo "status=${{ job.status }}" >> $GITHUB_OUTPUT