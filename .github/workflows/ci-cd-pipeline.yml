name: CI/CD Pipeline

on:
  pull_request:
    types: [opened, synchronize, reopened]
  push:
    branches: [main, develop]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: false
        type: choice
        options:
          - staging
          - production
        default: staging
      force_full_tests:
        description: 'Force comprehensive testing'
        required: false
        type: boolean
        default: false

permissions:
  contents: read
  deployments: write
  pull-requests: write
  issues: write
  statuses: write
  checks: write

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  # ==========================================
  # STAGE 1: PRE-COMMIT TESTS (30s)
  # Quick unit tests for immediate feedback
  # ==========================================
  
  pre-commit-tests:
    name: Pre-commit Tests
    runs-on: warp-custom-default
    timeout-minutes: 2
    outputs:
      status: ${{ steps.tests.outcome }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: Install minimal dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-xdist ruff black isort
          
      - name: Code quality checks
        run: |
          echo "=== Code Quality Checks ==="
          
          # Format checking
          black --check --diff . || (echo "âŒ Code formatting issues found" && exit 1)
          
          # Import sorting
          isort --check-only --diff . || (echo "âŒ Import sorting issues found" && exit 1)
          
          # Linting
          ruff check . || (echo "âŒ Linting issues found" && exit 1)
          
          echo "âœ… Code quality checks passed"
          
      - name: Run smoke tests
        id: tests
        run: |
          echo "=== Running Smoke Tests ==="
          
          # Run only the fastest critical tests
          python test_runner.py --level smoke --no-coverage --fast-fail --quiet
          
          echo "âœ… Pre-commit tests completed"

  # ==========================================
  # STAGE 2: PR TESTS (5min)
  # Unit + Integration tests for PR validation
  # ==========================================
  
  pr-validation-tests:
    name: PR Validation Tests
    needs: pre-commit-tests
    if: github.event_name == 'pull_request'
    uses: ./.github/workflows/unified-test-runner.yml
    with:
      test_level: integration
      strategy: parallel
      timeout_minutes: 8
      enable_real_services: true
      total_shards: 3
    secrets: inherit

  # ==========================================
  # STAGE 3: MAIN BRANCH TESTS (15min)
  # Comprehensive testing for main branch
  # ==========================================
  
  main-branch-tests:
    name: Main Branch Tests
    needs: pre-commit-tests
    if: github.ref == 'refs/heads/main' || inputs.force_full_tests
    uses: ./.github/workflows/unified-test-runner.yml
    with:
      test_level: comprehensive
      strategy: matrix
      timeout_minutes: 20
      enable_real_services: true
      total_shards: 6
      retry_failed: true
      max_retries: 2
    secrets: inherit

  # ==========================================
  # STAGE 4: DEPLOY TESTS (30min)
  # Full E2E testing before deployment
  # ==========================================
  
  deploy-readiness-tests:
    name: Deploy Readiness Tests
    needs: [pre-commit-tests]
    if: |
      (github.ref == 'refs/heads/main' && github.event_name == 'push') ||
      (github.event_name == 'workflow_dispatch')
    runs-on: warp-custom-default
    timeout-minutes: 35
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up test infrastructure
        run: |
          echo "=== Setting up Test Infrastructure ==="
          
          # Start comprehensive test services
          docker-compose -f docker-compose.test.yml up -d
          
          # Wait for services to be healthy
          echo "Waiting for services to be ready..."
          timeout 300 bash -c 'until docker-compose -f docker-compose.test.yml exec -T test-postgres pg_isready -U test_user; do sleep 2; done'
          timeout 300 bash -c 'until docker-compose -f docker-compose.test.yml exec -T test-redis redis-cli ping; do sleep 2; done'
          timeout 300 bash -c 'until curl -f http://localhost:8124/ping; do sleep 2; done'
          
          echo "âœ… All services are ready"
          
      - name: Run comprehensive E2E tests
        run: |
          echo "=== Running Comprehensive E2E Tests ==="
          
          # Run full test suite with real services
          python test_runner.py \
            --level comprehensive \
            --real-llm \
            --staging \
            --parallel 4 \
            --coverage-output e2e_coverage.xml \
            --json-output e2e_results.json
            
      - name: Performance and load testing
        run: |
          echo "=== Performance Testing ==="
          
          # Basic load testing
          if command -v hey &> /dev/null; then
            hey -n 100 -c 10 http://localhost:8000/health
          else
            echo "Hey not available, skipping load tests"
          fi
          
      - name: Security scanning
        run: |
          echo "=== Security Scanning ==="
          
          # Basic security checks
          if [ -f requirements.txt ]; then
            pip install safety
            safety check -r requirements.txt
          fi
          
      - name: Cleanup test infrastructure
        if: always()
        run: |
          echo "=== Cleaning up Test Infrastructure ==="
          docker-compose -f docker-compose.test.yml down -v --remove-orphans

  # ==========================================
  # PARALLEL SHARD EXECUTION
  # Advanced parallel testing with sharding
  # ==========================================
  
  parallel-shard-tests:
    name: Parallel Shard Tests
    needs: pre-commit-tests
    if: github.event_name == 'push' || inputs.force_full_tests
    strategy:
      matrix:
        shard: [0, 1, 2, 3, 4, 5]
        include:
          - shard: 0
            name: "core-backend"
            focus: "backend"
          - shard: 1
            name: "auth-service" 
            focus: "auth"
          - shard: 2
            name: "frontend"
            focus: "frontend"
          - shard: 3
            name: "api-integration"
            focus: "api"
          - shard: 4
            name: "websocket"
            focus: "websocket"
          - shard: 5
            name: "database"
            focus: "database"
      fail-fast: false
      
    uses: ./.github/workflows/unified-test-runner.yml
    with:
      test_level: integration
      strategy: matrix
      timeout_minutes: 15
      enable_real_services: true
      shard_index: ${{ matrix.shard }}
      total_shards: 6
    secrets: inherit

  # ==========================================
  # PERFORMANCE AND MONITORING
  # Performance metrics collection
  # ==========================================
  
  performance-monitoring:
    name: Performance Monitoring
    needs: [pr-validation-tests, main-branch-tests]
    if: always() && (needs.pr-validation-tests.result == 'success' || needs.main-branch-tests.result == 'success')
    runs-on: warp-custom-default
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Collect performance metrics
        run: |
          echo "=== Collecting Performance Metrics ==="
          
          # Create performance report
          cat > performance_report.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "workflow_run_id": "${{ github.run_id }}",
            "event": "${{ github.event_name }}",
            "ref": "${{ github.ref }}",
            "metrics": {
              "pre_commit_duration": "estimated",
              "pr_validation_duration": "estimated",
              "test_success_rate": "calculated from results"
            }
          }
          EOF
          
          echo "Performance metrics collected"
          
      - name: Upload performance data
        uses: actions/upload-artifact@v4
        with:
          name: performance-metrics-${{ github.run_id }}
          path: performance_report.json
          retention-days: 30

  # ==========================================
  # FAILURE ANALYSIS AND REPORTING
  # Advanced failure handling and debugging
  # ==========================================
  
  failure-analysis:
    name: Failure Analysis
    needs: [pre-commit-tests, pr-validation-tests, main-branch-tests, deploy-readiness-tests, parallel-shard-tests]
    if: always() && contains(needs.*.result, 'failure')
    runs-on: warp-custom-default
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Analyze failures
        run: |
          echo "=== Failure Analysis ==="
          
          # Collect failure information
          mkdir -p failure_analysis
          
          echo "{
            \"workflow_run_id\": \"${{ github.run_id }}\",
            \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",
            \"failed_jobs\": {
              \"pre_commit\": \"${{ needs.pre-commit-tests.result }}\",
              \"pr_validation\": \"${{ needs.pr-validation-tests.result }}\",
              \"main_branch\": \"${{ needs.main-branch-tests.result }}\",
              \"deploy_readiness\": \"${{ needs.deploy-readiness-tests.result }}\",
              \"parallel_shards\": \"${{ needs.parallel-shard-tests.result }}\"
            },
            \"analysis\": {
              \"primary_failure\": \"to_be_determined\",
              \"recommended_action\": \"check_logs_and_artifacts\"
            }
          }" > failure_analysis/failure_summary.json
          
          echo "Failure analysis completed"
          
      - name: Generate debugging guide
        run: |
          cat > failure_analysis/debugging_guide.md << 'EOF'
          # Debugging Guide for CI/CD Pipeline Failures
          
          ## Quick Checks
          1. Check the **workflow summary** for overall status
          2. Review **failed job logs** for specific error messages  
          3. Download **test artifacts** for detailed reports
          4. Check **service logs** if integration tests failed
          
          ## Common Issues
          - **Pre-commit failures**: Code quality issues (formatting, linting)
          - **Test failures**: Check test logs and coverage reports
          - **Service failures**: Database or service connectivity issues
          - **Timeout issues**: Tests taking too long, check resource usage
          
          ## Recovery Actions
          1. Fix code issues and push new commits
          2. Re-run failed jobs if transient
          3. Check service dependencies and infrastructure
          4. Contact maintainers if persistent issues
          EOF
          
      - name: Upload failure analysis
        uses: actions/upload-artifact@v4
        with:
          name: failure-analysis-${{ github.run_id }}
          path: failure_analysis/
          retention-days: 14
          
      - name: Create failure issue (if on main)
        if: github.ref == 'refs/heads/main'
        uses: actions/github-script@v7
        with:
          script: |
            const title = `CI/CD Pipeline Failure - Run ${{ github.run_id }}`;
            const body = `## ðŸš¨ CI/CD Pipeline Failure
            
            **Workflow Run:** [#${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            **Commit:** ${{ github.sha }}
            **Branch:** ${{ github.ref }}
            
            ### Failed Jobs
            - Pre-commit: ${{ needs.pre-commit-tests.result }}
            - PR Validation: ${{ needs.pr-validation-tests.result }}  
            - Main Branch: ${{ needs.main-branch-tests.result }}
            - Deploy Readiness: ${{ needs.deploy-readiness-tests.result }}
            - Parallel Shards: ${{ needs.parallel-shard-tests.result }}
            
            ### Next Steps
            1. Review the [workflow logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            2. Download test artifacts for detailed analysis
            3. Check the failure analysis report
            
            **Auto-generated by CI/CD Pipeline**`;
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['ci-failure', 'bug', 'priority-high']
            });

  # ==========================================
  # DEPLOYMENT INTEGRATION
  # Connect to existing deployment workflows
  # ==========================================
  
  trigger-deployment:
    name: Trigger Deployment
    needs: [deploy-readiness-tests]
    if: |
      needs.deploy-readiness-tests.result == 'success' &&
      github.ref == 'refs/heads/main' &&
      github.event_name == 'push'
    uses: ./.github/workflows/deploy-staging.yml
    with:
      environment: staging
      trigger_context: 'ci-cd-pipeline'
      skip_tests: true  # Tests already passed
    secrets: inherit

  # ==========================================
  # FINAL REPORTING AND NOTIFICATIONS
  # Comprehensive reporting with metrics
  # ==========================================
  
  final-report:
    name: Final CI/CD Report
    needs: [pre-commit-tests, pr-validation-tests, main-branch-tests, deploy-readiness-tests, parallel-shard-tests, performance-monitoring]
    if: always()
    runs-on: warp-custom-default
    timeout-minutes: 5
    
    steps:
      - name: Generate comprehensive report
        run: |
          echo "=== Generating Final CI/CD Report ==="
          
          # Calculate overall status
          OVERALL_STATUS="success"
          CRITICAL_FAILURES=0
          
          # Check critical job results
          if [[ "${{ needs.pre-commit-tests.result }}" == "failure" ]]; then
            OVERALL_STATUS="failure"
            CRITICAL_FAILURES=$((CRITICAL_FAILURES + 1))
          fi
          
          if [[ "${{ needs.pr-validation-tests.result }}" == "failure" ]]; then
            OVERALL_STATUS="failure" 
            CRITICAL_FAILURES=$((CRITICAL_FAILURES + 1))
          fi
          
          if [[ "${{ needs.main-branch-tests.result }}" == "failure" ]]; then
            OVERALL_STATUS="failure"
            CRITICAL_FAILURES=$((CRITICAL_FAILURES + 1))
          fi
          
          # Generate report
          cat > ci_cd_report.json << EOF
          {
            "workflow_run_id": "${{ github.run_id }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "event": "${{ github.event_name }}",
            "ref": "${{ github.ref }}",
            "overall_status": "$OVERALL_STATUS",
            "critical_failures": $CRITICAL_FAILURES,
            "stages": {
              "pre_commit": {
                "status": "${{ needs.pre-commit-tests.result }}",
                "duration": "~30s",
                "purpose": "Quick validation"
              },
              "pr_validation": {
                "status": "${{ needs.pr-validation-tests.result }}",
                "duration": "~5min", 
                "purpose": "PR integration testing"
              },
              "main_branch": {
                "status": "${{ needs.main-branch-tests.result }}",
                "duration": "~15min",
                "purpose": "Comprehensive testing"
              },
              "deploy_readiness": {
                "status": "${{ needs.deploy-readiness-tests.result }}",
                "duration": "~30min",
                "purpose": "E2E and deployment validation"
              },
              "parallel_shards": {
                "status": "${{ needs.parallel-shard-tests.result }}",
                "duration": "~15min",
                "purpose": "Parallel focused testing"
              }
            }
          }
          EOF
          
          echo "Final report generated"
          
      - name: Update commit status
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const overallStatus = '${{ needs.pre-commit-tests.result == 'success' && (needs.pr-validation-tests.result == 'success' || needs.pr-validation-tests.result == 'skipped') && 'success' || 'failure' }}';
            
            const description = overallStatus === 'success' ? 
              'CI/CD pipeline completed successfully' : 
              'CI/CD pipeline failed - check logs for details';
            
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: overallStatus,
              context: 'ci-cd-pipeline',
              description: description,
              target_url: `${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}`
            });
            
      - name: Create PR summary comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const preCommitStatus = '${{ needs.pre-commit-tests.result }}';
            const prValidationStatus = '${{ needs.pr-validation-tests.result }}';
            const overallStatus = preCommitStatus === 'success' && (prValidationStatus === 'success' || prValidationStatus === 'skipped') ? 'success' : 'failure';
            
            const statusIcon = overallStatus === 'success' ? 'âœ…' : 'âŒ';
            const preCommitIcon = preCommitStatus === 'success' ? 'âœ…' : 'âŒ';
            const prValidationIcon = prValidationStatus === 'success' ? 'âœ…' : prValidationStatus === 'skipped' ? 'â­ï¸' : 'âŒ';
            
            const body = `## ${statusIcon} CI/CD Pipeline Results
            
            ### ðŸš€ Pipeline Stages
            
            | Stage | Status | Duration | Purpose |
            |-------|--------|----------|---------|
            | Pre-commit | ${preCommitIcon} ${preCommitStatus} | ~30s | Code quality & smoke tests |
            | PR Validation | ${prValidationIcon} ${prValidationStatus} | ~5min | Integration testing |
            
            ### ðŸ“Š Summary
            - **Overall Status:** ${overallStatus.toUpperCase()}
            - **Event:** ${{ github.event_name }}
            - **Workflow:** [View Details](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            
            ${overallStatus === 'failure' ? '### âŒ Action Required\nSome stages failed. Please review the logs and fix any issues before merging.' : '### âœ… Ready to Merge\nAll required checks have passed successfully.'}
            
            ---
            *Generated by CI/CD Pipeline v1.0*`;
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
            
      - name: Upload final report
        uses: actions/upload-artifact@v4
        with:
          name: ci-cd-final-report-${{ github.run_id }}
          path: ci_cd_report.json
          retention-days: 30
          
      - name: Generate workflow summary
        run: |
          echo "## ðŸŽ¯ CI/CD Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow Run:** ${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY
          echo "**Event:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Stage Results" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status | Duration |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|----------|" >> $GITHUB_STEP_SUMMARY
          echo "| Pre-commit | ${{ needs.pre-commit-tests.result }} | ~30s |" >> $GITHUB_STEP_SUMMARY
          echo "| PR Validation | ${{ needs.pr-validation-tests.result || 'skipped' }} | ~5min |" >> $GITHUB_STEP_SUMMARY
          echo "| Main Branch | ${{ needs.main-branch-tests.result || 'skipped' }} | ~15min |" >> $GITHUB_STEP_SUMMARY
          echo "| Deploy Readiness | ${{ needs.deploy-readiness-tests.result || 'skipped' }} | ~30min |" >> $GITHUB_STEP_SUMMARY
          echo "| Parallel Shards | ${{ needs.parallel-shard-tests.result || 'skipped' }} | ~15min |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Pipeline completed at:** $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_STEP_SUMMARY