{
  "timestamp": "2025-08-14T16:56:15.898626",
  "level": "all",
  "metrics": {
    "total_tests": 1,
    "passed": 0,
    "failed": 0,
    "coverage": null
  },
  "results": {
    "backend": {
      "status": "failed",
      "duration": 57.26948547363281,
      "exit_code": 2,
      "output": "Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: 8\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -v -n 8 -x --maxfail=1 --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 --html=reports/tests/report.html --self-contained-html --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings\n================================================================================\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 8/8 workers\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m________ ERROR collecting app/tests/core/test_type_validation_part2.py ________\u001b[0m\nImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\core\\test_type_validation_part2.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\tests\\core\\test_type_validation_part2.py:19: in <module>\n    from app.core.exceptions_base import ValidationError as NetraValidationError\nE   ImportError: cannot import name 'ValidationError' from 'app.core.exceptions_base' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\core\\exceptions_base.py)\n- Generated html report: file:///C:/Users/antho/OneDrive/Desktop/Netra/netra-core-generation-1/reports/tests/report.html -\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app/tests/core/test_type_validation_part2.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 37.94s\u001b[0m\u001b[31m ==============================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 55.81s\n\n[Report] HTML Report: reports/tests/report.html\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\n",
      "test_counts": {
        "total": 1,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 1,
        "test_files": 0
      },
      "coverage": null,
      "test_details": []
    },
    "frontend": {
      "status": "failed",
      "duration": 3.7886171340942383,
      "exit_code": 1,
      "output": "================================================================================\nNETRA AI PLATFORM - FRONTEND TEST RUNNER\n================================================================================\n\n================================================================================\nRunning Cypress E2E Tests\n--------------------------------------------------------------------------------\n[WARNING] Frontend dev server is not running. Starting it...\n\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\scripts\\test_frontend.py\", line 560, in <module>\n    main()\n  File \"C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\scripts\\test_frontend.py\", line 519, in main\n    test_result = run_cypress_tests(args, isolation_manager)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\scripts\\test_frontend.py\", line 207, in run_cypress_tests\n    start_frontend()\n  File \"C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\scripts\\test_frontend.py\", line 279, in start_frontend\n    subprocess.Popen(\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\subprocess.py\", line 1026, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0,
        "test_files": 0
      },
      "coverage": null,
      "test_details": []
    },
    "e2e": {
      "status": "failed",
      "duration": 0,
      "exit_code": 1,
      "output": "",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      },
      "coverage": null
    },
    "overall": {
      "status": "failed",
      "start_time": 1755215714.824899,
      "end_time": 1755215775.8941247
    }
  }
}