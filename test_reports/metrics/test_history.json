{
  "runs": [
    {
      "timestamp": "2025-08-17T18:03:07.570931",
      "level": "agents",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 22.132052659988403,
          "exit_code": 2,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: agent\n  Parallel: 4\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/agents app/tests/services/agents app/tests/services/apex_optimizer_agent -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n4 workers [791 items]\n\nscheduling tests via LoadScheduling\n\napp\\tests\\agents\\test_agent_e2e_critical_collab.py::TestAgentE2ECriticalCollaboration::test_7_authentication_and_authorization \napp\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestAnalysisEngine::test_identify_outliers_zscore_no_variance <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py::TestDataSubAgentProcessing::test_process_with_cache_different_keys \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_insufficient_data \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestAnalysisEngine::test_identify_outliers_zscore_no_variance <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py \napp\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestAnalysisEngine::test_identify_outliers_invalid_method <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestAnalysisEngine::test_identify_outliers_invalid_method <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py \napp\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestDataSubAgentBasic::test_initialization <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[31mERROR\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestDataSubAgentBasic::test_initialization <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_insufficient_data \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_no_time_variation \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_no_time_variation \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_increasing \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_increasing \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_decreasing \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_decreasing \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_weak \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_weak \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_insufficient_data \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_insufficient_data \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py::TestDataSubAgentProcessing::test_process_with_cache_different_keys \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_insufficient_hourly_coverage \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_insufficient_hourly_coverage \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_with_pattern \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py::TestDataSubAgentProcessing::test_process_and_stream \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_with_pattern \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_no_pattern \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_no_pattern \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_insufficient_data \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_insufficient_data \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_iqr_method \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_iqr_method \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_zscore_method \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_zscore_method \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_zscore_no_variance \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_zscore_no_variance \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_invalid_method \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_invalid_method \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_analysis.py::TestDataSubAgentAnalysis::test_analyze_performance_metrics_no_data \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[31mERROR\u001b[0m app\\tests\\agents\\test_agent_e2e_critical_collab.py::TestAgentE2ECriticalCollaboration::test_7_authentication_and_authorization \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py::TestDataSubAgentProcessing::test_process_and_stream \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_analysis.py::TestDataSubAgentAnalysis::test_analyze_performance_metrics_no_data Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 93\n\n================================================================================\n\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m_________ ERROR at setup of TestDataSubAgentBasic.test_initialization _________\u001b[0m\n[gw1] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\nfile C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py, line 15\n      def test_initialization(self, mock_dependencies):\nE       fixture 'mock_dependencies' not found\n>       available fixtures: _session_faker, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, client, cov, db_session, doctest_namespace, event_loop, extra, extras, faker, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, real_agent_setup, real_llm_manager, real_tool_dispatcher, real_websocket_manager, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, setup_real_infrastructure, test_engine, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\nC:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py:15\n\u001b[31m\u001b[1m_ ERROR at setup of TestAgentE2ECriticalCollaboration.test_7_authentication_and_authorization _\u001b[0m\n[gw0] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\agents\\test_agent_e2e_critical_setup.py\u001b[0m:128: in setup_agent_infrastructure\n    \u001b[0msupervisor = \u001b[96mself\u001b[39;49;00m._create_supervisor_with_patches(db_session, llm_manager, websocket_manager, tool_dispatcher)\u001b[90m\u001b[39;49;00m\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\tests\\agents\\test_agent_e2e_critical_setup.py\u001b[0m:108: in _create_supervisor_with_patches\n    \u001b[0m\u001b[94mwith\u001b[39;49;00m patch.object(state_persistence_service, \u001b[33m'\u001b[39;49;00m\u001b[33mget_thread_context\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, mock_get_context):\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31m..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py\u001b[0m:1458: in __enter__\n    \u001b[0moriginal, local = \u001b[96mself\u001b[39;49;00m.get_original()\u001b[90m\u001b[39;49;00m\n                      ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31m..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py\u001b[0m:1431: in get_original\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AttributeError: <app.services.state_persistence.StatePersistenceService object at 0x000001B6E6EE9E20> does not have the attribute 'get_thread_context'\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:03:02.981 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n2025-08-17 18:03:02.982 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n================================== FAILURES ===================================\n\u001b[31m\u001b[1m_____________ TestDataSubAgentProcessing.test_process_and_stream ______________\u001b[0m\n[gw3] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py\u001b[0m:130: in test_process_and_stream\n    \u001b[0m\u001b[94massert\u001b[39;49;00m parsed[\u001b[33m\"\u001b[39;49;00m\u001b[33mprocessed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n           ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   KeyError: 'processed'\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:03:03.188 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:03:04.356 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m______ TestDataSubAgentAnalysis.test_analyze_performance_metrics_no_data ______\u001b[0m\n[gw2] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_analysis.py\u001b[0m:18: in test_analyze_performance_metrics_no_data\n    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m agent._analyze_performance_metrics(\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\data_sub_agent\\delegation.py\u001b[0m:80: in _analyze_performance_metrics\n    \u001b[0m\u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96manalysis_operations\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m AnalysisOperations\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\data_sub_agent\\analysis_operations.py\u001b[0m:10: in <module>\n    \u001b[0m\u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96musage_pattern_analyzer\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m UsagePatternAnalyzer\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\data_sub_agent\\usage_pattern_analyzer.py\u001b[0m:8: in <module>\n    \u001b[0m\u001b[94mclass\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[92mUsagePatternAnalyzer\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\data_sub_agent\\usage_pattern_analyzer.py\u001b[0m:102: in UsagePatternAnalyzer\n    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_find_peak_daily_usage\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, daily_patterns: Dict) -> Tuple[\u001b[96mint\u001b[39;49;00m, Dict]:\u001b[90m\u001b[39;49;00m\n                                                              ^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   NameError: name 'Tuple' is not defined\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:03:03.200 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n2025-08-17 18:03:03.202 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:03:04.406 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mFAILED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py::\u001b[1mTestDataSubAgentProcessing::test_process_and_stream\u001b[0m - KeyError: 'processed'\n\u001b[31mFAILED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_analysis.py::\u001b[1mTestDataSubAgentAnalysis::test_analyze_performance_metrics_no_data\u001b[0m - NameError: name 'Tuple' is not defined\n\u001b[31mERROR\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive.py::\u001b[1mTestDataSubAgentBasic::test_initialization\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\agents\\test_agent_e2e_critical_collab.py::\u001b[1mTestAgentE2ECriticalCollaboration::test_7_authentication_and_authorization\u001b[0m - AttributeError: <app.services.state_persistence.StatePersistenceService object at 0x000001B6E6EE9E20> does not have the attribute 'get_thread_context'\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 4 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m=================== \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m17 passed\u001b[0m, \u001b[31m\u001b[1m2 errors\u001b[0m\u001b[31m in 13.90s\u001b[0m\u001b[31m ===================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 21.05s\n================================================================================\n\n2025-08-17 18:02:49.171 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 18:02:49.172 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 18:02:49.172 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 18:02:49.173 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 18:02:49.173 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 18:02:49.173 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 18:02:49.173 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 18:02:49.173 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 18:02:49.173 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 18:02:49.173 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 18:02:49.173 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 18:02:49.173 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 18:02:49.174 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 18:02:49.174 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 18:02:49.174 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 18:02:49.174 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 18:02:49.175 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 18:02:49.175 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 18:02:49.176 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 18:02:49.176 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 18:02:49.176 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 18:02:49.176 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 18:02:49.176 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 18:02:49.176 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 18:02:49.176 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 18:02:49.195 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 18:02:49.195 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 18:02:49.195 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 18:02:49.212 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 18:02:49.427 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 18:02:49.604 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 18:02:50.431 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 18:02:50.496 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 18:02:50.670 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 18:02:50.740 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 18:02:51.296 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:02:51.331 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:02:51.396 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 18:02:51.401 | INFO     | app.services.quality_gate.quality_gate_core:__init__:28 | Quality Gate Service initialized\n2025-08-17 18:02:51.402 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 18:02:51.402 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n--- Logging error in Loguru Handler #2 ---\n--- Logging error in Loguru Handler #2 ---\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=10, microseconds=221378), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=16608, name='MainProcess'), 'thread': (id=41848, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 3, 5, 241974, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nRecord was: {'elapsed': datetime.timedelta(seconds=9, microseconds=287280), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=42620, name='MainProcess'), 'thread': (id=27064, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 3, 5, 241974, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=9, microseconds=66049), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=16984, name='MainProcess'), 'thread': (id=45472, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 3, 5, 241974, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nRecord was: {'elapsed': datetime.timedelta(seconds=8, microseconds=955443), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=34440, name='MainProcess'), 'thread': (id=51240, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 3, 5, 241974, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nTraceback (most recent call last):\nValueError: I/O operation on closed file.\n--- End of logging error ---\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=18, microseconds=724529), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=8792, name='MainProcess'), 'thread': (id=53500, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 3, 6, 844934, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 21,
            "passed": 17,
            "failed": 2,
            "skipped": 0,
            "errors": 2,
            "import_errors": 0,
            "test_files": 5,
            "status": "failed"
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755478965.3895707,
          "end_time": 1755478987.5382085
        }
      },
      "summary": {
        "total": 21,
        "passed": 17,
        "failed": 2,
        "skipped": 0,
        "errors": 2
      }
    },
    {
      "timestamp": "2025-08-17T18:03:44.761492",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 53.78305006027222,
          "exit_code": 2,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n4 workers [2484 items]\n\nscheduling tests via LoadScheduling\n\napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_websocket_disconnect_handling \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_compliance_aware_generation \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_search_records_with_filters \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_compliance_aware_generation \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_cost_optimized_generation \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_cost_optimized_generation \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_versioned_corpus_generation \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_versioned_corpus_generation \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_temporal_patterns \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_temporal_patterns \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_tool_invocations \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_websocket_disconnect_handling \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_tool_invocations \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_concurrent_agent_execution \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_errors \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_errors \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_concurrent_agent_execution \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_string_input \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_trace_hierarchies \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_trace_hierarchies \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_string_input \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_domain_specific \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_dict_input \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_domain_specific \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_distribution \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_dict_input \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceBasic::test_run_agent_with_request_model \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_distribution \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceBasic::test_run_agent_with_request_model \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_custom_tools \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_service_initialization \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_custom_tools \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_incremental \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_service_initialization \napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_not_found \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_execution_basic \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_not_found \napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_error \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_search_records_with_filters \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_execution_basic \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_count_records_success \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_error \napp\\tests\\services\\apex_optimizer_agent\\test_tool_builder.py::test_tool_builder_and_dispatcher \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_with_model_dump_fallback \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_count_records_success \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_with_model_dump_fallback \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_start_agent \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_get_summary_stats_success \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_get_summary_stats_success \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_start_agent \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_success \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_user_message \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_success \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_user_message \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_with_duration \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_thread_operations \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_incremental \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_from_corpus \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\test_tool_builder.py::test_tool_builder_and_dispatcher \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_with_duration \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_from_corpus \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_advanced_optimization_for_core_function.py::test_advanced_optimization_for_core_function_tool \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_with_corpus \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_thread_operations \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_advanced_optimization_for_core_function.py::test_advanced_optimization_for_core_function_tool \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_stop_agent \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_basic \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_with_corpus \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_synthetic \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_failure \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_basic \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_full \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_synthetic \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_all_workload_types \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_full \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_validation_missing_required \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_success \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_all_workload_types \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_schema_validation \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_validation_missing_required \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_stop_agent \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_unknown_type \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_dict_conversion \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_dict_conversion \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_schema_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_json_serialization \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_statistical_distribution_validation \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_success \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_failure \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_json_serialization \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_edge_cases \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_edge_cases \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_unknown_type \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_instantiation \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_instantiation \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_json_error \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_get_metadata \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_failure \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_get_metadata \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_wrapper \napp\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_measures_duration \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_json_error \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_statistical_distribution_validation \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_measures_duration \napp\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_without_context \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_referential_integrity_validation \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_wrapper \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_without_context \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_failure \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_disconnect_handling \napp\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_create_audit_logger_factory \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_referential_integrity_validation \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_failure \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_create_audit_logger_factory \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_temporal_consistency_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_concrete_tool_run_method \napp\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_end_to_end_audit_workflow \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_disconnect_handling \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_temporal_consistency_validation \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_concrete_tool_run_method \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_completeness_validation \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_concurrent_agent_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_llm_name \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_llm_name \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_end_to_end_audit_workflow \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_multiple_executions \napp\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_large_result_data_handling \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_concurrent_agent_execution \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_completeness_validation \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_anomaly_detection_in_generated_data \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_string_input \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_multiple_executions \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_anomaly_detection_in_generated_data \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_concurrent_execution \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_string_input \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_correlation_preservation \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_dict_input \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_large_result_data_handling \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_concurrent_execution \napp\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_metadata_edge_cases \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_without_metadata_attribute \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_dict_input \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_without_metadata_attribute \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceBasic::test_run_agent_with_request_model \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_metadata_edge_cases \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_inheritance_chain \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_correlation_preservation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_initialization \n[gw2]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_inheritance_chain \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_quality_metrics_calculation \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_quality_metrics_calculation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_complex_kwargs \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_diversity_validation \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceBasic::test_run_agent_with_request_model \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_failure_recovery \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_diversity_validation \n[gw2]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_complex_kwargs \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_initialization \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_validation_report_generation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_exception_types \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_validation_report_generation \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_get_circuit_breaker \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_get_circuit_breaker \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_operation_tracking_context_manager \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_circuit_breaker_functionality \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_circuit_breaker_functionality \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_generate_with_anomalies_method \n[gw2]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_exception_types \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_generate_with_anomalies_method \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_async_delay \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_detect_anomalies \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_operation_tracking_context_manager \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_detect_anomalies \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_quality_assessment_recording \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_quality_assessment_recording \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_no_data \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_snapshot_generation \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_no_data \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_invalid_data \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_invalid_data \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_corpus_unavailable_fallback \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_snapshot_generation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_export_json \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_export_json \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_time_series_data_retrieval \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_time_series_data_retrieval \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_comprehensive_report_generation \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_comprehensive_report_generation \n[gw2]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_async_delay \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_status \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_basic_functionality \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_status \n[gw2]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_basic_functionality \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_monitoring_lifecycle \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_empty_logs \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_monitoring_lifecycle \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_empty_logs \napp\\tests\\services\\test_corpus_metrics.py::TestCoreMetricsCollector::test_operation_timing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_single_log \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_single_log \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_failure_recovery \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_large_costs \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCoreMetricsCollector::test_operation_timing \napp\\tests\\services\\test_corpus_metrics.py::TestQualityMetricsCollector::test_quality_trend_tracking \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_timeout_handling \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_large_costs \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestQualityMetricsCollector::test_quality_trend_tracking \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_zero_costs \napp\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_json_export \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_json_export \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_zero_costs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_fractional_cents \napp\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_prometheus_export \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_prometheus_export \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_fractional_cents \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_status_enum \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_exception_handling \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_status_enum \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_exception_handling \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_schema \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_async_execution \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_schema \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_create_schema \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_create_schema \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_service_import \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_service_import \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_index_single_document \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_index_single_document \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_batch_indexing_pipeline \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_async_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_concurrent_logs \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_timeout_handling \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_batch_indexing_pipeline \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_resource_cleanup_on_error \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_reindex_corpus_with_new_model \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_reindex_corpus_with_new_model \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_concurrent_logs \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_incremental_indexing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_negative_costs \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_resource_cleanup_on_error \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_circuit_breaker_pattern \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_negative_costs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_mixed_model_types \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_incremental_indexing \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_document_deduplication \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_mixed_model_types \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_partial_failure \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_partial_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_rounding_edge_cases \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_rounding_edge_cases \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_reduction_quality_preservation.py::test_cost_reduction_quality_preservation_tool \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_circuit_breaker_pattern \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_graceful_degradation_under_load \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_reduction_quality_preservation.py::test_cost_reduction_quality_preservation_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_simulation_for_increased_usage.py::test_cost_simulation_for_increased_usage_tool \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_graceful_degradation_under_load \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_simulation_for_increased_usage.py::test_cost_simulation_for_increased_usage_tool \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_error_propagation_and_isolation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_kv_cache_optimization_audit.py::test_kv_cache_optimization_audit_tool \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_kv_cache_optimization_audit.py::test_kv_cache_optimization_audit_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_basic_functionality \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_basic_functionality \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_empty_logs \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_empty_logs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_single_log \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_single_log \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_high_latency_values \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_high_latency_values \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_zero_latency \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_zero_latency \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_sub_millisecond_latency \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_sub_millisecond_latency \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_exception_handling \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_document_deduplication \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_semantic_search \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_exception_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_async_execution \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_semantic_search \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_hybrid_search \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_hybrid_search \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_relevance_feedback \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_error_propagation_and_isolation \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_thread_history_handling \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_relevance_feedback \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_search_result_reranking \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_async_execution \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_thread_history_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_large_dataset \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_search_result_reranking \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_create_thread_handling \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_create_corpus_with_validation \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_create_thread_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_switch_thread_handling \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_switch_thread_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_delete_thread_handling \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_delete_thread_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_list_threads_handling \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_list_threads_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_all_thread_operations_batch \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_all_thread_operations_batch \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_websocket_message_handling_json_error \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_websocket_message_handling_json_error \napp\\tests\\services\\test_apex_optimizer_tool_selection_part1.py::TestApexOptimizerToolSelection::test_tool_selection_cost_optimization \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part1.py::TestApexOptimizerToolSelection::test_tool_selection_cost_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_latency_optimization \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_latency_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_cache_optimization \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_cache_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_model_analysis \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_model_analysis \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_multi_objective \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_multi_objective \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_empty_query \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_empty_query \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_llm_failure \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_llm_failure \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_invalid_json_response \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_invalid_json_response \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_custom_tool_selection \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_custom_tool_selection \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_simple_tool_chain_execution \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_large_dataset \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_varied_latencies \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_varied_latencies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_partial_failure \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_partial_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_edge_case_rounding \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_edge_case_rounding \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_negative_latencies \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_negative_latencies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_mixed_response_formats \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_mixed_response_formats \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_extreme_values \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_extreme_values \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_concurrent_execution_timing \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_simple_tool_chain_execution \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_conditional_tool_chaining \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_corpus_unavailable_fallback \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_clickhouse_connection_recovery \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_clickhouse_connection_recovery \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_conditional_tool_chaining \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_parallel_tool_execution \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_concurrent_execution_timing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_metadata \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_metadata \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_complete_workflow \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_complete_workflow \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_define_optimization_goals \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_parallel_tool_execution \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_define_optimization_goals \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_error_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_analyze_trade_offs \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_analyze_trade_offs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_propose_balanced_optimizations \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_propose_balanced_optimizations \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_simulate_multi_objective_impact \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_simulate_multi_objective_impact \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_with_various_kwargs \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_with_various_kwargs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_method_execution_order \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_method_execution_order \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_method_failure_propagation \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_method_failure_propagation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_concurrent_execution \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_concurrent_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_async_behavior_timing \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_create_corpus_with_validation \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_update_corpus_metadata \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_update_corpus_metadata \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestIndexOptimization::test_index_performance_monitoring \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestIndexOptimization::test_index_performance_monitoring \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_redis_connection_failure_recovery \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_async_behavior_timing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_execute_wrapper_integration \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_redis_connection_failure_recovery \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_retry_on_failure \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_execute_wrapper_integration \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_inheritance \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_inheritance \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_retry_on_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_context_parameter_passing \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_recover_from_partial_batch_failure \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_context_parameter_passing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_new_model_effectiveness_analysis.py::test_new_model_effectiveness_analysis_tool \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_recover_from_partial_batch_failure \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_new_model_effectiveness_analysis.py::test_new_model_effectiveness_analysis_tool \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_database_connection_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_empty_policies \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_empty_policies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_single_policy \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_database_connection_failure \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_single_policy \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_error_handling \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_search_fallback_on_vector_store_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_multiple_policies_only_simulates_first \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_cycle_prevention \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_multiple_policies_only_simulates_first \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_search_fallback_on_vector_store_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_simulation_failure \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_simulation_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_with_complex_policy \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_with_complex_policy \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_validation \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_serialization \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_serialization \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_async_behavior \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_unexpected_error \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_async_behavior \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_tool_latency_optimization.py::test_tool_latency_optimization_tool \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_tool_latency_optimization.py::test_tool_latency_optimization_tool \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_unexpected_error \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_workflow_integration <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_isolation \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_workflow_integration <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_multi_component_interaction <- tests\\helpers\\shared_test_types.py \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_multi_component_interaction <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_end_to_end_data_flow <- tests\\helpers\\shared_test_types.py \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_end_to_end_data_flow <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_execution_cycle \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_execution_cycle \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_concurrent_schedule_execution \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_concurrent_schedule_execution \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_connection_failure_recovery <- tests\\helpers\\shared_test_types.py \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_connection_failure_recovery <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failure \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failure \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_retry_on_failure \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_retry_on_failure \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failures \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failures \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_isolation \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_agent_execution_failures \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_timeout_handling \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_agent_execution_failures \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_cycle_prevention \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_failures_during_execution \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_dynamic_tool_chaining \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_failures_during_execution \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_default_values \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_default_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_custom_values \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_custom_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_hourly \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_hourly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_daily \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_daily \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_weekly \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_weekly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly_invalid_day \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly_invalid_day \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_enabled_and_time_reached \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_enabled_and_time_reached \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_disabled \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_disabled \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_time_not_reached \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_time_not_reached \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_update_after_run \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_update_after_run \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleFrequencyEnum::test_schedule_frequency_values \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleFrequencyEnum::test_schedule_frequency_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleTimeBoundaries::test_schedule_time_calculations_across_boundaries \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleTimeBoundaries::test_schedule_time_calculations_across_boundaries \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_no_redis \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_no_redis \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_with_redis \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_with_redis \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_all_schedules \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_all_schedules \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_dynamic_tool_chaining \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_multiple_days \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_selection_performance \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_multiple_days \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_redis_errors \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_redis_errors \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_add_schedule \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_add_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_exists \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_not_exists \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule_not_exists \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule_not_exists \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status_with_run_history \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status_with_run_history \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_success \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_success \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_failure \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_failure \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_caching \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_caching \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_no_redis \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_no_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_significant_price_changes \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_significant_price_changes \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_new_models \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_new_models \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_no_significant_changes \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_no_significant_changes \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_error_handling \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_error_handling \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_with_redis \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_with_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_without_redis \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_without_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedules_created \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedules_created \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedule_configurations \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedule_configurations \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler_already_running \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler_already_running \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_stop_scheduler \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_stop_scheduler \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_execution \n[gw3]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_timeout_handling \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_execution \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_no_due_schedules \n[gw3]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_no_due_schedules \n[gw3]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_error_handling \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \n[gw3]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_handling \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_error_handling \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_disabled_schedules \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_handling \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_connection_loss_during_transaction \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_disabled_schedules \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_exists \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_exists \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_not_exists \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_not_exists \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_connection_loss_during_transaction \napp\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_generation_job_monitoring \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_deadlock_detection_and_retry \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_selection_performance \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_concurrent_tool_execution_scaling \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_deadlock_detection_and_retry \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_state_tracking \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_state_tracking \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_repository_operation_logging \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_repository_operation_logging \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_high_concurrency_transactions \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_concurrent_tool_execution_scaling \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_chain_optimization_performance \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_chain_optimization_performance \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_metrics_and_monitoring \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_high_concurrency_transactions \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_throughput_measurement \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_generation_job_monitoring \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_throughput_measurement \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_memory_usage_during_batch_operations \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_metrics_and_monitoring \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_load_balancing \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_load_balancing \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_resource_management \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_resource_management \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_get \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_get \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_post \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_post \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_other_method \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_other_method \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_post \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_post \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_get \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_get \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_other_method \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_other_method \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_create \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_create \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_bulk_create \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_bulk_create \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_by_id \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_by_id \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_many \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_many \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_update \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_update \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_delete \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_delete \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_soft_delete \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_soft_delete \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_pagination \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_pagination \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_successful_llm_call \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_successful_llm_call \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_circuit_breaker_opens \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_circuit_breaker_opens \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_structured_output_protection \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_structured_output_protection \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_health_check \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_health_check \napp\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_successful_db_query \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_successful_db_query \napp\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_memory_usage_during_batch_operations \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_latency_distribution \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_latency_distribution \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_deadlock_recovery_performance \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_deadlock_recovery_performance \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_connection_pool_stress \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_connection_pool_stress \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_successful_transaction \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_successful_transaction \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_rollback_on_exception \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_rollback_on_exception \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_with_external_session \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_with_external_session \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_repository_access \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_repository_access \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_session_lifecycle \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_session_lifecycle \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_nested_transactions \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_nested_transactions \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_error_handling \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_error_handling \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_new_session \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_new_session \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_existing_session \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_existing_session \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_valid \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_valid \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_invalid \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_invalid \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_financial \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_financial \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_different_industries \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_different_industries \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_synthetic_metrics \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_synthetic_metrics \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report_session_not_found \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report_session_not_found \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status_not_found \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status_not_found \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_submit_feedback \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_submit_feedback \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_track_demo_interaction \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_track_demo_interaction \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_analytics_summary \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_analytics_summary \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_demo_response \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_demo_response \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_error_handling_redis_failure \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_error_handling_redis_failure \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_google_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_google_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_openai_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_openai_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_anthropic_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_anthropic_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_generic_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_generic_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_fast_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_fast_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_creation <- tests\\services\\test_http_error.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_creation <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_without_response_data <- tests\\services\\test_http_error.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_without_response_data <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_inheritance <- tests\\services\\test_http_error.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_inheritance <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization_defaults <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization_defaults <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_google <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_google <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_openai <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_openai <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_anthropic <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_anthropic <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_health <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_health <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_generic <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_generic <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_with_base_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_with_base_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_absolute_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_absolute_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_no_base_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_no_base_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_none <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_none <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_override <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_override <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_new <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_new <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_reuse <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_reuse <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_closed_recreate <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_closed_recreate <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_session <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_no_session <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_no_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_already_closed_session <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_already_closed_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_new <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_new <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_existing <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_existing <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_fallback_response <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_fallback_response <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_success <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_success <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_circuit_open <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_circuit_open <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_json <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_json <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_text <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_text <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_json <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_json <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_text <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_text <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_error <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_error <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_get_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_get_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_post_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_post_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_put_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_put_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_delete_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_delete_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_success <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_success <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_error <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_error <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_no_base_url <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_no_base_url <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_success <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_success <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_failure <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_failure <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_circuit <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_circuit <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_connectivity <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_connectivity <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_recovering <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_recovering <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_healthy <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_healthy <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_retryable_client_inheritance <- tests\\services\\test_retryable_client.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_retryable_client_inheritance <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_get_with_retry <- tests\\services\\test_retryable_client.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_get_with_retry <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_post_with_retry <- tests\\services\\test_retryable_client.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_post_with_retry <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_manager_initialization <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_manager_initialization <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_resilient <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_resilient <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_retryable <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_retryable <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_existing <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_existing <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_empty <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_empty <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_with_clients <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_with_clients <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_empty <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_empty <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_with_clients <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_with_clients <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGetHTTPClient::test_get_http_client_context_manager <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGetHTTPClient::test_get_http_client_context_manager <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_exists <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_exists <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_singleton_behavior <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_singleton_behavior <- tests\\services\\test_http_client_manager.py Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 94\n\n================================================================================\n\n\n\n================================== FAILURES ===================================\n\u001b[31m\u001b[1m____________ TestErrorRecovery.test_clickhouse_connection_recovery ____________\u001b[0m\n[gw0] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\synthetic_data\\test_error_recovery.py\u001b[0m:57: in test_clickhouse_connection_recovery\n    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m recovery_service.ingest_with_retry(\u001b[90m\u001b[39;49;00m\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AttributeError: 'SyntheticDataService' object has no attribute 'ingest_with_retry'\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:03:33.523 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:03:33.668 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m_____________ TestAdminVisibility.test_generation_job_monitoring ______________\u001b[0m\n[gw2] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\synthetic_data\\test_admin_visibility.py\u001b[0m:33: in test_generation_job_monitoring\n    \u001b[0m\u001b[94massert\u001b[39;49;00m status[\u001b[33m\"\u001b[39;49;00m\u001b[33mstate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[33m\"\u001b[39;49;00m\u001b[33mrunning\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n           ^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   TypeError: 'NoneType' object is not subscriptable\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:03:34.913 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured stderr call -----------------------------\n2025-08-17 18:03:34.926 | ERROR    | app.ws_manager_messaging:_validate_dict_message:70 | Message validation failed: Invalid message type: generation:started\n2025-08-17 18:03:34.926 | INFO     | app.core.unified_logging:_emit_log:117 | Generation job 9c845f2b-4420-4c1f-9a00-f56520a770cf started\nC:\\Users\\antho\\miniconda3\\Lib\\email\\utils.py:51: RuntimeWarning: coroutine 'SupplyResearchScheduler._scheduler_loop' was never awaited\n  def _has_surrogates(s):\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:03:36.031 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m______ TestDatabaseClientCircuitBreaker.test_db_circuit_breaker_fallback ______\u001b[0m\n[gw1] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\test_circuit_breaker_integration.py\u001b[0m:180: in test_db_circuit_breaker_fallback\n    \u001b[0m\u001b[94massert\u001b[39;49;00m postgres_circuit.failure_count == \u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   assert 0 == 1\u001b[0m\n\u001b[1m\u001b[31mE    +  where 0 = <app.core.adaptive_circuit_breaker_core.AdaptiveCircuitBreaker object at 0x000001D7B24F59A0>.failure_count\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:03:37.529 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured stderr call -----------------------------\n2025-08-17 18:03:37.535 | WARNING  | app.core.adaptive_circuit_breaker_core:_transition_to_open:197 | Circuit breaker db_read transitioning to OPEN\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:03:37.699 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::\u001b[1mTestErrorRecovery::test_clickhouse_connection_recovery\u001b[0m - AttributeError: 'SyntheticDataService' object has no attribute 'ingest_with_retry'\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::\u001b[1mTestAdminVisibility::test_generation_job_monitoring\u001b[0m - TypeError: 'NoneType' object is not subscriptable\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::\u001b[1mTestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback\u001b[0m - assert 0 == 1\n +  where 0 = <app.core.adaptive_circuit_breaker_core.AdaptiveCircuitBreaker object at 0x000001D7B24F59A0>.failure_count\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 3 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m================= \u001b[31m\u001b[1m3 failed\u001b[0m, \u001b[32m389 passed\u001b[0m, \u001b[33m10 skipped\u001b[0m\u001b[31m in 39.63s\u001b[0m\u001b[31m ==================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 52.77s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\nC:\\Users\\antho\\miniconda3\\Lib\\site-packages\\_pytest\\runner.py:146: RuntimeWarning: coroutine 'ResearchExecutor.execute_scheduled_research' was never awaited\n  item.funcargs = None  # type: ignore[attr-defined]\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n2025-08-17 18:02:57.333 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 18:02:57.334 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 18:02:57.335 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 18:02:57.335 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 18:02:57.336 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 18:02:57.336 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 18:02:57.336 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 18:02:57.338 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 18:02:57.338 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 18:02:57.339 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 18:02:57.339 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 18:02:57.339 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 18:02:57.340 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 18:02:57.340 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 18:02:57.341 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 18:02:57.341 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 18:02:57.342 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 18:02:57.342 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 18:02:57.342 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 18:02:57.343 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 18:02:57.343 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 18:02:57.345 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 18:02:57.345 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 18:02:57.345 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 18:02:57.345 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 18:02:57.397 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 18:02:57.398 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 18:02:57.398 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 18:02:57.467 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 18:02:57.869 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 18:02:58.235 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 18:02:59.953 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 18:03:00.044 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 18:03:00.511 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 18:03:00.627 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 18:03:01.873 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:03:01.954 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:03:02.117 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 18:03:02.187 | INFO     | app.services.quality_gate.quality_gate_core:__init__:28 | Quality Gate Service initialized\n2025-08-17 18:03:02.187 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 18:03:02.188 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=33, microseconds=635202), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=54112, name='MainProcess'), 'thread': (id=19688, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 3, 42, 141266, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #1 ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=34, microseconds=387677), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=43116, name='MainProcess'), 'thread': (id=36920, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 3, 42, 142423, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nRecord was: {'elapsed': datetime.timedelta(seconds=33, microseconds=844276), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=43732, name='MainProcess'), 'thread': (id=13744, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 3, 42, 142423, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=33, microseconds=437508), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=32608, name='MainProcess'), 'thread': (id=25928, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 3, 42, 172488, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=49, microseconds=258519), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=56012, name='MainProcess'), 'thread': (id=44348, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 3, 43, 953461, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 402,
            "passed": 389,
            "failed": 3,
            "skipped": 10,
            "errors": 0,
            "import_errors": 0,
            "test_files": 48,
            "status": "failed"
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.1652669906616211,
          "exit_code": 2,
          "output": "\nusage: test_frontend.py [-h]\n                        [--category {unit,integration,components,hooks,store,websocket,auth,e2e,smoke}]\n                        [--keyword KEYWORD] [--e2e] [--cypress-open] [--watch]\n                        [--coverage] [--update-snapshots] [--lint] [--fix]\n                        [--type-check] [--build] [--check-deps]\n                        [--install-deps] [--verbose] [--isolation]\n                        [--cleanup-on-exit]\n                        [tests ...]\ntest_frontend.py: error: unrecognized arguments: --no-cov -x --maxfail=1\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "import_errors": 0,
            "test_files": 0,
            "status": "unknown"
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755478970.738529,
          "end_time": 1755479024.7219074
        }
      },
      "summary": {
        "total": 402,
        "passed": 389,
        "failed": 3,
        "skipped": 10,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T18:05:08.727168",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 51.4669451713562,
          "exit_code": 2,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n4 workers [2484 items]\n\nscheduling tests via LoadScheduling\n\napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_compliance_aware_generation \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_websocket_disconnect_handling \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_search_records_with_filters \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_compliance_aware_generation \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_cost_optimized_generation \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_cost_optimized_generation \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_versioned_corpus_generation \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_versioned_corpus_generation \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_temporal_patterns \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_websocket_disconnect_handling \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_concurrent_agent_execution \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_concurrent_agent_execution \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_string_input \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_string_input \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_temporal_patterns \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_tool_invocations \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_dict_input \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_tool_invocations \napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_not_found \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_dict_input \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_errors \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceBasic::test_run_agent_with_request_model \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_not_found \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_errors \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_trace_hierarchies \napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_error \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceBasic::test_run_agent_with_request_model \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_trace_hierarchies \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_service_initialization \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_search_records_with_filters \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_service_initialization \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_error \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_domain_specific \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_count_records_success \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_execution_basic \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_domain_specific \napp\\tests\\services\\apex_optimizer_agent\\test_tool_builder.py::test_tool_builder_and_dispatcher \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_execution_basic \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_distribution \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_count_records_success \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_with_model_dump_fallback \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_get_summary_stats_success \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_distribution \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_get_summary_stats_success \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_custom_tools \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_with_model_dump_fallback \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_custom_tools \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_success \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_start_agent \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_incremental \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_start_agent \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\test_tool_builder.py::test_tool_builder_and_dispatcher \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_success \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_user_message \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_with_duration \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_advanced_optimization_for_core_function.py::test_advanced_optimization_for_core_function_tool \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_advanced_optimization_for_core_function.py::test_advanced_optimization_for_core_function_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_basic \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_basic \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_full \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_with_duration \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_full \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_user_message \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_validation_missing_required \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_thread_operations \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_validation_missing_required \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_dict_conversion \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_dict_conversion \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_json_serialization \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_json_serialization \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_edge_cases \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_edge_cases \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_failure \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_thread_operations \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_instantiation \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_instantiation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_get_metadata \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_get_metadata \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_stop_agent \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_wrapper \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_success \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_success \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_failure \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_stop_agent \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_unknown_type \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_wrapper \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_failure \napp\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_measures_duration \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_unknown_type \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_failure \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_json_error \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_concrete_tool_run_method \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_incremental \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_measures_duration \napp\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_without_context \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_from_corpus \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_without_context \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_concrete_tool_run_method \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_json_error \napp\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_create_audit_logger_factory \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_llm_name \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_from_corpus \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_disconnect_handling \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_llm_name \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_create_audit_logger_factory \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_multiple_executions \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_with_corpus \napp\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_end_to_end_audit_workflow \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_with_corpus \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_synthetic \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_synthetic \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_disconnect_handling \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_multiple_executions \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_all_workload_types \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_all_workload_types \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_schema_validation \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_concurrent_agent_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_concurrent_execution \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_end_to_end_audit_workflow \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_concurrent_execution \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_schema_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_without_metadata_attribute \napp\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_large_result_data_handling \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_concurrent_agent_execution \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_statistical_distribution_validation \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_string_input \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_without_metadata_attribute \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_large_result_data_handling \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_string_input \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_inheritance_chain \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_inheritance_chain \napp\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_metadata_edge_cases \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_dict_input \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_complex_kwargs \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_complex_kwargs \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_metadata_edge_cases \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_exception_types \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_dict_input \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_statistical_distribution_validation \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_referential_integrity_validation \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceBasic::test_run_agent_with_request_model \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_initialization \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_referential_integrity_validation \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceBasic::test_run_agent_with_request_model \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_temporal_consistency_validation \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_initialization \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_exception_types \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_failure_recovery \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_async_delay \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_temporal_consistency_validation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_operation_tracking_context_manager \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_completeness_validation \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_completeness_validation \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_anomaly_detection_in_generated_data \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_anomaly_detection_in_generated_data \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_operation_tracking_context_manager \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_correlation_preservation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_quality_assessment_recording \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_quality_assessment_recording \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_correlation_preservation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_snapshot_generation \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_quality_metrics_calculation \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_quality_metrics_calculation \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_diversity_validation \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_diversity_validation \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_validation_report_generation \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_validation_report_generation \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_get_circuit_breaker \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_get_circuit_breaker \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_circuit_breaker_functionality \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_circuit_breaker_functionality \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_generate_with_anomalies_method \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_generate_with_anomalies_method \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_snapshot_generation \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_detect_anomalies \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_export_json \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_detect_anomalies \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_export_json \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_time_series_data_retrieval \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_no_data \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_time_series_data_retrieval \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_no_data \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_comprehensive_report_generation \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_invalid_data \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_invalid_data \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_corpus_unavailable_fallback \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_async_delay \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_comprehensive_report_generation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_basic_functionality \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_status \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_status \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_basic_functionality \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_monitoring_lifecycle \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_empty_logs \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_monitoring_lifecycle \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_empty_logs \napp\\tests\\services\\test_corpus_metrics.py::TestCoreMetricsCollector::test_operation_timing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_single_log \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_single_log \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_large_costs \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_large_costs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_zero_costs \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCoreMetricsCollector::test_operation_timing \napp\\tests\\services\\test_corpus_metrics.py::TestQualityMetricsCollector::test_quality_trend_tracking \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_zero_costs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_fractional_cents \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestQualityMetricsCollector::test_quality_trend_tracking \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_fractional_cents \napp\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_json_export \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_exception_handling \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_json_export \napp\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_prometheus_export \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_failure_recovery \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_exception_handling \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_prometheus_export \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_timeout_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_async_execution \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_status_enum \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_status_enum \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_schema \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_schema \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_create_schema \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_create_schema \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_service_import \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_service_import \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_index_single_document \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_async_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_concurrent_logs \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_index_single_document \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_batch_indexing_pipeline \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_batch_indexing_pipeline \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_concurrent_logs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_negative_costs \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_reindex_corpus_with_new_model \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_negative_costs \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_reindex_corpus_with_new_model \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_mixed_model_types \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_incremental_indexing \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_timeout_handling \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_mixed_model_types \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_incremental_indexing \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_resource_cleanup_on_error \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_partial_failure \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_document_deduplication \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_partial_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_rounding_edge_cases \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_rounding_edge_cases \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_resource_cleanup_on_error \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_reduction_quality_preservation.py::test_cost_reduction_quality_preservation_tool \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_circuit_breaker_pattern \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_reduction_quality_preservation.py::test_cost_reduction_quality_preservation_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_simulation_for_increased_usage.py::test_cost_simulation_for_increased_usage_tool \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_simulation_for_increased_usage.py::test_cost_simulation_for_increased_usage_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_kv_cache_optimization_audit.py::test_kv_cache_optimization_audit_tool \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_kv_cache_optimization_audit.py::test_kv_cache_optimization_audit_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_basic_functionality \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_basic_functionality \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_empty_logs \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_empty_logs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_single_log \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_single_log \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_high_latency_values \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_circuit_breaker_pattern \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_graceful_degradation_under_load \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_high_latency_values \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_zero_latency \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_graceful_degradation_under_load \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_zero_latency \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_error_propagation_and_isolation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_sub_millisecond_latency \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_sub_millisecond_latency \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_exception_handling \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_exception_handling \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_document_deduplication \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_async_execution \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_semantic_search \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_semantic_search \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_hybrid_search \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_hybrid_search \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_relevance_feedback \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_relevance_feedback \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_search_result_reranking \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_async_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_large_dataset \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_search_result_reranking \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_create_corpus_with_validation \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_error_propagation_and_isolation \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_thread_history_handling \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_thread_history_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_create_thread_handling \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_create_thread_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_switch_thread_handling \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_switch_thread_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_delete_thread_handling \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_delete_thread_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_list_threads_handling \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_list_threads_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_all_thread_operations_batch \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_all_thread_operations_batch \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_websocket_message_handling_json_error \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_websocket_message_handling_json_error \napp\\tests\\services\\test_apex_optimizer_tool_selection_part1.py::TestApexOptimizerToolSelection::test_tool_selection_cost_optimization \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part1.py::TestApexOptimizerToolSelection::test_tool_selection_cost_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_latency_optimization \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_latency_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_cache_optimization \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_cache_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_model_analysis \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_model_analysis \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_multi_objective \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_multi_objective \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_empty_query \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_empty_query \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_llm_failure \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_llm_failure \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_invalid_json_response \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_invalid_json_response \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_custom_tool_selection \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_custom_tool_selection \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_simple_tool_chain_execution \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_large_dataset \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_varied_latencies \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_varied_latencies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_partial_failure \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_partial_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_edge_case_rounding \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_edge_case_rounding \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_negative_latencies \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_negative_latencies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_mixed_response_formats \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_mixed_response_formats \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_extreme_values \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_extreme_values \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_concurrent_execution_timing \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_simple_tool_chain_execution \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_conditional_tool_chaining \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_corpus_unavailable_fallback \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_clickhouse_connection_recovery \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_clickhouse_connection_recovery \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_concurrent_execution_timing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_metadata \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_metadata \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_complete_workflow \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_conditional_tool_chaining \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_parallel_tool_execution \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_complete_workflow \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_define_optimization_goals \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_define_optimization_goals \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_analyze_trade_offs \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_analyze_trade_offs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_propose_balanced_optimizations \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_propose_balanced_optimizations \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_simulate_multi_objective_impact \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_simulate_multi_objective_impact \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_with_various_kwargs \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_with_various_kwargs \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_create_corpus_with_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_method_execution_order \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_update_corpus_metadata \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_update_corpus_metadata \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestIndexOptimization::test_index_performance_monitoring \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_method_execution_order \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_method_failure_propagation \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestIndexOptimization::test_index_performance_monitoring \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_redis_connection_failure_recovery \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_method_failure_propagation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_concurrent_execution \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_redis_connection_failure_recovery \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_retry_on_failure \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_concurrent_execution \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_parallel_tool_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_async_behavior_timing \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_error_handling \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_retry_on_failure \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_recover_from_partial_batch_failure \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_recover_from_partial_batch_failure \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_async_behavior_timing \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_database_connection_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_execute_wrapper_integration \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_execute_wrapper_integration \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_inheritance \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_database_connection_failure \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_inheritance \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_context_parameter_passing \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_search_fallback_on_vector_store_failure \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_context_parameter_passing \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_search_fallback_on_vector_store_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_new_model_effectiveness_analysis.py::test_new_model_effectiveness_analysis_tool \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_new_model_effectiveness_analysis.py::test_new_model_effectiveness_analysis_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_empty_policies \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_empty_policies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_single_policy \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_single_policy \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_multiple_policies_only_simulates_first \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_multiple_policies_only_simulates_first \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_unexpected_error \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_simulation_failure \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_simulation_failure \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_unexpected_error \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_with_complex_policy \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_isolation \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_with_complex_policy \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_validation \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_serialization \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_serialization \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_async_behavior \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_async_behavior \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_tool_latency_optimization.py::test_tool_latency_optimization_tool \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_tool_latency_optimization.py::test_tool_latency_optimization_tool \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_workflow_integration <- tests\\helpers\\shared_test_types.py \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_workflow_integration <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_multi_component_interaction <- tests\\helpers\\shared_test_types.py \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_multi_component_interaction <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_end_to_end_data_flow <- tests\\helpers\\shared_test_types.py \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_end_to_end_data_flow <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_execution_cycle \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_execution_cycle \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_concurrent_schedule_execution \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_error_handling \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_cycle_prevention \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_concurrent_schedule_execution \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_connection_failure_recovery <- tests\\helpers\\shared_test_types.py \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_connection_failure_recovery <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failure \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failure \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_retry_on_failure \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_retry_on_failure \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failures \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failures \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_isolation \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_agent_execution_failures \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_timeout_handling \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_agent_execution_failures \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_failures_during_execution \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_failures_during_execution \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_default_values \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_default_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_custom_values \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_custom_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_hourly \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_hourly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_daily \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_daily \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_weekly \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_weekly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly_invalid_day \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly_invalid_day \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_enabled_and_time_reached \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_enabled_and_time_reached \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_disabled \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_disabled \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_time_not_reached \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_time_not_reached \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_update_after_run \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_update_after_run \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleFrequencyEnum::test_schedule_frequency_values \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleFrequencyEnum::test_schedule_frequency_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleTimeBoundaries::test_schedule_time_calculations_across_boundaries \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleTimeBoundaries::test_schedule_time_calculations_across_boundaries \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_no_redis \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_no_redis \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_with_redis \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_with_redis \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_all_schedules \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_all_schedules \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_multiple_days \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_multiple_days \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_redis_errors \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_redis_errors \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_add_schedule \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_add_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_exists \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_cycle_prevention \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_not_exists \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_dynamic_tool_chaining \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule_not_exists \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule_not_exists \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status_with_run_history \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status_with_run_history \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_success \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_success \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_failure \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_failure \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_caching \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_caching \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_no_redis \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_no_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_significant_price_changes \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_dynamic_tool_chaining \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_selection_performance \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_significant_price_changes \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_new_models \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_new_models \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_no_significant_changes \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_no_significant_changes \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_error_handling \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_error_handling \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_with_redis \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_with_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_without_redis \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_without_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedules_created \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedules_created \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedule_configurations \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedule_configurations \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler_already_running \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler_already_running \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_stop_scheduler \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_stop_scheduler \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_execution \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_execution \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_no_due_schedules \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_no_due_schedules \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_error_handling \n[gw3]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_timeout_handling \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_error_handling \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_disabled_schedules \n[gw3]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \n[gw3]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_disabled_schedules \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_exists \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_handling \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_exists \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_not_exists \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_not_exists \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_handling \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_connection_loss_during_transaction \napp\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_generation_job_monitoring \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_connection_loss_during_transaction \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_deadlock_detection_and_retry \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_deadlock_detection_and_retry \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_state_tracking \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_state_tracking \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_repository_operation_logging \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_repository_operation_logging \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_high_concurrency_transactions \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_high_concurrency_transactions \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_throughput_measurement \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_selection_performance \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_concurrent_tool_execution_scaling \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_concurrent_tool_execution_scaling \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_chain_optimization_performance \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_chain_optimization_performance \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_metrics_and_monitoring \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_generation_job_monitoring \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_throughput_measurement \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_memory_usage_during_batch_operations \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_metrics_and_monitoring \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_load_balancing \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_load_balancing \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_resource_management \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_resource_management \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_get \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_get \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_post \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_post \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_other_method \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_other_method \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_post \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_post \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_get \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_get \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_other_method \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_other_method \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_create \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_create \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_bulk_create \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_bulk_create \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_by_id \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_by_id \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_many \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_many \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_update \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_update \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_delete \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_delete \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_soft_delete \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_soft_delete \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_pagination \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_pagination \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_successful_llm_call \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_successful_llm_call \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_circuit_breaker_opens \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_circuit_breaker_opens \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_structured_output_protection \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_structured_output_protection \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_health_check \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_health_check \napp\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_successful_db_query \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_successful_db_query \napp\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_memory_usage_during_batch_operations \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_latency_distribution \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_latency_distribution \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_deadlock_recovery_performance \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_deadlock_recovery_performance \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_connection_pool_stress \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_connection_pool_stress \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_successful_transaction \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_successful_transaction \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_rollback_on_exception \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_rollback_on_exception \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_with_external_session \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_with_external_session \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_repository_access \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_repository_access \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_session_lifecycle \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_session_lifecycle \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_nested_transactions \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_nested_transactions \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_error_handling \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_error_handling \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_new_session \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_new_session \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_existing_session \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_existing_session \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_valid \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_valid \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_invalid \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_invalid \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_financial \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_financial \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_different_industries \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_different_industries \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_synthetic_metrics \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_synthetic_metrics \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report_session_not_found \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report_session_not_found \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status_not_found \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status_not_found \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_submit_feedback \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_submit_feedback \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_track_demo_interaction \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_track_demo_interaction \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_analytics_summary \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_analytics_summary \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_demo_response \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_demo_response \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_error_handling_redis_failure \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_error_handling_redis_failure \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_google_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_google_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_openai_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_openai_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_anthropic_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_anthropic_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_generic_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_generic_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_fast_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_fast_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_creation <- tests\\services\\test_http_error.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_creation <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_without_response_data <- tests\\services\\test_http_error.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_without_response_data <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_inheritance <- tests\\services\\test_http_error.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_inheritance <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization_defaults <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization_defaults <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_google <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_google <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_openai <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_openai <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_anthropic <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_anthropic <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_health <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_health <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_generic <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_generic <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_with_base_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_with_base_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_absolute_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_absolute_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_no_base_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_no_base_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_none <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_none <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_override <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_override <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_new <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_new <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_reuse <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_reuse <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_closed_recreate <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_closed_recreate <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_session <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_no_session <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_no_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_already_closed_session <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_already_closed_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_new <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_new <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_existing <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_existing <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_fallback_response <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_fallback_response <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_success <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_success <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_circuit_open <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_circuit_open <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_json <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_json <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_text <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_text <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_json <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_json <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_text <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_text <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_error <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_error <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_get_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_get_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_post_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_post_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_put_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_put_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_delete_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_delete_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_success <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_success <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_error <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_error <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_no_base_url <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_no_base_url <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_success <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_success <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_failure <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_failure <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_circuit <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_circuit <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_connectivity <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_connectivity <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_recovering <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_recovering <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_healthy <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_healthy <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_retryable_client_inheritance <- tests\\services\\test_retryable_client.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_retryable_client_inheritance <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_get_with_retry <- tests\\services\\test_retryable_client.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_get_with_retry <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_post_with_retry <- tests\\services\\test_retryable_client.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_post_with_retry <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_manager_initialization <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_manager_initialization <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_resilient <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_resilient <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_retryable <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_retryable <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_existing <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_existing <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_empty <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_empty <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_with_clients <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_with_clients <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_empty <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_empty <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_with_clients <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_with_clients <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGetHTTPClient::test_get_http_client_context_manager <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGetHTTPClient::test_get_http_client_context_manager <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_exists <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_exists <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_singleton_behavior <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_singleton_behavior <- tests\\services\\test_http_client_manager.py Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 94\n\n================================================================================\n\n\n\n================================== FAILURES ===================================\n\u001b[31m\u001b[1m____________ TestErrorRecovery.test_clickhouse_connection_recovery ____________\u001b[0m\n[gw1] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\synthetic_data\\test_error_recovery.py\u001b[0m:57: in test_clickhouse_connection_recovery\n    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m recovery_service.ingest_with_retry(\u001b[90m\u001b[39;49;00m\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AttributeError: 'SyntheticDataService' object has no attribute 'ingest_with_retry'\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:04:58.384 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:04:58.497 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m_____________ TestAdminVisibility.test_generation_job_monitoring ______________\u001b[0m\n[gw0] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\synthetic_data\\test_admin_visibility.py\u001b[0m:33: in test_generation_job_monitoring\n    \u001b[0m\u001b[94massert\u001b[39;49;00m status[\u001b[33m\"\u001b[39;49;00m\u001b[33mstate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[33m\"\u001b[39;49;00m\u001b[33mrunning\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n           ^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   TypeError: 'NoneType' object is not subscriptable\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:04:59.566 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured stderr call -----------------------------\n2025-08-17 18:04:59.570 | ERROR    | app.ws_manager_messaging:_validate_dict_message:70 | Message validation failed: Invalid message type: generation:started\n2025-08-17 18:04:59.570 | INFO     | app.core.unified_logging:_emit_log:117 | Generation job ad7ab07d-b089-47b3-9f54-108ca326b18b started\nC:\\Users\\antho\\miniconda3\\Lib\\email\\utils.py:51: RuntimeWarning: coroutine 'SupplyResearchScheduler._scheduler_loop' was never awaited\n  def _has_surrogates(s):\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:05:00.522 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m______ TestDatabaseClientCircuitBreaker.test_db_circuit_breaker_fallback ______\u001b[0m\n[gw2] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\test_circuit_breaker_integration.py\u001b[0m:180: in test_db_circuit_breaker_fallback\n    \u001b[0m\u001b[94massert\u001b[39;49;00m postgres_circuit.failure_count == \u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   assert 0 == 1\u001b[0m\n\u001b[1m\u001b[31mE    +  where 0 = <app.core.adaptive_circuit_breaker_core.AdaptiveCircuitBreaker object at 0x0000025CA7263AA0>.failure_count\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:05:02.393 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured stderr call -----------------------------\n2025-08-17 18:05:02.398 | WARNING  | app.core.adaptive_circuit_breaker_core:_transition_to_open:197 | Circuit breaker db_read transitioning to OPEN\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:05:02.497 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::\u001b[1mTestErrorRecovery::test_clickhouse_connection_recovery\u001b[0m - AttributeError: 'SyntheticDataService' object has no attribute 'ingest_with_retry'\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::\u001b[1mTestAdminVisibility::test_generation_job_monitoring\u001b[0m - TypeError: 'NoneType' object is not subscriptable\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::\u001b[1mTestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback\u001b[0m - assert 0 == 1\n +  where 0 = <app.core.adaptive_circuit_breaker_core.AdaptiveCircuitBreaker object at 0x0000025CA7263AA0>.failure_count\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 3 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m================= \u001b[31m\u001b[1m3 failed\u001b[0m, \u001b[32m389 passed\u001b[0m, \u001b[33m10 skipped\u001b[0m\u001b[31m in 38.50s\u001b[0m\u001b[31m ==================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 50.47s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\nC:\\Users\\antho\\miniconda3\\Lib\\site-packages\\_pytest\\runner.py:146: RuntimeWarning: coroutine 'ResearchExecutor.execute_scheduled_research' was never awaited\n  item.funcargs = None  # type: ignore[attr-defined]\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n2025-08-17 18:04:22.586 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 18:04:22.587 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 18:04:22.587 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 18:04:22.588 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 18:04:22.588 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 18:04:22.588 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 18:04:22.588 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 18:04:22.588 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 18:04:22.588 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 18:04:22.588 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 18:04:22.588 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 18:04:22.589 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 18:04:22.590 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 18:04:22.590 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 18:04:22.590 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 18:04:22.591 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 18:04:22.591 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 18:04:22.592 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 18:04:22.592 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 18:04:22.593 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 18:04:22.593 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 18:04:22.594 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 18:04:22.595 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 18:04:22.596 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 18:04:22.596 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 18:04:22.649 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 18:04:22.650 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 18:04:22.650 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 18:04:22.719 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 18:04:23.172 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 18:04:23.534 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 18:04:25.210 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 18:04:25.305 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 18:04:25.771 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 18:04:25.920 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 18:04:27.113 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:04:27.194 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:04:27.342 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 18:04:27.400 | INFO     | app.services.quality_gate.quality_gate_core:__init__:28 | Quality Gate Service initialized\n2025-08-17 18:04:27.401 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 18:04:27.401 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=32, microseconds=818529), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=50476, name='MainProcess'), 'thread': (id=47748, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 6, 94213, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=32, microseconds=601742), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=49736, name='MainProcess'), 'thread': (id=53328, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 6, 93224, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=33, microseconds=50877), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=58088, name='MainProcess'), 'thread': (id=1756, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 6, 94213, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\n--- End of logging error ---\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=32, microseconds=657121), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=54148, name='MainProcess'), 'thread': (id=1172, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 6, 203912, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=47, microseconds=584980), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=53408, name='MainProcess'), 'thread': (id=55612, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 7, 892916, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 402,
            "passed": 389,
            "failed": 3,
            "skipped": 10,
            "errors": 0,
            "import_errors": 0,
            "test_files": 48,
            "status": "failed"
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.15759587287902832,
          "exit_code": 2,
          "output": "\nusage: test_frontend.py [-h]\n                        [--category {unit,integration,components,hooks,store,websocket,auth,e2e,smoke}]\n                        [--keyword KEYWORD] [--e2e] [--cypress-open] [--watch]\n                        [--coverage] [--update-snapshots] [--lint] [--fix]\n                        [--type-check] [--build] [--check-deps]\n                        [--install-deps] [--verbose] [--isolation]\n                        [--cleanup-on-exit]\n                        [tests ...]\ntest_frontend.py: error: unrecognized arguments: --no-cov -x --maxfail=1\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "import_errors": 0,
            "test_files": 0,
            "status": "unknown"
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479057.0057082,
          "end_time": 1755479108.6919775
        }
      },
      "summary": {
        "total": 402,
        "passed": 389,
        "failed": 3,
        "skipped": 10,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T18:05:37.860701",
      "level": "real_e2e",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 11.683714151382446,
          "exit_code": 1,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -vv -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -k real_ or _real -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 969 items / 1 error\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 95\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m_______ ERROR collecting tests/auth/test_auth_middleware_integration.py _______\u001b[0m\n\u001b[31mImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\auth\\test_auth_middleware_integration.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\napp\\tests\\auth\\test_auth_middleware_integration.py:20: in <module>\n    from app.auth.auth_service import app\napp\\auth\\auth_service.py:24: in <module>\n    from .environment_config import AuthEnvironmentConfig\nE   ImportError: cannot import name 'AuthEnvironmentConfig' from 'app.auth.environment_config' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\environment_config.py)\u001b[0m\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\auth\\test_auth_middleware_integration.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n\u001b[31m============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.70s\u001b[0m\u001b[31m ===============================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 1 after 10.53s\n================================================================================\n\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=7, microseconds=954545), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=9996, name='MainProcess'), 'thread': (id=56736, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 37, 41764, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 1,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479126.1344697,
          "end_time": 1755479137.825102
        }
      },
      "summary": {
        "total": 1,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:05:52.317486",
      "level": "comprehensive-api",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 32.77923607826233,
          "exit_code": 2,
          "output": "Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\nLoaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -v -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -k routes or api -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 95\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m_______ ERROR collecting tests/auth/test_auth_middleware_integration.py _______\u001b[0m\nImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\auth\\test_auth_middleware_integration.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\tests\\auth\\test_auth_middleware_integration.py:20: in <module>\n    from app.auth.auth_service import app\napp\\auth\\auth_service.py:24: in <module>\n    from .environment_config import AuthEnvironmentConfig\nE   ImportError: cannot import name 'AuthEnvironmentConfig' from 'app.auth.environment_config' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\environment_config.py)\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\auth\\test_auth_middleware_integration.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 20.18s\u001b[0m\u001b[31m ==============================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 31.71s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\n2025-08-17 18:05:25.278 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 18:05:25.279 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 18:05:25.279 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 18:05:25.279 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 18:05:25.280 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 18:05:25.280 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 18:05:25.280 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 18:05:25.280 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 18:05:25.280 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 18:05:25.280 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 18:05:25.281 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 18:05:25.281 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 18:05:25.282 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 18:05:25.283 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 18:05:25.283 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 18:05:25.284 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 18:05:25.286 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 18:05:25.286 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 18:05:25.287 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 18:05:25.288 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 18:05:25.289 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 18:05:25.289 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 18:05:25.290 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 18:05:25.290 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 18:05:25.291 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 18:05:25.332 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 18:05:25.332 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 18:05:25.333 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 18:05:25.396 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 18:05:25.816 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 18:05:26.121 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 18:05:27.476 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 18:05:27.594 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 18:05:27.977 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 18:05:28.092 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 18:05:29.179 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:05:29.236 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:05:29.373 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 18:05:29.438 | INFO     | app.services.quality_gate.quality_gate_core:__init__:28 | Quality Gate Service initialized\n2025-08-17 18:05:29.439 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 18:05:29.439 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=14, microseconds=399393), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=13464, name='MainProcess'), 'thread': (id=6392, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 50, 29752, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=14, microseconds=843650), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=14940, name='MainProcess'), 'thread': (id=50688, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 50, 29752, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #2 ---\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=14, microseconds=550293), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=48360, name='MainProcess'), 'thread': (id=53984, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 50, 30755, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nRecord was: {'elapsed': datetime.timedelta(seconds=14, microseconds=280699), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=40308, name='MainProcess'), 'thread': (id=53348, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 50, 30755, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=28, microseconds=742785), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=22880, name='MainProcess'), 'thread': (id=53508, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 5, 51, 694156, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 1,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479119.4946306,
          "end_time": 1755479152.2803934
        }
      },
      "summary": {
        "total": 1,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:06:10.468142",
      "level": "real_e2e",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 10.649491786956787,
          "exit_code": 1,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -vv -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -k real_ or _real -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 1000 items / 1 error\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 96\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m_______ ERROR collecting tests/auth/test_auth_service_comprehensive.py ________\u001b[0m\n\u001b[31mImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\auth\\test_auth_service_comprehensive.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\napp\\tests\\auth\\test_auth_service_comprehensive.py:22: in <module>\n    from app.auth.auth_service import (\nE   ImportError: cannot import name 'validate_exchange_request' from 'app.auth.auth_service' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\auth_service.py)\u001b[0m\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\auth\\test_auth_service_comprehensive.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n\u001b[31m============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.20s\u001b[0m\u001b[31m ===============================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 1 after 9.52s\n================================================================================\n\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=6, microseconds=934506), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=56064, name='MainProcess'), 'thread': (id=58052, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 6, 9, 755836, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 1,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479159.7842486,
          "end_time": 1755479170.43674
        }
      },
      "summary": {
        "total": 1,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:06:35.187883",
      "level": "agents",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 22.62740659713745,
          "exit_code": 2,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: agent\n  Parallel: 4\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/agents app/tests/services/agents app/tests/services/apex_optimizer_agent -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n4 workers [791 items]\n\nscheduling tests via LoadScheduling\n\napp\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestAnalysisEngine::test_identify_outliers_zscore_no_variance <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py::TestDataSubAgentProcessing::test_process_with_cache_different_keys \napp\\tests\\agents\\test_agent_e2e_critical_collab.py::TestAgentE2ECriticalCollaboration::test_7_authentication_and_authorization \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_insufficient_data \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py::TestDataSubAgentProcessing::test_process_with_cache_different_keys \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestAnalysisEngine::test_identify_outliers_zscore_no_variance <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py::TestDataSubAgentProcessing::test_process_and_stream \napp\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestAnalysisEngine::test_identify_outliers_invalid_method <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestAnalysisEngine::test_identify_outliers_invalid_method <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py \napp\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestDataSubAgentBasic::test_initialization <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestDataSubAgentBasic::test_initialization <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_insufficient_data \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_no_time_variation \napp\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestDataSubAgentBasic::test_initialization_redis_failure <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_no_time_variation \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_increasing \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_increasing \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestDataSubAgentBasic::test_initialization_redis_failure <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_decreasing \napp\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestDataSubAgentBasic::test_get_cached_schema_success <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_decreasing \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_weak \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_trend_weak \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_insufficient_data \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_insufficient_data \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_insufficient_hourly_coverage \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_agent_e2e_critical_collab.py::TestAgentE2ECriticalCollaboration::test_7_authentication_and_authorization \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[31mERROR\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive.py::TestDataSubAgentBasic::test_get_cached_schema_success <- tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_insufficient_hourly_coverage \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_with_pattern \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_with_pattern \napp\\tests\\agents\\test_agent_e2e_critical_collab.py::TestAgentE2ECriticalCollaboration::test_8_multi_agent_collaboration \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_no_pattern \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_detect_seasonality_no_pattern \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_insufficient_data \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_insufficient_data \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_iqr_method \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_iqr_method \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_zscore_method \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_zscore_method \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_zscore_no_variance \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_zscore_no_variance \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_invalid_method \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_analysis_engine.py::TestAnalysisEngine::test_identify_outliers_invalid_method \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_analysis.py::TestDataSubAgentAnalysis::test_analyze_performance_metrics_no_data \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_agent_e2e_critical_collab.py::TestAgentE2ECriticalCollaboration::test_8_multi_agent_collaboration \napp\\tests\\agents\\test_agent_e2e_critical_core.py::TestAgentE2ECriticalCore::test_1_complete_agent_lifecycle_request_to_completion \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py::TestDataSubAgentProcessing::test_process_and_stream \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\agents\\test_agent_e2e_critical_core.py::TestAgentE2ECriticalCore::test_1_complete_agent_lifecycle_request_to_completion \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_analysis.py::TestDataSubAgentAnalysis::test_analyze_performance_metrics_no_data \napp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_analysis.py::TestDataSubAgentAnalysis::test_analyze_performance_metrics_minute_aggregation \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_analysis.py::TestDataSubAgentAnalysis::test_analyze_performance_metrics_minute_aggregation Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 97\n\n================================================================================\n\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m___ ERROR at setup of TestDataSubAgentBasic.test_get_cached_schema_success ____\u001b[0m\n[gw2] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\nfile C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py, line 39\n      async def test_get_cached_schema_success(self, agent):\n          \"\"\"Test getting cached schema information\"\"\"\n          with patch('app.agents.data_sub_agent.get_clickhouse_client') as mock_client:\n              mock_client_instance = AsyncMock()\n              mock_client_instance.execute_query = AsyncMock(return_value=[\n                  (\"column1\", \"String\"),\n                  (\"column2\", \"Int32\")\n              ])\n              mock_client.return_value.__aenter__.return_value = mock_client_instance\n\n              # Clear the cache first\n              agent._get_cached_schema.cache_clear()\n\n              result = await agent._get_cached_schema(\"test_table\")\n\n          assert result != None\n          assert result[\"table\"] == \"test_table\"\n          assert len(result[\"columns\"]) == 2\n          assert result[\"columns\"][0][\"name\"] == \"column1\"\n          assert result[\"columns\"][0][\"type\"] == \"String\"\nE       fixture 'agent' not found\n>       available fixtures: _session_faker, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, client, cov, db_session, doctest_namespace, event_loop, extra, extras, faker, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, json_metadata, metadata, mock_dependencies, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, real_agent_setup, real_llm_manager, real_tool_dispatcher, real_websocket_manager, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, setup_real_infrastructure, test_engine, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\nC:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_basic.py:39\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:06:29.791 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n2025-08-17 18:06:29.792 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n================================== FAILURES ===================================\n\u001b[31m\u001b[1m_____________ TestDataSubAgentProcessing.test_process_and_stream ______________\u001b[0m\n[gw3] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py\u001b[0m:130: in test_process_and_stream\n    \u001b[0m\u001b[94massert\u001b[39;49;00m parsed[\u001b[33m\"\u001b[39;49;00m\u001b[33mprocessed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n           ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   KeyError: 'processed'\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:06:29.777 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n2025-08-17 18:06:29.779 | DEBUG    | app.core.unified_logging:_emit_log:117 | Cache wrapper setup skipped - not currently required\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:06:30.606 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m_ TestAgentE2ECriticalCore.test_1_complete_agent_lifecycle_request_to_completion _\u001b[0m\n[gw0] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\agents\\test_agent_e2e_critical_core.py\u001b[0m:37: in test_1_complete_agent_lifecycle_request_to_completion\n    \u001b[0mresult_state = \u001b[94mawait\u001b[39;49;00m supervisor.run(user_request, supervisor.thread_id, supervisor.user_id, run_id)\u001b[90m\u001b[39;49;00m\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\supervisor_consolidated.py\u001b[0m:186: in run\n    \u001b[0mstate = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._execute_workflow_steps(flow_id, user_prompt, thread_id, user_id, run_id)\u001b[90m\u001b[39;49;00m\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\supervisor_consolidated.py\u001b[0m:200: in _execute_workflow_steps\n    \u001b[0mstate = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._initialize_state_step(flow_id, user_prompt, thread_id, user_id, run_id)\u001b[90m\u001b[39;49;00m\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\supervisor_consolidated.py\u001b[0m:216: in _initialize_state_step\n    \u001b[0mstate = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.state_manager.initialize_state(user_prompt, thread_id, user_id, run_id)\u001b[90m\u001b[39;49;00m\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\supervisor\\state_manager_core.py\u001b[0m:29: in initialize_state\n    \u001b[0m\u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.checkpoint_manager.create_initial_checkpoint(state, run_id, thread_id, user_id)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\supervisor\\state_checkpoint_manager.py\u001b[0m:30: in create_initial_checkpoint\n    \u001b[0msuccess, checkpoint_id = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._save_checkpoint_request(request)\u001b[90m\u001b[39;49;00m\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\supervisor\\state_checkpoint_manager.py\u001b[0m:45: in _save_checkpoint_request\n    \u001b[0msuccess = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._persist_state_data(request, state, session)\u001b[90m\u001b[39;49;00m\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\agents\\supervisor\\state_checkpoint_manager.py\u001b[0m:56: in _persist_state_data\n    \u001b[0msuccess, snapshot_id = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.state_persistence.save_agent_state(\u001b[90m\u001b[39;49;00m\n    ^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   ValueError: not enough values to unpack (expected 2, got 0)\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:06:29.919 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured stderr call -----------------------------\n2025-08-17 18:06:29.926 | INFO     | app.agents.supervisor.agent_registry:register:75 | Registered agent: triage\n2025-08-17 18:06:29.926 | DEBUG    | app.core.unified_logging:_emit_log:117 | Cache wrapper setup skipped - not currently required\n2025-08-17 18:06:29.926 | INFO     | app.agents.supervisor.agent_registry:register:75 | Registered agent: data\n2025-08-17 18:06:29.926 | INFO     | app.agents.supervisor.agent_registry:register:75 | Registered agent: optimization\n2025-08-17 18:06:29.926 | INFO     | app.agents.supervisor.agent_registry:register:75 | Registered agent: actions\n2025-08-17 18:06:29.926 | INFO     | app.agents.supervisor.agent_registry:register:75 | Registered agent: reporting\n2025-08-17 18:06:29.926 | INFO     | app.agents.supervisor.agent_registry:register:75 | Registered agent: synthetic_data\n2025-08-17 18:06:29.926 | INFO     | app.agents.supervisor.agent_registry:register:75 | Registered agent: corpus_admin\n2025-08-17 18:06:29.929 | INFO     | app.agents.supervisor.observability_flow:_log_json_data:162 | Supervisor flow: {\"type\": \"supervisor_flow\", \"event\": \"flow_started\", \"flow_id\": \"flow_40ce9f13\", \"correlation_id\": \"5dbb2743-4d17-4445-82c5-c906f23a8dbe\", \"timestamp\": 1755479189.929386, \"state_summary\": {\"total_steps\": 4, \"completed_steps\": 0, \"current_phase\": \"initialization\", \"active_agents\": []}}\n2025-08-17 18:06:29.930 | INFO     | app.agents.supervisor.observability_flow:_log_json_data:162 | Supervisor flow: {\"type\": \"supervisor_flow\", \"event\": \"step_started\", \"flow_id\": \"flow_40ce9f13\", \"correlation_id\": \"5dbb2743-4d17-4445-82c5-c906f23a8dbe\", \"timestamp\": 1755479189.930089, \"step_name\": \"create_context\", \"step_type\": \"initialization\", \"state_summary\": {\"total_steps\": 4, \"completed_steps\": 0, \"current_phase\": \"create_context\", \"active_agents\": []}}\n2025-08-17 18:06:29.930 | INFO     | app.agents.supervisor.observability_flow:_log_json_data:162 | Supervisor flow: {\"type\": \"supervisor_flow\", \"event\": \"step_completed\", \"flow_id\": \"flow_40ce9f13\", \"correlation_id\": \"5dbb2743-4d17-4445-82c5-c906f23a8dbe\", \"timestamp\": 1755479189.930089, \"step_name\": \"create_context\", \"step_type\": \"initialization\", \"state_summary\": {\"total_steps\": 4, \"completed_steps\": 1, \"current_phase\": \"create_context\", \"active_agents\": []}}\n2025-08-17 18:06:29.931 | INFO     | app.agents.supervisor.observability_flow:_log_json_data:162 | Supervisor flow: {\"type\": \"supervisor_flow\", \"event\": \"step_started\", \"flow_id\": \"flow_40ce9f13\", \"correlation_id\": \"5dbb2743-4d17-4445-82c5-c906f23a8dbe\", \"timestamp\": 1755479189.9311063, \"step_name\": \"initialize_state\", \"step_type\": \"state_management\", \"state_summary\": {\"total_steps\": 4, \"completed_steps\": 1, \"current_phase\": \"initialize_state\", \"active_agents\": []}}\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:06:30.828 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m_ TestDataSubAgentAnalysis.test_analyze_performance_metrics_minute_aggregation _\u001b[0m\n[gw1] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_analysis.py\u001b[0m:38: in test_analyze_performance_metrics_minute_aggregation\n    \u001b[0m\u001b[94massert\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mtime_range\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m result\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: assert 'time_range' in {'status': 'no_data', 'message': 'No performance metrics found for the specified criteria'}\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:06:31.048 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n2025-08-17 18:06:31.051 | DEBUG    | app.core.unified_logging:_emit_log:117 | Cache wrapper setup skipped - not currently required\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured stderr call -----------------------------\n2025-08-17 18:06:31.054 | DEBUG    | app.core.unified_logging:_emit_log:117 | Cache retrieval failed: object MagicMock can't be used in 'await' expression\n2025-08-17 18:06:31.329 | INFO     | app.core.unified_logging:_emit_log:117 | Attempting to create workload_events table\n2025-08-17 18:06:31.400 | INFO     | app.core.unified_logging:_emit_log:117 | Successfully created workload_events table\n2025-08-17 18:06:31.757 | ERROR    | app.core.unified_logging:_emit_log:115 | ClickHouse query failed: HTTPDriver for https://xedvrr4c3r.us-central1.gcp.clickhouse.cloud:8443 received ClickHouse error code 386\n Code: 386. DB::Exception: There is no supertype for types Array(Float64), Float64 because some of them are Array and some of them are not: In scope SELECT *, arrayFirstIndex(x -> (x = 'latency_ms'), metrics.name) AS idx, arrayFirstIndex(x -> (x = 'throughput'), metrics.name) AS idx2, arrayFirstIndex(x -> (x = 'cost_cents'), metrics.name) AS idx3, if(idx > 0, metrics.value[idx], 0.) AS metric_value, if(idx2 > 0, metrics.value[idx2], 0.) AS throughput_value, if(idx3 > 0, metrics.value[idx3], 0.) AS cost_value, idx > 0 AS has_latency, idx2 > 0 AS has_throughput, idx3 > 0 AS has_cost FROM workload_events WHERE (user_id = 1) AND (timestamp >= '2024-01-01T12:00:00') AND (timestamp <= '2024-01-01T12:30:00') AND (workload_id = 'test'). (NO_COMMON_TYPE) (version 25.6.2.5781 (official build))\n\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:06:32.372 | ERROR    | logging:handle:1028 | Task was destroyed but it is pending!\ntask: <Task pending name='Task-4' coro=<<async_generator_athrow without __name__>()>>\n2025-08-17 18:06:32.373 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[31m\u001b[1mERROR   \u001b[0m asyncio:base_events.py:1821 Task was destroyed but it is pending!\ntask: <Task pending name='Task-4' coro=<<async_generator_athrow without __name__>()>>\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mFAILED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_processing.py::\u001b[1mTestDataSubAgentProcessing::test_process_and_stream\u001b[0m - KeyError: 'processed'\n\u001b[31mFAILED\u001b[0m app\\tests\\agents\\test_agent_e2e_critical_core.py::\u001b[1mTestAgentE2ECriticalCore::test_1_complete_agent_lifecycle_request_to_completion\u001b[0m - ValueError: not enough values to unpack (expected 2, got 0)\n\u001b[31mFAILED\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive_suite\\test_data_sub_agent_analysis.py::\u001b[1mTestDataSubAgentAnalysis::test_analyze_performance_metrics_minute_aggregation\u001b[0m - AssertionError: assert 'time_range' in {'status': 'no_data', 'message': 'No performance metrics found for the specified criteria'}\n\u001b[31mERROR\u001b[0m app\\tests\\agents\\test_data_sub_agent_comprehensive.py::\u001b[1mTestDataSubAgentBasic::test_get_cached_schema_success\u001b[0m\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 4 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m=================== \u001b[31m\u001b[1m3 failed\u001b[0m, \u001b[32m22 passed\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 14.41s\u001b[0m\u001b[31m ====================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 21.59s\n================================================================================\n\n2025-08-17 18:06:16.534 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 18:06:16.535 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 18:06:16.535 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 18:06:16.535 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 18:06:16.535 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 18:06:16.536 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 18:06:16.536 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 18:06:16.536 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 18:06:16.536 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 18:06:16.537 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 18:06:16.537 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 18:06:16.538 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 18:06:16.538 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 18:06:16.540 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 18:06:16.540 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 18:06:16.540 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 18:06:16.541 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 18:06:16.541 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 18:06:16.541 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 18:06:16.541 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 18:06:16.541 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 18:06:16.541 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 18:06:16.541 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 18:06:16.541 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 18:06:16.541 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 18:06:16.573 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 18:06:16.573 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 18:06:16.573 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 18:06:16.588 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 18:06:16.845 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 18:06:17.043 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 18:06:17.845 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 18:06:17.899 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 18:06:18.179 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 18:06:18.237 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 18:06:18.837 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:06:18.875 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:06:18.939 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 18:06:18.942 | INFO     | app.services.quality_gate.quality_gate_core:__init__:28 | Quality Gate Service initialized\n2025-08-17 18:06:18.942 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 18:06:18.942 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=10, microseconds=296577), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=3816, name='MainProcess'), 'thread': (id=41488, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 6, 33, 15534, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=9, microseconds=792717), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=56792, name='MainProcess'), 'thread': (id=40472, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 6, 33, 15534, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=9, microseconds=945542), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=55468, name='MainProcess'), 'thread': (id=57676, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 6, 33, 15534, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=9, microseconds=990437), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=43628, name='MainProcess'), 'thread': (id=46376, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 6, 33, 17622, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=19, microseconds=86864), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=43000, name='MainProcess'), 'thread': (id=40112, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 6, 34, 511011, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 26,
            "passed": 22,
            "failed": 3,
            "skipped": 0,
            "errors": 1,
            "import_errors": 0,
            "test_files": 6,
            "status": "failed"
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479172.509268,
          "end_time": 1755479195.1502705
        }
      },
      "summary": {
        "total": 26,
        "passed": 22,
        "failed": 3,
        "skipped": 0,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:06:42.323658",
      "level": "real_e2e",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 13.999562978744507,
          "exit_code": 1,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -vv -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -k real_ or _real -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 1026 items / 1 error\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 98\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m__________ ERROR collecting tests/auth/test_auth_token_management.py __________\u001b[0m\n\u001b[31mImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\auth\\test_auth_token_management.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\napp\\tests\\auth\\test_auth_token_management.py:21: in <module>\n    from app.auth.auth_token_service import AuthTokenService, UserInfo\nE   ImportError: cannot import name 'UserInfo' from 'app.auth.auth_token_service' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\auth_token_service.py)\u001b[0m\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\auth\\test_auth_token_management.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n\u001b[31m============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.97s\u001b[0m\u001b[31m ===============================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 1 after 12.42s\n================================================================================\n\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=9, microseconds=428188), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=24340, name='MainProcess'), 'thread': (id=38004, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 6, 41, 168840, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 1,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479188.2631586,
          "end_time": 1755479202.2681246
        }
      },
      "summary": {
        "total": 1,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:07:19.657047",
      "level": "real_e2e",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 25.346779346466064,
          "exit_code": 1,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -vv -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -k real_ or _real -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 5364 items / 1 error / 1 skipped\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 98\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m__________ ERROR collecting tests/unit/auth_service/test_helpers.py ___________\u001b[0m\n\u001b[31mImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\unit\\auth_service\\test_helpers.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\napp\\tests\\unit\\auth_service\\test_helpers.py:15: in <module>\n    from app.auth.url_validators import (\nE   ImportError: cannot import name 'validate_return_url_security' from 'app.auth.url_validators' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\url_validators.py)\u001b[0m\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\unit\\auth_service\\test_helpers.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n\u001b[31m======================== \u001b[33m1 skipped\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 15.58s\u001b[0m\u001b[31m =========================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 1 after 23.84s\n================================================================================\n\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=21, microseconds=177900), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=2260, name='MainProcess'), 'thread': (id=17684, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 7, 18, 476112, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 2,
            "passed": 0,
            "failed": 0,
            "skipped": 1,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479214.264055,
          "end_time": 1755479239.6169193
        }
      },
      "summary": {
        "total": 2,
        "passed": 0,
        "failed": 0,
        "skipped": 1,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:07:47.363959",
      "level": "comprehensive-api",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 75.49027180671692,
          "exit_code": 2,
          "output": "Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\nLoaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -v -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -k routes or api -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 98\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m__________ ERROR collecting tests/unit/auth_service/test_helpers.py ___________\u001b[0m\nImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\unit\\auth_service\\test_helpers.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\tests\\unit\\auth_service\\test_helpers.py:15: in <module>\n    from app.auth.url_validators import (\nE   ImportError: cannot import name 'validate_return_url_security' from 'app.auth.url_validators' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\url_validators.py)\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\unit\\auth_service\\test_helpers.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m=================== \u001b[33m1 skipped\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 60.11s (0:01:00)\u001b[0m\u001b[31m ====================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 74.27s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\n2025-08-17 18:06:38.722 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 18:06:38.723 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 18:06:38.724 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 18:06:38.724 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 18:06:38.725 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 18:06:38.725 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 18:06:38.725 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 18:06:38.726 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 18:06:38.726 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 18:06:38.727 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 18:06:38.727 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 18:06:38.727 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 18:06:38.727 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 18:06:38.729 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 18:06:38.730 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 18:06:38.730 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 18:06:38.731 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 18:06:38.732 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 18:06:38.733 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 18:06:38.733 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 18:06:38.734 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 18:06:38.734 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 18:06:38.734 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 18:06:38.736 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 18:06:38.736 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 18:06:38.786 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 18:06:38.786 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 18:06:38.786 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 18:06:38.853 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 18:06:39.342 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 18:06:39.750 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 18:06:41.707 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 18:06:41.871 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 18:06:42.639 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 18:06:42.807 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 18:06:43.808 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:06:43.896 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:06:44.294 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 18:06:44.377 | INFO     | app.services.quality_gate.quality_gate_core:__init__:28 | Quality Gate Service initialized\n2025-08-17 18:06:44.378 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 18:06:44.378 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=55, microseconds=43186), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=37052, name='MainProcess'), 'thread': (id=28036, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 7, 44, 486105, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=54, microseconds=936480), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=28532, name='MainProcess'), 'thread': (id=53708, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 7, 44, 534258, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=55, microseconds=234806), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=51652, name='MainProcess'), 'thread': (id=56776, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 7, 44, 567589, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=55, microseconds=14553), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=32496, name='MainProcess'), 'thread': (id=58224, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 7, 44, 664561, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=70, microseconds=607588), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=4004, name='MainProcess'), 'thread': (id=45964, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 7, 46, 628711, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 2,
            "passed": 0,
            "failed": 0,
            "skipped": 1,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479191.8238375,
          "end_time": 1755479267.3219502
        }
      },
      "summary": {
        "total": 2,
        "passed": 0,
        "failed": 0,
        "skipped": 1,
        "errors": 1
      }
    }
  ],
  "flaky_tests": {},
  "failure_patterns": {},
  "performance_trends": []
}