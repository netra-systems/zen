{
  "runs": [
    {
      "timestamp": "2025-08-17T11:05:34.002531",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 18.99797511100769,
          "exit_code": 4,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\nLoaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n================================================================================\n[FAIL] TESTS FAILED with exit code 4 after 17.20s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\n2025-08-17 11:05:20.798 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 11:05:20.799 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 11:05:20.799 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 11:05:20.800 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 11:05:20.800 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 11:05:20.800 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 11:05:20.800 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 11:05:20.801 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 11:05:20.801 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 11:05:20.801 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 11:05:20.801 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 11:05:20.801 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 11:05:20.802 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 11:05:20.802 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 11:05:20.802 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 11:05:20.802 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 11:05:20.803 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 11:05:20.804 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 11:05:20.804 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 11:05:20.804 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 11:05:20.805 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 11:05:20.805 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 11:05:20.805 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 11:05:20.806 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 11:05:20.806 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 11:05:20.836 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 11:05:20.836 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 11:05:20.836 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 11:05:20.880 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 11:05:21.170 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 11:05:21.416 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 11:05:22.652 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 11:05:23.031 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 11:05:23.850 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 11:05:24.114 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 11:05:26.971 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 11:05:27.328 | INFO     | app.services.quality_gate.quality_gate_core:__init__:34 | Quality Gate Service initialized\n2025-08-17 11:05:27.328 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 11:05:27.329 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\nImportError while loading conftest 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\conftest.py'.\napp\\tests\\conftest.py:52: in <module>\n    from app.main import app\napp\\main.py:71: in <module>\n    app = create_app()\n          ^^^^^^^^^^^^\napp\\core\\app_factory.py:277: in create_app\n    _configure_app_routes(app)\napp\\core\\app_factory.py:290: in _configure_app_routes\n    register_api_routes(app)\napp\\core\\app_factory.py:95: in register_api_routes\n    _import_and_register_routes(app)\napp\\core\\app_factory.py:101: in _import_and_register_routes\n    route_configs = _get_route_configurations(route_modules)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:254: in _get_route_configurations\n    utility_configs = _get_utility_route_configs(modules)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:229: in _get_utility_route_configs\n    utility_configs = _get_utility_configs(modules)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:239: in _get_utility_configs\n    \"unified_tools\": (modules[\"unified_tools\"].router, \"/api/tools\", [\"unified-tools\"])}\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app.routes.unified_tools' has no attribute 'router'\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=13, microseconds=383115), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=56704, name='MainProcess'), 'thread': (id=22540, name='MainThread'), 'time': datetime(2025, 8, 17, 11, 5, 32, 325649, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.3585200309753418,
          "exit_code": 255,
          "output": "================================================================================\nNETRA AI PLATFORM - FRONTEND TEST RUNNER\n================================================================================\n\n================================================================================\nRunning Jest Tests\n--------------------------------------------------------------------------------\nRunning: npm run test -- --forceExit --detectOpenHandles --testMatch **/__tests__/@(components|hooks|store|services|lib|utils)/**/*.test.[jt]s?(x)\n--------------------------------------------------------------------------------\n\n================================================================================\n[FAIL] CHECKS FAILED with exit code 255\n================================================================================\n\nCleaning up test processes...\n\n'hooks' is not recognized as an internal or external command,\noperable program or batch file.\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755453914.5823388,
          "end_time": 1755453933.952953
        }
      },
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T11:05:37.969379",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 23.143317699432373,
          "exit_code": 4,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\nLoaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n================================================================================\n[FAIL] TESTS FAILED with exit code 4 after 21.53s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\n2025-08-17 11:05:21.058 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 11:05:21.062 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 11:05:21.062 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 11:05:21.064 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 11:05:21.064 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 11:05:21.065 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 11:05:21.065 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 11:05:21.067 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 11:05:21.067 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 11:05:21.071 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 11:05:21.073 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 11:05:21.074 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 11:05:21.075 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 11:05:21.075 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 11:05:21.076 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 11:05:21.076 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 11:05:21.077 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 11:05:21.077 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 11:05:21.078 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 11:05:21.078 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 11:05:21.079 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 11:05:21.079 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 11:05:21.080 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 11:05:21.080 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 11:05:21.081 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 11:05:21.169 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 11:05:21.170 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 11:05:21.171 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 11:05:21.292 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 11:05:22.260 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 11:05:23.027 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 11:05:27.024 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 11:05:27.368 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 11:05:28.130 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 11:05:28.400 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 11:05:31.653 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 11:05:32.065 | INFO     | app.services.quality_gate.quality_gate_core:__init__:34 | Quality Gate Service initialized\n2025-08-17 11:05:32.068 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 11:05:32.068 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\nImportError while loading conftest 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\conftest.py'.\napp\\tests\\conftest.py:52: in <module>\n    from app.main import app\napp\\main.py:71: in <module>\n    app = create_app()\n          ^^^^^^^^^^^^\napp\\core\\app_factory.py:277: in create_app\n    _configure_app_routes(app)\napp\\core\\app_factory.py:290: in _configure_app_routes\n    register_api_routes(app)\napp\\core\\app_factory.py:95: in register_api_routes\n    _import_and_register_routes(app)\napp\\core\\app_factory.py:101: in _import_and_register_routes\n    route_configs = _get_route_configurations(route_modules)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:254: in _get_route_configurations\n    utility_configs = _get_utility_route_configs(modules)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:229: in _get_utility_route_configs\n    utility_configs = _get_utility_configs(modules)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:239: in _get_utility_configs\n    \"unified_tools\": (modules[\"unified_tools\"].router, \"/api/tools\", [\"unified-tools\"])}\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app.routes.unified_tools' has no attribute 'router'\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=17, microseconds=455388), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=54184, name='MainProcess'), 'thread': (id=47872, name='MainThread'), 'time': datetime(2025, 8, 17, 11, 5, 36, 399929, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.4419887065887451,
          "exit_code": 255,
          "output": "================================================================================\nNETRA AI PLATFORM - FRONTEND TEST RUNNER\n================================================================================\n\n================================================================================\nRunning Jest Tests\n--------------------------------------------------------------------------------\nRunning: npm run test -- --forceExit --detectOpenHandles --testMatch **/__tests__/@(components|hooks|store|services|lib|utils)/**/*.test.[jt]s?(x)\n--------------------------------------------------------------------------------\n\n================================================================================\n[FAIL] CHECKS FAILED with exit code 255\n================================================================================\n\nCleaning up test processes...\n\n'hooks' is not recognized as an internal or external command,\noperable program or batch file.\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755453914.3331556,
          "end_time": 1755453937.927029
        }
      },
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T11:07:30.173269",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 12.270200252532959,
          "exit_code": 4,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\nLoaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n================================================================================\n[FAIL] TESTS FAILED with exit code 4 after 11.20s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\n2025-08-17 11:07:24.394 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 11:07:24.396 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 11:07:24.396 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 11:07:24.397 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 11:07:24.398 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 11:07:24.399 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 11:07:24.399 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 11:07:24.399 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 11:07:24.400 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 11:07:24.400 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 11:07:24.400 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 11:07:24.400 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 11:07:24.400 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 11:07:24.401 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 11:07:24.401 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 11:07:24.401 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 11:07:24.402 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 11:07:24.403 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 11:07:24.403 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 11:07:24.404 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 11:07:24.405 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 11:07:24.405 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 11:07:24.406 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 11:07:24.406 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 11:07:24.407 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 11:07:24.447 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 11:07:24.448 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 11:07:24.448 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 11:07:24.515 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 11:07:24.918 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 11:07:25.238 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 11:07:26.779 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 11:07:26.874 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 11:07:27.170 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 11:07:27.272 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 11:07:28.382 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 11:07:28.521 | INFO     | app.services.quality_gate.quality_gate_core:__init__:34 | Quality Gate Service initialized\n2025-08-17 11:07:28.522 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 11:07:28.522 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\nImportError while loading conftest 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\conftest.py'.\napp\\tests\\conftest.py:52: in <module>\n    from app.main import app\napp\\main.py:71: in <module>\n    app = create_app()\n          ^^^^^^^^^^^^\napp\\core\\app_factory.py:277: in create_app\n    _configure_app_routes(app)\napp\\core\\app_factory.py:290: in _configure_app_routes\n    register_api_routes(app)\napp\\core\\app_factory.py:95: in register_api_routes\n    _import_and_register_routes(app)\napp\\core\\app_factory.py:100: in _import_and_register_routes\n    route_modules = _import_route_modules()\n                    ^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:190: in _import_route_modules\n    factory_routers = _import_factory_routers()\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:165: in _import_factory_routers\n    status_routers = _import_factory_status_routers()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:172: in _import_factory_status_routers\n    from app.routes.factory_status import router as factory_status_router\nE   ImportError: cannot import name 'router' from 'app.routes.factory_status' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\routes\\factory_status\\__init__.py). Did you mean: 'routes'?\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=7, microseconds=396646), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=40824, name='MainProcess'), 'thread': (id=15008, name='MainThread'), 'time': datetime(2025, 8, 17, 11, 7, 29, 85752, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.5091781616210938,
          "exit_code": 15,
          "output": "\n'hooks' is not recognized as an internal or external command,\noperable program or batch file.\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755454037.3682923,
          "end_time": 1755454050.15381
        }
      },
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T11:08:24.965008",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 13.396212100982666,
          "exit_code": 4,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\nLoaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n================================================================================\n[FAIL] TESTS FAILED with exit code 4 after 12.19s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\n2025-08-17 11:08:16.007 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 11:08:16.009 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 11:08:16.009 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 11:08:16.010 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 11:08:16.010 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 11:08:16.010 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 11:08:16.010 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 11:08:16.010 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 11:08:16.010 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 11:08:16.011 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 11:08:16.011 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 11:08:16.011 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 11:08:16.011 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 11:08:16.011 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 11:08:16.012 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 11:08:16.012 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 11:08:16.013 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 11:08:16.014 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 11:08:16.014 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 11:08:16.014 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 11:08:16.015 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 11:08:16.015 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 11:08:16.015 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 11:08:16.015 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 11:08:16.015 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 11:08:16.045 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 11:08:16.045 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 11:08:16.046 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 11:08:16.088 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 11:08:16.378 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 11:08:16.635 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 11:08:18.953 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 11:08:19.198 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 11:08:19.728 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 11:08:19.936 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 11:08:22.095 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 11:08:22.340 | INFO     | app.services.quality_gate.quality_gate_core:__init__:34 | Quality Gate Service initialized\n2025-08-17 11:08:22.341 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 11:08:22.341 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\nImportError while loading conftest 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\conftest.py'.\napp\\tests\\conftest.py:52: in <module>\n    from app.main import app\napp\\main.py:71: in <module>\n    app = create_app()\n          ^^^^^^^^^^^^\napp\\core\\app_factory.py:277: in create_app\n    _configure_app_routes(app)\napp\\core\\app_factory.py:290: in _configure_app_routes\n    register_api_routes(app)\napp\\core\\app_factory.py:95: in register_api_routes\n    _import_and_register_routes(app)\napp\\core\\app_factory.py:100: in _import_and_register_routes\n    route_modules = _import_route_modules()\n                    ^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:190: in _import_route_modules\n    factory_routers = _import_factory_routers()\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:165: in _import_factory_routers\n    status_routers = _import_factory_status_routers()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:172: in _import_factory_status_routers\n    from app.routes.factory_status import router as factory_status_router\nE   ImportError: cannot import name 'router' from 'app.routes.factory_status' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\routes\\factory_status\\__init__.py). Did you mean: 'routes'?\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=9, microseconds=611229), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=51736, name='MainProcess'), 'thread': (id=13004, name='MainThread'), 'time': datetime(2025, 8, 17, 11, 8, 23, 745961, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.35938382148742676,
          "exit_code": 15,
          "output": "\n'hooks' is not recognized as an internal or external command,\noperable program or batch file.\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755454091.170307,
          "end_time": 1755454104.93506
        }
      },
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T11:08:59.307468",
      "level": "unit",
      "results": {
        "backend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "frontend": {
          "status": "failed",
          "duration": 0.315990686416626,
          "exit_code": 15,
          "output": "\n'hooks' is not recognized as an internal or external command,\noperable program or batch file.\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755454138.97976,
          "end_time": 1755454139.2967525
        }
      },
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T11:32:05.232553",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 4.029964208602905,
          "exit_code": 4,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\nLoaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n================================================================================\n[FAIL] TESTS FAILED with exit code 4 after 3.44s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\nImportError while loading conftest 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\conftest.py'.\napp\\tests\\conftest.py:52: in <module>\n    from app.main import app\napp\\main.py:69: in <module>\n    from app.core.app_factory import create_app\napp\\core\\app_factory.py:9: in <module>\n    from app.core.lifespan_manager import lifespan\napp\\core\\lifespan_manager.py:8: in <module>\n    from app.startup_module import run_complete_startup\napp\\startup_module.py:16: in <module>\n    from app.config import settings\nE   ImportError: cannot import name 'settings' from 'app.config' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\config\\__init__.py)\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(microseconds=750130), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=13084, name='MainProcess'), 'thread': (id=16920, name='MainThread'), 'time': datetime(2025, 8, 17, 11, 32, 4, 623644, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.366743803024292,
          "exit_code": 255,
          "output": "================================================================================\nNETRA AI PLATFORM - FRONTEND TEST RUNNER\n================================================================================\n\n================================================================================\nRunning Jest Tests\n--------------------------------------------------------------------------------\nRunning: npm run test -- --forceExit --detectOpenHandles --testMatch **/__tests__/@(components|hooks|store|services|lib|utils)/**/*.test.[jt]s?(x)\n--------------------------------------------------------------------------------\n\n================================================================================\n[FAIL] CHECKS FAILED with exit code 255\n================================================================================\n\nCleaning up test processes...\n\n'hooks' is not recognized as an internal or external command,\noperable program or batch file.\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755455520.8192115,
          "end_time": 1755455525.2191868
        }
      },
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T11:34:29.872935",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 3.5652222633361816,
          "exit_code": 4,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\nLoaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n================================================================================\n[FAIL] TESTS FAILED with exit code 4 after 3.12s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\nImportError while loading conftest 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\conftest.py'.\napp\\tests\\conftest.py:52: in <module>\n    from app.main import app\napp\\main.py:69: in <module>\n    from app.core.app_factory import create_app\napp\\core\\app_factory.py:9: in <module>\n    from app.core.lifespan_manager import lifespan\napp\\core\\lifespan_manager.py:8: in <module>\n    from app.startup_module import run_complete_startup\napp\\startup_module.py:16: in <module>\n    from app.config import settings\nE   ImportError: cannot import name 'settings' from 'app.config' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\config\\__init__.py)\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(microseconds=832646), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=41016, name='MainProcess'), 'thread': (id=46248, name='MainThread'), 'time': datetime(2025, 8, 17, 11, 34, 29, 281170, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.41980600357055664,
          "exit_code": 15,
          "output": "\n'hooks' is not recognized as an internal or external command,\noperable program or batch file.\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755455665.87729,
          "end_time": 1755455669.8672097
        }
      },
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T11:37:48.347142",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 5.685929536819458,
          "exit_code": 4,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\nLoaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n================================================================================\n[FAIL] TESTS FAILED with exit code 4 after 4.94s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\nImportError while loading conftest 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\conftest.py'.\napp\\tests\\conftest.py:52: in <module>\n    from app.main import app\napp\\main.py:69: in <module>\n    from app.core.app_factory import create_app\napp\\core\\app_factory.py:9: in <module>\n    from app.core.lifespan_manager import lifespan\napp\\core\\lifespan_manager.py:8: in <module>\n    from app.startup_module import run_complete_startup\napp\\startup_module.py:16: in <module>\n    from app.config import settings\nE   ImportError: cannot import name 'settings' from 'app.config' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\config\\__init__.py)\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=1, microseconds=212170), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=45732, name='MainProcess'), 'thread': (id=41580, name='MainThread'), 'time': datetime(2025, 8, 17, 11, 37, 47, 587879, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.47469234466552734,
          "exit_code": 15,
          "output": "\n'hooks' is not recognized as an internal or external command,\noperable program or batch file.\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755455862.1610425,
          "end_time": 1755455868.3265953
        }
      },
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T11:48:56.081356",
      "level": "smoke",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 0.15553045272827148,
          "exit_code": 2,
          "output": "\nusage: test_backend.py [-h]\n                       [--category {unit,integration,agent,websocket,auth,database,critical,smoke}]\n                       [--keyword KEYWORD] [--markers MARKERS]\n                       [--parallel PARALLEL] [--fail-fast] [--failed-first]\n                       [--coverage] [--min-coverage MIN_COVERAGE] [--verbose]\n                       [--quiet] [--json-output] [--html-output] [--profile]\n                       [--check-deps] [--show-warnings] [--isolation]\n                       [--no-bad-test-detection]\n                       [tests ...]\ntest_backend.py: error: unrecognized arguments: -W -W ignore::PendingDeprecationWarning --no-cov --maxfail=1\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755456535.9146054,
          "end_time": 1755456536.0717092
        }
      },
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T11:49:50.633561",
      "level": "smoke",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 2.7132179737091064,
          "exit_code": 4,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: smoke\n  Parallel: auto\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/routes/test_health_route.py app/tests/core/test_error_handling.py::TestNetraExceptions::test_configuration_error app/tests/core/test_config_manager.py::TestConfigManager::test_initialization app/tests/services/test_security_service.py::test_encrypt_and_decrypt tests/test_system_startup.py::TestSystemStartup::test_configuration_loading -v -n auto -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\nLoaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n================================================================================\n[FAIL] TESTS FAILED with exit code 4 after 2.22s\n================================================================================\n\nImportError while loading conftest 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\conftest.py'.\napp\\tests\\conftest.py:52: in <module>\n    from app.main import app\napp\\main.py:69: in <module>\n    from app.core.app_factory import create_app\napp\\core\\app_factory.py:9: in <module>\n    from app.core.lifespan_manager import lifespan\napp\\core\\lifespan_manager.py:8: in <module>\n    from app.startup_module import run_complete_startup\napp\\startup_module.py:16: in <module>\n    from app.config import settings\nE   ImportError: cannot import name 'settings' from 'app.config' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\config\\__init__.py)\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(microseconds=446112), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=43752, name='MainProcess'), 'thread': (id=29288, name='MainThread'), 'time': datetime(2025, 8, 17, 11, 49, 50, 425166, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "test_files": 4
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755456587.9131937,
          "end_time": 1755456590.6289449
        }
      },
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      }
    }
  ],
  "flaky_tests": {},
  "failure_patterns": {},
  "performance_trends": []
}