{
  "runs": [
    {
      "timestamp": "2025-08-17T18:08:08.136962",
      "level": "real_e2e",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 24.614020109176636,
          "exit_code": 1,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -vv -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -k real_ or _real -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 5364 items / 1 error / 1 skipped\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 99\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m__________ ERROR collecting tests/unit/auth_service/test_helpers.py ___________\u001b[0m\n\u001b[31mImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\unit\\auth_service\\test_helpers.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\napp\\tests\\unit\\auth_service\\test_helpers.py:15: in <module>\n    from app.auth.url_validators import (\nE   ImportError: cannot import name 'get_oauth_redirect_uri' from 'app.auth.url_validators' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\url_validators.py)\u001b[0m\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\unit\\auth_service\\test_helpers.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n\u001b[31m======================== \u001b[33m1 skipped\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 15.43s\u001b[0m\u001b[31m =========================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 1 after 22.96s\n================================================================================\n\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=20, microseconds=356866), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=53512, name='MainProcess'), 'thread': (id=53976, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 8, 6, 874918, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 2,
            "passed": 0,
            "failed": 0,
            "skipped": 1,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479263.4790351,
          "end_time": 1755479288.0975773
        }
      },
      "summary": {
        "total": 2,
        "passed": 0,
        "failed": 0,
        "skipped": 1,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:08:45.064956",
      "level": "real_e2e",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 22.18638300895691,
          "exit_code": 1,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -vv -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -k real_ or _real -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 5364 items / 1 error / 1 skipped\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 100\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m__________ ERROR collecting tests/unit/auth_service/test_helpers.py ___________\u001b[0m\n\u001b[31mImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\unit\\auth_service\\test_helpers.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\napp\\tests\\unit\\auth_service\\test_helpers.py:19: in <module>\n    from app.auth.oauth_utils import (\nE   ImportError: cannot import name 'perform_token_exchange_request' from 'app.auth.oauth_utils' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\oauth_utils.py)\u001b[0m\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\unit\\auth_service\\test_helpers.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n\u001b[31m======================== \u001b[33m1 skipped\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 13.90s\u001b[0m\u001b[31m =========================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 1 after 20.75s\n================================================================================\n\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=18, microseconds=516748), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=32216, name='MainProcess'), 'thread': (id=6788, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 8, 43, 898737, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 2,
            "passed": 0,
            "failed": 0,
            "skipped": 1,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479302.8327875,
          "end_time": 1755479325.0257182
        }
      },
      "summary": {
        "total": 2,
        "passed": 0,
        "failed": 0,
        "skipped": 1,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:09:13.354131",
      "level": "comprehensive-api",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 61.87179493904114,
          "exit_code": 2,
          "output": "Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\nLoaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -v -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -k routes or api -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 100\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m__________ ERROR collecting tests/unit/auth_service/test_helpers.py ___________\u001b[0m\nImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\unit\\auth_service\\test_helpers.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\tests\\unit\\auth_service\\test_helpers.py:19: in <module>\n    from app.auth.oauth_utils import (\nE   ImportError: cannot import name 'perform_token_exchange_request' from 'app.auth.oauth_utils' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\oauth_utils.py)\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\unit\\auth_service\\test_helpers.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m======================== \u001b[33m1 skipped\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 50.93s\u001b[0m\u001b[31m =========================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 60.85s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\n2025-08-17 18:08:16.061 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 18:08:16.062 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 18:08:16.062 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 18:08:16.062 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 18:08:16.062 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 18:08:16.062 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 18:08:16.062 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 18:08:16.062 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 18:08:16.062 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 18:08:16.064 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 18:08:16.064 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 18:08:16.065 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 18:08:16.065 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 18:08:16.065 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 18:08:16.065 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 18:08:16.066 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 18:08:16.067 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 18:08:16.067 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 18:08:16.067 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 18:08:16.068 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 18:08:16.068 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 18:08:16.068 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 18:08:16.069 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 18:08:16.069 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 18:08:16.069 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 18:08:16.098 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 18:08:16.100 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 18:08:16.100 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 18:08:16.141 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 18:08:16.420 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 18:08:16.658 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 18:08:18.148 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 18:08:18.228 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 18:08:18.582 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 18:08:18.669 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 18:08:19.612 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:08:19.659 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:08:19.770 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 18:08:19.811 | INFO     | app.services.quality_gate.quality_gate_core:__init__:28 | Quality Gate Service initialized\n2025-08-17 18:08:19.811 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 18:08:19.812 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=46, microseconds=68627), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=32804, name='MainProcess'), 'thread': (id=37356, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 9, 10, 538533, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=46, microseconds=411319), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=56644, name='MainProcess'), 'thread': (id=43652, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 9, 10, 538978, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=46, microseconds=282888), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=52812, name='MainProcess'), 'thread': (id=36608, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 9, 10, 538978, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- End of logging error ---\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=46, microseconds=244195), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=56680, name='MainProcess'), 'thread': (id=48364, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 9, 10, 612601, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=58, microseconds=486302), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=29996, name='MainProcess'), 'thread': (id=45088, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 9, 12, 623158, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 2,
            "passed": 0,
            "failed": 0,
            "skipped": 1,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479291.437346,
          "end_time": 1755479353.315194
        }
      },
      "summary": {
        "total": 2,
        "passed": 0,
        "failed": 0,
        "skipped": 1,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:09:22.747022",
      "level": "real_e2e",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 22.816954612731934,
          "exit_code": 1,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -vv -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -k real_ or _real -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 5364 items / 1 error / 1 skipped\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 101\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m__________ ERROR collecting tests/unit/auth_service/test_helpers.py ___________\u001b[0m\n\u001b[31mImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\unit\\auth_service\\test_helpers.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\napp\\tests\\unit\\auth_service\\test_helpers.py:23: in <module>\n    from app.auth.auth_response_builders import (\nE   ImportError: cannot import name 'build_pr_environment_response' from 'app.auth.auth_response_builders' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\auth_response_builders.py)\u001b[0m\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\unit\\auth_service\\test_helpers.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n\u001b[31m======================== \u001b[33m1 skipped\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 14.56s\u001b[0m\u001b[31m =========================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 1 after 21.38s\n================================================================================\n\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=19, microseconds=200252), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=45616, name='MainProcess'), 'thread': (id=57160, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 9, 21, 610799, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 2,
            "passed": 0,
            "failed": 0,
            "skipped": 1,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479339.8771782,
          "end_time": 1755479362.7044353
        }
      },
      "summary": {
        "total": 2,
        "passed": 0,
        "failed": 0,
        "skipped": 1,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:10:01.670971",
      "level": "real_e2e",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 22.98296022415161,
          "exit_code": 1,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -vv -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -k real_ or _real -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 5364 items / 1 error / 1 skipped\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 102\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m__________ ERROR collecting tests/unit/auth_service/test_helpers.py ___________\u001b[0m\n\u001b[31mImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\unit\\auth_service\\test_helpers.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\napp\\tests\\unit\\auth_service\\test_helpers.py:23: in <module>\n    from app.auth.auth_response_builders import (\nE   ImportError: cannot import name 'set_pr_auth_cookies' from 'app.auth.auth_response_builders' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\auth_response_builders.py)\u001b[0m\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\unit\\auth_service\\test_helpers.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n\u001b[31m======================== \u001b[33m1 skipped\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 14.29s\u001b[0m\u001b[31m =========================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 1 after 21.52s\n================================================================================\n\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=19, microseconds=139115), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=9264, name='MainProcess'), 'thread': (id=13336, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 0, 537348, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 2,
            "passed": 0,
            "failed": 0,
            "skipped": 1,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479378.644028,
          "end_time": 1755479401.6314106
        }
      },
      "summary": {
        "total": 2,
        "passed": 0,
        "failed": 0,
        "skipped": 1,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:10:06.425706",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 52.2029492855072,
          "exit_code": 2,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n4 workers [2484 items]\n\nscheduling tests via LoadScheduling\n\napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_websocket_disconnect_handling \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_compliance_aware_generation \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_search_records_with_filters \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_compliance_aware_generation \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_cost_optimized_generation \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_cost_optimized_generation \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_versioned_corpus_generation \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_versioned_corpus_generation \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_temporal_patterns \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_websocket_disconnect_handling \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_concurrent_agent_execution \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_concurrent_agent_execution \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_temporal_patterns \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_string_input \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_tool_invocations \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_tool_invocations \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_string_input \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_errors \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_dict_input \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_errors \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_dict_input \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_trace_hierarchies \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceBasic::test_run_agent_with_request_model \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_trace_hierarchies \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceBasic::test_run_agent_with_request_model \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_domain_specific \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_service_initialization \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_domain_specific \napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_not_found \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_service_initialization \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_distribution \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_execution_basic \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_not_found \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_distribution \napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_error \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_execution_basic \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_custom_tools \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_with_model_dump_fallback \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_error \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_custom_tools \napp\\tests\\services\\apex_optimizer_agent\\test_tool_builder.py::test_tool_builder_and_dispatcher \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_incremental \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_with_model_dump_fallback \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_start_agent \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_start_agent \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_user_message \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_user_message \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_thread_operations \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_search_records_with_filters \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\test_tool_builder.py::test_tool_builder_and_dispatcher \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_count_records_success \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_advanced_optimization_for_core_function.py::test_advanced_optimization_for_core_function_tool \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_thread_operations \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_advanced_optimization_for_core_function.py::test_advanced_optimization_for_core_function_tool \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_count_records_success \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_basic \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_stop_agent \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_get_summary_stats_success \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_basic \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_full \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_full \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_validation_missing_required \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_get_summary_stats_success \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_stop_agent \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_incremental \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_validation_missing_required \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_dict_conversion \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_from_corpus \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_success \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_unknown_type \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_dict_conversion \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_json_serialization \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_json_serialization \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_from_corpus \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_edge_cases \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_unknown_type \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_with_corpus \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_edge_cases \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_success \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_instantiation \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_json_error \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_with_duration \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_with_corpus \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_synthetic \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_instantiation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_get_metadata \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_synthetic \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_all_workload_types \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_get_metadata \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_all_workload_types \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_wrapper \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_with_duration \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_schema_validation \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_failure \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_json_error \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_schema_validation \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_disconnect_handling \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_wrapper \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_statistical_distribution_validation \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_failure \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_success \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_disconnect_handling \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_failure \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_concurrent_agent_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_concrete_tool_run_method \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_success \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_concrete_tool_run_method \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_failure \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_concurrent_agent_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_llm_name \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_llm_name \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_statistical_distribution_validation \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_string_input \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_multiple_executions \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_failure \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_referential_integrity_validation \napp\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_measures_duration \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_string_input \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_referential_integrity_validation \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_multiple_executions \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_dict_input \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_temporal_consistency_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_concurrent_execution \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_measures_duration \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_temporal_consistency_validation \napp\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_without_context \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_dict_input \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_without_context \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_completeness_validation \napp\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_create_audit_logger_factory \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_concurrent_execution \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceBasic::test_run_agent_with_request_model \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_without_metadata_attribute \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_create_audit_logger_factory \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_completeness_validation \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceBasic::test_run_agent_with_request_model \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_anomaly_detection_in_generated_data \napp\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_end_to_end_audit_workflow \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_without_metadata_attribute \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_failure_recovery \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_inheritance_chain \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_inheritance_chain \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_anomaly_detection_in_generated_data \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_complex_kwargs \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_end_to_end_audit_workflow \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_correlation_preservation \napp\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_large_result_data_handling \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_complex_kwargs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_exception_types \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_large_result_data_handling \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_correlation_preservation \napp\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_metadata_edge_cases \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_quality_metrics_calculation \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_exception_types \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_quality_metrics_calculation \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_diversity_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_async_delay \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_metadata_edge_cases \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_diversity_validation \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_validation_report_generation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_initialization \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_validation_report_generation \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_get_circuit_breaker \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_get_circuit_breaker \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_circuit_breaker_functionality \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_initialization \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_circuit_breaker_functionality \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_generate_with_anomalies_method \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_operation_tracking_context_manager \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_generate_with_anomalies_method \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_detect_anomalies \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_detect_anomalies \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_operation_tracking_context_manager \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_quality_assessment_recording \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_no_data \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_no_data \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_quality_assessment_recording \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_invalid_data \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_snapshot_generation \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_invalid_data \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_corpus_unavailable_fallback \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_snapshot_generation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_export_json \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_async_delay \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_export_json \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_basic_functionality \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_time_series_data_retrieval \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_basic_functionality \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_time_series_data_retrieval \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_comprehensive_report_generation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_empty_logs \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_empty_logs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_single_log \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_single_log \n[gw2]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_failure_recovery \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_comprehensive_report_generation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_large_costs \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_timeout_handling \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_status \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_large_costs \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_status \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_zero_costs \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_monitoring_lifecycle \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_zero_costs \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_monitoring_lifecycle \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_fractional_cents \napp\\tests\\services\\test_corpus_metrics.py::TestCoreMetricsCollector::test_operation_timing \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_fractional_cents \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_exception_handling \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_exception_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_async_execution \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCoreMetricsCollector::test_operation_timing \napp\\tests\\services\\test_corpus_metrics.py::TestQualityMetricsCollector::test_quality_trend_tracking \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestQualityMetricsCollector::test_quality_trend_tracking \napp\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_json_export \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_json_export \napp\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_prometheus_export \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_prometheus_export \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_status_enum \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_status_enum \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_async_execution \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_schema \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_schema \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_concurrent_logs \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_create_schema \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_create_schema \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_timeout_handling \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_service_import \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_resource_cleanup_on_error \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_service_import \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_index_single_document \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_concurrent_logs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_negative_costs \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_resource_cleanup_on_error \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_index_single_document \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_circuit_breaker_pattern \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_batch_indexing_pipeline \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_negative_costs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_mixed_model_types \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_batch_indexing_pipeline \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_reindex_corpus_with_new_model \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_mixed_model_types \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_partial_failure \n[gw3]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_reindex_corpus_with_new_model \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_incremental_indexing \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_partial_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_rounding_edge_cases \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_incremental_indexing \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_document_deduplication \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_rounding_edge_cases \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_circuit_breaker_pattern \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_reduction_quality_preservation.py::test_cost_reduction_quality_preservation_tool \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_graceful_degradation_under_load \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_reduction_quality_preservation.py::test_cost_reduction_quality_preservation_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_simulation_for_increased_usage.py::test_cost_simulation_for_increased_usage_tool \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_graceful_degradation_under_load \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_error_propagation_and_isolation \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_simulation_for_increased_usage.py::test_cost_simulation_for_increased_usage_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_kv_cache_optimization_audit.py::test_kv_cache_optimization_audit_tool \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_kv_cache_optimization_audit.py::test_kv_cache_optimization_audit_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_basic_functionality \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_basic_functionality \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_empty_logs \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_empty_logs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_single_log \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_single_log \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_high_latency_values \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_high_latency_values \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_zero_latency \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_zero_latency \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_sub_millisecond_latency \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_sub_millisecond_latency \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_exception_handling \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_exception_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_async_execution \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_document_deduplication \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_semantic_search \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_semantic_search \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_hybrid_search \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_error_propagation_and_isolation \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_thread_history_handling \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_hybrid_search \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_thread_history_handling \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_async_execution \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_relevance_feedback \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_create_thread_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_large_dataset \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_create_thread_handling \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_relevance_feedback \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_switch_thread_handling \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_search_result_reranking \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_switch_thread_handling \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_search_result_reranking \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_delete_thread_handling \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_create_corpus_with_validation \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_delete_thread_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_list_threads_handling \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_list_threads_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_all_thread_operations_batch \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_all_thread_operations_batch \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_websocket_message_handling_json_error \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_websocket_message_handling_json_error \napp\\tests\\services\\test_apex_optimizer_tool_selection_part1.py::TestApexOptimizerToolSelection::test_tool_selection_cost_optimization \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part1.py::TestApexOptimizerToolSelection::test_tool_selection_cost_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_latency_optimization \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_latency_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_cache_optimization \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_cache_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_model_analysis \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_model_analysis \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_multi_objective \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_multi_objective \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_empty_query \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_empty_query \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_llm_failure \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_llm_failure \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_invalid_json_response \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_invalid_json_response \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_custom_tool_selection \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_custom_tool_selection \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_simple_tool_chain_execution \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_large_dataset \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_varied_latencies \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_varied_latencies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_partial_failure \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_partial_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_edge_case_rounding \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_edge_case_rounding \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_simple_tool_chain_execution \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_conditional_tool_chaining \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_negative_latencies \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_negative_latencies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_mixed_response_formats \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_mixed_response_formats \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_extreme_values \n[gw0]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_extreme_values \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_concurrent_execution_timing \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_corpus_unavailable_fallback \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_clickhouse_connection_recovery \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_conditional_tool_chaining \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_parallel_tool_execution \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_clickhouse_connection_recovery \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_generation_checkpoint_recovery \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_generation_checkpoint_recovery \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_websocket_disconnect_recovery \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_parallel_tool_execution \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_error_handling \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_concurrent_execution_timing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_metadata \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_metadata \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_complete_workflow \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_complete_workflow \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_define_optimization_goals \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_define_optimization_goals \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_analyze_trade_offs \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_analyze_trade_offs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_propose_balanced_optimizations \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_propose_balanced_optimizations \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_simulate_multi_objective_impact \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_simulate_multi_objective_impact \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_with_various_kwargs \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_with_various_kwargs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_method_execution_order \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_method_execution_order \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_method_failure_propagation \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_method_failure_propagation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_concurrent_execution \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_concurrent_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_async_behavior_timing \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_websocket_disconnect_recovery \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_async_behavior_timing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_execute_wrapper_integration \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_execute_wrapper_integration \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_error_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_inheritance \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_cycle_prevention \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_inheritance \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_context_parameter_passing \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_context_parameter_passing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_new_model_effectiveness_analysis.py::test_new_model_effectiveness_analysis_tool \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_new_model_effectiveness_analysis.py::test_new_model_effectiveness_analysis_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_empty_policies \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_empty_policies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_single_policy \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_single_policy \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_create_corpus_with_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_multiple_policies_only_simulates_first \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_update_corpus_metadata \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_multiple_policies_only_simulates_first \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_simulation_failure \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_update_corpus_metadata \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestIndexOptimization::test_index_performance_monitoring \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_simulation_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_with_complex_policy \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestIndexOptimization::test_index_performance_monitoring \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_with_complex_policy \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_redis_connection_failure_recovery \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_validation \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_serialization \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_redis_connection_failure_recovery \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_serialization \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_retry_on_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_async_behavior \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_retry_on_failure \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_recover_from_partial_batch_failure \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_recover_from_partial_batch_failure \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_async_behavior \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_database_connection_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_tool_latency_optimization.py::test_tool_latency_optimization_tool \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_tool_latency_optimization.py::test_tool_latency_optimization_tool \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_workflow_integration <- tests\\helpers\\shared_test_types.py \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_database_connection_failure \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_search_fallback_on_vector_store_failure \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_workflow_integration <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_multi_component_interaction <- tests\\helpers\\shared_test_types.py \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_multi_component_interaction <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_end_to_end_data_flow <- tests\\helpers\\shared_test_types.py \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_search_fallback_on_vector_store_failure \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_end_to_end_data_flow <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_execution_cycle \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_execution_cycle \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_cycle_prevention \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_concurrent_schedule_execution \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_dynamic_tool_chaining \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_unexpected_error \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_concurrent_schedule_execution \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_connection_failure_recovery <- tests\\helpers\\shared_test_types.py \n[gw3]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_unexpected_error \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_connection_failure_recovery <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_isolation \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failure \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failure \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_retry_on_failure \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_retry_on_failure \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failures \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failures \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_agent_execution_failures \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_agent_execution_failures \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_failures_during_execution \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_failures_during_execution \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_default_values \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_default_values \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_dynamic_tool_chaining \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_custom_values \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_selection_performance \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_custom_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_hourly \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_hourly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_daily \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_daily \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_weekly \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_weekly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly_invalid_day \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly_invalid_day \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_enabled_and_time_reached \n[gw3]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_isolation \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_enabled_and_time_reached \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_disabled \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_timeout_handling \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_disabled \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_time_not_reached \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_time_not_reached \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_update_after_run \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_update_after_run \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleFrequencyEnum::test_schedule_frequency_values \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleFrequencyEnum::test_schedule_frequency_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleTimeBoundaries::test_schedule_time_calculations_across_boundaries \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleTimeBoundaries::test_schedule_time_calculations_across_boundaries \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_no_redis \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_no_redis \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_with_redis \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_with_redis \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_all_schedules \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_all_schedules \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_multiple_days \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_multiple_days \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_redis_errors \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_redis_errors \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_add_schedule \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_add_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_exists \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_not_exists \n[gw0]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule_not_exists \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule_not_exists \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status_with_run_history \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status_with_run_history \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_success \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_success \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_failure \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_failure \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_caching \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_caching \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_no_redis \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_no_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_significant_price_changes \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_significant_price_changes \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_new_models \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_new_models \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_no_significant_changes \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_no_significant_changes \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_error_handling \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_error_handling \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_with_redis \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_with_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_without_redis \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_without_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedules_created \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedules_created \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedule_configurations \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedule_configurations \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler_already_running \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler_already_running \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_stop_scheduler \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_stop_scheduler \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_execution \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_execution \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_no_due_schedules \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_no_due_schedules \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_error_handling \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_error_handling \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_selection_performance \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_concurrent_tool_execution_scaling \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_disabled_schedules \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_timeout_handling \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_disabled_schedules \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_exists \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_exists \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_not_exists \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_not_exists \napp\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_generation_job_monitoring \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_handling \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_concurrent_tool_execution_scaling \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_chain_optimization_performance \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_handling \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_connection_loss_during_transaction \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_connection_loss_during_transaction \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_deadlock_detection_and_retry \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_deadlock_detection_and_retry \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_state_tracking \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_state_tracking \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_repository_operation_logging \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_repository_operation_logging \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_high_concurrency_transactions \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_chain_optimization_performance \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_metrics_and_monitoring \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_high_concurrency_transactions \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_throughput_measurement \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_generation_job_monitoring \napp\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_corpus_usage_analytics \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_corpus_usage_analytics \napp\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_audit_log_generation \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_audit_log_generation \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_metrics_and_monitoring \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_load_balancing \n[gw3]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_throughput_measurement \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_memory_usage_during_batch_operations \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_load_balancing \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_resource_management \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_resource_management \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_get \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_get \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_post \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_post \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_other_method \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_other_method \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_post \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_post \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_get \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_get \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_other_method \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_other_method \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_create \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_create \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_bulk_create \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_bulk_create \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_by_id \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_by_id \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_many \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_many \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_update \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_update \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_delete \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_delete \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_soft_delete \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_soft_delete \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_pagination \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_pagination \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_successful_llm_call \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_successful_llm_call \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_circuit_breaker_opens \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_circuit_breaker_opens \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_structured_output_protection \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_structured_output_protection \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_health_check \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_health_check \napp\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_successful_db_query \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_successful_db_query \napp\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_memory_usage_during_batch_operations \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_latency_distribution \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_latency_distribution \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_deadlock_recovery_performance \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_deadlock_recovery_performance \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_connection_pool_stress \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_connection_pool_stress \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_successful_transaction \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_successful_transaction \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_rollback_on_exception \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_rollback_on_exception \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_with_external_session \n[gw3]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_with_external_session \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_repository_access \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_repository_access \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_session_lifecycle \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_session_lifecycle \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_nested_transactions \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_nested_transactions \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_error_handling \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_error_handling \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_new_session \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_new_session \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_existing_session \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_existing_session \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_valid \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_valid \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_invalid \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_invalid \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_financial \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_financial \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_different_industries \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_different_industries \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_synthetic_metrics \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_synthetic_metrics \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report_session_not_found \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report_session_not_found \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status_not_found \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status_not_found \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_submit_feedback \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_submit_feedback \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_track_demo_interaction \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_track_demo_interaction \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_analytics_summary \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_analytics_summary \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_demo_response \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_demo_response \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_error_handling_redis_failure \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_error_handling_redis_failure \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_google_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_google_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_openai_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_openai_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_anthropic_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_anthropic_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_generic_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_generic_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_fast_api_config <- tests\\services\\test_external_api_config.py \n[gw3]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_fast_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_creation <- tests\\services\\test_http_error.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_creation <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_without_response_data <- tests\\services\\test_http_error.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_without_response_data <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_inheritance <- tests\\services\\test_http_error.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_inheritance <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization_defaults <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization_defaults <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_google <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_google <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_openai <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_openai <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_anthropic <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_anthropic <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_health <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_health <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_generic <- tests\\services\\test_resilient_client_init.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_generic <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_with_base_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_with_base_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_absolute_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_absolute_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_no_base_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_no_base_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_none <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_none <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_override <- tests\\services\\test_resilient_client_url_headers.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_override <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_new <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_new <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_reuse <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_reuse <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_closed_recreate <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_closed_recreate <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_session <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_no_session <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_no_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_already_closed_session <- tests\\services\\test_resilient_client_session.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_already_closed_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_new <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_new <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_existing <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_existing <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_fallback_response <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_fallback_response <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_success <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_success <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_circuit_open <- tests\\services\\test_resilient_client_circuit.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_circuit_open <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_json <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_json <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_text <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_text <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_json <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_json <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_text <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_text <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_error <- tests\\services\\test_resilient_client_response.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_error <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_get_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_get_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_post_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_post_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_put_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_put_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_delete_method <- tests\\services\\test_resilient_client_methods.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_delete_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_success <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_success <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_error <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_error <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_no_base_url <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_no_base_url <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_success <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_success <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_failure <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_failure <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_circuit <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_circuit <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_connectivity <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_connectivity <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_recovering <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_recovering <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_healthy <- tests\\services\\test_resilient_client_health.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_healthy <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_retryable_client_inheritance <- tests\\services\\test_retryable_client.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_retryable_client_inheritance <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_get_with_retry <- tests\\services\\test_retryable_client.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_get_with_retry <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_post_with_retry <- tests\\services\\test_retryable_client.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_post_with_retry <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_manager_initialization <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_manager_initialization <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_resilient <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_resilient <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_retryable <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_retryable <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_existing <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_existing <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_empty <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_empty <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_with_clients <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_with_clients <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_empty <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_empty <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_with_clients <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_with_clients <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGetHTTPClient::test_get_http_client_context_manager <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGetHTTPClient::test_get_http_client_context_manager <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_exists <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_exists <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_singleton_behavior <- tests\\services\\test_http_client_manager.py \n[gw3]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_singleton_behavior <- tests\\services\\test_http_client_manager.py Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 102\n\n================================================================================\n\n\n\n================================== FAILURES ===================================\n\u001b[31m\u001b[1m____________ TestErrorRecovery.test_websocket_disconnect_recovery _____________\u001b[0m\n[gw1] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\synthetic_data\\test_error_recovery.py\u001b[0m:104: in test_websocket_disconnect_recovery\n    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m recovery_service.generate_with_ws_updates(\u001b[90m\u001b[39;49;00m\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AttributeError: 'SyntheticDataService' object has no attribute 'generate_with_ws_updates'. Did you mean: 'generate_with_audit'?\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:09:54.107 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:09:54.367 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m________________ TestAdminVisibility.test_audit_log_generation ________________\u001b[0m\n[gw0] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\synthetic_data\\test_admin_visibility.py\u001b[0m:63: in test_audit_log_generation\n    \u001b[0m\u001b[94mawait\u001b[39;49;00m admin_service.generate_with_audit(\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\services\\synthetic_data\\synthetic_data_service_main.py\u001b[0m:59: in generate_with_audit\n    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.job_ops.generate_with_audit(config, job_id, user_id, db)\u001b[90m\u001b[39;49;00m\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\services\\synthetic_data\\job_operations.py\u001b[0m:40: in generate_with_audit\n    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.audit_interface.generate_with_audit(\u001b[96mself\u001b[39;49;00m, config, job_id, user_id, db)\u001b[90m\u001b[39;49;00m\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\services\\synthetic_data\\audit_interface.py\u001b[0m:26: in generate_with_audit\n    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m service.generate_synthetic_data(config, db, user_id, \u001b[94mNone\u001b[39;49;00m, job_id)\u001b[90m\u001b[39;49;00m\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AttributeError: 'JobOperations' object has no attribute 'generate_synthetic_data'\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:09:56.408 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:09:56.641 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m______ TestDatabaseClientCircuitBreaker.test_db_circuit_breaker_fallback ______\u001b[0m\n[gw2] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\test_circuit_breaker_integration.py\u001b[0m:180: in test_db_circuit_breaker_fallback\n    \u001b[0m\u001b[94massert\u001b[39;49;00m postgres_circuit.failure_count == \u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   assert 0 == 1\u001b[0m\n\u001b[1m\u001b[31mE    +  where 0 = <app.core.adaptive_circuit_breaker_core.AdaptiveCircuitBreaker object at 0x000001473A3EA330>.failure_count\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:09:58.015 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured stderr call -----------------------------\n2025-08-17 18:09:58.022 | WARNING  | app.core.adaptive_circuit_breaker_core:_transition_to_open:197 | Circuit breaker db_read transitioning to OPEN\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:09:58.197 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::\u001b[1mTestErrorRecovery::test_websocket_disconnect_recovery\u001b[0m - AttributeError: 'SyntheticDataService' object has no attribute 'generate_with_ws_updates'. Did you mean: 'generate_with_audit'?\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::\u001b[1mTestAdminVisibility::test_audit_log_generation\u001b[0m - AttributeError: 'JobOperations' object has no attribute 'generate_synthetic_data'\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::\u001b[1mTestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback\u001b[0m - assert 0 == 1\n +  where 0 = <app.core.adaptive_circuit_breaker_core.AdaptiveCircuitBreaker object at 0x000001473A3EA330>.failure_count\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 3 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m================= \u001b[31m\u001b[1m3 failed\u001b[0m, \u001b[32m393 passed\u001b[0m, \u001b[33m10 skipped\u001b[0m\u001b[31m in 39.80s\u001b[0m\u001b[31m ==================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 51.15s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\nC:\\Users\\antho\\miniconda3\\Lib\\site-packages\\_pytest\\runner.py:146: RuntimeWarning: coroutine 'ResearchExecutor.execute_scheduled_research' was never awaited\n  item.funcargs = None  # type: ignore[attr-defined]\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n2025-08-17 18:09:18.784 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 18:09:18.785 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 18:09:18.785 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 18:09:18.785 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 18:09:18.785 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 18:09:18.786 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 18:09:18.786 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 18:09:18.786 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 18:09:18.786 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 18:09:18.786 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 18:09:18.787 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 18:09:18.787 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 18:09:18.787 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 18:09:18.788 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 18:09:18.788 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 18:09:18.789 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 18:09:18.790 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 18:09:18.791 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 18:09:18.791 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 18:09:18.791 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 18:09:18.792 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 18:09:18.792 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 18:09:18.792 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 18:09:18.792 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 18:09:18.794 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 18:09:18.827 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 18:09:18.828 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 18:09:18.828 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 18:09:18.874 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 18:09:19.184 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 18:09:19.479 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 18:09:21.061 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 18:09:21.177 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 18:09:21.769 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 18:09:21.917 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 18:09:23.220 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:09:23.284 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:09:23.419 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 18:09:23.490 | INFO     | app.services.quality_gate.quality_gate_core:__init__:28 | Quality Gate Service initialized\n2025-08-17 18:09:23.491 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 18:09:23.491 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=35, microseconds=69040), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=31716, name='MainProcess'), 'thread': (id=29608, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 3, 431749, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=35, microseconds=211999), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=51352, name='MainProcess'), 'thread': (id=54300, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 3, 431749, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=35, microseconds=157238), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=28160, name='MainProcess'), 'thread': (id=6652, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 3, 432748, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=35, microseconds=130315), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=32552, name='MainProcess'), 'thread': (id=32536, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 3, 566772, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=48, microseconds=676295), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=9436, name='MainProcess'), 'thread': (id=6340, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 5, 511539, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 406,
            "passed": 393,
            "failed": 3,
            "skipped": 10,
            "errors": 0,
            "import_errors": 0,
            "test_files": 48,
            "status": "failed"
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.11997365951538086,
          "exit_code": 2,
          "output": "\nusage: test_frontend.py [-h]\n                        [--category {unit,integration,components,hooks,store,websocket,auth,e2e,smoke}]\n                        [--keyword KEYWORD] [--e2e] [--cypress-open] [--watch]\n                        [--coverage] [--update-snapshots] [--lint] [--fix]\n                        [--type-check] [--build] [--check-deps]\n                        [--install-deps] [--verbose] [--isolation]\n                        [--cleanup-on-exit]\n                        [tests ...]\ntest_frontend.py: error: unrecognized arguments: --no-cov\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "import_errors": 0,
            "test_files": 0,
            "status": "unknown"
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479353.9958718,
          "end_time": 1755479406.382248
        }
      },
      "summary": {
        "total": 406,
        "passed": 393,
        "failed": 3,
        "skipped": 10,
        "errors": 0
      }
    },
    {
      "timestamp": "2025-08-17T18:10:42.875188",
      "level": "comprehensive-api",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 63.928088665008545,
          "exit_code": 2,
          "output": "Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\nLoaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -v -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -k routes or api -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 102\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m__________ ERROR collecting tests/unit/auth_service/test_helpers.py ___________\u001b[0m\nImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\unit\\auth_service\\test_helpers.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\tests\\unit\\auth_service\\test_helpers.py:23: in <module>\n    from app.auth.auth_response_builders import (\nE   ImportError: cannot import name 'set_pr_auth_cookies' from 'app.auth.auth_response_builders' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\auth\\auth_response_builders.py)\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\unit\\auth_service\\test_helpers.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m======================== \u001b[33m1 skipped\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 50.41s\u001b[0m\u001b[31m =========================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 62.91s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\n2025-08-17 18:09:44.405 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 18:09:44.405 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 18:09:44.405 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 18:09:44.405 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 18:09:44.405 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 18:09:44.405 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 18:09:44.408 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 18:09:44.408 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 18:09:44.408 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 18:09:44.408 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 18:09:44.408 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 18:09:44.408 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 18:09:44.408 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 18:09:44.410 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 18:09:44.410 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 18:09:44.410 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 18:09:44.412 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 18:09:44.412 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 18:09:44.412 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 18:09:44.412 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 18:09:44.412 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 18:09:44.414 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 18:09:44.414 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 18:09:44.414 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 18:09:44.414 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 18:09:44.449 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 18:09:44.451 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 18:09:44.451 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 18:09:44.500 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 18:09:44.867 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 18:09:45.268 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 18:09:47.017 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 18:09:47.137 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 18:09:47.676 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 18:09:47.839 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 18:09:49.240 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:09:49.313 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:09:49.481 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 18:09:49.547 | INFO     | app.services.quality_gate.quality_gate_core:__init__:28 | Quality Gate Service initialized\n2025-08-17 18:09:49.547 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 18:09:49.549 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=44, microseconds=995565), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=41448, name='MainProcess'), 'thread': (id=15516, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 39, 966708, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=44, microseconds=727430), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=14680, name='MainProcess'), 'thread': (id=52068, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 39, 967785, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=44, microseconds=861052), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=41272, name='MainProcess'), 'thread': (id=20052, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 39, 967785, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=44, microseconds=755178), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=16256, name='MainProcess'), 'thread': (id=37092, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 40, 14794, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=60, microseconds=68469), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=34760, name='MainProcess'), 'thread': (id=45304, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 42, 186515, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 2,
            "passed": 0,
            "failed": 0,
            "skipped": 1,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479378.9047325,
          "end_time": 1755479442.8405404
        }
      },
      "summary": {
        "total": 2,
        "passed": 0,
        "failed": 0,
        "skipped": 1,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:10:57.862455",
      "level": "real_e2e",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 19.549230813980103,
          "exit_code": 1,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -vv -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -k real_ or _real -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 5502 items / 1 error / 1 skipped\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 103\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m_____________ ERROR collecting tests/unit/test_pr_router_auth.py ______________\u001b[0m\n\u001b[31mImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\unit\\test_pr_router_auth.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\napp\\tests\\unit\\test_pr_router_auth.py:6: in <module>\n    from app.auth.pr_router import (\nE   ModuleNotFoundError: No module named 'app.auth.pr_router'\u001b[0m\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\unit\\test_pr_router_auth.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n\u001b[31m======================== \u001b[33m1 skipped\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 11.20s\u001b[0m\u001b[31m =========================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 1 after 18.27s\n================================================================================\n\n--- Logging error in Loguru Handler #7 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=15, microseconds=328178), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=56152, name='MainProcess'), 'thread': (id=29312, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 10, 56, 895994, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 2,
            "passed": 0,
            "failed": 0,
            "skipped": 1,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479438.2644112,
          "end_time": 1755479457.8201826
        }
      },
      "summary": {
        "total": 2,
        "passed": 0,
        "failed": 0,
        "skipped": 1,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:11:40.003425",
      "level": "real_e2e",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 10.594346761703491,
          "exit_code": 1,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests tests integration_tests -vv -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings -k real_ or _real -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 901 items / 1 error\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 105\n\n================================================================================\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m_______ ERROR collecting tests/auth/test_auth_cloud_run_environment.py ________\u001b[0m\n\u001b[31mImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\auth\\test_auth_cloud_run_environment.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n..\\..\\..\\..\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n..\\..\\..\\..\\miniconda3\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\napp\\tests\\auth\\test_auth_cloud_run_environment.py:18: in <module>\n    from app.auth.environment_config import (\nE   ModuleNotFoundError: No module named 'app.auth.environment_config'\u001b[0m\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mERROR\u001b[0m app\\tests\\auth\\test_auth_cloud_run_environment.py\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n\u001b[31m============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.68s\u001b[0m\u001b[31m ===============================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 1 after 9.60s\n================================================================================\n\n--- Logging error in Loguru Handler #2 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=7, microseconds=437119), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=44964, name='MainProcess'), 'thread': (id=9808, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 11, 39, 328134, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 1,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 1,
            "import_errors": 2,
            "status": "import_error",
            "test_files": 0
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "skipped",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479489.3703694,
          "end_time": 1755479499.9708314
        }
      },
      "summary": {
        "total": 1,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 1
      }
    },
    {
      "timestamp": "2025-08-17T18:12:34.715205",
      "level": "unit",
      "results": {
        "backend": {
          "status": "failed",
          "duration": 48.30363154411316,
          "exit_code": 2,
          "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services -p test_framework.pytest_bad_test_plugin --test-component backend\n================================================================================\n[BAD TEST DETECTOR] Initialized for backend tests\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n4 workers [2484 items]\n\nscheduling tests via LoadScheduling\n\napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_compliance_aware_generation \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_websocket_disconnect_handling \napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_search_records_with_filters \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_compliance_aware_generation \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_cost_optimized_generation \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_cost_optimized_generation \napp\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_versioned_corpus_generation \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_features.py::TestAdvancedFeatures::test_versioned_corpus_generation \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_temporal_patterns \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_temporal_patterns \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_tool_invocations \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_websocket_disconnect_handling \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_tool_invocations \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_concurrent_agent_execution \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_errors \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_errors \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_trace_hierarchies \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_concurrent_agent_execution \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_trace_hierarchies \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_string_input \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_domain_specific \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_string_input \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_domain_specific \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_dict_input \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_distribution \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_distribution \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceOrchestration::test_message_parsing_dict_input \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_custom_tools \napp\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceBasic::test_run_agent_with_request_model \n[gw3]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_with_custom_tools \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_basic.py::TestAgentServiceBasic::test_run_agent_with_request_model \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_incremental \napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_not_found \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_service_initialization \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_service_initialization \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_not_found \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_execution_basic \napp\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_error \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_search_records_with_filters \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_execution_basic \n[gw1]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\agents\\test_tools.py::test_tool_dispatcher_tool_error \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_count_records_success \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_with_model_dump_fallback \napp\\tests\\services\\apex_optimizer_agent\\test_tool_builder.py::test_tool_builder_and_dispatcher \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_count_records_success \n[gw2]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_agent_run_with_model_dump_fallback \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_get_summary_stats_success \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_start_agent \n[gw0]\u001b[36m [  0%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditRepository::test_get_summary_stats_success \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_start_agent \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_success \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_user_message \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_user_message \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\test_tool_builder.py::test_tool_builder_and_dispatcher \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_success \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_thread_operations \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_with_duration \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_advanced_optimization_for_core_function.py::test_advanced_optimization_for_core_function_tool \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_incremental \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_advanced_optimization_for_core_function.py::test_advanced_optimization_for_core_function_tool \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_with_duration \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_basic \napp\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_from_corpus \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_failure \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_basic \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_thread_operations \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_full \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_stop_agent \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_creation_full \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_validation_missing_required \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_advanced_generation.py::TestAdvancedGenerationMethods::test_generate_from_corpus \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_validation_missing_required \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_with_corpus \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_dict_conversion \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_log_operation_failure \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_dict_conversion \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_with_corpus \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_stop_agent \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_unknown_type \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_success \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_json_serialization \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_json_serialization \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_synthetic \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_synthetic \napp\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_all_workload_types \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_content_generation.py::TestContentGeneration::test_generate_content_all_workload_types \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_schema_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_edge_cases \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestToolMetadata::test_tool_metadata_edge_cases \n[gw0]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_success \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_unknown_type \n[gw3]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_schema_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_instantiation \napp\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_failure \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_instantiation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_get_metadata \n[gw1]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_get_metadata \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_statistical_distribution_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_wrapper \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_json_error \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestCorpusAuditLogger::test_search_audit_logs_failure \napp\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_measures_duration \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_message_handling_json_error \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_wrapper \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_disconnect_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_failure \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_measures_duration \napp\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_without_context \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_failure \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_statistical_distribution_validation \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditTimer::test_timer_without_context \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_websocket_disconnect_handling \napp\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_create_audit_logger_factory \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_referential_integrity_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_concrete_tool_run_method \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_concurrent_agent_execution \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_concrete_tool_run_method \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_create_audit_logger_factory \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_referential_integrity_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_llm_name \napp\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_end_to_end_audit_workflow \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_llm_name \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_temporal_consistency_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_multiple_executions \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_concurrent_agent_execution \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_temporal_consistency_validation \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_string_input \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditIntegration::test_end_to_end_audit_workflow \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_completeness_validation \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_multiple_executions \napp\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_large_result_data_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_concurrent_execution \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_string_input \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_completeness_validation \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_large_result_data_handling \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_dict_input \napp\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_metadata_edge_cases \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_anomaly_detection_in_generated_data \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_concurrent_execution \n[gw0]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_audit.py::TestAuditPerformance::test_metadata_edge_cases \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_without_metadata_attribute \n[gw3]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_anomaly_detection_in_generated_data \n[gw2]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceOrchestrationCore::test_message_parsing_dict_input \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_correlation_preservation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_initialization \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_execute_without_metadata_attribute \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_inheritance_chain \n[gw1]\u001b[36m [  2%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_inheritance_chain \napp\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceBasic::test_run_agent_with_request_model \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_complex_kwargs \n[gw2]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_core.py::TestAgentServiceBasic::test_run_agent_with_request_model \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_initialization \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_operation_tracking_context_manager \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_failure_recovery \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_with_complex_kwargs \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_correlation_preservation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_exception_types \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_quality_metrics_calculation \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_quality_metrics_calculation \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_diversity_validation \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_data_diversity_validation \napp\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_validation_report_generation \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_exception_types \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_data_quality_validation.py::TestDataQualityValidation::test_validation_report_generation \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_get_circuit_breaker \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_async_delay \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_get_circuit_breaker \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_operation_tracking_context_manager \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_circuit_breaker_functionality \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestCircuitBreakerAndErrorHandling::test_circuit_breaker_functionality \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_quality_assessment_recording \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_generate_with_anomalies_method \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_generate_with_anomalies_method \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_detect_anomalies \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_quality_assessment_recording \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_snapshot_generation \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_detect_anomalies \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_no_data \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_no_data \napp\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_invalid_data \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_snapshot_generation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_export_json \n[gw3]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_handling.py::TestErrorScenarios::test_calculate_correlation_invalid_data \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_corpus_unavailable_fallback \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_metrics_export_json \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_time_series_data_retrieval \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_time_series_data_retrieval \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_comprehensive_report_generation \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_comprehensive_report_generation \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_status \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_collector_status \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_base.py::TestBaseTool::test_base_tool_async_delay \napp\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_monitoring_lifecycle \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_basic_functionality \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCorpusMetricsCollector::test_monitoring_lifecycle \napp\\tests\\services\\test_corpus_metrics.py::TestCoreMetricsCollector::test_operation_timing \n[gw1]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_basic_functionality \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_empty_logs \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_empty_logs \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestCoreMetricsCollector::test_operation_timing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_single_log \napp\\tests\\services\\test_corpus_metrics.py::TestQualityMetricsCollector::test_quality_trend_tracking \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestQualityMetricsCollector::test_quality_trend_tracking \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_single_log \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_large_costs \napp\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_json_export \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_json_export \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_large_costs \napp\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_prometheus_export \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_zero_costs \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_failure_recovery \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_metrics.py::TestMetricsExporter::test_prometheus_export \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_status_enum \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_zero_costs \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_timeout_handling \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_status_enum \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_fractional_cents \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_schema \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_schema \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_fractional_cents \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_create_schema \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_exception_handling \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_create_schema \napp\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_service_import \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_exception_handling \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service.py::TestCorpusService::test_corpus_service_import \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_async_execution \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_index_single_document \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_index_single_document \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_batch_indexing_pipeline \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_batch_indexing_pipeline \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_reindex_corpus_with_new_model \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_reindex_corpus_with_new_model \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_incremental_indexing \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_async_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_concurrent_logs \n[gw0]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_incremental_indexing \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_document_deduplication \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_timeout_handling \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_resource_cleanup_on_error \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_concurrent_logs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_negative_costs \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_negative_costs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_mixed_model_types \n[gw2]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_agent_resource_cleanup_on_error \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_circuit_breaker_pattern \n[gw1]\u001b[36m [  4%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_mixed_model_types \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_partial_failure \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_partial_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_rounding_edge_cases \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_analyzer.py::TestCostAnalyzer::test_cost_analyzer_rounding_edge_cases \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_reduction_quality_preservation.py::test_cost_reduction_quality_preservation_tool \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_reduction_quality_preservation.py::test_cost_reduction_quality_preservation_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_simulation_for_increased_usage.py::test_cost_simulation_for_increased_usage_tool \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_cost_simulation_for_increased_usage.py::test_cost_simulation_for_increased_usage_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_kv_cache_optimization_audit.py::test_kv_cache_optimization_audit_tool \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_circuit_breaker_pattern \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_kv_cache_optimization_audit.py::test_kv_cache_optimization_audit_tool \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_basic_functionality \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_graceful_degradation_under_load \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_graceful_degradation_under_load \napp\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_error_propagation_and_isolation \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_basic_functionality \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_empty_logs \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_empty_logs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_single_log \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_single_log \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_high_latency_values \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusDocumentIndexing::test_document_deduplication \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_high_latency_values \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_semantic_search \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_zero_latency \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_zero_latency \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_semantic_search \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_sub_millisecond_latency \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_hybrid_search \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_sub_millisecond_latency \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_exception_handling \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[33mSKIPPED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_hybrid_search \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_relevance_feedback \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_exception_handling \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_async_execution \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_relevance_feedback \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_search_result_reranking \n[gw0]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusSearchRelevance::test_search_result_reranking \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_create_corpus_with_validation \n[gw1]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_async_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_large_dataset \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_orchestration_workflows.py::TestAgentErrorRecovery::test_error_propagation_and_isolation \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_thread_history_handling \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_thread_history_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_create_thread_handling \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_create_thread_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_switch_thread_handling \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_switch_thread_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_delete_thread_handling \n[gw2]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_delete_thread_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_list_threads_handling \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_list_threads_handling \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_all_thread_operations_batch \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_all_thread_operations_batch \napp\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_websocket_message_handling_json_error \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_agent_service_thread_operations.py::TestAgentServiceThreadOperations::test_websocket_message_handling_json_error \napp\\tests\\services\\test_apex_optimizer_tool_selection_part1.py::TestApexOptimizerToolSelection::test_tool_selection_cost_optimization \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part1.py::TestApexOptimizerToolSelection::test_tool_selection_cost_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_latency_optimization \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_latency_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_cache_optimization \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_cache_optimization \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_model_analysis \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_model_analysis \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_multi_objective \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_multi_objective \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_empty_query \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_empty_query \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_llm_failure \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_llm_failure \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_invalid_json_response \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_tool_selection_invalid_json_response \napp\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_custom_tool_selection \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part2.py::TestApexOptimizerAdvancedToolSelection::test_custom_tool_selection \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_simple_tool_chain_execution \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_large_dataset \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_varied_latencies \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_varied_latencies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_partial_failure \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_partial_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_edge_case_rounding \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_edge_case_rounding \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_negative_latencies \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_negative_latencies \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_mixed_response_formats \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_mixed_response_formats \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_extreme_values \n[gw1]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_extreme_values \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_concurrent_execution_timing \n[gw3]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_corpus_unavailable_fallback \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_clickhouse_connection_recovery \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_simple_tool_chain_execution \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_conditional_tool_chaining \n[gw3]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_clickhouse_connection_recovery \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_generation_checkpoint_recovery \n[gw3]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_generation_checkpoint_recovery \napp\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_websocket_disconnect_recovery \n[gw2]\u001b[36m [  6%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_conditional_tool_chaining \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_parallel_tool_execution \n[gw3]\u001b[36m [  7%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::TestErrorRecovery::test_websocket_disconnect_recovery \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_latency_analyzer.py::TestLatencyAnalyzer::test_latency_analyzer_concurrent_execution_timing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_metadata \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_metadata \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_complete_workflow \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_complete_workflow \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_define_optimization_goals \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_define_optimization_goals \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_analyze_trade_offs \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_analyze_trade_offs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_propose_balanced_optimizations \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_propose_balanced_optimizations \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_parallel_tool_execution \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_simulate_multi_objective_impact \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_error_handling \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_simulate_multi_objective_impact \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_with_various_kwargs \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_with_various_kwargs \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_method_execution_order \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_method_execution_order \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_create_corpus_with_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_method_failure_propagation \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_update_corpus_metadata \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_run_method_failure_propagation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_concurrent_execution \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestCorpusManagement::test_update_corpus_metadata \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_concurrent_execution \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestIndexOptimization::test_index_performance_monitoring \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_async_behavior_timing \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestIndexOptimization::test_index_performance_monitoring \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_redis_connection_failure_recovery \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_redis_connection_failure_recovery \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_retry_on_failure \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_retry_on_failure \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_recover_from_partial_batch_failure \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_recover_from_partial_batch_failure \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_database_connection_failure \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_async_behavior_timing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_execute_wrapper_integration \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_database_connection_failure \napp\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_search_fallback_on_vector_store_failure \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_execute_wrapper_integration \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_inheritance \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_tool_inheritance \n[gw0]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_corpus_service_comprehensive.py::TestErrorHandling::test_search_fallback_on_vector_store_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_context_parameter_passing \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \n[gw1]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_multi_objective_optimization.py::TestMultiObjectiveOptimizationTool::test_context_parameter_passing \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_new_model_effectiveness_analysis.py::test_new_model_effectiveness_analysis_tool \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_new_model_effectiveness_analysis.py::test_new_model_effectiveness_analysis_tool \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_empty_policies \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_empty_policies \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_single_policy \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_single_policy \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_multiple_policies_only_simulates_first \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_unexpected_error \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_multiple_policies_only_simulates_first \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_simulation_failure \n[gw2]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_error_handling \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_unexpected_error \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_cycle_prevention \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_isolation \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_simulation_failure \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_with_complex_policy \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_with_complex_policy \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_validation \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_validation \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_serialization \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_learned_policy_model_serialization \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_async_behavior \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_policy_simulator.py::TestPolicySimulator::test_policy_simulator_async_behavior \napp\\tests\\services\\apex_optimizer_agent\\tools\\test_tool_latency_optimization.py::test_tool_latency_optimization_tool \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\apex_optimizer_agent\\tools\\test_tool_latency_optimization.py::test_tool_latency_optimization_tool \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_workflow_integration <- tests\\helpers\\shared_test_types.py \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_workflow_integration <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_multi_component_interaction <- tests\\helpers\\shared_test_types.py \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_multi_component_interaction <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_end_to_end_data_flow <- tests\\helpers\\shared_test_types.py \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_end_to_end_data_flow <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_execution_cycle \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_full_execution_cycle \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_concurrent_schedule_execution \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_isolation \napp\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_timeout_handling \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestIntegrationScenarios::test_concurrent_schedule_execution \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_connection_failure_recovery <- tests\\helpers\\shared_test_types.py \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_connection_failure_recovery <- tests\\helpers\\shared_test_types.py \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failure \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failure \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_retry_on_failure \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_retry_on_failure \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failures \n[gw1]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_database_connection_failures \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_agent_execution_failures \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_agent_execution_failures \napp\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_failures_during_execution \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_integration.py::TestErrorHandling::test_redis_failures_during_execution \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_default_values \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_default_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_custom_values \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_schedule_initialization_custom_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_hourly \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_hourly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_daily \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_daily \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_weekly \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_weekly \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_tool_chain_cycle_prevention \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly_invalid_day \napp\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_dynamic_tool_chaining \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_calculate_next_run_monthly_invalid_day \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_enabled_and_time_reached \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_enabled_and_time_reached \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_disabled \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_disabled \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_time_not_reached \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_should_run_time_not_reached \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_update_after_run \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestResearchSchedule::test_update_after_run \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleFrequencyEnum::test_schedule_frequency_values \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleFrequencyEnum::test_schedule_frequency_values \napp\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleTimeBoundaries::test_schedule_time_calculations_across_boundaries \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_research_schedule.py::TestScheduleTimeBoundaries::test_schedule_time_calculations_across_boundaries \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_no_redis \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_no_redis \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_with_redis \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_with_redis \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_all_schedules \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_all_schedules \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_multiple_days \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_multiple_days \napp\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_redis_errors \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_result_retrieval.py::TestResultRetrieval::test_get_recent_results_redis_errors \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_add_schedule \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_add_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_exists \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_exists \n[gw2]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part3.py::TestApexOptimizerToolChaining::test_dynamic_tool_chaining \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_not_exists \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_selection_performance \n[gw1]\u001b[36m [  9%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_remove_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule_not_exists \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_enable_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule_not_exists \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_disable_schedule_not_exists \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status \napp\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status_with_run_history \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_schedule_management.py::TestScheduleManagement::test_get_schedule_status_with_run_history \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_success \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_success \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_failure \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_failure \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_caching \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_caching \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_no_redis \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestScheduledResearchExecution::test_execute_scheduled_research_no_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_significant_price_changes \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_significant_price_changes \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_new_models \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_new_models \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_no_significant_changes \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_no_significant_changes \napp\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_error_handling \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduled_execution.py::TestChangeNotifications::test_check_and_notify_changes_error_handling \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_with_redis \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_with_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_without_redis \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_initialization_without_redis \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedules_created \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedules_created \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedule_configurations \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerInitialization::test_default_schedule_configurations \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler_already_running \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_start_scheduler_already_running \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_stop_scheduler \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_initialization.py::TestSchedulerStartStop::test_stop_scheduler \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_execution \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_execution \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_no_due_schedules \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_basic_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_timeout_handling \n[gw1]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_no_due_schedules \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_error_handling \n[gw0]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_successful_transaction_commit \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_integrity_error \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_rollback_on_sql_error \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_handling \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_error_handling \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_disabled_schedules \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_concurrent_transaction_handling \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_connection_loss_during_transaction \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_connection_loss_during_transaction \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestSchedulerLoop::test_scheduler_loop_disabled_schedules \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_deadlock_detection_and_retry \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_exists \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_exists \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_deadlock_detection_and_retry \napp\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_not_exists \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_state_tracking \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_transaction_state_tracking \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\supply_research_scheduler\\test_scheduler_loop.py::TestManualExecution::test_run_schedule_now_not_exists \napp\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_repository_operation_logging \napp\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_generation_job_monitoring \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_repository_transactions.py::TestDatabaseRepositoryTransactions::test_repository_operation_logging \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_high_concurrency_transactions \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_selection_performance \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_concurrent_tool_execution_scaling \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_high_concurrency_transactions \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_throughput_measurement \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_concurrent_tool_execution_scaling \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_chain_optimization_performance \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_chain_optimization_performance \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_metrics_and_monitoring \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_generation_job_monitoring \napp\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_corpus_usage_analytics \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_corpus_usage_analytics \napp\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_audit_log_generation \n[gw0]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_throughput_measurement \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_memory_usage_during_batch_operations \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_metrics_and_monitoring \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_load_balancing \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_audit_log_generation \napp\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_performance_profiling \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_performance_profiling \napp\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_alert_configuration \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_load_balancing \napp\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_resource_management \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_apex_optimizer_tool_selection_part4.py::TestApexOptimizerPerformanceAndScaling::test_tool_resource_management \n[gw1]\u001b[36m [ 11%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::TestAdminVisibility::test_alert_configuration \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_get \n[gw2]\u001b[36m [ 11%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_get \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_post \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_post \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_other_method \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_google_api_other_method \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_post \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_post \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_get \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_get \napp\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_other_method \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_api_convenience_functions.py::TestConvenienceFunctions::test_call_openai_api_other_method \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_create \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_create \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_bulk_create \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_bulk_create \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_by_id \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_by_id \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_many \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_get_many \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_update \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_update \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_delete \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_delete \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_soft_delete \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_soft_delete \napp\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_pagination \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_base_repository.py::TestBaseRepository::test_repository_pagination \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_successful_llm_call \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_successful_llm_call \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_circuit_breaker_opens \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_circuit_breaker_opens \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_structured_output_protection \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_structured_output_protection \napp\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_health_check \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestLLMClientCircuitBreaker::test_llm_health_check \napp\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_successful_db_query \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_successful_db_query \napp\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback \n[gw2]\u001b[36m [ 12%] \u001b[0m\u001b[31mFAILED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::TestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback \n[gw0]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_memory_usage_during_batch_operations \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_latency_distribution \n[gw0]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_transaction_latency_distribution \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_deadlock_recovery_performance \n[gw0]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_deadlock_recovery_performance \napp\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_connection_pool_stress \n[gw0]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_transaction_performance.py::TestTransactionPerformanceAndScaling::test_connection_pool_stress \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_successful_transaction \n[gw0]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_successful_transaction \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_rollback_on_exception \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_rollback_on_exception \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_with_external_session \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_with_external_session \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_repository_access \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_repository_access \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_session_lifecycle \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_session_lifecycle \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_nested_transactions \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_nested_transactions \napp\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_error_handling \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_database_unit_of_work_transactions.py::TestUnitOfWorkTransactions::test_unit_of_work_error_handling \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_new_session \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_new_session \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_existing_session \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_process_demo_chat_existing_session \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_valid \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_valid \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_invalid \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_industry_templates_invalid \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_financial \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_financial \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_different_industries \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_calculate_roi_different_industries \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_synthetic_metrics \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_synthetic_metrics \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report_session_not_found \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_report_session_not_found \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status_not_found \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_session_status_not_found \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_submit_feedback \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_submit_feedback \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_track_demo_interaction \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_track_demo_interaction \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_get_analytics_summary \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_get_analytics_summary \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_demo_response \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_generate_demo_response \napp\\tests\\services\\test_demo_service.py::TestDemoService::test_error_handling_redis_failure \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_demo_service.py::TestDemoService::test_error_handling_redis_failure \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_google_api_config <- tests\\services\\test_external_api_config.py \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_google_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_openai_api_config <- tests\\services\\test_external_api_config.py \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_openai_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_anthropic_api_config <- tests\\services\\test_external_api_config.py \n[gw0]\u001b[36m [ 13%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_anthropic_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_generic_api_config <- tests\\services\\test_external_api_config.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_generic_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_fast_api_config <- tests\\services\\test_external_api_config.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestExternalAPIConfig::test_fast_api_config <- tests\\services\\test_external_api_config.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_creation <- tests\\services\\test_http_error.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_creation <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_without_response_data <- tests\\services\\test_http_error.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_without_response_data <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_inheritance <- tests\\services\\test_http_error.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPError::test_http_error_inheritance <- tests\\services\\test_http_error.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization <- tests\\services\\test_resilient_client_init.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization_defaults <- tests\\services\\test_resilient_client_init.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_client_initialization_defaults <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_google <- tests\\services\\test_resilient_client_init.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_google <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_openai <- tests\\services\\test_resilient_client_init.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_openai <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_anthropic <- tests\\services\\test_resilient_client_init.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_anthropic <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_health <- tests\\services\\test_resilient_client_init.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_health <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_generic <- tests\\services\\test_resilient_client_init.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientInit::test_select_config_generic <- tests\\services\\test_resilient_client_init.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_with_base_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_with_base_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_absolute_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_absolute_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_no_base_url <- tests\\services\\test_resilient_client_url_headers.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_build_url_no_base_url <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers <- tests\\services\\test_resilient_client_url_headers.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_none <- tests\\services\\test_resilient_client_url_headers.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_none <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_override <- tests\\services\\test_resilient_client_url_headers.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientUrlHeaders::test_merge_headers_override <- tests\\services\\test_resilient_client_url_headers.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_new <- tests\\services\\test_resilient_client_session.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_new <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_reuse <- tests\\services\\test_resilient_client_session.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_reuse <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_closed_recreate <- tests\\services\\test_resilient_client_session.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_get_session_closed_recreate <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_session <- tests\\services\\test_resilient_client_session.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_no_session <- tests\\services\\test_resilient_client_session.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_no_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_already_closed_session <- tests\\services\\test_resilient_client_session.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientSession::test_close_already_closed_session <- tests\\services\\test_resilient_client_session.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_new <- tests\\services\\test_resilient_client_circuit.py \n[gw0]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_new <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_existing <- tests\\services\\test_resilient_client_circuit.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_circuit_existing <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_fallback_response <- tests\\services\\test_resilient_client_circuit.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_get_fallback_response <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_success <- tests\\services\\test_resilient_client_circuit.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_success <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_circuit_open <- tests\\services\\test_resilient_client_circuit.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientCircuit::test_request_circuit_open <- tests\\services\\test_resilient_client_circuit.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_json <- tests\\services\\test_resilient_client_response.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_json <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_text <- tests\\services\\test_resilient_client_response.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_extract_error_data_text <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_json <- tests\\services\\test_resilient_client_response.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_json <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_text <- tests\\services\\test_resilient_client_response.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_success_text <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_error <- tests\\services\\test_resilient_client_response.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientResponse::test_process_response_error <- tests\\services\\test_resilient_client_response.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_get_method <- tests\\services\\test_resilient_client_methods.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_get_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_post_method <- tests\\services\\test_resilient_client_methods.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_post_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_put_method <- tests\\services\\test_resilient_client_methods.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_put_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_delete_method <- tests\\services\\test_resilient_client_methods.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientMethods::test_delete_method <- tests\\services\\test_resilient_client_methods.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_success <- tests\\services\\test_resilient_client_health.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_success <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_error <- tests\\services\\test_resilient_client_health.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_health_check_error <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_no_base_url <- tests\\services\\test_resilient_client_health.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_no_base_url <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_success <- tests\\services\\test_resilient_client_health.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_success <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_failure <- tests\\services\\test_resilient_client_health.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_test_connectivity_failure <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_circuit <- tests\\services\\test_resilient_client_health.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_circuit <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_connectivity <- tests\\services\\test_resilient_client_health.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_unhealthy_connectivity <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_recovering <- tests\\services\\test_resilient_client_health.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_recovering <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_healthy <- tests\\services\\test_resilient_client_health.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestResilientHTTPClientHealth::test_assess_health_healthy <- tests\\services\\test_resilient_client_health.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_retryable_client_inheritance <- tests\\services\\test_retryable_client.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_retryable_client_inheritance <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_get_with_retry <- tests\\services\\test_retryable_client.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_get_with_retry <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_post_with_retry <- tests\\services\\test_retryable_client.py \n[gw0]\u001b[36m [ 15%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestRetryableHTTPClient::test_post_with_retry <- tests\\services\\test_retryable_client.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_manager_initialization <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_manager_initialization <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_resilient <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_resilient <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_retryable <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_new_retryable <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_existing <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_get_client_existing <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_empty <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_empty <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_with_clients <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_health_check_all_with_clients <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_empty <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_empty <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_with_clients <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestHTTPClientManager::test_close_all_with_clients <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGetHTTPClient::test_get_http_client_context_manager <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGetHTTPClient::test_get_http_client_context_manager <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_exists <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_exists <- tests\\services\\test_http_client_manager.py \napp\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_singleton_behavior <- tests\\services\\test_http_client_manager.py \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app\\tests\\services\\test_external_api_client.py::TestGlobalClientManager::test_global_manager_singleton_behavior <- tests\\services\\test_http_client_manager.py Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\nLoaded .env.development file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development\nLoaded .env.development.local file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.development.local\n\n================================================================================\nBAD TEST DETECTION REPORT\n================================================================================\n\nTotal Bad Tests Detected: 0\nTotal Test Runs Analyzed: 106\n\n================================================================================\n\n\n\n================================== FAILURES ===================================\n\u001b[31m\u001b[1m____________ TestErrorRecovery.test_websocket_disconnect_recovery _____________\u001b[0m\n[gw3] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\synthetic_data\\test_error_recovery.py\u001b[0m:104: in test_websocket_disconnect_recovery\n    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m recovery_service.generate_with_ws_updates(\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   TypeError: SyntheticDataService.generate_with_ws_updates() missing 1 required positional argument: 'job_id'\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:12:23.854 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:12:24.034 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m________________ TestAdminVisibility.test_alert_configuration _________________\u001b[0m\n[gw1] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31m..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py\u001b[0m:913: in assert_called\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: Expected 'send_alert' to have been called.\u001b[0m\n\n\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n\u001b[1m\u001b[31mapp\\tests\\services\\synthetic_data\\test_admin_visibility.py\u001b[0m:103: in test_alert_configuration\n    \u001b[0mmock_alert.assert_called()\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: Expected 'send_alert' to have been called.\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:12:26.758 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured stderr call -----------------------------\n2025-08-17 18:12:26.763 | WARNING  | app.core.unified_logging:_emit_log:117 | ALERT [warning]: Large generation job detected\nC:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\services\\synthetic_data\\core_service_base.py:82: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\n  db.add(db_synthetic_data)\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\nC:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\services\\synthetic_data\\core_service_base.py:83: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\n  db.commit()\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\nC:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\services\\synthetic_data\\core_service_base.py:84: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\n  db.refresh(db_synthetic_data)\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n2025-08-17 18:12:26.850 | ERROR    | app.ws_manager_messaging:_validate_dict_message:70 | Message validation failed: Invalid message type: generation:started\n2025-08-17 18:12:26.851 | INFO     | app.core.unified_logging:_emit_log:117 | Generation job a77e6e65-d27f-42cc-9776-16f1817507c3 started\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:12:27.368 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m______ TestDatabaseClientCircuitBreaker.test_db_circuit_breaker_fallback ______\u001b[0m\n[gw2] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\services\\test_circuit_breaker_integration.py\u001b[0m:180: in test_db_circuit_breaker_fallback\n    \u001b[0m\u001b[94massert\u001b[39;49;00m postgres_circuit.failure_count == \u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   assert 0 == 1\u001b[0m\n\u001b[1m\u001b[31mE    +  where 0 = <app.core.adaptive_circuit_breaker_core.AdaptiveCircuitBreaker object at 0x000001A5873200B0>.failure_count\u001b[0m\n---------------------------- Captured stderr setup ----------------------------\n2025-08-17 18:12:27.865 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured stderr call -----------------------------\n2025-08-17 18:12:27.872 | WARNING  | app.core.adaptive_circuit_breaker_core:_transition_to_open:197 | Circuit breaker db_read transitioning to OPEN\n-------------------------- Captured stderr teardown ---------------------------\n2025-08-17 18:12:28.000 | DEBUG    | logging:handle:1028 | Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_error_recovery.py::\u001b[1mTestErrorRecovery::test_websocket_disconnect_recovery\u001b[0m - TypeError: SyntheticDataService.generate_with_ws_updates() missing 1 required positional argument: 'job_id'\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\synthetic_data\\test_admin_visibility.py::\u001b[1mTestAdminVisibility::test_alert_configuration\u001b[0m - AssertionError: Expected 'send_alert' to have been called.\n\u001b[31mFAILED\u001b[0m app\\tests\\services\\test_circuit_breaker_integration.py::\u001b[1mTestDatabaseClientCircuitBreaker::test_db_circuit_breaker_fallback\u001b[0m - assert 0 == 1\n +  where 0 = <app.core.adaptive_circuit_breaker_core.AdaptiveCircuitBreaker object at 0x000001A5873200B0>.failure_count\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 3 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m================= \u001b[31m\u001b[1m3 failed\u001b[0m, \u001b[32m395 passed\u001b[0m, \u001b[33m10 skipped\u001b[0m\u001b[31m in 37.10s\u001b[0m\u001b[31m ==================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 47.34s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\nC:\\Users\\antho\\miniconda3\\Lib\\site-packages\\_pytest\\runner.py:146: RuntimeWarning: coroutine 'ResearchExecutor.execute_scheduled_research' was never awaited\n  item.funcargs = None  # type: ignore[attr-defined]\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n2025-08-17 18:11:50.948 | INFO     | app.core.unified_logging:_emit_log:117 | Loading configuration for: testing\n2025-08-17 18:11:50.949 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set database_url from DATABASE_URL\n2025-08-17 18:11:50.949 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set redis_url from REDIS_URL\n2025-08-17 18:11:50.950 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set clickhouse_url from CLICKHOUSE_URL\n2025-08-17 18:11:50.950 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set secret_key from SECRET_KEY\n2025-08-17 18:11:50.950 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set jwt_secret_key from JWT_SECRET_KEY\n2025-08-17 18:11:50.951 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set fernet_key from FERNET_KEY\n2025-08-17 18:11:50.951 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set log_level from LOG_LEVEL\n2025-08-17 18:11:50.951 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set environment from ENVIRONMENT\n2025-08-17 18:11:50.951 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse host: localhost\n2025-08-17 18:11:50.951 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse port: 9000\n2025-08-17 18:11:50.951 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse password\n2025-08-17 18:11:50.951 | DEBUG    | app.core.unified_logging:_emit_log:117 | Set ClickHouse user: default\n2025-08-17 18:11:50.951 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 12 env vars\n2025-08-17 18:11:50.953 | INFO     | app.core.unified_logging:_emit_log:117 | Loading secrets...\n2025-08-17 18:11:50.953 | INFO     | app.core.unified_logging:_emit_log:117 | Starting secret=REDACTED process for environment: development\n2025-08-17 18:11:50.953 | INFO     | app.core.unified_logging:_emit_log:117 | Loaded 8 secrets from environment variables\n2025-08-17 18:11:50.953 | DEBUG    | app.core.unified_logging:_emit_log:117 | Critical secrets present in env: jwt-secret-key, fernet-key\n2025-08-17 18:11:50.953 | INFO     | app.core.unified_logging:_emit_log:117 | Using only environment variables for secrets (local development mode): 8 secrets loaded\n2025-08-17 18:11:50.954 | INFO     | app.core.unified_logging:_emit_log:117 | Applying 8 secrets\n2025-08-17 18:11:50.954 | INFO     | app.core.unified_logging:_emit_log:117 | Applied 8 secrets (from 8 loaded)\n2025-08-17 18:11:50.955 | INFO     | app.core.unified_logging:_emit_log:117 | Critical secrets loaded: 2 (jwt-secret-key, fernet-key)\n2025-08-17 18:11:50.955 | WARNING  | app.core.unified_logging:_emit_log:117 | Critical secrets not found in loaded secrets: 1 (gemini-api-key)\n2025-08-17 18:11:50.955 | WARNING  | app.core.unified_logging:_emit_log:117 | LLM configuration warnings: Gemini API key is not configured (required for all LLM operations)\n2025-08-17 18:11:50.956 | INFO     | app.core.unified_logging:_emit_log:117 | Configuration validation completed successfully\n2025-08-17 18:11:50.982 | DEBUG    | logging:handle:1028 | loaded lazy attr 'SafeConfigParser': <class 'configparser.ConfigParser'>\n2025-08-17 18:11:50.982 | DEBUG    | logging:handle:1028 | loaded lazy attr 'NativeStringIO': <class '_io.StringIO'>\n2025-08-17 18:11:50.982 | DEBUG    | logging:handle:1028 | loaded lazy attr 'BytesIO': <class '_io.BytesIO'>\n2025-08-17 18:11:51.022 | DEBUG    | logging:handle:1028 | registered 'bcrypt' handler: <class 'passlib.handlers.bcrypt.bcrypt'>\n2025-08-17 18:11:51.282 | INFO     | app.db.postgres_core:_create_and_setup_engine:258 | PostgreSQL async engine created with AsyncAdaptedQueuePool connection pooling\n2025-08-17 18:11:51.524 | DEBUG    | app.services.metrics.agent_metrics:__init__:24 | Initialized AgentMetricsCollector with buffer size 5000\n2025-08-17 18:11:52.764 | DEBUG    | logging:handle:1028 | Using orjson library for writing JSON byte strings\n2025-08-17 18:11:52.916 | DEBUG    | logging:handle:1028 | Looking up time zone info from registry\n2025-08-17 18:11:53.296 | INFO     | logging:handle:1028 | Session middleware config: same_site=lax, https_only=False, environment=development\n2025-08-17 18:11:53.415 | INFO     | app.core.unified_logging:_emit_log:117 | SyntheticDataService initialized successfully\n2025-08-17 18:11:54.452 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:11:54.506 | INFO     | logging:handle:1028 | UnifiedToolRegistry initialized\n2025-08-17 18:11:54.647 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n2025-08-17 18:11:54.690 | INFO     | app.services.quality_gate.quality_gate_core:__init__:28 | Quality Gate Service initialized\n2025-08-17 18:11:54.690 | INFO     | app.services.quality_monitoring.service:__init__:48 | Quality Monitoring Service initialized\n2025-08-17 18:11:54.690 | INFO     | app.services.fallback_response.response_generator:__init__:25 | Response Generator initialized\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=32, microseconds=115490), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=31908, name='MainProcess'), 'thread': (id=43856, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 12, 31, 849917, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=32, microseconds=212275), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=36392, name='MainProcess'), 'thread': (id=12632, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 12, 31, 850918, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=32, microseconds=76583), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=44604, name='MainProcess'), 'thread': (id=47260, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 12, 31, 850918, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=32, microseconds=429670), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\u2139\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=25028, name='MainProcess'), 'thread': (id=49128, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 12, 32, 60294, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n--- Logging error in Loguru Handler #1 ---\nRecord was: {'elapsed': datetime.timedelta(seconds=44, microseconds=756439), 'exception': None, 'extra': {}, 'file': (name='__init__.py', path='C:\\\\Users\\\\antho\\\\miniconda3\\\\Lib\\\\logging\\\\__init__.py'), 'function': 'handle', 'level': (name='INFO', no=20, icon='\\u2139\\ufe0f'), 'line': 1028, 'message': 'Multiprocessing resources cleaned up', 'module': '__init__', 'name': 'logging', 'process': (id=53236, name='MainProcess'), 'thread': (id=48196, name='MainThread'), 'time': datetime(2025, 8, 17, 18, 12, 33, 905910, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'Pacific Daylight Time'))}\nTraceback (most recent call last):\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_handler.py\", line 315, in _queued_writer\n    self._sink.write(message)\n  File \"C:\\Users\\antho\\miniconda3\\Lib\\site-packages\\loguru\\_simple_sinks.py\", line 16, in write\n    self._stream.write(message)\nValueError: I/O operation on closed file.\n--- End of logging error ---\n",
          "test_counts": {
            "total": 408,
            "passed": 395,
            "failed": 3,
            "skipped": 10,
            "errors": 0,
            "import_errors": 0,
            "test_files": 48,
            "status": "failed"
          },
          "coverage": null,
          "test_details": []
        },
        "frontend": {
          "status": "failed",
          "duration": 0.11008858680725098,
          "exit_code": 2,
          "output": "\nusage: test_frontend.py [-h]\n                        [--category {unit,integration,components,hooks,store,websocket,auth,e2e,smoke}]\n                        [--keyword KEYWORD] [--e2e] [--cypress-open] [--watch]\n                        [--coverage] [--update-snapshots] [--lint] [--fix]\n                        [--type-check] [--build] [--check-deps]\n                        [--install-deps] [--verbose] [--isolation]\n                        [--cleanup-on-exit]\n                        [tests ...]\ntest_frontend.py: error: unrecognized arguments: --no-cov\n",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0,
            "import_errors": 0,
            "test_files": 0,
            "status": "unknown"
          },
          "coverage": null,
          "test_details": []
        },
        "e2e": {
          "status": "pending",
          "duration": 0,
          "exit_code": null,
          "output": "",
          "test_counts": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "skipped": 0,
            "errors": 0
          },
          "coverage": null
        },
        "overall": {
          "status": "failed",
          "start_time": 1755479506.2106247,
          "end_time": 1755479554.6702738
        }
      },
      "summary": {
        "total": 408,
        "passed": 395,
        "failed": 3,
        "skipped": 10,
        "errors": 0
      }
    }
  ],
  "flaky_tests": {},
  "failure_patterns": {},
  "performance_trends": []
}