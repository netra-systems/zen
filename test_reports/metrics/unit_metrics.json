{
  "timestamp": "2025-08-13T23:44:07.120635",
  "level": "unit",
  "metrics": {
    "total_tests": 0,
    "passed": 0,
    "failed": 0,
    "coverage": null
  },
  "results": {
    "backend": {
      "status": "failed",
      "duration": 7.69404673576355,
      "exit_code": 4,
      "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings\n================================================================================\nLoaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\n================================================================================\n[FAIL] TESTS FAILED with exit code 4 after 6.97s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\nImportError while loading conftest 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\conftest.py'.\napp\\tests\\conftest.py:52: in <module>\n    from app.main import app\napp\\main.py:46: in <module>\n    from app.agents.supervisor_consolidated import SupervisorAgent as Supervisor\napp\\agents\\supervisor_consolidated.py:27: in <module>\n    from app.agents.supervisor.execution_context import (\napp\\agents\\supervisor\\__init__.py:5: in <module>\n    from .agent_registry import AgentRegistry\napp\\agents\\supervisor\\agent_registry.py:13: in <module>\n    from app.agents.triage_sub_agent import TriageSubAgent  # This will import from the .py file\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napp\\agents\\triage_sub_agent\\__init__.py:27: in <module>\n    from .agent import TriageSubAgent\nE   ModuleNotFoundError: No module named 'app.agents.triage_sub_agent.agent'\n",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0,
        "test_files": 0
      },
      "coverage": null,
      "test_details": []
    },
    "frontend": {
      "status": "failed",
      "duration": 0.49273109436035156,
      "exit_code": 255,
      "output": "================================================================================\nNETRA AI PLATFORM - FRONTEND TEST RUNNER\n================================================================================\n\n================================================================================\nRunning Jest Tests\n--------------------------------------------------------------------------------\nRunning: npm run test -- --forceExit --detectOpenHandles --testMatch **/__tests__/@(components|hooks|store|services|lib|utils)/**/*.test.[jt]s?(x)\n--------------------------------------------------------------------------------\n\n================================================================================\n[FAIL] CHECKS FAILED with exit code 255\n================================================================================\n\nCleaning up test processes...\n\n'hooks' is not recognized as an internal or external command,\noperable program or batch file.\n",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0,
        "test_files": 0
      },
      "coverage": null,
      "test_details": []
    },
    "e2e": {
      "status": "pending",
      "duration": 0,
      "exit_code": null,
      "output": "",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      },
      "coverage": null
    },
    "overall": {
      "status": "failed",
      "start_time": 1755153838.9271698,
      "end_time": 1755153847.119637
    }
  }
}