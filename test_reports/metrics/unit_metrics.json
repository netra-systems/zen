{
  "timestamp": "2025-08-14T17:01:06.841123",
  "level": "unit",
  "metrics": {
    "total_tests": 0,
    "passed": 0,
    "failed": 0,
    "coverage": null
  },
  "results": {
    "backend": {
      "status": "failed",
      "duration": 7.637876749038696,
      "exit_code": 4,
      "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: unit\n  Parallel: 4\n  Coverage: enabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/services app/tests/core -vv -n 4 -x --maxfail=1 --cov=app --cov-report=html:reports/coverage/html --cov-report=term-missing --cov-report=json:reports/coverage/coverage.json --cov-fail-under=70 -m not real_services --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings\n================================================================================\nLoaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\n================================================================================\n[FAIL] TESTS FAILED with exit code 4 after 6.83s\n[Coverage] Coverage Report: reports/coverage/html/index.html\n================================================================================\n\nImportError while loading conftest 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\conftest.py'.\napp\\tests\\conftest.py:52: in <module>\n    from app.main import app\napp\\main.py:32: in <module>\n    app = create_app()\n          ^^^^^^^^^^^^\napp\\core\\app_factory.py:159: in create_app\n    register_api_routes(app)\napp\\core\\app_factory.py:80: in register_api_routes\n    _import_and_register_routes(app)\napp\\core\\app_factory.py:85: in _import_and_register_routes\n    route_modules = _import_route_modules()\n                    ^^^^^^^^^^^^^^^^^^^^^^^\napp\\core\\app_factory.py:92: in _import_route_modules\n    from app.routes import (\napp\\routes\\supply.py:4: in <module>\n    from app.dependencies import DbDep\napp\\dependencies.py:30: in <module>\n    def get_agent_supervisor(request: Request) -> Supervisor:\n                                                  ^^^^^^^^^^\nE   NameError: name 'Supervisor' is not defined\n",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0,
        "test_files": 0
      },
      "coverage": null,
      "test_details": []
    },
    "frontend": {
      "status": "failed",
      "duration": 0.5667779445648193,
      "exit_code": 255,
      "output": "================================================================================\nNETRA AI PLATFORM - FRONTEND TEST RUNNER\n================================================================================\n\n================================================================================\nRunning Jest Tests\n--------------------------------------------------------------------------------\nRunning: npm run test -- --forceExit --detectOpenHandles --testMatch **/__tests__/@(components|hooks|store|services|lib|utils)/**/*.test.[jt]s?(x)\n--------------------------------------------------------------------------------\n\n================================================================================\n[FAIL] CHECKS FAILED with exit code 255\n================================================================================\n\nCleaning up test processes...\n\n'hooks' is not recognized as an internal or external command,\noperable program or batch file.\n",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0,
        "test_files": 0
      },
      "coverage": null,
      "test_details": []
    },
    "e2e": {
      "status": "pending",
      "duration": 0,
      "exit_code": null,
      "output": "",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      },
      "coverage": null
    },
    "overall": {
      "status": "failed",
      "start_time": 1755216058.630406,
      "end_time": 1755216066.8350606
    }
  }
}