{
  "timestamp": "2025-08-14T17:12:39.145567",
  "level": "agents",
  "metrics": {
    "total_tests": 15,
    "passed": 11,
    "failed": 3,
    "coverage": null
  },
  "results": {
    "backend": {
      "status": "failed",
      "duration": 13.634280681610107,
      "exit_code": 2,
      "output": "Loaded test environment from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env.test\n================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: all\n  Parallel: 4\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: testing\n\nRunning command:\n  pytest app/tests/agents/test_data_sub_agent.py tests/test_actions_sub_agent.py -vv -n 4 -x --maxfail=1 --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings\n================================================================================\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\ncreated: 4/4 workers\n4 workers [56 items]\n\nscheduling tests via LoadScheduling\n\napp/tests/agents/test_data_sub_agent.py::TestDataTransformation::test_transform_text_data \napp/tests/agents/test_data_sub_agent.py::TestDataValidation::test_validate_required_fields \napp/tests/agents/test_data_sub_agent.py::TestDataProcessing::test_process_data_success \napp/tests/agents/test_data_sub_agent.py::TestDataSubAgentInitialization::test_initialization_with_defaults \n[gw2]\u001b[36m [  1%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataValidation::test_validate_required_fields \napp/tests/agents/test_data_sub_agent.py::TestDataValidation::test_validate_missing_fields \n[gw0]\u001b[36m [  3%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataSubAgentInitialization::test_initialization_with_defaults \n[gw3]\u001b[36m [  5%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataTransformation::test_transform_text_data \n[gw2]\u001b[36m [  7%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataValidation::test_validate_missing_fields \napp/tests/agents/test_data_sub_agent.py::TestDataSubAgentInitialization::test_initialization_with_custom_config \napp/tests/agents/test_data_sub_agent.py::TestDataValidation::test_validate_data_types \n[gw0]\u001b[36m [  8%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataSubAgentInitialization::test_initialization_with_custom_config \napp/tests/agents/test_data_sub_agent.py::TestDataTransformation::test_transform_json_data \n[gw2]\u001b[36m [ 10%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataValidation::test_validate_data_types \n[gw1]\u001b[36m [ 12%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataProcessing::test_process_data_success \napp/tests/agents/test_data_sub_agent.py::TestDataEnrichment::test_enrich_with_metadata \napp/tests/agents/test_data_sub_agent.py::TestDataSubAgentInitialization::test_initialization_with_redis \n[gw3]\u001b[36m [ 14%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataTransformation::test_transform_json_data \napp/tests/agents/test_data_sub_agent.py::TestDataProcessing::test_process_data_validation_failure \n[gw0]\u001b[36m [ 16%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataSubAgentInitialization::test_initialization_with_redis \napp/tests/agents/test_data_sub_agent.py::TestErrorHandling::test_retry_on_failure \n[gw1]\u001b[36m [ 17%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataProcessing::test_process_data_validation_failure \napp/tests/agents/test_data_sub_agent.py::TestDataTransformation::test_transform_with_pipeline \napp/tests/agents/test_data_sub_agent.py::TestDataProcessing::test_batch_processing \n[gw1]\u001b[36m [ 19%] \u001b[0m\u001b[32mPASSED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataProcessing::test_batch_processing \napp/tests/agents/test_data_sub_agent.py::TestIntegration::test_async_operations <- app\\tests\\helpers\\shared_test_types.py \n[gw1]\u001b[36m [ 21%] \u001b[0m\u001b[31mERROR\u001b[0m app/tests/agents/test_data_sub_agent.py::TestIntegration::test_async_operations <- app\\tests\\helpers\\shared_test_types.py \n[gw2]\u001b[36m [ 23%] \u001b[0m\u001b[31mFAILED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataEnrichment::test_enrich_with_metadata \n[gw3]\u001b[36m [ 25%] \u001b[0m\u001b[31mFAILED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestDataTransformation::test_transform_with_pipeline \n[gw0]\u001b[36m [ 26%] \u001b[0m\u001b[31mFAILED\u001b[0m app/tests/agents/test_data_sub_agent.py::TestErrorHandling::test_retry_on_failure Loaded .env file from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.env\n\n\n=================================== ERRORS ====================================\n\u001b[31m\u001b[1m___________ ERROR at setup of TestIntegration.test_async_operations ___________\u001b[0m\n[gw1] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\nfile C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\helpers\\shared_test_types.py, line 159\n      @pytest.mark.asyncio\n      async def test_async_operations(self, service):\n          \"\"\"Test async operations work correctly\"\"\"\n          # Test async methods if they exist\n          async_methods = []\n          for attr_name in dir(service):\n              attr = getattr(service, attr_name)\n              if callable(attr) and not attr_name.startswith('_'):\n                  # Check if it's an async method\n                  if hasattr(attr, '__code__') and attr.__code__.co_flags & 0x80:\n                      async_methods.append(attr_name)\n\n          # If async methods exist, they should be callable\n          for method_name in async_methods[:1]:  # Test first async method\n              method = getattr(service, method_name)\n              try:\n                  result = await method()\n                  # Should not raise an exception\n                  assert True\n              except TypeError:\n                  # Method might require parameters\n                  assert True\nE       fixture 'service' not found\n>       available fixtures: _session_faker, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, client, cov, db_session, doctest_namespace, event_loop, extra, extras, faker, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, setup_real_infrastructure, test_engine, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\nC:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\\tests\\helpers\\shared_test_types.py:159\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n================================== FAILURES ===================================\n\u001b[31m\u001b[1m________________ TestDataEnrichment.test_enrich_with_metadata _________________\u001b[0m\n[gw2] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\agents\\test_data_sub_agent.py\u001b[0m:280: in test_enrich_with_metadata\n    \u001b[0menriched = \u001b[94mawait\u001b[39;49;00m agent.enrich_data(input_data)\u001b[90m\u001b[39;49;00m\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31m<@beartype(app.agents.data_sub_agent.delegation.AgentDelegation.enrich_data_external) at 0x20529b32f20>\u001b[0m:11: in enrich_data_external\n    \u001b[0m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\core\\type_validators.py\u001b[0m:66: in wrapper\n    \u001b[0m\u001b[94mreturn\u001b[39;49;00m func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n           ^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   TypeError: AgentDelegation.enrich_data_external() missing 1 required positional argument: 'run_id'\u001b[0m\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m_____________ TestDataTransformation.test_transform_with_pipeline _____________\u001b[0m\n[gw3] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\agents\\test_data_sub_agent.py\u001b[0m:260: in test_transform_with_pipeline\n    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m agent._transform_with_pipeline(input_data, pipeline)\u001b[90m\u001b[39;49;00m\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31m<@beartype(app.agents.data_sub_agent.delegation.AgentDelegation._transform_with_pipeline) at 0x2871af331a0>\u001b[0m:11: in _transform_with_pipeline\n    \u001b[0m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\core\\type_validators.py\u001b[0m:66: in wrapper\n    \u001b[0m\u001b[94mreturn\u001b[39;49;00m func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n           ^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\core\\type_validators.py\u001b[0m:83: in wrapper\n    \u001b[0m_validate_execute_state(state)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\core\\type_validators.py\u001b[0m:93: in _validate_execute_state\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m TypeValidationError(\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   app.core.type_validators.TypeValidationError: State missing user_request\u001b[0m\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[31m\u001b[1m___________________ TestErrorHandling.test_retry_on_failure ___________________\u001b[0m\n[gw0] win32 -- Python 3.12.4 C:\\Users\\antho\\miniconda3\\python.exe\n\u001b[1m\u001b[31mapp\\tests\\agents\\test_data_sub_agent.py\u001b[0m:323: in test_retry_on_failure\n    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m agent.process_with_retry({\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m})\u001b[90m\u001b[39;49;00m\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31m<@beartype(app.agents.data_sub_agent.delegation.AgentDelegation.process_with_retry) at 0x294d3f0e0c0>\u001b[0m:11: in process_with_retry\n    \u001b[0m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mapp\\core\\type_validators.py\u001b[0m:66: in wrapper\n    \u001b[0m\u001b[94mreturn\u001b[39;49;00m func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n           ^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   TypeError: AgentDelegation.process_with_retry() missing 1 required positional argument: 'run_id'\u001b[0m\n----------------------------- Captured log setup ------------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n---------------------------- Captured log teardown ----------------------------\n\u001b[35mDEBUG   \u001b[0m asyncio:proactor_events.py:634 Using proactor: IocpProactor\n\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n\u001b[31mFAILED\u001b[0m app/tests/agents/test_data_sub_agent.py::\u001b[1mTestDataEnrichment::test_enrich_with_metadata\u001b[0m - TypeError: AgentDelegation.enrich_data_external() missing 1 required positional argument: 'run_id'\n\u001b[31mFAILED\u001b[0m app/tests/agents/test_data_sub_agent.py::\u001b[1mTestDataTransformation::test_transform_with_pipeline\u001b[0m - app.core.type_validators.TypeValidationError: State missing user_request\n\u001b[31mFAILED\u001b[0m app/tests/agents/test_data_sub_agent.py::\u001b[1mTestErrorHandling::test_retry_on_failure\u001b[0m - TypeError: AgentDelegation.process_with_retry() missing 1 required positional argument: 'run_id'\n\u001b[31mERROR\u001b[0m app/tests/agents/test_data_sub_agent.py::\u001b[1mTestIntegration::test_async_operations\u001b[0m\n\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 4 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n!!!!!!!!!!!! xdist.dsession.Interrupted: stopping after 1 failures !!!!!!!!!!!!\n\u001b[31m==================== \u001b[31m\u001b[1m3 failed\u001b[0m, \u001b[32m11 passed\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 7.82s\u001b[0m\u001b[31m ====================\u001b[0m\n================================================================================\n[FAIL] TESTS FAILED with exit code 2 after 12.80s\n================================================================================\n\n",
      "test_counts": {
        "total": 15,
        "passed": 11,
        "failed": 3,
        "skipped": 0,
        "errors": 1,
        "test_files": 1
      },
      "coverage": null,
      "test_details": []
    },
    "frontend": {
      "status": "skipped",
      "duration": 0,
      "exit_code": null,
      "output": "",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      },
      "coverage": null
    },
    "e2e": {
      "status": "pending",
      "duration": 0,
      "exit_code": null,
      "output": "",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      },
      "coverage": null
    },
    "overall": {
      "status": "failed",
      "start_time": 1755216745.5112867,
      "end_time": 1755216759.1455674
    }
  }
}