{
  "timestamp": "2025-08-12T13:39:23.088696",
  "level": "smoke",
  "metrics": {
    "total_tests": 2,
    "passed": 2,
    "failed": 0,
    "coverage": null
  },
  "results": {
    "backend": {
      "status": "passed",
      "duration": 8.433302640914917,
      "exit_code": 0,
      "output": "================================================================================\nNETRA AI PLATFORM - BACKEND TEST RUNNER\n================================================================================\nTest Configuration:\n  Category: smoke\n  Parallel: disabled\n  Coverage: disabled\n  Fail Fast: enabled\n  Environment: development\n\nRunning command:\n  pytest app/tests/routes/test_health_route.py -v -x --maxfail=1 -m not real_services --tb=short --asyncio-mode=auto --color=yes --strict-markers --disable-warnings -p no:warnings\n================================================================================\n\u001b[1m============================= test session starts =============================\u001b[0m\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\antho\\miniconda3\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.4', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.4.2', 'langsmith': '0.4.10', 'asyncio': '0.21.1', 'cov': '6.2.1', 'html': '4.1.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'timeout': '2.4.0', 'xdist': '3.8.0', 'typeguard': '4.4.4'}}\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\app\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.4.2, langsmith-0.4.10, asyncio-0.21.1, cov-6.2.1, html-4.1.1, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, timeout-2.4.0, xdist-3.8.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO\n\u001b[1mcollecting ... \u001b[0mcollected 2 items\n\napp\\tests\\routes\\test_health_route.py::test_basic_import \u001b[32mPASSED\u001b[0m\u001b[32m          [ 50%]\u001b[0m\napp\\tests\\routes\\test_health_route.py::test_health_endpoint_direct \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n\n\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.20s\u001b[0m\u001b[32m ==============================\u001b[0m\n================================================================================\n[PASS] ALL TESTS PASSED in 7.27s\n================================================================================\n\n",
      "test_counts": {
        "total": 2,
        "passed": 2,
        "failed": 0,
        "skipped": 0,
        "errors": 0,
        "test_files": 1
      },
      "coverage": null
    },
    "frontend": {
      "status": "timeout",
      "duration": 106.82314372062683,
      "exit_code": -1,
      "output": "Tests timed out after 30s",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      },
      "coverage": null
    },
    "e2e": {
      "status": "pending",
      "duration": 0,
      "exit_code": null,
      "output": "",
      "test_counts": {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "errors": 0
      },
      "coverage": null
    },
    "overall": {
      "status": "passed",
      "start_time": 1755031047.83225,
      "end_time": 1755031163.0886965
    }
  }
}