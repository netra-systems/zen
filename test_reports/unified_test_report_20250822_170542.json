{
  "timestamp": "20250822_170542",
  "level": "integration",
  "environment": "local",
  "services": {
    "backend": {
      "success": false,
      "duration": 10.312506198883057,
      "output": "============================= test session starts =============================\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.5.3, langsmith-0.4.15, asyncio-1.1.0, cov-6.2.1, mock-3.14.1, xdist-3.8.0, html-4.1.1, json-report-1.5.0, metadata-3.1.1, timeout-2.4.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=session, asyncio_default_test_loop_scope=function\ncollected 3982 items / 1 error\n\n=================================== ERRORS ====================================\n_ ERROR collecting tests/integration/critical_paths/test_multi_tenant_isolation.py _\nImportError while importing test module 'C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_multi_tenant_isolation.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\antho\\miniconda3\\Lib\\importlib\\__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests\\integration\\critical_paths\\test_multi_tenant_isolation.py:35: in <module>\n    from netra_backend.app.core.security import SecurityContext\nE   ImportError: cannot import name 'SecurityContext' from 'netra_backend.app.core.security' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\core\\security\\__init__.py)\n============================== warnings summary ===============================\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_fields.py:198\n  C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_fields.py:198: UserWarning: Field name \"schema\" in \"DataSample\" shadows an attribute in parent \"BaseModel\"\n    warnings.warn(\n\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_fields.py:198\n  C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_fields.py:198: UserWarning: Field name \"schema\" in \"DataCatalog\" shadows an attribute in parent \"BaseModel\"\n    warnings.warn(\n\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_config.py:323\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_config.py:323\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_config.py:323\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_config.py:323\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_config.py:323\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_config.py:323\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_config.py:323\n  C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_config.py:323: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n    warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_generate_schema.py:298\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_generate_schema.py:298\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_generate_schema.py:298\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_generate_schema.py:298\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_generate_schema.py:298\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_generate_schema.py:298\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_generate_schema.py:298\n  C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_generate_schema.py:298: PydanticDeprecatedSince20: `json_encoders` is deprecated. See https://docs.pydantic.dev/2.11/concepts/serialization/#custom-serializers for alternatives. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n    warnings.warn(\n\ntests\\unified_system\\fixtures.py:111\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\unified_system\\fixtures.py:111: DeprecationWarning: websockets.WebSocketServerProtocol is deprecated\n    connection: websockets.WebSocketServerProtocol\n\n..\\..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\websockets\\legacy\\__init__.py:6\n  C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\websockets\\legacy\\__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions\n    warnings.warn(  # deprecated in 14.0 - 2024-11-09\n\ntests\\integration\\critical_paths\\test_alert_routing_escalation.py:40\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_alert_routing_escalation.py:40: PytestUnknownMarkWarning: Unknown pytest.mark.observability - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.observability,\n\ntests\\integration\\critical_paths\\test_alert_routing_escalation.py:41\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_alert_routing_escalation.py:41: PytestUnknownMarkWarning: Unknown pytest.mark.alerting - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.alerting\n\ntests\\integration\\critical_paths\\test_business_critical_flows_l2.py:1062\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_business_critical_flows_l2.py:1062: PytestUnknownMarkWarning: Unknown pytest.mark.l2 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2\n\ntests\\integration\\critical_paths\\test_custom_metrics_registration.py:41\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_custom_metrics_registration.py:41: PytestUnknownMarkWarning: Unknown pytest.mark.observability - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.observability,\n\ntests\\integration\\critical_paths\\test_custom_metrics_registration.py:42\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_custom_metrics_registration.py:42: PytestUnknownMarkWarning: Unknown pytest.mark.custom_metrics - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.custom_metrics\n\ntests\\integration\\critical_paths\\test_dashboard_query_performance.py:43\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_dashboard_query_performance.py:43: PytestUnknownMarkWarning: Unknown pytest.mark.observability - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.observability,\n\ntests\\integration\\critical_paths\\test_dashboard_query_performance.py:45\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_dashboard_query_performance.py:45: PytestUnknownMarkWarning: Unknown pytest.mark.dashboard - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.dashboard\n\ntests\\integration\\critical_paths\\test_data_migration_integrity_l4.py:1340\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_data_migration_integrity_l4.py:1340: PytestUnknownMarkWarning: Unknown pytest.mark.critical_path - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.critical_path\n\ntests\\integration\\critical_paths\\test_dev_environment_agent_response_flow_l4.py:894\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_dev_environment_agent_response_flow_l4.py:894: PytestUnknownMarkWarning: Unknown pytest.mark.level_4 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.level_4\n\ntests\\integration\\critical_paths\\test_dev_environment_auth_login_complete_l4.py:607\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_dev_environment_auth_login_complete_l4.py:607: PytestUnknownMarkWarning: Unknown pytest.mark.level_4 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.level_4\n\ntests\\integration\\critical_paths\\test_dev_environment_chat_initialization_l4.py:756\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_dev_environment_chat_initialization_l4.py:756: PytestUnknownMarkWarning: Unknown pytest.mark.level_4 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.level_4\n\ntests\\integration\\critical_paths\\test_dev_environment_concurrent_users_l4.py:829\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_dev_environment_concurrent_users_l4.py:829: PytestUnknownMarkWarning: Unknown pytest.mark.level_4 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.level_4\n\ntests\\integration\\critical_paths\\test_dev_environment_websocket_connection_l4.py:440\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_dev_environment_websocket_connection_l4.py:440: PytestUnknownMarkWarning: Unknown pytest.mark.level_4 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.level_4\n\ntests\\integration\\critical_paths\\test_disaster_recovery_failover_l4.py:1146\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_disaster_recovery_failover_l4.py:1146: PytestUnknownMarkWarning: Unknown pytest.mark.critical_path - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.critical_path\n\ntests\\integration\\critical_paths\\test_disaster_recovery_failover_l4.py:1147\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_disaster_recovery_failover_l4.py:1147: PytestUnknownMarkWarning: Unknown pytest.mark.disaster_recovery - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.disaster_recovery\n\ntests\\integration\\critical_paths\\test_distributed_tracing_propagation.py:40\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_distributed_tracing_propagation.py:40: PytestUnknownMarkWarning: Unknown pytest.mark.observability - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.observability,\n\ntests\\integration\\critical_paths\\test_distributed_tracing_propagation.py:41\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_distributed_tracing_propagation.py:41: PytestUnknownMarkWarning: Unknown pytest.mark.tracing - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.tracing\n\ntests\\integration\\critical_paths\\test_enterprise_resource_isolation_l4.py:1398\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_enterprise_resource_isolation_l4.py:1398: PytestUnknownMarkWarning: Unknown pytest.mark.enterprise - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.enterprise\n\ntests\\integration\\critical_paths\\test_enterprise_resource_isolation_l4.py:1425\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_enterprise_resource_isolation_l4.py:1425: PytestUnknownMarkWarning: Unknown pytest.mark.enterprise - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.enterprise\n\ntests\\integration\\critical_paths\\test_enterprise_resource_isolation_l4.py:1448\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_enterprise_resource_isolation_l4.py:1448: PytestUnknownMarkWarning: Unknown pytest.mark.enterprise - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.enterprise\n\ntests\\integration\\critical_paths\\test_health_check_cascade_initialization.py:49\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_health_check_cascade_initialization.py:49: PytestUnknownMarkWarning: Unknown pytest.mark.health_monitoring - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.health_monitoring,\n\ntests\\integration\\critical_paths\\test_health_check_cascade_initialization.py:50\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_health_check_cascade_initialization.py:50: PytestUnknownMarkWarning: Unknown pytest.mark.initialization - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.initialization\n\ntests\\integration\\critical_paths\\test_jwt_token_propagation_l4.py:981\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_jwt_token_propagation_l4.py:981: PytestUnknownMarkWarning: Unknown pytest.mark.critical_path - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.critical_path\n\ntests\\integration\\critical_paths\\test_llm_agent_orchestration_l4.py:753\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_llm_agent_orchestration_l4.py:753: PytestUnknownMarkWarning: Unknown pytest.mark.llm_integration - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.llm_integration\n\ntests\\integration\\critical_paths\\test_llm_agent_orchestration_l4.py:778\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_llm_agent_orchestration_l4.py:778: PytestUnknownMarkWarning: Unknown pytest.mark.cost_validation - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.cost_validation\n\ntests\\integration\\critical_paths\\test_log_aggregation_pipeline.py:38\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_log_aggregation_pipeline.py:38: PytestUnknownMarkWarning: Unknown pytest.mark.observability - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.observability,\n\ntests\\integration\\critical_paths\\test_log_aggregation_pipeline.py:39\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_log_aggregation_pipeline.py:39: PytestUnknownMarkWarning: Unknown pytest.mark.logging - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.logging\n\ntests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:631\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:631: PytestUnknownMarkWarning: Unknown pytest.mark.l2_realism - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2_realism\n\ntests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:678\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:678: PytestUnknownMarkWarning: Unknown pytest.mark.l2_realism - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2_realism\n\ntests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:723\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:723: PytestUnknownMarkWarning: Unknown pytest.mark.l2_realism - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2_realism\n\ntests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:788\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:788: PytestUnknownMarkWarning: Unknown pytest.mark.l2_realism - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2_realism\n\ntests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:831\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:831: PytestUnknownMarkWarning: Unknown pytest.mark.l2_realism - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2_realism\n\ntests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:868\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:868: PytestUnknownMarkWarning: Unknown pytest.mark.l2_realism - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2_realism\n\ntests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:917\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:917: PytestUnknownMarkWarning: Unknown pytest.mark.l2_realism - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2_realism\n\ntests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:953\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:953: PytestUnknownMarkWarning: Unknown pytest.mark.l2_realism - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2_realism\n\ntests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:987\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:987: PytestUnknownMarkWarning: Unknown pytest.mark.l2_realism - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2_realism\n\ntests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:1023\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_message_queue_websocket_broadcast.py:1023: PytestUnknownMarkWarning: Unknown pytest.mark.l2_realism - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.l2_realism\n\ntests\\integration\\critical_paths\\test_metrics_cardinality_explosion.py:44\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_metrics_cardinality_explosion.py:44: PytestUnknownMarkWarning: Unknown pytest.mark.observability - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.observability,\n\ntests\\integration\\critical_paths\\test_metrics_cardinality_explosion.py:45\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_metrics_cardinality_explosion.py:45: PytestUnknownMarkWarning: Unknown pytest.mark.cardinality - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.cardinality\n\ntests\\integration\\critical_paths\\test_metrics_pipeline_l4.py:46\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_metrics_pipeline_l4.py:46: PytestUnknownMarkWarning: Unknown pytest.mark.observability - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.observability,\n\ntests\\integration\\critical_paths\\test_metrics_retention_policy.py:37\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_metrics_retention_policy.py:37: PytestUnknownMarkWarning: Unknown pytest.mark.observability - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.observability,\n\ntests\\integration\\critical_paths\\test_metrics_retention_policy.py:38\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\integration\\critical_paths\\test_metrics_retention_policy.py:38: PytestUnknownMarkWarning: Unknown pytest.mark.retention - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    pytest.mark.retention\n\n..\\test_framework\\unified\\__init__.py:66\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\test_framework\\unified\\__init__.py:66: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n    timestamp: datetime = datetime.utcnow()\n\napp\\core\\cache\\__init__.py:26\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\core\\cache\\__init__.py:26: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n    created_at: datetime = datetime.utcnow()\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ===========================\nERROR tests/integration/critical_paths/test_multi_tenant_isolation.py\n!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\n======================== 62 warnings, 1 error in 5.94s ========================\n",
      "errors": ""
    },
    "auth": {
      "success": false,
      "duration": 18.223448276519775,
      "output": "============================= test session starts =============================\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\auth_service\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.5.3, langsmith-0.4.15, asyncio-1.1.0, cov-6.2.1, mock-3.14.1, xdist-3.8.0, html-4.1.1, json-report-1.5.0, metadata-3.1.1, timeout-2.4.0, typeguard-4.4.4\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollected 193 items\n\ntests\\integration\\test_auth_oauth_errors.py ........                     [  4%]\ntests\\integration\\test_auth_oauth_google.py ........                     [  8%]\ntests\\integration\\test_oauth_comprehensive_failures.py ................. [ 17%]\n............sss                                                          [ 24%]\ntests\\integration\\test_oauth_flows_auth.py ..                            [ 25%]\ntests\\integration\\test_oauth_flows_core.py ...                           [ 27%]\ntests\\integration\\test_oauth_flows_sync.py ............                  [ 33%]\ntests\\test_auth_token_generation.py ..........                           [ 38%]\ntests\\test_auth_token_security.py .F\n\n================================== FAILURES ===================================\n_______ TestJWTClaimsExtraction.test_extract_claims_security_validation _______\n\nself = <auth_service.tests.test_auth_token_security.TestJWTClaimsExtraction testMethod=test_extract_claims_security_validation>\n\n    def test_extract_claims_security_validation(self):\n        \"\"\"Test claims extraction with security validation\"\"\"\n        token = self.jwt_handler.create_access_token(\n            self.test_user_id,\n            self.test_email,\n            self.test_permissions\n        )\n    \n        # Test secure claims extraction\n        payload = self.jwt_handler.validate_token_jwt(token, \"access\")\n>       assert payload is not None\nE       assert None is not None\n\ntests\\test_auth_token_security.py:86: AssertionError\n------------------------------ Captured log call ------------------------------\nWARNING  auth_service.auth_core.core.jwt_handler:jwt_handler.py:135 Invalid token: Invalid audience\n============================== warnings summary ===============================\ntests\\integration\\test_oauth_comprehensive_failures.py:1245\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\auth_service\\tests\\integration\\test_oauth_comprehensive_failures.py:1245: PytestUnknownMarkWarning: Unknown pytest.mark.staging - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.staging\n\ntests\\integration\\test_oauth_comprehensive_failures.py:1288\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\auth_service\\tests\\integration\\test_oauth_comprehensive_failures.py:1288: PytestUnknownMarkWarning: Unknown pytest.mark.staging - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.staging\n\ntests/integration/test_auth_oauth_errors.py::TestOAuthErrorHandling::test_oauth_invalid_state_parameter\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\auth_service\\tests\\conftest.py:59: DeprecationWarning: There is no current event loop\n    loop = asyncio.get_event_loop()\n\ntests/integration/test_auth_oauth_errors.py: 1 warning\ntests/integration/test_auth_oauth_google.py: 5 warnings\ntests/integration/test_oauth_comprehensive_failures.py: 7 warnings\ntests/integration/test_oauth_flows_sync.py: 1 warning\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\auth_service\\auth_core\\core\\session_manager.py:438: RuntimeWarning: coroutine 'AsyncSession.merge' was never awaited\n    session.merge(auth_session)\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/integration/test_oauth_comprehensive_failures.py: 21 warnings\n  C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\auth_service\\auth_core\\routes\\auth_routes.py:982: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n    content=response.dict(),\n\ntests/integration/test_oauth_comprehensive_failures.py::TestOAuthComprehensiveFailures::test_05_cross_site_request_forgery_token_binding\ntests/integration/test_oauth_comprehensive_failures.py::TestOAuthComprehensiveFailures::test_25_session_fixation_attack\n  C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\starlette\\testclient.py:451: DeprecationWarning: Setting per-request cookies=<...> is being deprecated, because the expected behaviour on cookie persistence is ambiguous. Set cookies directly on the client instance instead.\n    return super().request(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ===========================\nFAILED tests/test_auth_token_security.py::TestJWTClaimsExtraction::test_extract_claims_security_validation\n!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\n============ 1 failed, 73 passed, 3 skipped, 40 warnings in 16.01s ============\n",
      "errors": ""
    },
    "frontend": {
      "success": false,
      "duration": 5.436762571334839,
      "output": "  console.warn\n    [2025-08-23T00:05:04.744Z] WARN: Received 401, attempting [REDACTED] undefined\n\n    \u001b[0m \u001b[90m 217 |\u001b[39m       \u001b[36mreturn\u001b[39m\u001b[33m;\u001b[39m\n     \u001b[90m 218 |\u001b[39m     }\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 219 |\u001b[39m     originalWarn\u001b[33m.\u001b[39mcall(console\u001b[33m,\u001b[39m \u001b[33m...\u001b[39margs)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                  \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 220 |\u001b[39m   }\u001b[33m;\u001b[39m\n     \u001b[90m 221 |\u001b[39m })\u001b[33m;\u001b[39m\n     \u001b[90m 222 |\u001b[39m\u001b[0m\n\n      at console.call (jest.setup.js:219:18)\n      at FrontendLogger.warn [as log] (lib/logger.ts:145:19)\n      at FrontendLogger.log [as warn] (lib/logger.ts:211:10)\n      at AuthInterceptor.warn [as authenticatedFetch] (lib/auth-interceptor.ts:186:16)\n      at performFetch (services/apiClientWrapper.ts:145:24)\n      at ApiClientWrapper.retryRequest (services/apiClientWrapper.ts:83:16)\n      at ApiClientWrapper.request (services/apiClientWrapper.ts:188:16)\n\n  console.info\n    [2025-08-23T00:05:04.832Z] INFO: [REDACTED] successfully undefined\n\n      at FrontendLogger.info [as log] (lib/logger.ts:142:19)\n\n  console.info\n    [2025-08-23T00:05:04.833Z] INFO: Retrying request with refreshed token undefined\n\n      at FrontendLogger.info [as log] (lib/logger.ts:142:19)\n\n  console.log\n    Auth config from context: {\n      development_mode: true,\n      google_client_id: 'mock-google-client-id',\n      endpoints: {\n        login: 'http://localhost:8081/auth/login',\n        logout: 'http://localhost:8081/auth/logout',\n        callback: 'http://localhost:8081/auth/callback',\n        token: 'http://localhost:8081/auth/token',\n        user: 'http://localhost:8081/auth/me',\n        dev_login: 'http://localhost:8081/auth/dev/login'\n      },\n      authorized_javascript_origins: [ 'http://localhost:3000' ],\n      authorized_redirect_uris: [ 'http://localhost:3000/auth/callback' ]\n    }\n\n      at Object.log (__tests__/auth/context.auth-operations.test.tsx:118:13)\n\n  console.log\n    Login function type: function\n\n      at Object.log (__tests__/auth/context.auth-operations.test.tsx:119:13)\n\n  console.log\n    Calling login, authConfig at call time: {\n      development_mode: true,\n      google_client_id: 'mock-google-client-id',\n      endpoints: {\n        login: 'http://localhost:8081/auth/login',\n        logout: 'http://localhost:8081/auth/logout',\n        callback: 'http://localhost:8081/auth/callback',\n        token: 'http://localhost:8081/auth/token',\n        user: 'http://localhost:8081/auth/me',\n        dev_login: 'http://localhost:8081/auth/dev/login'\n      },\n      authorized_javascript_origins: [ 'http://localhost:3000' ],\n      authorized_redirect_uris: [ 'http://localhost:3000/auth/callback' ]\n    }\n\n      at log (__tests__/auth/context.auth-operations.test.tsx:108:15)\n\n  console.log\n    \ud83d\udce6 ChatSidebarHooks module mock created\n\n      at log (__tests__/components/ChatSidebar/setup.tsx:43:11)\n\n  console.log\n    \ud83d\udd27 Configuring authentication mocks with: { isAuthenticated: true, userTier: 'Early' }\n\n      at ChatSidebarTestSetup.log [as beforeEach] (__tests__/components/ChatSidebar/setup.tsx:300:13)\n\n  console.log\n    \ud83d\udd27 configureAuthState called with overrides: { isAuthenticated: true, userTier: 'Early' }\n\n      at ChatSidebarTestSetup.log [as configureAuthState] (__tests__/components/ChatSidebar/setup.tsx:476:13)\n\n  console.log\n    \ud83c\udfaf Final authStateConfig: {\n      isAuthenticated: true,\n      isLoading: false,\n      user: { id: 'test-user-1', email: 'test@example.com', role: 'user' },\n      userTier: 'Early',\n      error: null,\n      refreshAuth: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      },\n      logout: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      },\n      clearError: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      },\n      hasPermission: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      },\n      isAdminOrHigher: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      },\n      isDeveloperOrHigher: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      }\n    }\n\n      at ChatSidebarTestSetup.log [as configureAuthState] (__tests__/components/ChatSidebar/setup.tsx:477:13)\n\n  console.log\n    \ud83d\udd27 configureChatSidebarHooks called with: {\n      threadsProvided: true,\n      threadsCount: 3,\n      threadIds: [ 'thread-1', 'thread-2', 'thread-3' ]\n    }\n\n      at ChatSidebarTestSetup.log [as configureChatSidebarHooks] (__tests__/components/ChatSidebar/setup.tsx:378:13)\n\n  console.log\n    \ud83c\udfaf Mock configurations: {\n      threadLoaderConfig: {\n        threads: [ [Object], [Object], [Object] ],\n        isLoadingThreads: false,\n        loadError: null,\n        loadThreads: [Function: mockConstructor] {\n          _isMockFunction: true,\n          getMockImplementation: [Function (anonymous)],\n          mock: [Getter/Setter],\n          mockClear: [Function (anonymous)],\n          mockReset: [Function (anonymous)],\n          mockRestore: [Function (anonymous)],\n          mockReturnValueOnce: [Function (anonymous)],\n          mockResolvedValueOnce: [Function (anonymous)],\n          mockRejectedValueOnce: [Function (anonymous)],\n          mockReturnValue: [Function (anonymous)],\n          mockResolvedValue: [Function (anonymous)],\n          mockRejectedValue: [Function (anonymous)],\n          mockImplementationOnce: [Function (anonymous)],\n          withImplementation: [Function: bound withImplementation],\n          mockImplementation: [Function (anonymous)],\n          mockReturnThis: [Function (anonymous)],\n          mockName: [Function (anonymous)],\n          getMockName: [Function (anonymous)],\n          Symbol(Symbol.dispose): [Function (anonymous)]\n        }\n      },\n      threadFilteringConfig: {\n        sortedThreads: [ [Object], [Object], [Object] ],\n        paginatedThreads: [ [Object], [Object], [Object] ],\n        totalPages: 1\n      }\n    }\n\n      at ChatSidebarTestSetup.log [as configureChatSidebarHooks] (__tests__/components/ChatSidebar/setup.tsx:416:13)\n\n  console.log\n    \ud83c\udfaf Applied mock configurations using mockImplementation with debugging\n\n      at ChatSidebarTestSetup.log [as configureChatSidebarHooks] (__tests__/components/ChatSidebar/setup.tsx:453:13)\n\n  console.log\n    \ud83d\udd25 HOOK CALLED: useChatSidebarState (CONFIGURED) {\n      searchQuery: '',\n      setSearchQuery: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      },\n      isCreatingThread: false,\n      setIsCreatingThread: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      },\n      showAllThreads: false,\n      setShowAllThreads: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      },\n      filterType: 'all',\n      setFilterType: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      },\n      currentPage: 1,\n      setCurrentPage: [Function: mockConstructor] {\n        _isMockFunction: true,\n        getMockImplementation: [Function (anonymous)],\n        mock: [Getter/Setter],\n        mockClear: [Function (anonymous)],\n        mockReset: [Function (anonymous)],\n        mockRestore: [Function (anonymous)],\n        mockReturnValueOnce: [Function (anonymous)],\n        mockResolvedValueOnce: [Function (anonymous)],\n        mockRejectedValueOnce: [Function (anonymous)],\n        mockReturnValue: [Function (anonymous)],\n        mockResolvedValue: [Function (anonymous)],\n        mockRejectedValue: [Function (anonymous)],\n        mockImplementationOnce: [Function (anonymous)],\n        withImplementation: [Function: bound withImplementation],\n        mockImplementation: [Function (anonymous)],\n        mockReturnThis: [Function (anonymous)],\n        mockName: [Function (anonymous)],\n        getMockName: [Function (anonymous)],\n        Symbol(Symbol.dispose): [Function (anonymous)]\n      }\n    }\n\n      at Object.log (__tests__/components/ChatSidebar/setup.tsx:424:15)\n\n  console.error\n    An update to RetryTestComponent inside a test was not wrapped in act(...).\n    \n    When testing, code that causes React state updates should be wrapped into act(...):\n    \n    act(() => {\n      /* fire events that update state */\n    });\n    /* assert on the output */\n    \n    This ensures that you're testing the behavior the user would see in the browser. Learn more at https://react.dev/link/wrap-tests-with-act\n\n    \u001b[0m \u001b[90m 207 |\u001b[39m       \u001b[36mreturn\u001b[39m\u001b[33m;\u001b[39m\n     \u001b[90m 208 |\u001b[39m     }\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 209 |\u001b[39m     originalError\u001b[33m.\u001b[39mcall(console\u001b[33m,\u001b[39m \u001b[33m...\u001b[39margs)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                   \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 210 |\u001b[39m   }\u001b[33m;\u001b[39m\n     \u001b[90m 211 |\u001b[39m   \n     \u001b[90m 212 |\u001b[39m   console\u001b[33m.\u001b[39mwarn \u001b[33m=\u001b[39m (\u001b[33m...\u001b[39margs) \u001b[33m=>\u001b[39m {\u001b[0m\n\n      at console.call [as error] (jest.setup.js:209:19)\n      at node_modules/react-dom/cjs/react-dom-client.development.js:16023:19\n      at runWithFiberInDEV (node_modules/react-dom/cjs/react-dom-client.development.js:1522:13)\n      at warnIfUpdatesNotWrappedWithActDEV (node_modules/react-dom/cjs/react-dom-client.development.js:16022:9)\n      at scheduleUpdateOnFiber (node_modules/react-dom/cjs/react-dom-client.development.js:14396:11)\n      at dispatchSetStateInternal (node_modules/react-dom/cjs/react-dom-client.development.js:6969:13)\n      at dispatchSetState (node_modules/react-dom/cjs/react-dom-client.development.js:6927:7)\n      at setRetryCount (__tests__/integration/error-handling-retry.test.tsx:173:31)\n      at RobustApiClient.onRetry (__tests__/integration/error-handling-retry.test.tsx:97:11)\n      at makeRequest (__tests__/integration/error-handling-retry.test.tsx:171:22)\n\n  console.error\n    An update to RetryTestComponent inside a test was not wrapped in act(...).\n    \n    When testing, code that causes React state updates should be wrapped into act(...):\n    \n    act(() => {\n      /* fire events that update state */\n    });\n    /* assert on the output */\n    \n    This ensures that you're testing the behavior the user would see in the browser. Learn more at https://react.dev/link/wrap-tests-with-act\n\n    \u001b[0m \u001b[90m 207 |\u001b[39m       \u001b[36mreturn\u001b[39m\u001b[33m;\u001b[39m\n     \u001b[90m 208 |\u001b[39m     }\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 209 |\u001b[39m     originalError\u001b[33m.\u001b[39mcall(console\u001b[33m,\u001b[39m \u001b[33m...\u001b[39margs)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                   \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 210 |\u001b[39m   }\u001b[33m;\u001b[39m\n     \u001b[90m 211 |\u001b[39m   \n     \u001b[90m 212 |\u001b[39m   console\u001b[33m.\u001b[39mwarn \u001b[33m=\u001b[39m (\u001b[33m...\u001b[39margs) \u001b[33m=>\u001b[39m {\u001b[0m\n\n      at console.call [as error] (jest.setup.js:209:19)\n      at node_modules/react-dom/cjs/react-dom-client.development.js:16023:19\n      at runWithFiberInDEV (node_modules/react-dom/cjs/react-dom-client.development.js:1522:13)\n      at warnIfUpdatesNotWrappedWithActDEV (node_modules/react-dom/cjs/react-dom-client.development.js:16022:9)\n      at scheduleUpdateOnFiber (node_modules/react-dom/cjs/react-dom-client.development.js:14396:11)\n      at dispatchSetStateInternal (node_modules/react-dom/cjs/react-dom-client.development.js:6969:13)\n      at dispatchSetState (node_modules/react-dom/cjs/react-dom-client.development.js:6927:7)\n      at setRetryCount (__tests__/integration/error-handling-retry.test.tsx:173:31)\n      at RobustApiClient.onRetry (__tests__/integration/error-handling-retry.test.tsx:97:11)\n      at makeRequest (__tests__/integration/error-handling-retry.test.tsx:171:22)\n\n  console.error\n    An update to TestComponent inside a test was not wrapped in act(...).\n    \n    When testing, code that causes React state updates should be wrapped into act(...):\n    \n    act(() => {\n      /* fire events that update state */\n    });\n    /* assert on the output */\n    \n    This ensures that you're testing the behavior the user would see in the browser. Learn more at https://react.dev/link/wrap-tests-with-act\n\n    \u001b[0m \u001b[90m 207 |\u001b[39m       \u001b[36mreturn\u001b[39m\u001b[33m;\u001b[39m\n     \u001b[90m 208 |\u001b[39m     }\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 209 |\u001b[39m     originalError\u001b[33m.\u001b[39mcall(console\u001b[33m,\u001b[39m \u001b[33m...\u001b[39margs)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                   \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 210 |\u001b[39m   }\u001b[33m;\u001b[39m\n     \u001b[90m 211 |\u001b[39m   \n     \u001b[90m 212 |\u001b[39m   console\u001b[33m.\u001b[39mwarn \u001b[33m=\u001b[39m (\u001b[33m...\u001b[39margs) \u001b[33m=>\u001b[39m {\u001b[0m\n\n      at console.call [as error] (jest.setup.js:209:19)\n      at node_modules/react-dom/cjs/react-dom-client.development.js:16023:19\n      at runWithFiberInDEV (node_modules/react-dom/cjs/react-dom-client.development.js:1522:13)\n      at warnIfUpdatesNotWrappedWithActDEV (node_modules/react-dom/cjs/react-dom-client.development.js:16022:9)\n      at scheduleUpdateOnFiber (node_modules/react-dom/cjs/react-dom-client.development.js:14396:11)\n      at dispatchSetStateInternal (node_modules/react-dom/cjs/react-dom-client.development.js:6969:13)\n      at dispatchSetState (node_modules/react-dom/cjs/react-dom-client.development.js:6927:7)\n      at setRetryCount (__tests__/integration/error-handling-retry.test.tsx:460:15)\n      at RobustApiClient.onRetry (__tests__/integration/error-handling-retry.test.tsx:97:11)\n      at makeRequest (__tests__/integration/error-handling-retry.test.tsx:448:11)\n\n  console.log\n    \ud83d\udd25 HOOK CALLED: useThreadLoader (CONFIGURED) {\n      args: [ false, 'all', 'thread-1', [AsyncFunction (anonymous)] ],\n      returning: {\n        threads: [ [Object], [Object], [Object] ],\n        isLoadingThreads: false,\n        loadError: null,\n        loadThreads: [Function: mockConstructor] {\n          _isMockFunction: true,\n          getMockImplementation: [Function (anonymous)],\n          mock: [Getter/Setter],\n          mockClear: [Function (anonymous)],\n          mockReset: [Function (anonymous)],\n          mockRestore: [Function (anonymous)],\n          mockReturnValueOnce: [Function (anonymous)],\n          mockResolvedValueOnce: [Function (anonymous)],\n          mockRejectedValueOnce: [Function (anonymous)],\n          mockReturnValue: [Function (anonymous)],\n          mockResolvedValue: [Function (anonymous)],\n          mockRejectedValue: [Function (anonymous)],\n          mockImplementationOnce: [Function (anonymous)],\n          withImplementation: [Function: bound withImplementation],\n          mockImplementation: [Function (anonymous)],\n          mockReturnThis: [Function (anonymous)],\n          mockName: [Function (anonymous)],\n          getMockName: [Function (anonymous)],\n          Symbol(Symbol.dispose): [Function (anonymous)]\n        }\n      }\n    }\n\n      at Object.log (__tests__/components/ChatSidebar/setup.tsx:429:15)\n\n  console.log\n    \ud83d\udd25 HOOK CALLED: useThreadFiltering (CONFIGURED) {\n      threadsType: 'object',\n      isArray: true,\n      threadsLength: 3,\n      returning: {\n        sortedThreads: [ [Object], [Object], [Object] ],\n        paginatedThreads: [ [Object], [Object], [Object] ],\n        totalPages: 1\n      }\n    }\n\n      at Object.log (__tests__/components/ChatSidebar/setup.tsx:434:15)\n\n  console.log\n    \ud83e\uddea TestChatSidebar rendering with threads: {\n      threadsLength: 3,\n      paginatedThreadsLength: 3,\n      isLoadingThreads: false,\n      loadError: null\n    }\n\n      at log (__tests__/components/ChatSidebar/setup.tsx:791:11)\n\n  console.log\n    \ud83c\udfaf Rendering thread thread-1, activeThreadId: thread-1, isActive: true\n\n      at log (__tests__/components/ChatSidebar/setup.tsx:649:23)\n          at Array.map (<anonymous>)\n\n  console.error\n    [Error: Not implemented: navigation (except hash changes)] {\n      type: 'not implemented'\n    }\n\n    \u001b[0m \u001b[90m 207 |\u001b[39m       \u001b[36mreturn\u001b[39m\u001b[33m;\u001b[39m\n     \u001b[90m 208 |\u001b[39m     }\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 209 |\u001b[39m     originalError\u001b[33m.\u001b[39mcall(console\u001b[33m,\u001b[39m \u001b[33m...\u001b[39margs)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                   \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 210 |\u001b[39m   }\u001b[33m;\u001b[39m\n     \u001b[90m 211 |\u001b[39m   \n     \u001b[90m 212 |\u001b[39m   console\u001b[33m.\u001b[39mwarn \u001b[33m=\u001b[39m (\u001b[33m...\u001b[39margs) \u001b[33m=>\u001b[39m {\u001b[0m\n\n      at console.call [as error] (jest.setup.js:209:19)\n      at VirtualConsole.<anonymous> (node_modules/@jest/environment-jsdom-abstract/build/index.js:78:23)\n      at module.exports (node_modules/jsdom/lib/jsdom/browser/not-implemented.js:12:26)\n      at navigateFetch (node_modules/jsdom/lib/jsdom/living/window/navigation.js:77:3)\n      at exports.navigate (node_modules/jsdom/lib/jsdom/living/window/navigation.js:55:3)\n      at Timeout._onTimeout (node_modules/jsdom/lib/jsdom/living/nodes/HTMLHyperlinkElementUtils-impl.js:80:7)\n\n  console.log\n    \ud83c\udfaf Rendering thread thread-2, activeThreadId: thread-1, isActive: false\n\n      at log (__tests__/components/ChatSidebar/setup.tsx:649:23)\n          at Array.map (<anonymous>)\n\n  console.log\n    \ud83c\udfaf Rendering thread thread-3, activeThreadId: thread-1, isActive: false\n\n      at log (__tests__/components/ChatSidebar/setup.tsx:649:23)\n          at Array.map (<anonymous>)\n\n  console.error\n    An update to TimeoutComponent inside a test was not wrapped in act(...).\n    \n    When testing, code that causes React state updates should be wrapped into act(...):\n    \n    act(() => {\n      /* fire events that update state */\n    });\n    /* assert on the output */\n    \n    This ensures that you're testing the behavior the user would see in the browser. Learn more at https://react.dev/link/wrap-tests-with-act\n\n    \u001b[0m \u001b[90m 207 |\u001b[39m       \u001b[36mreturn\u001b[39m\u001b[33m;\u001b[39m\n     \u001b[90m 208 |\u001b[39m     }\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 209 |\u001b[39m     originalError\u001b[33m.\u001b[39mcall(console\u001b[33m,\u001b[39m \u001b[33m...\u001b[39margs)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                   \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 210 |\u001b[39m   }\u001b[33m;\u001b[39m\n     \u001b[90m 211 |\u001b[39m   \n     \u001b[90m 212 |\u001b[39m   console\u001b[33m.\u001b[39mwarn \u001b[33m=\u001b[39m (\u001b[33m...\u001b[39margs) \u001b[33m=>\u001b[39m {\u001b[0m\n\n      at console.call [as error] (jest.setup.js:209:19)\n      at node_modules/react-dom/cjs/react-dom-client.development.js:16023:19\n      at runWithFiberInDEV (node_modules/react-dom/cjs/react-dom-client.development.js:1522:13)\n      at warnIfUpdatesNotWrappedWithActDEV (node_modules/react-dom/cjs/react-dom-client.development.js:16022:9)\n      at scheduleUpdateOnFiber (node_modules/react-dom/cjs/react-dom-client.development.js:14396:11)\n      at dispatchSetStateInternal (node_modules/react-dom/cjs/react-dom-client.development.js:6969:13)\n      at dispatchSetState (node_modules/react-dom/cjs/react-dom-client.development.js:6927:7)\n      at setResult (__tests__/integration/error-handling-retry.test.tsx:267:7)\n\n  console.error\n    An update to TimeoutComponent inside a test was not wrapped in act(...).\n    \n    When testing, code that causes React state updates should be wrapped into act(...):\n    \n    act(() => {\n      /* fire events that update state */\n    });\n    /* assert on the output */\n    \n    This ensures that you're testing the behavior the user would see in the browser. Learn more at https://react.dev/link/wrap-tests-with-act\n\n    \u001b[0m \u001b[90m 207 |\u001b[39m       \u001b[36mreturn\u001b[39m\u001b[33m;\u001b[39m\n     \u001b[90m 208 |\u001b[39m     }\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 209 |\u001b[39m     originalError\u001b[33m.\u001b[39mcall(console\u001b[33m,\u001b[39m \u001b[33m...\u001b[39margs)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                   \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 210 |\u001b[39m   }\u001b[33m;\u001b[39m\n     \u001b[90m 211 |\u001b[39m   \n     \u001b[90m 212 |\u001b[39m   console\u001b[33m.\u001b[39mwarn \u001b[33m=\u001b[39m (\u001b[33m...\u001b[39margs) \u001b[33m=>\u001b[39m {\u001b[0m\n\n      at console.call [as error] (jest.setup.js:209:19)\n      at node_modules/react-dom/cjs/react-dom-client.development.js:16023:19\n      at runWithFiberInDEV (node_modules/react-dom/cjs/react-dom-client.development.js:1522:13)\n      at warnIfUpdatesNotWrappedWithActDEV (node_modules/react-dom/cjs/react-dom-client.development.js:16022:9)\n      at scheduleUpdateOnFiber (node_modules/react-dom/cjs/react-dom-client.development.js:14396:11)\n      at dispatchSetStateInternal (node_modules/react-dom/cjs/react-dom-client.development.js:6969:13)\n      at dispatchSetState (node_modules/react-dom/cjs/react-dom-client.development.js:6927:7)\n      at setLoading (__tests__/integration/error-handling-retry.test.tsx:275:7)\n\n",
      "errors": "FAIL Integration Tests __tests__/integration/error-handling-retry.test.tsx\n  Error Handling - Retry Logic\n    \u00d7 retries failed requests with exponential backoff (184 ms)\n    \u221a respects max retry limit (27 ms)\n    \u221a uses linear backoff when exponential is disabled (22 ms)\n  Error Handling - Request Cancellation\n    \u00d7 cancels ongoing requests (31 ms)\n    \u221a handles multiple concurrent cancellations (33 ms)\n  Error Handling - Timeout Handling\n    \u00d7 handles request timeouts correctly (20 ms)\n    \u221a succeeds when response is within timeout (35 ms)\n\n  \u25cf Error Handling - Retry Logic \u203a retries failed requests with exponential backoff\n\n    expect(element).toHaveTextContent()\n\n    Expected element to have text content:\n      Retry 1\n    Received:\n      Retry 2\n\n    Ignored nodes: comments, script, style\n    \u001b[36m<html>\u001b[39m\n      \u001b[36m<head />\u001b[39m\n      \u001b[36m<body>\u001b[39m\n        \u001b[36m<div>\u001b[39m\n          \u001b[36m<div\u001b[39m\n            \u001b[33mdata-testid\u001b[39m=\u001b[32m\"retry-test-component\"\u001b[39m\n          \u001b[36m>\u001b[39m\n            \u001b[36m<button\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"start-request\"\u001b[39m\n            \u001b[36m>\u001b[39m\n              \u001b[0mStart Request\u001b[0m\n            \u001b[36m</button>\u001b[39m\n            \u001b[36m<div\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"loading\"\u001b[39m\n            \u001b[36m>\u001b[39m\n              \u001b[0mLoading...\u001b[0m\n              \u001b[36m<span\u001b[39m\n                \u001b[33mdata-testid\u001b[39m=\u001b[32m\"retry-count\"\u001b[39m\n              \u001b[36m>\u001b[39m\n                \u001b[0mRetry \u001b[0m\n                \u001b[0m2\u001b[0m\n              \u001b[36m</span>\u001b[39m\n            \u001b[36m</div>\u001b[39m\n          \u001b[36m</div>\u001b[39m\n        \u001b[36m</div>\u001b[39m\n      \u001b[36m</body>\u001b[39m\n    \u001b[36m</html>\u001b[39m\n\n    \u001b[0m \u001b[90m 393 |\u001b[39m     \n     \u001b[90m 394 |\u001b[39m     \u001b[36mawait\u001b[39m waitFor(() \u001b[33m=>\u001b[39m {\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 395 |\u001b[39m       expect(screen\u001b[33m.\u001b[39mgetByTestId(\u001b[32m'retry-count'\u001b[39m))\u001b[33m.\u001b[39mtoHaveTextContent(\u001b[32m'Retry 1'\u001b[39m)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                                                 \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 396 |\u001b[39m     })\u001b[33m;\u001b[39m\n     \u001b[90m 397 |\u001b[39m     \n     \u001b[90m 398 |\u001b[39m     act(() \u001b[33m=>\u001b[39m {\u001b[0m\n\n      at toHaveTextContent (__tests__/integration/error-handling-retry.test.tsx:395:49)\n      at runWithExpensiveErrorDiagnosticsDisabled (node_modules/@testing-library/dom/dist/config.js:47:12)\n      at checkCallback (node_modules/@testing-library/dom/dist/wait-for.js:124:77)\n      at node_modules/@testing-library/dom/dist/wait-for.js:82:9\n\n  \u25cf Error Handling - Request Cancellation \u203a cancels ongoing requests\n\n    Unable to find an element by: [data-testid=\"error\"]\n\n    Ignored nodes: comments, script, style\n    \u001b[36m<body>\u001b[39m\n      \u001b[36m<div>\u001b[39m\n        \u001b[36m<div\u001b[39m\n          \u001b[33mdata-testid\u001b[39m=\u001b[32m\"cancellable-request\"\u001b[39m\n        \u001b[36m>\u001b[39m\n          \u001b[36m<button\u001b[39m\n            \u001b[33mdata-testid\u001b[39m=\u001b[32m\"start-request\"\u001b[39m\n            \u001b[33mdisabled\u001b[39m=\u001b[32m\"\"\u001b[39m\n          \u001b[36m>\u001b[39m\n            \u001b[0mStart Request\u001b[0m\n          \u001b[36m</button>\u001b[39m\n          \u001b[36m<button\u001b[39m\n            \u001b[33mdata-testid\u001b[39m=\u001b[32m\"cancel-request\"\u001b[39m\n          \u001b[36m>\u001b[39m\n            \u001b[0mCancel Request\u001b[0m\n          \u001b[36m</button>\u001b[39m\n          \u001b[36m<div\u001b[39m\n            \u001b[33mdata-testid\u001b[39m=\u001b[32m\"loading\"\u001b[39m\n          \u001b[36m>\u001b[39m\n            \u001b[0mLoading...\u001b[0m\n          \u001b[36m</div>\u001b[39m\n        \u001b[36m</div>\u001b[39m\n      \u001b[36m</div>\u001b[39m\n    \u001b[36m</body>\u001b[39m\n\n    \u001b[0m \u001b[90m 508 |\u001b[39m     userEvent\u001b[33m.\u001b[39mclick(screen\u001b[33m.\u001b[39mgetByTestId(\u001b[32m'cancel-request'\u001b[39m))\u001b[33m;\u001b[39m\n     \u001b[90m 509 |\u001b[39m     \n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 510 |\u001b[39m     \u001b[36mawait\u001b[39m waitFor(() \u001b[33m=>\u001b[39m {\n     \u001b[90m     |\u001b[39m                  \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 511 |\u001b[39m       expect(screen\u001b[33m.\u001b[39mgetByTestId(\u001b[32m'error'\u001b[39m))\u001b[33m.\u001b[39mtoHaveTextContent(\u001b[32m'Request cancelled'\u001b[39m)\u001b[33m;\u001b[39m\n     \u001b[90m 512 |\u001b[39m     })\u001b[33m;\u001b[39m\n     \u001b[90m 513 |\u001b[39m   })\u001b[33m;\u001b[39m\u001b[0m\n\n      at waitForWrapper (node_modules/@testing-library/dom/dist/wait-for.js:163:27)\n      at Object.<anonymous> (__tests__/integration/error-handling-retry.test.tsx:510:18)\n\n  \u25cf Error Handling - Timeout Handling \u203a handles request timeouts correctly\n\n    expect(element).toHaveTextContent()\n\n    Expected element to have text content:\n      Timeout\n    Received:\n\n\n    Ignored nodes: comments, script, style\n    \u001b[36m<html>\u001b[39m\n      \u001b[36m<head />\u001b[39m\n      \u001b[36m<body>\u001b[39m\n        \u001b[36m<div>\u001b[39m\n          \u001b[36m<div\u001b[39m\n            \u001b[33mdata-testid\u001b[39m=\u001b[32m\"timeout-component\"\u001b[39m\n          \u001b[36m>\u001b[39m\n            \u001b[36m<button\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"fast-timeout\"\u001b[39m\n              \u001b[33mdisabled\u001b[39m=\u001b[32m\"\"\u001b[39m\n            \u001b[36m>\u001b[39m\n              \u001b[0mFast Timeout (100ms)\u001b[0m\n            \u001b[36m</button>\u001b[39m\n            \u001b[36m<button\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"slow-timeout\"\u001b[39m\n              \u001b[33mdisabled\u001b[39m=\u001b[32m\"\"\u001b[39m\n            \u001b[36m>\u001b[39m\n              \u001b[0mSlow Timeout (10s)\u001b[0m\n            \u001b[36m</button>\u001b[39m\n            \u001b[36m<div\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"loading\"\u001b[39m\n            \u001b[36m>\u001b[39m\n              \u001b[0mLoading...\u001b[0m\n            \u001b[36m</div>\u001b[39m\n            \u001b[36m<div\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"result\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n          \u001b[36m</div>\u001b[39m\n        \u001b[36m</div>\u001b[39m\n      \u001b[36m</body>\u001b[39m\n    \u001b[36m</html>\u001b[39m\n\n    \u001b[0m \u001b[90m 585 |\u001b[39m     \n     \u001b[90m 586 |\u001b[39m     \u001b[36mawait\u001b[39m waitFor(() \u001b[33m=>\u001b[39m {\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 587 |\u001b[39m       expect(screen\u001b[33m.\u001b[39mgetByTestId(\u001b[32m'result'\u001b[39m))\u001b[33m.\u001b[39mtoHaveTextContent(\u001b[32m'Timeout'\u001b[39m)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                                            \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 588 |\u001b[39m     })\u001b[33m;\u001b[39m\n     \u001b[90m 589 |\u001b[39m   })\u001b[33m;\u001b[39m\n     \u001b[90m 590 |\u001b[39m\u001b[0m\n\n      at toHaveTextContent (__tests__/integration/error-handling-retry.test.tsx:587:44)\n      at runWithExpensiveErrorDiagnosticsDisabled (node_modules/@testing-library/dom/dist/config.js:47:12)\n      at checkCallback (node_modules/@testing-library/dom/dist/wait-for.js:124:77)\n      at node_modules/@testing-library/dom/dist/wait-for.js:82:9\n\nSummary of all failing tests\nFAIL __tests__/integration/error-handling-retry.test.tsx\n  \u25cf Error Handling - Retry Logic \u203a retries failed requests with exponential backoff\n\n    expect(element).toHaveTextContent()\n\n    Expected element to have text content:\n      Retry 1\n    Received:\n      Retry 2\n\n    Ignored nodes: comments, script, style\n    \u001b[36m<html>\u001b[39m\n      \u001b[36m<head />\u001b[39m\n      \u001b[36m<body>\u001b[39m\n        \u001b[36m<div>\u001b[39m\n          \u001b[36m<div\u001b[39m\n            \u001b[33mdata-testid\u001b[39m=\u001b[32m\"retry-test-component\"\u001b[39m\n          \u001b[36m>\u001b[39m\n            \u001b[36m<button\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"start-request\"\u001b[39m\n            \u001b[36m>\u001b[39m\n              \u001b[0mStart Request\u001b[0m\n            \u001b[36m</button>\u001b[39m\n            \u001b[36m<div\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"loading\"\u001b[39m\n            \u001b[36m>\u001b[39m\n              \u001b[0mLoading...\u001b[0m\n              \u001b[36m<span\u001b[39m\n                \u001b[33mdata-testid\u001b[39m=\u001b[32m\"retry-count\"\u001b[39m\n              \u001b[36m>\u001b[39m\n                \u001b[0mRetry \u001b[0m\n                \u001b[0m2\u001b[0m\n              \u001b[36m</span>\u001b[39m\n            \u001b[36m</div>\u001b[39m\n          \u001b[36m</div>\u001b[39m\n        \u001b[36m</div>\u001b[39m\n      \u001b[36m</body>\u001b[39m\n    \u001b[36m</html>\u001b[39m\n\n    \u001b[0m \u001b[90m 393 |\u001b[39m     \n     \u001b[90m 394 |\u001b[39m     \u001b[36mawait\u001b[39m waitFor(() \u001b[33m=>\u001b[39m {\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 395 |\u001b[39m       expect(screen\u001b[33m.\u001b[39mgetByTestId(\u001b[32m'retry-count'\u001b[39m))\u001b[33m.\u001b[39mtoHaveTextContent(\u001b[32m'Retry 1'\u001b[39m)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                                                 \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 396 |\u001b[39m     })\u001b[33m;\u001b[39m\n     \u001b[90m 397 |\u001b[39m     \n     \u001b[90m 398 |\u001b[39m     act(() \u001b[33m=>\u001b[39m {\u001b[0m\n\n      at toHaveTextContent (__tests__/integration/error-handling-retry.test.tsx:395:49)\n      at runWithExpensiveErrorDiagnosticsDisabled (node_modules/@testing-library/dom/dist/config.js:47:12)\n      at checkCallback (node_modules/@testing-library/dom/dist/wait-for.js:124:77)\n      at node_modules/@testing-library/dom/dist/wait-for.js:82:9\n\n  \u25cf Error Handling - Request Cancellation \u203a cancels ongoing requests\n\n    Unable to find an element by: [data-testid=\"error\"]\n\n    Ignored nodes: comments, script, style\n    \u001b[36m<body>\u001b[39m\n      \u001b[36m<div>\u001b[39m\n        \u001b[36m<div\u001b[39m\n          \u001b[33mdata-testid\u001b[39m=\u001b[32m\"cancellable-request\"\u001b[39m\n        \u001b[36m>\u001b[39m\n          \u001b[36m<button\u001b[39m\n            \u001b[33mdata-testid\u001b[39m=\u001b[32m\"start-request\"\u001b[39m\n            \u001b[33mdisabled\u001b[39m=\u001b[32m\"\"\u001b[39m\n          \u001b[36m>\u001b[39m\n            \u001b[0mStart Request\u001b[0m\n          \u001b[36m</button>\u001b[39m\n          \u001b[36m<button\u001b[39m\n            \u001b[33mdata-testid\u001b[39m=\u001b[32m\"cancel-request\"\u001b[39m\n          \u001b[36m>\u001b[39m\n            \u001b[0mCancel Request\u001b[0m\n          \u001b[36m</button>\u001b[39m\n          \u001b[36m<div\u001b[39m\n            \u001b[33mdata-testid\u001b[39m=\u001b[32m\"loading\"\u001b[39m\n          \u001b[36m>\u001b[39m\n            \u001b[0mLoading...\u001b[0m\n          \u001b[36m</div>\u001b[39m\n        \u001b[36m</div>\u001b[39m\n      \u001b[36m</div>\u001b[39m\n    \u001b[36m</body>\u001b[39m\n\n    \u001b[0m \u001b[90m 508 |\u001b[39m     userEvent\u001b[33m.\u001b[39mclick(screen\u001b[33m.\u001b[39mgetByTestId(\u001b[32m'cancel-request'\u001b[39m))\u001b[33m;\u001b[39m\n     \u001b[90m 509 |\u001b[39m     \n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 510 |\u001b[39m     \u001b[36mawait\u001b[39m waitFor(() \u001b[33m=>\u001b[39m {\n     \u001b[90m     |\u001b[39m                  \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 511 |\u001b[39m       expect(screen\u001b[33m.\u001b[39mgetByTestId(\u001b[32m'error'\u001b[39m))\u001b[33m.\u001b[39mtoHaveTextContent(\u001b[32m'Request cancelled'\u001b[39m)\u001b[33m;\u001b[39m\n     \u001b[90m 512 |\u001b[39m     })\u001b[33m;\u001b[39m\n     \u001b[90m 513 |\u001b[39m   })\u001b[33m;\u001b[39m\u001b[0m\n\n      at waitForWrapper (node_modules/@testing-library/dom/dist/wait-for.js:163:27)\n      at Object.<anonymous> (__tests__/integration/error-handling-retry.test.tsx:510:18)\n\n  \u25cf Error Handling - Timeout Handling \u203a handles request timeouts correctly\n\n    expect(element).toHaveTextContent()\n\n    Expected element to have text content:\n      Timeout\n    Received:\n\n\n    Ignored nodes: comments, script, style\n    \u001b[36m<html>\u001b[39m\n      \u001b[36m<head />\u001b[39m\n      \u001b[36m<body>\u001b[39m\n        \u001b[36m<div>\u001b[39m\n          \u001b[36m<div\u001b[39m\n            \u001b[33mdata-testid\u001b[39m=\u001b[32m\"timeout-component\"\u001b[39m\n          \u001b[36m>\u001b[39m\n            \u001b[36m<button\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"fast-timeout\"\u001b[39m\n              \u001b[33mdisabled\u001b[39m=\u001b[32m\"\"\u001b[39m\n            \u001b[36m>\u001b[39m\n              \u001b[0mFast Timeout (100ms)\u001b[0m\n            \u001b[36m</button>\u001b[39m\n            \u001b[36m<button\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"slow-timeout\"\u001b[39m\n              \u001b[33mdisabled\u001b[39m=\u001b[32m\"\"\u001b[39m\n            \u001b[36m>\u001b[39m\n              \u001b[0mSlow Timeout (10s)\u001b[0m\n            \u001b[36m</button>\u001b[39m\n            \u001b[36m<div\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"loading\"\u001b[39m\n            \u001b[36m>\u001b[39m\n              \u001b[0mLoading...\u001b[0m\n            \u001b[36m</div>\u001b[39m\n            \u001b[36m<div\u001b[39m\n              \u001b[33mdata-testid\u001b[39m=\u001b[32m\"result\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n          \u001b[36m</div>\u001b[39m\n        \u001b[36m</div>\u001b[39m\n      \u001b[36m</body>\u001b[39m\n    \u001b[36m</html>\u001b[39m\n\n    \u001b[0m \u001b[90m 585 |\u001b[39m     \n     \u001b[90m 586 |\u001b[39m     \u001b[36mawait\u001b[39m waitFor(() \u001b[33m=>\u001b[39m {\n    \u001b[31m\u001b[1m>\u001b[22m\u001b[39m\u001b[90m 587 |\u001b[39m       expect(screen\u001b[33m.\u001b[39mgetByTestId(\u001b[32m'result'\u001b[39m))\u001b[33m.\u001b[39mtoHaveTextContent(\u001b[32m'Timeout'\u001b[39m)\u001b[33m;\u001b[39m\n     \u001b[90m     |\u001b[39m                                            \u001b[31m\u001b[1m^\u001b[22m\u001b[39m\n     \u001b[90m 588 |\u001b[39m     })\u001b[33m;\u001b[39m\n     \u001b[90m 589 |\u001b[39m   })\u001b[33m;\u001b[39m\n     \u001b[90m 590 |\u001b[39m\u001b[0m\n\n      at toHaveTextContent (__tests__/integration/error-handling-retry.test.tsx:587:44)\n      at runWithExpensiveErrorDiagnosticsDisabled (node_modules/@testing-library/dom/dist/config.js:47:12)\n      at checkCallback (node_modules/@testing-library/dom/dist/wait-for.js:124:77)\n      at node_modules/@testing-library/dom/dist/wait-for.js:82:9\n\n\nTest Suites: 1 failed, 1 of 163 total\nTests:       3 failed, 4 passed, 7 total\nSnapshots:   0 total\nTime:        3.928 s, estimated 122 s\nRan all test suites.\n"
    },
    "dev_launcher": {
      "success": false,
      "duration": 35.865758180618286,
      "output": "============================= test session starts =============================\nplatform win32 -- Python 3.12.4, pytest-8.4.1, pluggy-1.6.0\nrootdir: C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.5.3, langsmith-0.4.15, asyncio-1.1.0, cov-6.2.1, mock-3.14.1, xdist-3.8.0, html-4.1.1, json-report-1.5.0, metadata-3.1.1, timeout-2.4.0, typeguard-4.4.4\nasyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=function, asyncio_default_test_loop_scope=function\ntimeout: 300.0s\ntimeout method: thread\ntimeout func_only: False\ncollected 22 items\n\ntests\\e2e\\test_dev_launcher_real_startup.py F\n\n================================== FAILURES ===================================\n_____ TestDevLauncherRealStartup.test_real_dev_launcher_startup_sequence ______\ntests\\e2e\\test_dev_launcher_real_startup.py:285: in test_real_dev_launcher_startup_sequence\n    assert startup_success, \"Dev launcher failed to start services\"\nE   AssertionError: Dev launcher failed to start services\nE   assert False\n---------------------------- Captured stdout setup ----------------------------\nBacked up original config to C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.dev_services.json.backup\nUsing test config with mock databases\nSet DATABASE_URL=postgresql://mock:mock@localhost:5432/mock\nSet REDIS_URL=redis://localhost:6379/0\nSet CLICKHOUSE_URL=clickhouse://default@localhost:8123/netra_dev\nSet DISABLE_DB_INIT=true\nSet TESTING=true\nSet JWT_SECRET_KEY=test-jwt-secret-key-for-dev-launcher-testing-334572c7c03dce9f196132fda7ecc1a8\nSet FERNET_KEY=SvTcm7oOSVaQXsVHHMV0z_ZCwErOSVOvfJwcFwDF3E4=\nSet SKIP_DATABASE_INIT=true\n----------------------------- Captured log setup ------------------------------\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.address`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.address` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.automotive`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.automotive` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.bank`.\nDEBUG    faker.factory:factory.py:88 Specified locale `en_US` is not available for provider `faker.providers.bank`. Locale reset to `en_GB` for this provider.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.barcode`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.barcode` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.color`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.color` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.company`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.company` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.credit_card`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.credit_card` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.currency`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.currency` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.date_time`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.date_time` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.doi` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.emoji` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.file` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.geo`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.geo` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.internet`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.internet` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.isbn`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.isbn` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.job`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.job` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.lorem`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.lorem` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.misc`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.misc` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.passport`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.passport` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.person`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.person` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.phone_number`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.phone_number` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.profile` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.python` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.sbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.ssn`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.ssn` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.user_agent` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    asyncio:proactor_events.py:634 Using proactor: IocpProactor\nDEBUG    asyncio:proactor_events.py:634 Using proactor: IocpProactor\nINFO     dev_launcher.service_config:service_config.py:363 Configuration loaded from C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\.dev_services.json\nINFO     dev_launcher.service_config:service_config.py:549 Loaded existing service configuration\n---------------------------- Captured stdout call -----------------------------\n\\n=== STARTING REAL DEV LAUNCHER STARTUP TEST ===\\nSUCCESS: The process with PID 12816 has been terminated.\\r\\nSUCCESS: The process with PID 7444 has been terminated.\\r\\n\\U0001f50d DISCOVER | POSTGRESQL: postgresql://mock:***@localhost:5432/mock\\n\\U0001f50d DISCOVER | CLICKHOUSE: clickhouse://default:***@localhost:8123/netra_dev\\n\\U0001f50d DISCOVER | REDIS: redis://localhost:6379/0\\n[DISCOVER] WEBSOCKET | Discovered endpoint: main_ws -> ws://localhost:8000/ws (required)\\n[DISCOVER] WEBSOCKET | Discovered endpoint: mcp_ws -> ws://localhost:8000/api/mcp/ws (optional)\\n============================================================\\n\\U0001f680 Netra AI Development Environment\\n============================================================\\n\\U0001f4dd Configuration:\\n\\U0001f527 Service Modes:\\n  \\U0001f4bb Redis       : Local  (localhost:6379)\\n  \\U0001f4bb ClickHouse  : Local  (localhost:9000)\\n  \\U0001f4bb PostgreSQL  : Local  (localhost:5433)\\n  \\u2601\\ufe0f LLM         : Cloud \\n\\n  \\u2022 Dynamic ports: NO\\n  \\u2022 Backend hot reload: NO\\n  \\u2022 Frontend hot reload: YES (Next.js native)\\n  \\u2022 Real-time logging: YES\\n  \\u2022 Turbopack: NO\\n  \\u2022 Secret loading: NO\\n  \\u2022 Verbose output: NO\\n\\n\\U0001f50d Checking environment...\\n\\U0001f50d Checking environment...\\n\\u2705 Environment check passed\\n\\u2139\\ufe0f Set BACKEND_PORT=8000\\n\\u2139\\ufe0f Set FRONTEND_PORT=3000\\n\\u2139\\ufe0f Set AUTH_PORT=8081\\n\\u2139\\ufe0f Set WEBSOCKET_PORT=8000\\n\\u2139\\ufe0f Set CORS_ORIGINS=*\\n\\U0001f511 Using existing cross-service auth token\\n\\u2705 Environment check passed\\n\\U0001f512 Secret loading disabled (--no-secrets flag)\\n\\U0001f504 Checking cache and environment...\\n\\U0001f504 Loading secrets...\\n\\U0001f504 Validating database connections...\\n\\U0001f504 DATABASE | Validating 3 database connections...\\n\\U0001f504 CONNECT | main_postgres: Attempt 1/5\\n\\U0001f504 CONNECT | main_clickhouse: Attempt 1/5\\n\\U0001f504 CONNECT | main_redis: Attempt 1/5\\n\\u2705 CONNECT | main_redis: Connected successfully\\n\\u2705 CONNECT | main_clickhouse: Connected successfully\\n\\U0001f504 CONNECT | main_postgres: Attempt 2/5\\n\\U0001f504 CONNECT | main_postgres: Attempt 3/5\\n\\U0001f504 CONNECT | main_postgres: Attempt 4/5\\n\\U0001f504 CONNECT | main_postgres: Attempt 5/5\\n\\u274c CONNECT | main_postgres: Failed after 5 attempts - Connection test failed\\n\\u274c DATABASE | Database validation failed - check logs for details\\n\\u274c Database validation failed\\n\\u274c Failed to start services\\nLauncher exited with code: 1\n------------------------------ Captured log call ------------------------------\nINFO     dev_launcher.health_monitor:health_monitor.py:139 HealthMonitor initialized (check_interval: 30s)\nINFO     dev_launcher.health_monitor:health_monitor.py:141 Windows process verification enabled\nINFO     dev_launcher.process_manager:process_manager.py:58 ProcessManager initialized for win32\nINFO     dev_launcher.process_manager:process_manager.py:60 Enhanced Windows process tree management enabled\nINFO     dev_launcher.database_connector:database_connector.py:130 Discovered 3 database connections\nINFO     dev_launcher.websocket_validator:websocket_validator.py:82 Discovered 2 WebSocket endpoints\nINFO     dev_launcher.launcher:launcher.py:165 Signal handlers registered for graceful shutdown\nDEBUG    dev_launcher.service_discovery:service_discovery.py:95 Cleared all service discovery information\n-------------------------- Captured stdout teardown ---------------------------\nCleaning up launcher instance...\nRestored environment variables\nRemoved test configuration\nRestored original configuration\n=========================== short test summary info ===========================\nFAILED tests/e2e/test_dev_launcher_real_startup.py::TestDevLauncherRealStartup::test_real_dev_launcher_startup_sequence\n!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!\n============================= 1 failed in 32.24s ==============================\n",
      "errors": ""
    }
  },
  "overall_success": false,
  "total_duration": 69.83847522735596
}