{"created": 1756033439.4934413, "duration": 3.502068042755127, "exitcode": 1, "root": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend", "environment": {}, "summary": {"failed": 77, "error": 4, "passed": 42, "total": 123, "collected": 123}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests/config", "type": "Package"}]}, {"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection::test_get_environment_testing", "type": "Function", "lineno": 64}, {"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection::test_get_environment_cloud_run_detected", "type": "Function", "lineno": 75}, {"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection::test_get_environment_defaults_to_development", "type": "Function", "lineno": 88}, {"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection::test_get_environment_explicit_environment_var", "type": "Function", "lineno": 100}, {"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection::test_testing_environment_takes_precedence", "type": "Function", "lineno": 123}]}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation::test_create_config_development", "type": "Function", "lineno": 148}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation::test_create_config_production", "type": "Function", "lineno": 160}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation::test_create_config_staging", "type": "Function", "lineno": 172}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation::test_create_config_testing", "type": "Function", "lineno": 184}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation::test_create_config_unknown_environment_defaults", "type": "Function", "lineno": 196}]}, {"nodeid": "tests/config/test_config_environment.py::TestEnvironmentValidation", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_environment.py::TestEnvironmentValidation::test_validate_environment_valid_environments", "type": "Function", "lineno": 214}, {"nodeid": "tests/config/test_config_environment.py::TestEnvironmentValidation::test_validate_environment_invalid_environments", "type": "Function", "lineno": 224}, {"nodeid": "tests/config/test_config_environment.py::TestEnvironmentValidation::test_environment_config_mapping_completeness", "type": "Function", "lineno": 233}]}, {"nodeid": "tests/config/test_config_environment.py::TestCloudEnvironmentDetection", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_environment.py::TestCloudEnvironmentDetection::test_cloud_run_detection_with_k_service", "type": "Function", "lineno": 254}, {"nodeid": "tests/config/test_config_environment.py::TestCloudEnvironmentDetection::test_app_engine_detection", "type": "Function", "lineno": 268}, {"nodeid": "tests/config/test_config_environment.py::TestCloudEnvironmentDetection::test_google_cloud_project_detection", "type": "Function", "lineno": 282}]}, {"nodeid": "tests/config/test_config_environment.py::TestConfigurationLogging", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_environment.py::TestConfigurationLogging::test_logger_initialization", "type": "Function", "lineno": 303}, {"nodeid": "tests/config/test_config_environment.py::TestConfigurationLogging::test_environment_detection_logging", "type": "Function", "lineno": 309}, {"nodeid": "tests/config/test_config_environment.py::TestConfigurationLogging::test_config_creation_logging", "type": "Function", "lineno": 320}]}, {"nodeid": "tests/config/test_config_environment.py::TestPerformanceAndEdgeCases", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_environment.py::TestPerformanceAndEdgeCases::test_multiple_environment_detections_consistent", "type": "Function", "lineno": 338}, {"nodeid": "tests/config/test_config_environment.py::TestPerformanceAndEdgeCases::test_config_creation_performance", "type": "Function", "lineno": 349}, {"nodeid": "tests/config/test_config_environment.py::TestPerformanceAndEdgeCases::test_environment_variable_unicode_handling", "type": "Function", "lineno": 364}]}, {"nodeid": "tests/config/test_config_environment.py", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection", "type": "Class"}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation", "type": "Class"}, {"nodeid": "tests/config/test_config_environment.py::TestEnvironmentValidation", "type": "Class"}, {"nodeid": "tests/config/test_config_environment.py::TestCloudEnvironmentDetection", "type": "Class"}, {"nodeid": "tests/config/test_config_environment.py::TestConfigurationLogging", "type": "Class"}, {"nodeid": "tests/config/test_config_environment.py::TestPerformanceAndEdgeCases", "type": "Class"}]}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_cloud_run_environment_with_k_service", "type": "Function", "lineno": 79}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_cloud_run_environment_staging_pattern", "type": "Function", "lineno": 91}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_cloud_run_environment_not_present", "type": "Function", "lineno": 103}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_app_engine_environment_standard", "type": "Function", "lineno": 111}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_app_engine_environment_flex", "type": "Function", "lineno": 123}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_kubernetes_environment", "type": "Function", "lineno": 135}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_multiple_cloud_environments_precedence", "type": "Function", "lineno": 148}]}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading::test_load_config_from_environment_success", "type": "Function", "lineno": 180}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading::test_load_config_from_environment_missing_variables", "type": "Function", "lineno": 209}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading::test_load_config_from_environment_type_conversion", "type": "Function", "lineno": 230}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading::test_load_config_with_default_values", "type": "Function", "lineno": 263}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading::test_load_config_environment_override_defaults", "type": "Function", "lineno": 288}]}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation::test_validate_required_config_success", "type": "Function", "lineno": 321}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation::test_validate_required_config_missing_keys", "type": "Function", "lineno": 335}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation::test_validate_required_config_empty_values", "type": "Function", "lineno": 352}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation::test_validate_config_with_custom_validators", "type": "Function", "lineno": 369}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation::test_validate_config_custom_validator_failure", "type": "Function", "lineno": 394}]}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationFallbackMechanisms", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_loader.py::TestConfigurationFallbackMechanisms::test_fallback_to_default_configuration", "type": "Function", "lineno": 431}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationFallbackMechanisms::test_fallback_configuration_hierarchy", "type": "Function", "lineno": 457}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationFallbackMechanisms::test_graceful_degradation_partial_config_failure", "type": "Function", "lineno": 492}]}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderErrorHandling", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderErrorHandling::test_config_load_error_creation", "type": "Function", "lineno": 517}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderErrorHandling::test_config_loader_type_conversion_errors", "type": "Function", "lineno": 535}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderErrorHandling::test_config_loader_circular_reference_detection", "type": "Function", "lineno": 566}]}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderPerformance", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderPerformance::test_config_loading_performance_large_environment", "type": "Function", "lineno": 584}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderPerformance::test_config_validation_performance", "type": "Function", "lineno": 608}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderPerformance::test_cloud_environment_detection_caching", "type": "Function", "lineno": 624}]}, {"nodeid": "tests/config/test_config_loader.py", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection", "type": "Class"}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading", "type": "Class"}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation", "type": "Class"}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationFallbackMechanisms", "type": "Class"}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderErrorHandling", "type": "Class"}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderPerformance", "type": "Class"}]}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_secrets_manager_initialization", "type": "Function", "lineno": 56}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_load_secrets_into_config_success", "type": "Function", "lineno": 65}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_load_secrets_into_config_no_secrets", "type": "Function", "lineno": 86}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_load_secrets_into_config_error_handling", "type": "Function", "lineno": 100}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_apply_secrets_to_config_with_direct_mapping", "type": "Function", "lineno": 114}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_apply_secrets_to_config_with_nested_mapping", "type": "Function", "lineno": 126}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_analyze_critical_secrets_all_present", "type": "Function", "lineno": 140}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_analyze_critical_secrets_some_missing", "type": "Function", "lineno": 157}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_set_nested_field_success", "type": "Function", "lineno": 173}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_set_nested_field_error_handling", "type": "Function", "lineno": 184}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_get_secret_mappings", "type": "Function", "lineno": 194}]}, {"nodeid": "tests/config/test_config_secrets_manager.py", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager", "type": "Class"}]}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigurationBootstrap", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigurationBootstrap::test_fresh_startup_loads_config", "type": "Function", "lineno": 24}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigurationBootstrap::test_staging_environment_bootstrap", "type": "Function", "lineno": 43}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigurationBootstrap::test_production_environment_security", "type": "Function", "lineno": 61}]}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestDatabaseE2E", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_e2e.py::TestDatabaseE2E::test_database_connection_lifecycle", "type": "Coroutine", "lineno": 79}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestDatabaseE2E::test_database_pool_behavior", "type": "Coroutine", "lineno": 96}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestDatabaseE2E::test_database_transaction_retry_config", "type": "Function", "lineno": 121}]}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestRedisE2E", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_e2e.py::TestRedisE2E::test_redis_connection_modes", "type": "Coroutine", "lineno": 145}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestRedisE2E::test_redis_failover_scenario", "type": "Coroutine", "lineno": 172}]}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestCacheE2E", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_e2e.py::TestCacheE2E::test_cache_with_adaptive_ttl", "type": "Coroutine", "lineno": 210}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestCacheE2E::test_cache_disabled_scenario", "type": "Coroutine", "lineno": 245}]}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestMultiEnvironmentE2E", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_e2e.py::TestMultiEnvironmentE2E::test_development_to_staging_transition", "type": "Function", "lineno": 281}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestMultiEnvironmentE2E::test_pr_environment_detection", "type": "Function", "lineno": 302}]}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigValidationE2E", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigValidationE2E::test_complete_config_validation", "type": "Function", "lineno": 322}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigValidationE2E::test_validation_with_missing_secrets", "type": "Function", "lineno": 335}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigValidationE2E::test_validation_with_database_issues", "type": "Function", "lineno": 349}]}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigPerformanceE2E", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigPerformanceE2E::test_config_caching_performance", "type": "Function", "lineno": 366}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigPerformanceE2E::test_hot_reload_performance", "type": "Function", "lineno": 383}]}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigRecoveryE2E", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigRecoveryE2E::test_recovery_from_corrupt_config", "type": "Function", "lineno": 398}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigRecoveryE2E::test_fallback_chain_for_critical_services", "type": "Function", "lineno": 426}]}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigObservabilityE2E", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigObservabilityE2E::test_config_summary_provides_insights", "type": "Function", "lineno": 456}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigObservabilityE2E::test_environment_overrides_visibility", "type": "Function", "lineno": 474}]}, {"nodeid": "tests/config/test_unified_config_e2e.py", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigurationBootstrap", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestDatabaseE2E", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestRedisE2E", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestCacheE2E", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestMultiEnvironmentE2E", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigValidationE2E", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigPerformanceE2E", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigRecoveryE2E", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigObservabilityE2E", "type": "Class"}]}, {"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration::test_database_url_retrieval_from_config", "type": "Function", "lineno": 22}, {"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration::test_sync_engine_creation_uses_config", "type": "Function", "lineno": 34}, {"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration::test_async_engine_creation_uses_config", "type": "Function", "lineno": 51}, {"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration::test_environment_detection_from_config", "type": "Function", "lineno": 68}, {"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration::test_test_mode_detection_from_config", "type": "Function", "lineno": 80}]}, {"nodeid": "tests/config/test_unified_config_integration.py::TestRedisManagerIntegration", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_integration.py::TestRedisManagerIntegration::test_redis_mode_from_config", "type": "Coroutine", "lineno": 95}, {"nodeid": "tests/config/test_unified_config_integration.py::TestRedisManagerIntegration::test_redis_connection_uses_config", "type": "Coroutine", "lineno": 109}, {"nodeid": "tests/config/test_unified_config_integration.py::TestRedisManagerIntegration::test_redis_fallback_on_failure", "type": "Coroutine", "lineno": 135}]}, {"nodeid": "tests/config/test_unified_config_integration.py::TestPostgresCoreIntegration", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_integration.py::TestPostgresCoreIntegration::test_sync_database_pool_config", "type": "Function", "lineno": 163}, {"nodeid": "tests/config/test_unified_config_integration.py::TestPostgresCoreIntegration::test_async_database_pool_config", "type": "Coroutine", "lineno": 185}, {"nodeid": "tests/config/test_unified_config_integration.py::TestPostgresCoreIntegration::test_pool_sizing_with_minimum_values", "type": "Function", "lineno": 208}]}, {"nodeid": "tests/config/test_unified_config_integration.py::TestCacheCoreIntegration", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_integration.py::TestCacheCoreIntegration::test_cache_config_from_unified", "type": "Coroutine", "lineno": 232}, {"nodeid": "tests/config/test_unified_config_integration.py::TestCacheCoreIntegration::test_cache_disabled_from_config", "type": "Coroutine", "lineno": 257}]}, {"nodeid": "tests/config/test_unified_config_integration.py::TestStartupModuleIntegration", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_integration.py::TestStartupModuleIntegration::test_postgres_mode_detection_from_config", "type": "Function", "lineno": 281}, {"nodeid": "tests/config/test_unified_config_integration.py::TestStartupModuleIntegration::test_startup_fallback_on_config_error", "type": "Function", "lineno": 295}]}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigConsistency", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_integration.py::TestConfigConsistency::test_database_and_cache_config_alignment", "type": "Function", "lineno": 310}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigConsistency::test_service_mode_consistency", "type": "Function", "lineno": 322}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigConsistency::test_security_config_consistency", "type": "Function", "lineno": 338}]}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigHotReload", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_integration.py::TestConfigHotReload::test_hot_reload_updates_all_components", "type": "Function", "lineno": 354}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigHotReload::test_hot_reload_disabled_in_production", "type": "Function", "lineno": 373}]}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigErrorHandling", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_integration.py::TestConfigErrorHandling::test_database_fallback_on_config_error", "type": "Function", "lineno": 390}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigErrorHandling::test_redis_graceful_degradation", "type": "Function", "lineno": 399}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigErrorHandling::test_cache_defaults_on_config_error", "type": "Function", "lineno": 411}]}, {"nodeid": "tests/config/test_unified_config_integration.py", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_integration.py::TestRedisManagerIntegration", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_integration.py::TestPostgresCoreIntegration", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_integration.py::TestCacheCoreIntegration", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_integration.py::TestStartupModuleIntegration", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigConsistency", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigHotReload", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigErrorHandling", "type": "Class"}]}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_singleton_pattern", "type": "Function", "lineno": 22}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_config_loading_caches_result", "type": "Function", "lineno": 28}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_environment_detection", "type": "Function", "lineno": 35}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_hot_reload_capability", "type": "Function", "lineno": 46}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_config_summary_generation", "type": "Function", "lineno": 56}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_configuration_validation", "type": "Function", "lineno": 71}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_error_handling_with_fallback", "type": "Function", "lineno": 82}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_config_class_selection_by_environment", "type": "Function", "lineno": 91}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_environment_override_detection", "type": "Function", "lineno": 107}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_configuration_population_order", "type": "Function", "lineno": 118}]}, {"nodeid": "tests/config/test_unified_config_unit.py::TestDatabaseConfigFields", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_unit.py::TestDatabaseConfigFields::test_database_pool_settings", "type": "Function", "lineno": 137}, {"nodeid": "tests/config/test_unified_config_unit.py::TestDatabaseConfigFields::test_database_connection_settings", "type": "Function", "lineno": 155}, {"nodeid": "tests/config/test_unified_config_unit.py::TestDatabaseConfigFields::test_database_advanced_settings", "type": "Function", "lineno": 167}]}, {"nodeid": "tests/config/test_unified_config_unit.py::TestCacheConfigFields", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_unit.py::TestCacheConfigFields::test_cache_basic_settings", "type": "Function", "lineno": 183}, {"nodeid": "tests/config/test_unified_config_unit.py::TestCacheConfigFields::test_cache_adaptive_settings", "type": "Function", "lineno": 198}]}, {"nodeid": "tests/config/test_unified_config_unit.py::TestConfigHelperFunctions", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_unit.py::TestConfigHelperFunctions::test_get_unified_config_returns_appconfig", "type": "Function", "lineno": 214}, {"nodeid": "tests/config/test_unified_config_unit.py::TestConfigHelperFunctions::test_reload_unified_config_delegates_to_manager", "type": "Function", "lineno": 219}, {"nodeid": "tests/config/test_unified_config_unit.py::TestConfigHelperFunctions::test_validate_config_integrity_returns_tuple", "type": "Function", "lineno": 225}]}, {"nodeid": "tests/config/test_unified_config_unit.py::TestAPIKeyConfiguration", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_unit.py::TestAPIKeyConfiguration::test_llm_api_key_fields", "type": "Function", "lineno": 235}, {"nodeid": "tests/config/test_unified_config_unit.py::TestAPIKeyConfiguration::test_oauth_credential_fields", "type": "Function", "lineno": 243}]}, {"nodeid": "tests/config/test_unified_config_unit.py", "outcome": "passed", "result": [{"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_unit.py::TestDatabaseConfigFields", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_unit.py::TestCacheConfigFields", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_unit.py::TestConfigHelperFunctions", "type": "Class"}, {"nodeid": "tests/config/test_unified_config_unit.py::TestAPIKeyConfiguration", "type": "Class"}]}, {"nodeid": "tests/config", "outcome": "passed", "result": [{"nodeid": "tests/config/test_config_environment.py", "type": "Module"}, {"nodeid": "tests/config/test_config_loader.py", "type": "Module"}, {"nodeid": "tests/config/test_config_secrets_manager.py", "type": "Module"}, {"nodeid": "tests/config/test_unified_config_e2e.py", "type": "Module"}, {"nodeid": "tests/config/test_unified_config_integration.py", "type": "Module"}, {"nodeid": "tests/config/test_unified_config_unit.py", "type": "Module"}]}], "tests": [{"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection::test_get_environment_testing", "lineno": 64, "outcome": "failed", "keywords": ["test_get_environment_testing", "TestConfigEnvironmentDetection", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.1074283000016294, "outcome": "passed", "stderr": "2025-08-24 04:03:56.225 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.address`.</dim>\n2025-08-24 04:03:56.225 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.address`.</dim>\n2025-08-24 04:03:56.230 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.address` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.230 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.address` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.231 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.automotive`.</dim>\n2025-08-24 04:03:56.231 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.automotive`.</dim>\n2025-08-24 04:03:56.237 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.automotive` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.238 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.automotive` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.241 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.bank`.</dim>\n2025-08-24 04:03:56.241 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.bank`.</dim>\n2025-08-24 04:03:56.244 | DEBUG    | logging:handle:1028 | <dim>Specified locale `en_US` is not available for provider `faker.providers.bank`. Locale reset to `en_GB` for this provider.</dim>\n2025-08-24 04:03:56.245 | DEBUG    | logging:handle:1028 | <dim>Specified locale `en_US` is not available for provider `faker.providers.bank`. Locale reset to `en_GB` for this provider.</dim>\n2025-08-24 04:03:56.246 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.barcode`.</dim>\n2025-08-24 04:03:56.246 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.barcode`.</dim>\n2025-08-24 04:03:56.247 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.barcode` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.247 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.barcode` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.250 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.color`.</dim>\n2025-08-24 04:03:56.250 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.color`.</dim>\n2025-08-24 04:03:56.253 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.color` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.253 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.color` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.254 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.company`.</dim>\n2025-08-24 04:03:56.254 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.company`.</dim>\n2025-08-24 04:03:56.258 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.company` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.258 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.company` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.260 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.credit_card`.</dim>\n2025-08-24 04:03:56.260 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.credit_card`.</dim>\n2025-08-24 04:03:56.261 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.credit_card` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.262 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.credit_card` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.264 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.currency`.</dim>\n2025-08-24 04:03:56.264 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.currency`.</dim>\n2025-08-24 04:03:56.267 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.currency` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.267 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.currency` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.268 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.date_time`.</dim>\n2025-08-24 04:03:56.268 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.date_time`.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.date_time` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.date_time` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.doi` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.doi` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.emoji` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.emoji` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.file` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.file` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.geo`.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.geo`.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.geo` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.269 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.geo` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.279 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.internet`.</dim>\n2025-08-24 04:03:56.279 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.internet`.</dim>\n2025-08-24 04:03:56.283 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.internet` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.283 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.internet` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.285 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.isbn`.</dim>\n2025-08-24 04:03:56.285 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.isbn`.</dim>\n2025-08-24 04:03:56.286 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.isbn` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.286 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.isbn` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.288 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.job`.</dim>\n2025-08-24 04:03:56.288 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.job`.</dim>\n2025-08-24 04:03:56.291 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.job` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.291 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.job` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.292 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.lorem`.</dim>\n2025-08-24 04:03:56.292 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.lorem`.</dim>\n2025-08-24 04:03:56.294 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.lorem` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.294 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.lorem` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.294 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.misc`.</dim>\n2025-08-24 04:03:56.294 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.misc`.</dim>\n2025-08-24 04:03:56.294 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.misc` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.294 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.misc` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.298 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.passport`.</dim>\n2025-08-24 04:03:56.298 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.passport`.</dim>\n2025-08-24 04:03:56.298 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.passport` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.298 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.passport` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.300 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.person`.</dim>\n2025-08-24 04:03:56.300 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.person`.</dim>\n2025-08-24 04:03:56.308 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.person` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.309 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.person` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.313 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.phone_number`.</dim>\n2025-08-24 04:03:56.314 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.phone_number`.</dim>\n2025-08-24 04:03:56.318 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.phone_number` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.318 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.phone_number` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.321 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.profile` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.321 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.profile` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.321 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.python` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.321 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.python` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.321 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.sbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.321 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.sbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.321 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.ssn`.</dim>\n2025-08-24 04:03:56.321 | DEBUG    | logging:handle:1028 | <dim>Looking for locale `en_US` in provider `faker.providers.ssn`.</dim>\n2025-08-24 04:03:56.326 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.ssn` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.326 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.ssn` has been localized to `en_US`.</dim>\n2025-08-24 04:03:56.329 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.user_agent` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n2025-08-24 04:03:56.330 | DEBUG    | logging:handle:1028 | <dim>Provider `faker.providers.user_agent` does not feature localization. Specified locale `en_US` is not utilized for this provider.</dim>\n", "log": [{"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.address`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2252672, "msecs": 225.0, "relativeCreated": 3660.9134674072266, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.address` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.2301068, "msecs": 230.0, "relativeCreated": 3665.753126144409, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.automotive`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2319303, "msecs": 231.0, "relativeCreated": 3667.576551437378, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.automotive` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.2376945, "msecs": 237.0, "relativeCreated": 3673.3407974243164, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.bank`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2411559, "msecs": 241.0, "relativeCreated": 3676.802158355713, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Specified locale `en_US` is not available for provider `faker.providers.bank`. Locale reset to `en_GB` for this provider.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 88, "funcName": "_find_provider_class", "created": 1756033436.2445133, "msecs": 244.0, "relativeCreated": 3680.159568786621, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.barcode`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2463832, "msecs": 246.0, "relativeCreated": 3682.0294857025146, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.barcode` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.2476954, "msecs": 247.0, "relativeCreated": 3683.3417415618896, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.color`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2502441, "msecs": 250.0, "relativeCreated": 3685.8904361724854, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.color` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.2531378, "msecs": 253.0, "relativeCreated": 3688.784122467041, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.company`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2542696, "msecs": 254.0, "relativeCreated": 3689.915895462036, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.company` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.2582352, "msecs": 258.0, "relativeCreated": 3693.8815116882324, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.credit_card`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2601366, "msecs": 260.0, "relativeCreated": 3695.7828998565674, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.credit_card` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.2616653, "msecs": 261.0, "relativeCreated": 3697.3116397857666, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.currency`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.264006, "msecs": 264.0, "relativeCreated": 3699.6521949768066, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.currency` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.2663713, "msecs": 266.0, "relativeCreated": 3702.0175457000732, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.date_time`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2688804, "msecs": 268.0, "relativeCreated": 3704.526662826538, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.date_time` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.269985, "msecs": 269.0, "relativeCreated": 3705.6312561035156, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.doi` does not feature localization. Specified locale `en_US` is not utilized for this provider.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 108, "funcName": "_find_provider_class", "created": 1756033436.269985, "msecs": 269.0, "relativeCreated": 3705.6312561035156, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.emoji` does not feature localization. Specified locale `en_US` is not utilized for this provider.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 108, "funcName": "_find_provider_class", "created": 1756033436.269985, "msecs": 269.0, "relativeCreated": 3705.6312561035156, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.file` does not feature localization. Specified locale `en_US` is not utilized for this provider.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 108, "funcName": "_find_provider_class", "created": 1756033436.269985, "msecs": 269.0, "relativeCreated": 3705.6312561035156, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.geo`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.269985, "msecs": 269.0, "relativeCreated": 3705.6312561035156, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.geo` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.269985, "msecs": 269.0, "relativeCreated": 3705.6312561035156, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.internet`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2790406, "msecs": 279.0, "relativeCreated": 3714.686870574951, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.internet` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.283478, "msecs": 283.0, "relativeCreated": 3719.1243171691895, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.isbn`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2856584, "msecs": 285.0, "relativeCreated": 3721.3046550750732, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.isbn` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.2862382, "msecs": 286.0, "relativeCreated": 3721.8844890594482, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.job`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.288078, "msecs": 288.0, "relativeCreated": 3723.724365234375, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.job` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.2912505, "msecs": 291.0, "relativeCreated": 3726.8967628479004, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.lorem`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.29295, "msecs": 292.0, "relativeCreated": 3728.5962104797363, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.lorem` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.294976, "msecs": 294.0, "relativeCreated": 3730.6222915649414, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.misc`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.294976, "msecs": 294.0, "relativeCreated": 3730.6222915649414, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.misc` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.294976, "msecs": 294.0, "relativeCreated": 3730.6222915649414, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.passport`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.2981386, "msecs": 298.0, "relativeCreated": 3733.7849140167236, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.passport` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.2981386, "msecs": 298.0, "relativeCreated": 3733.7849140167236, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.person`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.3008223, "msecs": 300.0, "relativeCreated": 3736.468553543091, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.person` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.3087313, "msecs": 308.0, "relativeCreated": 3744.377613067627, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.phone_number`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.313552, "msecs": 313.0, "relativeCreated": 3749.1981983184814, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.phone_number` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.318094, "msecs": 318.0, "relativeCreated": 3753.7403106689453, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.profile` does not feature localization. Specified locale `en_US` is not utilized for this provider.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 108, "funcName": "_find_provider_class", "created": 1756033436.321383, "msecs": 321.0, "relativeCreated": 3757.0292949676514, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.python` does not feature localization. Specified locale `en_US` is not utilized for this provider.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 108, "funcName": "_find_provider_class", "created": 1756033436.321383, "msecs": 321.0, "relativeCreated": 3757.0292949676514, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.sbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 108, "funcName": "_find_provider_class", "created": 1756033436.321383, "msecs": 321.0, "relativeCreated": 3757.0292949676514, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Looking for locale `en_US` in provider `faker.providers.ssn`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 78, "funcName": "_find_provider_class", "created": 1756033436.321383, "msecs": 321.0, "relativeCreated": 3757.0292949676514, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.ssn` has been localized to `en_US`.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 97, "funcName": "_find_provider_class", "created": 1756033436.326293, "msecs": 326.0, "relativeCreated": 3761.939287185669, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "faker.factory", "msg": "Provider `faker.providers.user_agent` does not feature localization. Specified locale `en_US` is not utilized for this provider.", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\faker\\factory.py", "filename": "factory.py", "module": "factory", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 108, "funcName": "_find_provider_class", "created": 1756033436.3299003, "msecs": 329.0, "relativeCreated": 3765.5465602874756, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0002462999982526526, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py", "lineno": 71, "message": "AttributeError: 'EnvironmentDetector' object has no attribute 'get_environment'. Did you mean: '_detect_environment'?"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 71, "message": "in test_get_environment_testing"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:71: in test_get_environment_testing\n    result = config_env.get_environment()\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'EnvironmentDetector' object has no attribute 'get_environment'. Did you mean: '_detect_environment'?"}, "teardown": {"duration": 0.0025487000020802952, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection::test_get_environment_cloud_run_detected", "lineno": 75, "outcome": "failed", "keywords": ["test_get_environment_cloud_run_detected", "TestConfigEnvironmentDetection", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0006744999991497025, "outcome": "passed"}, "call": {"duration": 0.0020865999977104366, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "AttributeError: module 'app' has no attribute 'config_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 79, "message": "in test_get_environment_cloud_run_detected"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1442, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "in resolve_name"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:79: in test_get_environment_cloud_run_detected\n    with patch('app.config_environment.detect_cloud_run_environment') as mock_detect:\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1442: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py:528: in resolve_name\n    result = getattr(result, p)\n             ^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app' has no attribute 'config_environment'"}, "teardown": {"duration": 0.0014110999982221983, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection::test_get_environment_defaults_to_development", "lineno": 88, "outcome": "failed", "keywords": ["test_get_environment_defaults_to_development", "TestConfigEnvironmentDetection", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00035710000156541355, "outcome": "passed"}, "call": {"duration": 0.0004121000019949861, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "AttributeError: module 'app' has no attribute 'config_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 92, "message": "in test_get_environment_defaults_to_development"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1442, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "in resolve_name"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:92: in test_get_environment_defaults_to_development\n    with patch('app.config_environment.detect_cloud_run_environment') as mock_detect:\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1442: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py:528: in resolve_name\n    result = getattr(result, p)\n             ^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app' has no attribute 'config_environment'"}, "teardown": {"duration": 0.0019314000019221567, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection::test_get_environment_explicit_environment_var", "lineno": 100, "outcome": "failed", "keywords": ["test_get_environment_explicit_environment_var", "TestConfigEnvironmentDetection", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0003811000024143141, "outcome": "passed"}, "call": {"duration": 0.0004092999988642987, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "AttributeError: module 'app' has no attribute 'config_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 112, "message": "in test_get_environment_explicit_environment_var"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1442, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "in resolve_name"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:112: in test_get_environment_explicit_environment_var\n    with patch('app.config_environment.detect_cloud_run_environment') as mock_detect:\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1442: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py:528: in resolve_name\n    result = getattr(result, p)\n             ^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app' has no attribute 'config_environment'"}, "teardown": {"duration": 0.0021061999977973755, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigEnvironmentDetection::test_testing_environment_takes_precedence", "lineno": 123, "outcome": "failed", "keywords": ["test_testing_environment_takes_precedence", "TestConfigEnvironmentDetection", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0007022999998298474, "outcome": "passed"}, "call": {"duration": 0.000576900001760805, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "AttributeError: module 'app' has no attribute 'config_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 130, "message": "in test_testing_environment_takes_precedence"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1442, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "in resolve_name"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:130: in test_testing_environment_takes_precedence\n    with patch('app.config_environment.detect_cloud_run_environment') as mock_detect:\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1442: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py:528: in resolve_name\n    result = getattr(result, p)\n             ^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app' has no attribute 'config_environment'"}, "teardown": {"duration": 0.0014887999968777876, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation::test_create_config_development", "lineno": 148, "outcome": "failed", "keywords": ["test_create_config_development", "TestConfigObjectCreation", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00024189999749069102, "outcome": "passed"}, "call": {"duration": 0.00017740000112098642, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4A6C770> does not have the attribute 'get_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 152, "message": "in test_create_config_development"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1458, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "in get_original"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:152: in test_create_config_development\n    with patch.object(config_env, 'get_environment', return_value='development'):\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1458: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1431: in get_original\n    raise AttributeError(\nE   AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4A6C770> does not have the attribute 'get_environment'"}, "teardown": {"duration": 0.0002505999982531648, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation::test_create_config_production", "lineno": 160, "outcome": "failed", "keywords": ["test_create_config_production", "TestConfigObjectCreation", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00025010000172187574, "outcome": "passed"}, "call": {"duration": 0.00019949999841628596, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4AE0890> does not have the attribute 'get_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 164, "message": "in test_create_config_production"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1458, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "in get_original"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:164: in test_create_config_production\n    with patch.object(config_env, 'get_environment', return_value='production'):\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1458: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1431: in get_original\n    raise AttributeError(\nE   AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4AE0890> does not have the attribute 'get_environment'"}, "teardown": {"duration": 0.0002494000000297092, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation::test_create_config_staging", "lineno": 172, "outcome": "failed", "keywords": ["test_create_config_staging", "TestConfigObjectCreation", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00023689999943599105, "outcome": "passed"}, "call": {"duration": 0.00017099999968195334, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4AFE9C0> does not have the attribute 'get_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 176, "message": "in test_create_config_staging"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1458, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "in get_original"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:176: in test_create_config_staging\n    with patch.object(config_env, 'get_environment', return_value='staging'):\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1458: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1431: in get_original\n    raise AttributeError(\nE   AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4AFE9C0> does not have the attribute 'get_environment'"}, "teardown": {"duration": 0.00024839999969117343, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation::test_create_config_testing", "lineno": 184, "outcome": "failed", "keywords": ["test_create_config_testing", "TestConfigObjectCreation", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0002199000009568408, "outcome": "passed"}, "call": {"duration": 0.00017999999909079634, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4AFC950> does not have the attribute 'get_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 188, "message": "in test_create_config_testing"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1458, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "in get_original"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:188: in test_create_config_testing\n    with patch.object(config_env, 'get_environment', return_value='testing'):\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1458: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1431: in get_original\n    raise AttributeError(\nE   AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4AFC950> does not have the attribute 'get_environment'"}, "teardown": {"duration": 0.00024059999850578606, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigObjectCreation::test_create_config_unknown_environment_defaults", "lineno": 196, "outcome": "failed", "keywords": ["test_create_config_unknown_environment_defaults", "TestConfigObjectCreation", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0002463999990141019, "outcome": "passed"}, "call": {"duration": 0.0001843999998527579, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4AFF7A0> does not have the attribute 'get_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 200, "message": "in test_create_config_unknown_environment_defaults"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1458, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "in get_original"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:200: in test_create_config_unknown_environment_defaults\n    with patch.object(config_env, 'get_environment', return_value='unknown'):\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1458: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1431: in get_original\n    raise AttributeError(\nE   AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4AFF7A0> does not have the attribute 'get_environment'"}, "teardown": {"duration": 0.00023850000070524402, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestEnvironmentValidation::test_validate_environment_valid_environments", "lineno": 214, "outcome": "failed", "keywords": ["test_validate_environment_valid_environments", "TestEnvironmentValidation", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00023130000045057386, "outcome": "passed"}, "call": {"duration": 0.00018769999951473437, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py", "lineno": 223, "message": "AttributeError: 'EnvironmentDetector' object has no attribute 'validate_environment'. Did you mean: '_detect_environment'?"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 223, "message": "in test_validate_environment_valid_environments"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:223: in test_validate_environment_valid_environments\n    assert config_env.validate_environment(env) is True\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'EnvironmentDetector' object has no attribute 'validate_environment'. Did you mean: '_detect_environment'?"}, "teardown": {"duration": 0.0003175000019837171, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestEnvironmentValidation::test_validate_environment_invalid_environments", "lineno": 224, "outcome": "failed", "keywords": ["test_validate_environment_invalid_environments", "TestEnvironmentValidation", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0003299999989394564, "outcome": "passed"}, "call": {"duration": 0.00019160000010742806, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py", "lineno": 232, "message": "AttributeError: 'EnvironmentDetector' object has no attribute 'validate_environment'. Did you mean: '_detect_environment'?"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 232, "message": "in test_validate_environment_invalid_environments"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:232: in test_validate_environment_invalid_environments\n    assert config_env.validate_environment(env) is False\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'EnvironmentDetector' object has no attribute 'validate_environment'. Did you mean: '_detect_environment'?"}, "teardown": {"duration": 0.00022709999757353216, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestEnvironmentValidation::test_environment_config_mapping_completeness", "lineno": 233, "outcome": "failed", "keywords": ["test_environment_config_mapping_completeness", "TestEnvironmentValidation", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00024560000019846484, "outcome": "passed"}, "call": {"duration": 0.0002702000019780826, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4A8CB60> does not have the attribute 'get_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 244, "message": "in test_environment_config_mapping_completeness"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1458, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "in get_original"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:244: in test_environment_config_mapping_completeness\n    with patch.object(config_env, 'get_environment', return_value=env_name):\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1458: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1431: in get_original\n    raise AttributeError(\nE   AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4A8CB60> does not have the attribute 'get_environment'"}, "teardown": {"duration": 0.00024359999952139333, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestCloudEnvironmentDetection::test_cloud_run_detection_with_k_service", "lineno": 254, "outcome": "error", "keywords": ["test_cloud_run_detection_with_k_service", "TestCloudEnvironmentDetection", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00026699999943957664, "outcome": "failed", "longrepr": "file C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py, line 255\n      def test_cloud_run_detection_with_k_service(self, config_env, clean_environment):\nE       fixture 'clean_environment' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_faker, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, auth_service_db_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, common_test_user, config_env, cov, database_cleanup, db_session, doctest_namespace, e2e_logger, e2e_test_config, event_loop, event_loop_policy, extra, extras, faker, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_test_users, json_metadata, metadata, mock_agent_service, mock_agent_supervisor, mock_auth_redis, mock_background_task_manager, mock_clickhouse, mock_clickhouse_client, mock_clickhouse_connection, mock_database_factory, mock_database_manager, mock_key_manager, mock_llm_manager, mock_postgres_connection, mock_redis, mock_redis_client, mock_redis_manager, mock_run_data, mock_security_service, mock_thread_data, mock_tool_dispatcher, mock_transaction_context, mock_user, mock_websocket_manager, mocker, module_mocker, monkeypatch, netra_backend_db_session, no_cover, package_mocker, performance_monitor, pytestconfig, real_llm_config, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_data, session_mocker, setup_test_database, test_client, test_config, test_db_session, test_user_data, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\nC:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py:255"}, "teardown": {"duration": 0.00018009999985224567, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestCloudEnvironmentDetection::test_app_engine_detection", "lineno": 268, "outcome": "error", "keywords": ["test_app_engine_detection", "TestCloudEnvironmentDetection", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00021980000019539148, "outcome": "failed", "longrepr": "file C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py, line 269\n      def test_app_engine_detection(self, config_env, clean_environment):\nE       fixture 'clean_environment' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_faker, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, auth_service_db_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, common_test_user, config_env, cov, database_cleanup, db_session, doctest_namespace, e2e_logger, e2e_test_config, event_loop, event_loop_policy, extra, extras, faker, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_test_users, json_metadata, metadata, mock_agent_service, mock_agent_supervisor, mock_auth_redis, mock_background_task_manager, mock_clickhouse, mock_clickhouse_client, mock_clickhouse_connection, mock_database_factory, mock_database_manager, mock_key_manager, mock_llm_manager, mock_postgres_connection, mock_redis, mock_redis_client, mock_redis_manager, mock_run_data, mock_security_service, mock_thread_data, mock_tool_dispatcher, mock_transaction_context, mock_user, mock_websocket_manager, mocker, module_mocker, monkeypatch, netra_backend_db_session, no_cover, package_mocker, performance_monitor, pytestconfig, real_llm_config, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_data, session_mocker, setup_test_database, test_client, test_config, test_db_session, test_user_data, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\nC:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py:269"}, "teardown": {"duration": 0.00016529999993508682, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestCloudEnvironmentDetection::test_google_cloud_project_detection", "lineno": 282, "outcome": "error", "keywords": ["test_google_cloud_project_detection", "TestCloudEnvironmentDetection", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.000198500001715729, "outcome": "failed", "longrepr": "file C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py, line 283\n      def test_google_cloud_project_detection(self, config_env, clean_environment):\nE       fixture 'clean_environment' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_faker, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, auth_service_db_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, common_test_user, config_env, cov, database_cleanup, db_session, doctest_namespace, e2e_logger, e2e_test_config, event_loop, event_loop_policy, extra, extras, faker, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_test_users, json_metadata, metadata, mock_agent_service, mock_agent_supervisor, mock_auth_redis, mock_background_task_manager, mock_clickhouse, mock_clickhouse_client, mock_clickhouse_connection, mock_database_factory, mock_database_manager, mock_key_manager, mock_llm_manager, mock_postgres_connection, mock_redis, mock_redis_client, mock_redis_manager, mock_run_data, mock_security_service, mock_thread_data, mock_tool_dispatcher, mock_transaction_context, mock_user, mock_websocket_manager, mocker, module_mocker, monkeypatch, netra_backend_db_session, no_cover, package_mocker, performance_monitor, pytestconfig, real_llm_config, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_data, session_mocker, setup_test_database, test_client, test_config, test_db_session, test_user_data, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\nC:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py:283"}, "teardown": {"duration": 0.0001523000028100796, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigurationLogging::test_logger_initialization", "lineno": 303, "outcome": "passed", "keywords": ["test_logger_initialization", "TestConfigurationLogging", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00018479999926057644, "outcome": "passed"}, "call": {"duration": 0.00016420000247308053, "outcome": "passed"}, "teardown": {"duration": 0.0001441000022168737, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigurationLogging::test_environment_detection_logging", "lineno": 309, "outcome": "failed", "keywords": ["test_environment_detection_logging", "TestConfigurationLogging", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001770999988366384, "outcome": "passed"}, "call": {"duration": 0.0005593000023509376, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "AttributeError: module 'app' has no attribute 'config_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 313, "message": "in test_environment_detection_logging"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1442, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "in resolve_name"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:313: in test_environment_detection_logging\n    with patch('app.config_environment.detect_cloud_run_environment', return_value=None):\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1442: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py:528: in resolve_name\n    result = getattr(result, p)\n             ^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app' has no attribute 'config_environment'"}, "teardown": {"duration": 0.00022140000146464445, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestConfigurationLogging::test_config_creation_logging", "lineno": 320, "outcome": "failed", "keywords": ["test_config_creation_logging", "TestConfigurationLogging", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00022790000002714805, "outcome": "passed"}, "call": {"duration": 0.000460300001577707, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4C03EF0> does not have the attribute 'get_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 324, "message": "in test_config_creation_logging"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1458, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "in get_original"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:324: in test_config_creation_logging\n    with patch.object(config_env, 'get_environment', return_value='development'):\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1458: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1431: in get_original\n    raise AttributeError(\nE   AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4C03EF0> does not have the attribute 'get_environment'"}, "teardown": {"duration": 0.000267100000201026, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestPerformanceAndEdgeCases::test_multiple_environment_detections_consistent", "lineno": 338, "outcome": "failed", "keywords": ["test_multiple_environment_detections_consistent", "TestPerformanceAndEdgeCases", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00025010000172187574, "outcome": "passed"}, "call": {"duration": 0.000463699998363154, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "AttributeError: module 'app' has no attribute 'config_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 341, "message": "in test_multiple_environment_detections_consistent"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1442, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "in resolve_name"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:341: in test_multiple_environment_detections_consistent\n    with patch('app.config_environment.detect_cloud_run_environment', return_value='production'):\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1442: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py:528: in resolve_name\n    result = getattr(result, p)\n             ^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app' has no attribute 'config_environment'"}, "teardown": {"duration": 0.00024340000163647346, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestPerformanceAndEdgeCases::test_config_creation_performance", "lineno": 349, "outcome": "failed", "keywords": ["test_config_creation_performance", "TestPerformanceAndEdgeCases", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0002463000018906314, "outcome": "passed"}, "call": {"duration": 0.00018490000002202578, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4C023F0> does not have the attribute 'get_environment'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_environment.py", "lineno": 354, "message": "in test_config_creation_performance"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1458, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1431, "message": "in get_original"}], "longrepr": "netra_backend\\tests\\config\\test_config_environment.py:354: in test_config_creation_performance\n    with patch.object(config_env, 'get_environment', return_value='development'):\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1458: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1431: in get_original\n    raise AttributeError(\nE   AttributeError: <netra_backend.app.core.configuration.environment.EnvironmentDetector object at 0x000001FFB4C023F0> does not have the attribute 'get_environment'"}, "teardown": {"duration": 0.00026559999969322234, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_environment.py::TestPerformanceAndEdgeCases::test_environment_variable_unicode_handling", "lineno": 364, "outcome": "error", "keywords": ["test_environment_variable_unicode_handling", "TestPerformanceAndEdgeCases", "test_config_environment.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00042269999903510325, "outcome": "failed", "longrepr": "file C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py, line 365\n      def test_environment_variable_unicode_handling(self, config_env, clean_environment):\nE       fixture 'clean_environment' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_faker, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, auth_service_db_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, common_test_user, config_env, cov, database_cleanup, db_session, doctest_namespace, e2e_logger, e2e_test_config, event_loop, event_loop_policy, extra, extras, faker, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_test_users, json_metadata, metadata, mock_agent_service, mock_agent_supervisor, mock_auth_redis, mock_background_task_manager, mock_clickhouse, mock_clickhouse_client, mock_clickhouse_connection, mock_database_factory, mock_database_manager, mock_key_manager, mock_llm_manager, mock_postgres_connection, mock_redis, mock_redis_client, mock_redis_manager, mock_run_data, mock_security_service, mock_thread_data, mock_tool_dispatcher, mock_transaction_context, mock_user, mock_websocket_manager, mocker, module_mocker, monkeypatch, netra_backend_db_session, no_cover, package_mocker, performance_monitor, pytestconfig, real_llm_config, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_data, session_mocker, setup_test_database, test_client, test_config, test_db_session, test_user_data, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\nC:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_environment.py:365"}, "teardown": {"duration": 0.00019360000078449957, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_cloud_run_environment_with_k_service", "lineno": 79, "outcome": "failed", "keywords": ["test_detect_cloud_run_environment_with_k_service", "TestCloudEnvironmentDetection", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0003113999991910532, "outcome": "passed"}, "call": {"duration": 0.0004179999996267725, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 90, "message": "AssertionError: assert 'development' == 'production'\n  \n  - production\n  + development"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 90, "message": "in test_detect_cloud_run_environment_with_k_service"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:90: in test_detect_cloud_run_environment_with_k_service\n    assert result == \"production\"\nE   AssertionError: assert 'development' == 'production'\nE     \nE     - production\nE     + development"}, "teardown": {"duration": 0.0017039999984262977, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_cloud_run_environment_staging_pattern", "lineno": 91, "outcome": "passed", "keywords": ["test_detect_cloud_run_environment_staging_pattern", "TestCloudEnvironmentDetection", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00038439999843831174, "outcome": "passed"}, "call": {"duration": 0.00023119999968912452, "outcome": "passed"}, "teardown": {"duration": 0.001828700002079131, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_cloud_run_environment_not_present", "lineno": 103, "outcome": "passed", "keywords": ["test_detect_cloud_run_environment_not_present", "TestCloudEnvironmentDetection", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0005466000002343208, "outcome": "passed"}, "call": {"duration": 0.0002826999989338219, "outcome": "passed"}, "teardown": {"duration": 0.0015918999997666106, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_app_engine_environment_standard", "lineno": 111, "outcome": "failed", "keywords": ["test_detect_app_engine_environment_standard", "TestCloudEnvironmentDetection", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0003169999981764704, "outcome": "passed"}, "call": {"duration": 0.00030280000282800756, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 122, "message": "AssertionError: assert True == 'production'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 122, "message": "in test_detect_app_engine_environment_standard"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:122: in test_detect_app_engine_environment_standard\n    assert result == \"production\"\nE   AssertionError: assert True == 'production'"}, "teardown": {"duration": 0.0015604000000166707, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_app_engine_environment_flex", "lineno": 123, "outcome": "failed", "keywords": ["test_detect_app_engine_environment_flex", "TestCloudEnvironmentDetection", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00036729999919771217, "outcome": "passed"}, "call": {"duration": 0.00026989999969373457, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 134, "message": "AssertionError: assert True == 'staging'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 134, "message": "in test_detect_app_engine_environment_flex"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:134: in test_detect_app_engine_environment_flex\n    assert result == \"staging\"\nE   AssertionError: assert True == 'staging'"}, "teardown": {"duration": 0.0024239000013039913, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_kubernetes_environment", "lineno": 135, "outcome": "failed", "keywords": ["test_detect_kubernetes_environment", "TestCloudEnvironmentDetection", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0005643000004056375, "outcome": "passed"}, "call": {"duration": 0.00034270000105607323, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 144, "message": "AttributeError: 'EnvironmentDetector' object has no attribute 'detect_gke_environment'. Did you mean: '_detect_environment'?"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 144, "message": "in test_detect_kubernetes_environment"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:144: in test_detect_kubernetes_environment\n    result = detector.detect_gke_environment()\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'EnvironmentDetector' object has no attribute 'detect_gke_environment'. Did you mean: '_detect_environment'?"}, "teardown": {"duration": 0.0027086000009148847, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestCloudEnvironmentDetection::test_detect_multiple_cloud_environments_precedence", "lineno": 148, "outcome": "failed", "keywords": ["test_detect_multiple_cloud_environments_precedence", "TestCloudEnvironmentDetection", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0005564999992202502, "outcome": "passed"}, "call": {"duration": 0.000356399999873247, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 158, "message": "AttributeError: 'EnvironmentDetector' object has no attribute 'detect_environment'. Did you mean: '_detect_environment'?"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 158, "message": "in test_detect_multiple_cloud_environments_precedence"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:158: in test_detect_multiple_cloud_environments_precedence\n    result = detector.detect_environment()\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'EnvironmentDetector' object has no attribute 'detect_environment'. Did you mean: '_detect_environment'?"}, "teardown": {"duration": 0.0025127000008069444, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading::test_load_config_from_environment_success", "lineno": 180, "outcome": "failed", "keywords": ["test_load_config_from_environment_success", "TestConfigurationLoading", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00035320000097271986, "outcome": "passed"}, "call": {"duration": 0.00022840000019641593, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 201, "message": "TypeError: load_config_from_environment() takes 0 positional arguments but 1 was given"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 201, "message": "in test_load_config_from_environment_success"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:201: in test_load_config_from_environment_success\n    result = load_config_from_environment(config_mapping)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: load_config_from_environment() takes 0 positional arguments but 1 was given"}, "teardown": {"duration": 0.0014950000004319008, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading::test_load_config_from_environment_missing_variables", "lineno": 209, "outcome": "failed", "keywords": ["test_load_config_from_environment_missing_variables", "TestConfigurationLoading", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00033740000071702525, "outcome": "passed"}, "call": {"duration": 0.00017189999925903976, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 222, "message": "TypeError: load_config_from_environment() got an unexpected keyword argument 'required_vars'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 222, "message": "in test_load_config_from_environment_missing_variables"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:222: in test_load_config_from_environment_missing_variables\n    result = load_config_from_environment(\nE   TypeError: load_config_from_environment() got an unexpected keyword argument 'required_vars'"}, "teardown": {"duration": 0.0014205000006768387, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading::test_load_config_from_environment_type_conversion", "lineno": 230, "outcome": "failed", "keywords": ["test_load_config_from_environment_type_conversion", "TestConfigurationLoading", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00038530000165337697, "outcome": "passed"}, "call": {"duration": 0.00022540000281878747, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 251, "message": "TypeError: load_config_from_environment() got an unexpected keyword argument 'env_mapping'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 251, "message": "in test_load_config_from_environment_type_conversion"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:251: in test_load_config_from_environment_type_conversion\n    result = load_config_from_environment(\nE   TypeError: load_config_from_environment() got an unexpected keyword argument 'env_mapping'"}, "teardown": {"duration": 0.00149030000102357, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading::test_load_config_with_default_values", "lineno": 263, "outcome": "failed", "keywords": ["test_load_config_with_default_values", "TestConfigurationLoading", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00034810000215657055, "outcome": "passed"}, "call": {"duration": 0.0002855000020645093, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 280, "message": "TypeError: load_config_from_environment() got an unexpected keyword argument 'default_values'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 280, "message": "in test_load_config_with_default_values"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:280: in test_load_config_with_default_values\n    result = load_config_from_environment(\nE   TypeError: load_config_from_environment() got an unexpected keyword argument 'default_values'"}, "teardown": {"duration": 0.0015626999993401114, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationLoading::test_load_config_environment_override_defaults", "lineno": 288, "outcome": "failed", "keywords": ["test_load_config_environment_override_defaults", "TestConfigurationLoading", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0005590000000665896, "outcome": "passed"}, "call": {"duration": 0.00029770000037387945, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 309, "message": "TypeError: load_config_from_environment() got an unexpected keyword argument 'default_values'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 309, "message": "in test_load_config_environment_override_defaults"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:309: in test_load_config_environment_override_defaults\n    result = load_config_from_environment(\nE   TypeError: load_config_from_environment() got an unexpected keyword argument 'default_values'"}, "teardown": {"duration": 0.0015725000012025703, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation::test_validate_required_config_success", "lineno": 321, "outcome": "failed", "keywords": ["test_validate_required_config_success", "TestConfigurationValidation", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0002057999990938697, "outcome": "passed"}, "call": {"duration": 0.0001717000013741199, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 334, "message": "TypeError: validate_required_config() takes 1 positional argument but 2 were given"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 334, "message": "in test_validate_required_config_success"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:334: in test_validate_required_config_success\n    validate_required_config(config, required_keys)\nE   TypeError: validate_required_config() takes 1 positional argument but 2 were given"}, "teardown": {"duration": 0.0004152000001340639, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation::test_validate_required_config_missing_keys", "lineno": 335, "outcome": "failed", "keywords": ["test_validate_required_config_missing_keys", "TestConfigurationValidation", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00023349999901256524, "outcome": "passed"}, "call": {"duration": 0.00021399999968707561, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 347, "message": "TypeError: validate_required_config() takes 1 positional argument but 2 were given"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 347, "message": "in test_validate_required_config_missing_keys"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:347: in test_validate_required_config_missing_keys\n    validate_required_config(config, required_keys)\nE   TypeError: validate_required_config() takes 1 positional argument but 2 were given"}, "teardown": {"duration": 0.0003037999995285645, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation::test_validate_required_config_empty_values", "lineno": 352, "outcome": "failed", "keywords": ["test_validate_required_config_empty_values", "TestConfigurationValidation", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00045899999895482324, "outcome": "passed"}, "call": {"duration": 0.00024230000053648837, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 366, "message": "TypeError: validate_required_config() takes 1 positional argument but 2 were given"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 366, "message": "in test_validate_required_config_empty_values"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:366: in test_validate_required_config_empty_values\n    validate_required_config(config, required_keys)\nE   TypeError: validate_required_config() takes 1 positional argument but 2 were given"}, "teardown": {"duration": 0.0002609999974083621, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation::test_validate_config_with_custom_validators", "lineno": 369, "outcome": "failed", "keywords": ["test_validate_config_with_custom_validators", "TestConfigurationValidation", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0002454999994370155, "outcome": "passed"}, "call": {"duration": 0.0002001999964704737, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 393, "message": "TypeError: validate_required_config() takes 1 positional argument but 3 were given"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 393, "message": "in test_validate_config_with_custom_validators"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:393: in test_validate_config_with_custom_validators\n    validate_required_config(config, ['database_url', 'port', 'email'], validators)\nE   TypeError: validate_required_config() takes 1 positional argument but 3 were given"}, "teardown": {"duration": 0.00020849999782512896, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationValidation::test_validate_config_custom_validator_failure", "lineno": 394, "outcome": "failed", "keywords": ["test_validate_config_custom_validator_failure", "TestConfigurationValidation", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016910000340430997, "outcome": "passed"}, "call": {"duration": 0.00020670000230893493, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 418, "message": "TypeError: validate_required_config() takes 1 positional argument but 3 were given"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 418, "message": "in test_validate_config_custom_validator_failure"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:418: in test_validate_config_custom_validator_failure\n    validate_required_config(config, ['port', 'email'], validators)\nE   TypeError: validate_required_config() takes 1 positional argument but 3 were given"}, "teardown": {"duration": 0.00021130000095581636, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationFallbackMechanisms::test_fallback_to_default_configuration", "lineno": 431, "outcome": "failed", "keywords": ["test_fallback_to_default_configuration", "TestConfigurationFallbackMechanisms", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00029910000012023374, "outcome": "passed"}, "call": {"duration": 0.00016310000137309544, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 449, "message": "TypeError: load_config_from_environment() got an unexpected keyword argument 'fallback_config'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 449, "message": "in test_fallback_to_default_configuration"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:449: in test_fallback_to_default_configuration\n    result = load_config_from_environment(\nE   TypeError: load_config_from_environment() got an unexpected keyword argument 'fallback_config'"}, "teardown": {"duration": 0.0013847000009263866, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationFallbackMechanisms::test_fallback_configuration_hierarchy", "lineno": 457, "outcome": "failed", "keywords": ["test_fallback_configuration_hierarchy", "TestConfigurationFallbackMechanisms", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0003052000029128976, "outcome": "passed"}, "call": {"duration": 0.00017600000137463212, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 482, "message": "TypeError: load_config_from_environment() got an unexpected keyword argument 'default_values'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 482, "message": "in test_fallback_configuration_hierarchy"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:482: in test_fallback_configuration_hierarchy\n    result = load_config_from_environment(\nE   TypeError: load_config_from_environment() got an unexpected keyword argument 'default_values'"}, "teardown": {"duration": 0.0015714000001025852, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigurationFallbackMechanisms::test_graceful_degradation_partial_config_failure", "lineno": 492, "outcome": "failed", "keywords": ["test_graceful_degradation_partial_config_failure", "TestConfigurationFallbackMechanisms", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00031909999961499125, "outcome": "passed"}, "call": {"duration": 0.0001795999996829778, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 505, "message": "TypeError: load_config_from_environment() got an unexpected keyword argument 'required_vars'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 505, "message": "in test_graceful_degradation_partial_config_failure"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:505: in test_graceful_degradation_partial_config_failure\n    result = load_config_from_environment(\nE   TypeError: load_config_from_environment() got an unexpected keyword argument 'required_vars'"}, "teardown": {"duration": 0.001434900001186179, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderErrorHandling::test_config_load_error_creation", "lineno": 517, "outcome": "failed", "keywords": ["test_config_load_error_creation", "TestConfigLoaderErrorHandling", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00019890000112354755, "outcome": "passed"}, "call": {"duration": 0.00018529999942984432, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\core\\exceptions_config.py", "lineno": 13, "message": "TypeError: NetraException.__init__() got an unexpected keyword argument 'missing_keys'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 525, "message": "in test_config_load_error_creation"}, {"path": "netra_backend\\app\\core\\exceptions_config.py", "lineno": 13, "message": "in __init__"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:525: in test_config_load_error_creation\n    error = ConfigLoadError(\nnetra_backend\\app\\core\\exceptions_config.py:13: in __init__\n    super().__init__(\nE   TypeError: NetraException.__init__() got an unexpected keyword argument 'missing_keys'"}, "teardown": {"duration": 0.00021359999664127827, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderErrorHandling::test_config_loader_type_conversion_errors", "lineno": 535, "outcome": "failed", "keywords": ["test_config_loader_type_conversion_errors", "TestConfigLoaderErrorHandling", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00017189999925903976, "outcome": "passed"}, "call": {"duration": 0.00021780000315629877, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 559, "message": "TypeError: load_config_from_environment() got an unexpected keyword argument 'type_mapping'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 559, "message": "in test_config_loader_type_conversion_errors"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:559: in test_config_loader_type_conversion_errors\n    load_config_from_environment(\nE   TypeError: load_config_from_environment() got an unexpected keyword argument 'type_mapping'"}, "teardown": {"duration": 0.00020769999900949188, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderErrorHandling::test_config_loader_circular_reference_detection", "lineno": 566, "outcome": "failed", "keywords": ["test_config_loader_circular_reference_detection", "TestConfigLoaderErrorHandling", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016340000001946464, "outcome": "passed"}, "call": {"duration": 0.00016900000264286064, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 577, "message": "Failed: DID NOT RAISE <class 'netra_backend.app.core.exceptions_config.ConfigurationError'>"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 577, "message": "in test_config_loader_circular_reference_detection"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:577: in test_config_loader_circular_reference_detection\n    with pytest.raises(ConfigLoadError) as exc_info:\nE   Failed: DID NOT RAISE <class 'netra_backend.app.core.exceptions_config.ConfigurationError'>"}, "teardown": {"duration": 0.000216199998249067, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderPerformance::test_config_loading_performance_large_environment", "lineno": 584, "outcome": "failed", "keywords": ["test_config_loading_performance_large_environment", "TestConfigLoaderPerformance", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001548000000184402, "outcome": "passed"}, "call": {"duration": 0.05744550000235904, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 602, "message": "TypeError: load_config_from_environment() takes 0 positional arguments but 1 was given"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 602, "message": "in test_config_loading_performance_large_environment"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:602: in test_config_loading_performance_large_environment\n    result = load_config_from_environment(config_mapping)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: load_config_from_environment() takes 0 positional arguments but 1 was given"}, "teardown": {"duration": 0.0002235000029031653, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderPerformance::test_config_validation_performance", "lineno": 608, "outcome": "failed", "keywords": ["test_config_validation_performance", "TestConfigLoaderPerformance", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016649999815854244, "outcome": "passed"}, "call": {"duration": 0.00047479999921051785, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 619, "message": "TypeError: validate_required_config() takes 1 positional argument but 2 were given"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 619, "message": "in test_config_validation_performance"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:619: in test_config_validation_performance\n    validate_required_config(large_config, required_keys)\nE   TypeError: validate_required_config() takes 1 positional argument but 2 were given"}, "teardown": {"duration": 0.00019439999960013665, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_loader.py::TestConfigLoaderPerformance::test_cloud_environment_detection_caching", "lineno": 624, "outcome": "failed", "keywords": ["test_cloud_environment_detection_caching", "TestConfigLoaderPerformance", "test_config_loader.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00018249999993713573, "outcome": "passed"}, "call": {"duration": 0.0015558000013697892, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_loader.py", "lineno": 632, "message": "AttributeError: 'EnvironmentDetector' object has no attribute 'detect_environment'. Did you mean: '_detect_environment'?"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_loader.py", "lineno": 632, "message": "in test_cloud_environment_detection_caching"}], "longrepr": "netra_backend\\tests\\config\\test_config_loader.py:632: in test_cloud_environment_detection_caching\n    result1 = detector.detect_environment()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'EnvironmentDetector' object has no attribute 'detect_environment'. Did you mean: '_detect_environment'?"}, "teardown": {"duration": 0.0002499999973224476, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_secrets_manager_initialization", "lineno": 56, "outcome": "failed", "keywords": ["test_secrets_manager_initialization", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001644000003580004, "outcome": "passed"}, "call": {"duration": 0.0001899999988381751, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 63, "message": "AttributeError: 'SecretManager' object has no attribute '_secret_manager'. Did you mean: '_secret_cache'?"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 63, "message": "in test_secrets_manager_initialization"}], "longrepr": "netra_backend\\tests\\config\\test_config_secrets_manager.py:63: in test_secrets_manager_initialization\n    assert manager._secret_manager is not None\n           ^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'SecretManager' object has no attribute '_secret_manager'. Did you mean: '_secret_cache'?"}, "teardown": {"duration": 0.0004445000013220124, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_load_secrets_into_config_success", "lineno": 65, "outcome": "failed", "keywords": ["test_load_secrets_into_config_success", "__wrapped__", "patchings", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.000937000000703847, "outcome": "passed"}, "call": {"duration": 0.0005854999981238507, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "AttributeError: module 'app' has no attribute 'config_secrets_manager'"}, "traceback": [{"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1387, "message": "in patched"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py", "lineno": 137, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1369, "message": "in decoration_helper"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py", "lineno": 526, "message": "in enter_context"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1442, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "in resolve_name"}], "longrepr": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1387: in patched\n    with self.decoration_helper(patched,\n..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1369: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py:526: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1442: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py:528: in resolve_name\n    result = getattr(result, p)\n             ^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app' has no attribute 'config_secrets_manager'"}, "teardown": {"duration": 0.00023019999935058877, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_load_secrets_into_config_no_secrets", "lineno": 86, "outcome": "failed", "keywords": ["test_load_secrets_into_config_no_secrets", "__wrapped__", "patchings", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0008634000005258713, "outcome": "passed"}, "call": {"duration": 0.0006229999999050051, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "AttributeError: module 'app' has no attribute 'config_secrets_manager'"}, "traceback": [{"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1387, "message": "in patched"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py", "lineno": 137, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1369, "message": "in decoration_helper"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py", "lineno": 526, "message": "in enter_context"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1442, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "in resolve_name"}], "longrepr": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1387: in patched\n    with self.decoration_helper(patched,\n..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1369: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py:526: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1442: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py:528: in resolve_name\n    result = getattr(result, p)\n             ^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app' has no attribute 'config_secrets_manager'"}, "teardown": {"duration": 0.0002356000004510861, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_load_secrets_into_config_error_handling", "lineno": 100, "outcome": "failed", "keywords": ["test_load_secrets_into_config_error_handling", "__wrapped__", "patchings", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0005469999996421393, "outcome": "passed"}, "call": {"duration": 0.0004092999988642987, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "AttributeError: module 'app' has no attribute 'config_secrets_manager'"}, "traceback": [{"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1387, "message": "in patched"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py", "lineno": 137, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1369, "message": "in decoration_helper"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py", "lineno": 526, "message": "in enter_context"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1442, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "in resolve_name"}], "longrepr": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1387: in patched\n    with self.decoration_helper(patched,\n..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1369: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py:526: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1442: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py:528: in resolve_name\n    result = getattr(result, p)\n             ^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app' has no attribute 'config_secrets_manager'"}, "teardown": {"duration": 0.00027709999994840473, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_apply_secrets_to_config_with_direct_mapping", "lineno": 114, "outcome": "failed", "keywords": ["test_apply_secrets_to_config_with_direct_mapping", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0006547999983013142, "outcome": "passed"}, "call": {"duration": 0.00020819999917875975, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 122, "message": "AttributeError: 'SecretManager' object has no attribute '_apply_all_secrets'. Did you mean: '_apply_single_secret'?"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 122, "message": "in test_apply_secrets_to_config_with_direct_mapping"}], "longrepr": "netra_backend\\tests\\config\\test_config_secrets_manager.py:122: in test_apply_secrets_to_config_with_direct_mapping\n    result = secrets_manager._apply_all_secrets(mock_config, secrets, mappings)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'SecretManager' object has no attribute '_apply_all_secrets'. Did you mean: '_apply_single_secret'?"}, "teardown": {"duration": 0.0002440999996906612, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_apply_secrets_to_config_with_nested_mapping", "lineno": 126, "outcome": "failed", "keywords": ["test_apply_secrets_to_config_with_nested_mapping", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0006214000022737309, "outcome": "passed"}, "call": {"duration": 0.00027010000121663325, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 136, "message": "AttributeError: 'SecretManager' object has no attribute '_apply_all_secrets'. Did you mean: '_apply_single_secret'?"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 136, "message": "in test_apply_secrets_to_config_with_nested_mapping"}], "longrepr": "netra_backend\\tests\\config\\test_config_secrets_manager.py:136: in test_apply_secrets_to_config_with_nested_mapping\n    result = secrets_manager._apply_all_secrets(mock_config, secrets, mappings)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'SecretManager' object has no attribute '_apply_all_secrets'. Did you mean: '_apply_single_secret'?"}, "teardown": {"duration": 0.000216199998249067, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_analyze_critical_secrets_all_present", "lineno": 140, "outcome": "failed", "keywords": ["test_analyze_critical_secrets_all_present", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00022870000248076394, "outcome": "passed"}, "call": {"duration": 0.0001635999979043845, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 151, "message": "AttributeError: 'SecretManager' object has no attribute '_analyze_critical_secrets'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 151, "message": "in test_analyze_critical_secrets_all_present"}], "longrepr": "netra_backend\\tests\\config\\test_config_secrets_manager.py:151: in test_analyze_critical_secrets_all_present\n    critical, applied, missing = secrets_manager._analyze_critical_secrets(secrets)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'SecretManager' object has no attribute '_analyze_critical_secrets'"}, "teardown": {"duration": 0.00022030000036465935, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_analyze_critical_secrets_some_missing", "lineno": 157, "outcome": "failed", "keywords": ["test_analyze_critical_secrets_some_missing", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00023290000171982683, "outcome": "passed"}, "call": {"duration": 0.00015160000111791305, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 164, "message": "AttributeError: 'SecretManager' object has no attribute '_analyze_critical_secrets'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 164, "message": "in test_analyze_critical_secrets_some_missing"}], "longrepr": "netra_backend\\tests\\config\\test_config_secrets_manager.py:164: in test_analyze_critical_secrets_some_missing\n    critical, applied, missing = secrets_manager._analyze_critical_secrets(secrets)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'SecretManager' object has no attribute '_analyze_critical_secrets'"}, "teardown": {"duration": 0.000238199998420896, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_set_nested_field_success", "lineno": 173, "outcome": "failed", "keywords": ["test_set_nested_field_success", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0005806000008306, "outcome": "passed"}, "call": {"duration": 0.0002238000015495345, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 181, "message": "AttributeError: 'SecretManager' object has no attribute '_set_nested_field'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 181, "message": "in test_set_nested_field_success"}], "longrepr": "netra_backend\\tests\\config\\test_config_secrets_manager.py:181: in test_set_nested_field_success\n    secrets_manager._set_nested_field(mock_config, 'database', 'password', 'test_value')\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'SecretManager' object has no attribute '_set_nested_field'"}, "teardown": {"duration": 0.00023249999867402948, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_set_nested_field_error_handling", "lineno": 184, "outcome": "failed", "keywords": ["test_set_nested_field_error_handling", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0005299000004015397, "outcome": "passed"}, "call": {"duration": 0.00016709999908925965, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 191, "message": "AttributeError: 'SecretManager' object has no attribute '_set_nested_field'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_config_secrets_manager.py", "lineno": 191, "message": "in test_set_nested_field_error_handling"}], "longrepr": "netra_backend\\tests\\config\\test_config_secrets_manager.py:191: in test_set_nested_field_error_handling\n    secrets_manager._set_nested_field(mock_config, 'nonexistent', 'field', 'value')\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'SecretManager' object has no attribute '_set_nested_field'"}, "teardown": {"duration": 0.0003496999997878447, "outcome": "passed"}}, {"nodeid": "tests/config/test_config_secrets_manager.py::TestConfigSecretsManager::test_get_secret_mappings", "lineno": 194, "outcome": "failed", "keywords": ["test_get_secret_mappings", "__wrapped__", "patchings", "TestConfigSecretsManager", "test_config_secrets_manager.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.000380000001314329, "outcome": "passed"}, "call": {"duration": 0.0005579999997280538, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "AttributeError: module 'app' has no attribute 'config_secrets_manager'"}, "traceback": [{"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1387, "message": "in patched"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py", "lineno": 137, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1369, "message": "in decoration_helper"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py", "lineno": 526, "message": "in enter_context"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py", "lineno": 1442, "message": "in __enter__"}, {"path": "..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py", "lineno": 528, "message": "in resolve_name"}], "longrepr": "..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1387: in patched\n    with self.decoration_helper(patched,\n..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1369: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\contextlib.py:526: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\unittest\\mock.py:1442: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n..\\..\\..\\..\\miniconda3\\Lib\\pkgutil.py:528: in resolve_name\n    result = getattr(result, p)\n             ^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'app' has no attribute 'config_secrets_manager'"}, "teardown": {"duration": 0.0003378000001248438, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigurationBootstrap::test_fresh_startup_loads_config", "lineno": 24, "outcome": "failed", "keywords": ["test_fresh_startup_loads_config", "TestConfigurationBootstrap", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0002714000002015382, "outcome": "passed"}, "call": {"duration": 0.002001699998800177, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 41, "message": "AssertionError: assert 'postgresql+a...st:5432/netra' == 'postgresql:/...alhost/testdb'\n  \n  - postgresql://localhost/testdb\n  + postgresql+asyncpg://postgres:postgres@localhost:5432/netra"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 41, "message": "in test_fresh_startup_loads_config"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_e2e.py:41: in test_fresh_startup_loads_config\n    assert config.database_url == 'postgresql://localhost/testdb'\nE   AssertionError: assert 'postgresql+a...st:5432/netra' == 'postgresql:/...alhost/testdb'\nE     \nE     - postgresql://localhost/testdb\nE     + postgresql+asyncpg://postgres:postgres@localhost:5432/netra"}, "teardown": {"duration": 0.00022360000002663583, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigurationBootstrap::test_staging_environment_bootstrap", "lineno": 43, "outcome": "failed", "keywords": ["test_staging_environment_bootstrap", "TestConfigurationBootstrap", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00019840000095427968, "outcome": "passed"}, "call": {"duration": 0.00244369999927585, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 58, "message": "AssertionError: assert 'development' == 'staging'\n  \n  - staging\n  + development"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 58, "message": "in test_staging_environment_bootstrap"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_e2e.py:58: in test_staging_environment_bootstrap\n    assert config.environment == 'staging'\nE   AssertionError: assert 'development' == 'staging'\nE     \nE     - staging\nE     + development"}, "teardown": {"duration": 0.00020460000087041408, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigurationBootstrap::test_production_environment_security", "lineno": 61, "outcome": "passed", "keywords": ["test_production_environment_security", "TestConfigurationBootstrap", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001883000004454516, "outcome": "passed"}, "call": {"duration": 0.0017286000002059154, "outcome": "passed"}, "teardown": {"duration": 0.0001545999984955415, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestDatabaseE2E::test_database_connection_lifecycle", "lineno": 79, "outcome": "passed", "keywords": ["test_database_connection_lifecycle", "asyncio", "pytestmark", "TestDatabaseE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0026852000009967014, "outcome": "passed", "stderr": "2025-08-24 04:03:58.174 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n2025-08-24 04:03:58.175 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.1742814, "msecs": 174.0, "relativeCreated": 5609.927654266357, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.175583, "msecs": 175.0, "relativeCreated": 5611.229181289673, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0018825999977707397, "outcome": "passed"}, "teardown": {"duration": 0.0007344000005105045, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestDatabaseE2E::test_database_pool_behavior", "lineno": 96, "outcome": "failed", "keywords": ["test_database_pool_behavior", "asyncio", "pytestmark", "TestDatabaseE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0015060000005178154, "outcome": "passed", "stderr": "2025-08-24 04:03:58.180 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.1800673, "msecs": 180.0, "relativeCreated": 5615.713596343994, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0009461000008741394, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\db\\postgres_core.py", "lineno": 181, "message": "NameError: name 'asyncio' is not defined. Did you forget to import 'asyncio'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 115, "message": "in test_database_pool_behavior"}, {"path": "netra_backend\\app\\db\\postgres_core.py", "lineno": 181, "message": "in __init__"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_e2e.py:115: in test_database_pool_behavior\n    db = AsyncDatabase('postgresql+asyncpg://localhost/test')\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnetra_backend\\app\\db\\postgres_core.py:181: in __init__\n    self._connection_lock = asyncio.Lock()\n                            ^^^^^^^\nE   NameError: name 'asyncio' is not defined. Did you forget to import 'asyncio'"}, "teardown": {"duration": 0.0007642000018677209, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestDatabaseE2E::test_database_transaction_retry_config", "lineno": 121, "outcome": "passed", "keywords": ["test_database_transaction_retry_config", "TestDatabaseE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001832999987527728, "outcome": "passed"}, "call": {"duration": 0.00017330000264337286, "outcome": "passed"}, "teardown": {"duration": 0.0001221999991685152, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestRedisE2E::test_redis_connection_modes", "lineno": 145, "outcome": "failed", "keywords": ["test_redis_connection_modes", "asyncio", "pytestmark", "TestRedisE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0016109999996842816, "outcome": "passed", "stderr": "2025-08-24 04:03:58.198 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.1982226, "msecs": 198.0, "relativeCreated": 5633.868932723999, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0007248000001709443, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 161, "message": "AssertionError: assert 'shared' == 'local'\n  \n  - local\n  + shared"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 161, "message": "in test_redis_connection_modes"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_e2e.py:161: in test_redis_connection_modes\n    assert manager._get_redis_mode() == 'local'\nE   AssertionError: assert 'shared' == 'local'\nE     \nE     - local\nE     + shared"}, "teardown": {"duration": 0.000583999997616047, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestRedisE2E::test_redis_failover_scenario", "lineno": 172, "outcome": "failed", "keywords": ["test_redis_failover_scenario", "asyncio", "pytestmark", "TestRedisE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0011088000028394163, "outcome": "passed", "stderr": "2025-08-24 04:03:58.207 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.207573, "msecs": 207.0, "relativeCreated": 5643.219232559204, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.002391699999861885, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 205, "message": "AssertionError: assert 'shared' == 'local'\n  \n  - local\n  + shared"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 205, "message": "in test_redis_failover_scenario"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_e2e.py:205: in test_redis_failover_scenario\n    assert config_obj.redis_mode == 'local'\nE   AssertionError: assert 'shared' == 'local'\nE     \nE     - local\nE     + shared"}, "teardown": {"duration": 0.0007186000002548099, "outcome": "passed", "stderr": "2025-08-24 04:03:58.209 | INFO     | netra_backend.app.core.unified_logging:_emit_log:165 | <white>Redis connected successfully</white>\n2025-08-24 04:03:58.209 | INFO     | netra_backend.app.core.unified_logging:_emit_log:165 | <white>Successfully connected to local Redis fallback</white>\n"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestCacheE2E::test_cache_with_adaptive_ttl", "lineno": 210, "outcome": "failed", "keywords": ["test_cache_with_adaptive_ttl", "asyncio", "pytestmark", "TestCacheE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.001200899998366367, "outcome": "passed", "stderr": "2025-08-24 04:03:58.220 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.220114, "msecs": 220.0, "relativeCreated": 5655.760288238525, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0006908000032126438, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 244, "message": "assert 300 == 600"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 244, "message": "in test_cache_with_adaptive_ttl"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_e2e.py:244: in test_cache_with_adaptive_ttl\n    assert ttl == 600  # 300 * 2.0\n    ^^^^^^^^^^^^^^^^^\nE   assert 300 == 600"}, "teardown": {"duration": 0.0005653000007441733, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestCacheE2E::test_cache_disabled_scenario", "lineno": 245, "outcome": "failed", "keywords": ["test_cache_disabled_scenario", "asyncio", "pytestmark", "TestCacheE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0011152000006404705, "outcome": "passed", "stderr": "2025-08-24 04:03:58.230 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.2303557, "msecs": 230.0, "relativeCreated": 5666.002035140991, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0014523000027111266, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 276, "message": "assert True is False"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 276, "message": "in test_cache_disabled_scenario"}], "stderr": "2025-08-24 04:03:58.232 | DEBUG    | netra_backend.app.db.cache_storage:_update_metrics_and_log:120 | <dim>Cached query result with TTL 300s</dim>\n", "longrepr": "netra_backend\\tests\\config\\test_unified_config_e2e.py:276: in test_cache_disabled_scenario\n    assert result is False  # Should not cache\n    ^^^^^^^^^^^^^^^^^^^^^^\nE   assert True is False"}, "teardown": {"duration": 0.0006319000021903776, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestMultiEnvironmentE2E::test_development_to_staging_transition", "lineno": 281, "outcome": "failed", "keywords": ["test_development_to_staging_transition", "TestMultiEnvironmentE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00024979999943752773, "outcome": "passed"}, "call": {"duration": 0.004959499998221872, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 301, "message": "AssertionError: assert 'DEBUG' == 'INFO'\n  \n  - INFO\n  + DEBUG"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 301, "message": "in test_development_to_staging_transition"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_e2e.py:301: in test_development_to_staging_transition\n    assert staging_config.log_level == 'INFO'\nE   AssertionError: assert 'DEBUG' == 'INFO'\nE     \nE     - INFO\nE     + DEBUG"}, "teardown": {"duration": 0.0002879999992728699, "outcome": "passed", "stderr": "2025-08-24 04:03:58.243 | DEBUG    | netra_backend.app.core.unified_logging:_emit_log:165 | <dim>Populated database config for testing</dim>\n2025-08-24 04:03:58.243 | DEBUG    | netra_backend.app.core.unified_logging:_emit_log:165 | <dim>Populated service config for development</dim>\n"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestMultiEnvironmentE2E::test_pr_environment_detection", "lineno": 302, "outcome": "failed", "keywords": ["test_pr_environment_detection", "TestMultiEnvironmentE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016940000205067918, "outcome": "passed"}, "call": {"duration": 0.0018684999995457474, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 315, "message": "AssertionError: assert None == '123'\n +  where None = NetraTestingConfig(environment='staging', app_name='netra', google_cloud=GoogleCloudConfig(project_id='cryptic-net-466001-n0', client_id='', client_secret=''), oauth_config=OAuthConfig(client_id='', client_secret='', token_uri='https://oauth2.googleapis.com/token', auth_uri='https://accounts.google.com/o/oauth2/v2/auth', userinfo_endpoint='https://www.googleapis.com/oauth2/userinfo', scopes=['openid', 'email', 'profile', 'https://www.googleapis.com/auth/userinfo.email'], authorized_javascript_origins=['https://app.netrasystems.ai', 'https://127.0.0.1', 'http://localhost'], authorized_redirect_uris=['http://localhost:8000/api/auth/callback', 'http://localhost:8001/api/auth/callback', 'http://localhost:3000/auth/callback']), clickhouse_native=ClickHouseNativeConfig(host='localhost', port=9000, user='default', password='', database='default'), clickhouse_http=ClickHouseHTTPConfig(host='localhost', port=8123, user='default', password='', database='default'), clickhouse_https=ClickHouseHTTPSConfig(host='localhost', port=8123, user='default', password='', database='default'), clickhouse_logging=ClickHouseLoggingConfig(enabled=True, default_table='logs', default_time_period_days=7, avai...de='true', allow_degraded_mode='true', startup_max_retries=3, startup_circuit_breaker_threshold=3, startup_recovery_timeout=300, llm_configs={'default': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={}), 'analysis': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={'temperature': 0.5}), 'triage': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={}), 'data': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={}), 'optimizations_core': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={}), 'actions_to_meet_goals': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={}), 'reporting': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={})}).pr_number"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 315, "message": "in test_pr_environment_detection"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_e2e.py:315: in test_pr_environment_detection\n    assert config.pr_number == '123'\nE   AssertionError: assert None == '123'\nE    +  where None = NetraTestingConfig(environment='staging', app_name='netra', google_cloud=GoogleCloudConfig(project_id='cryptic-net-466001-n0', client_id='', client_secret=''), oauth_config=OAuthConfig(client_id='', client_secret='', token_uri='https://oauth2.googleapis.com/token', auth_uri='https://accounts.google.com/o/oauth2/v2/auth', userinfo_endpoint='https://www.googleapis.com/oauth2/userinfo', scopes=['openid', 'email', 'profile', 'https://www.googleapis.com/auth/userinfo.email'], authorized_javascript_origins=['https://app.netrasystems.ai', 'https://127.0.0.1', 'http://localhost'], authorized_redirect_uris=['http://localhost:8000/api/auth/callback', 'http://localhost:8001/api/auth/callback', 'http://localhost:3000/auth/callback']), clickhouse_native=ClickHouseNativeConfig(host='localhost', port=9000, user='default', password='', database='default'), clickhouse_http=ClickHouseHTTPConfig(host='localhost', port=8123, user='default', password='', database='default'), clickhouse_https=ClickHouseHTTPSConfig(host='localhost', port=8123, user='default', password='', database='default'), clickhouse_logging=ClickHouseLoggingConfig(enabled=True, default_table='logs', default_time_period_days=7, avai...de='true', allow_degraded_mode='true', startup_max_retries=3, startup_circuit_breaker_threshold=3, startup_recovery_timeout=300, llm_configs={'default': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={}), 'analysis': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={'temperature': 0.5}), 'triage': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={}), 'data': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={}), 'optimizations_core': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={}), 'actions_to_meet_goals': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={}), 'reporting': LLMConfig(provider=<LLMProvider.GOOGLE: 'google'>, model_name='gemini-2.5-pro', api_key='test-gemini-api-key', generation_config={})}).pr_number"}, "teardown": {"duration": 0.00020349999977042899, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigValidationE2E::test_complete_config_validation", "lineno": 322, "outcome": "passed", "keywords": ["test_complete_config_validation", "TestConfigValidationE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0002117000003636349, "outcome": "passed"}, "call": {"duration": 0.00021130000095581636, "outcome": "passed"}, "teardown": {"duration": 0.00013169999874662608, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigValidationE2E::test_validation_with_missing_secrets", "lineno": 335, "outcome": "passed", "keywords": ["test_validation_with_missing_secrets", "TestConfigValidationE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00013930000204709359, "outcome": "passed"}, "call": {"duration": 0.000951300000451738, "outcome": "passed"}, "teardown": {"duration": 0.00015829999756533653, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigValidationE2E::test_validation_with_database_issues", "lineno": 349, "outcome": "passed", "keywords": ["test_validation_with_database_issues", "TestConfigValidationE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00015199999688775279, "outcome": "passed"}, "call": {"duration": 0.0005219000013312325, "outcome": "passed"}, "teardown": {"duration": 0.00014039999950909987, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigPerformanceE2E::test_config_caching_performance", "lineno": 366, "outcome": "failed", "keywords": ["test_config_caching_performance", "TestConfigPerformanceE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00014940000255592167, "outcome": "passed"}, "call": {"duration": 0.00021320000087143853, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 382, "message": "assert 0.0 < (0.0 * 0.1)"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 382, "message": "in test_config_caching_performance"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_e2e.py:382: in test_config_caching_performance\n    assert cached_time < cold_time * 0.1  # At least 10x faster\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   assert 0.0 < (0.0 * 0.1)"}, "teardown": {"duration": 0.00021159999960218556, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigPerformanceE2E::test_hot_reload_performance", "lineno": 383, "outcome": "passed", "keywords": ["test_hot_reload_performance", "TestConfigPerformanceE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016460000188089907, "outcome": "passed"}, "call": {"duration": 0.0006571000012627337, "outcome": "passed", "stderr": "2025-08-24 04:03:58.274 | INFO     | netra_backend.app.core.unified_logging:_emit_log:165 | <white>Configuration reloaded</white>\n"}, "teardown": {"duration": 0.0001390999968862161, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigRecoveryE2E::test_recovery_from_corrupt_config", "lineno": 398, "outcome": "failed", "keywords": ["test_recovery_from_corrupt_config", "TestConfigRecoveryE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00014350000128615648, "outcome": "passed"}, "call": {"duration": 0.0015797000014572404, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\core\\configuration\\base.py", "lineno": 286, "message": "netra_backend.app.core.exceptions_config.ConfigurationError: CONFIGURATION_ERROR: CRITICAL: Configuration loading failed: 'Mock' object is not iterable"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_e2e.py", "lineno": 424, "message": "in test_recovery_from_corrupt_config"}, {"path": "netra_backend\\app\\core\\configuration\\base.py", "lineno": 177, "message": "in get_config"}, {"path": "netra_backend\\app\\core\\configuration\\base.py", "lineno": 189, "message": "in _load_complete_configuration"}, {"path": "netra_backend\\app\\core\\configuration\\base.py", "lineno": 286, "message": "in _handle_configuration_error"}], "stderr": ":03:58.276 | DEBUG    | netra_backend.app.core.unified_logging:_emit_log:165 | <dim>Populated database config for testing</dim>\n", "longrepr": "netra_backend\\app\\core\\configuration\\base.py:185: in _load_complete_configuration\n    self._populate_configuration_data(config)\nnetra_backend\\app\\core\\configuration\\base.py:220: in _populate_configuration_data\n    self._services_manager.populate_service_config(config)\nnetra_backend\\app\\core\\configuration\\services.py:120: in populate_service_config\n    self._populate_llm_config(config)\nnetra_backend\\app\\core\\configuration\\services.py:138: in _populate_llm_config\n    self._set_llm_api_keys(config, llm_api_key)\nnetra_backend\\app\\core\\configuration\\services.py:186: in _set_llm_api_keys\n    for llm_name, llm_config in config.llm_configs.items():\nE   TypeError: 'Mock' object is not iterable\n\nDuring handling of the above exception, another exception occurred:\nnetra_backend\\tests\\config\\test_unified_config_e2e.py:424: in test_recovery_from_corrupt_config\n    config = config_manager.get_config()\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnetra_backend\\app\\core\\configuration\\base.py:177: in get_config\n    self._config_cache = self._load_complete_configuration()\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnetra_backend\\app\\core\\configuration\\base.py:189: in _load_complete_configuration\n    self._handle_configuration_error(e)\nnetra_backend\\app\\core\\configuration\\base.py:286: in _handle_configuration_error\n    raise ConfigurationError(error_msg)\nE   netra_backend.app.core.exceptions_config.ConfigurationError: CONFIGURATION_ERROR: CRITICAL: Configuration loading failed: 'Mock' object is not iterable"}, "teardown": {"duration": 0.0001953999999386724, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigRecoveryE2E::test_fallback_chain_for_critical_services", "lineno": 426, "outcome": "passed", "keywords": ["test_fallback_chain_for_critical_services", "TestConfigRecoveryE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016589999722782522, "outcome": "passed"}, "call": {"duration": 0.002902899999753572, "outcome": "passed", "stderr": "2025-08-24 04:03:58.307 | DEBUG    | netra_backend.app.core.unified_logging:_emit_log:165 | <dim>Populated database config for testing</dim>\n"}, "teardown": {"duration": 0.0004259000015736092, "outcome": "passed", "stderr": "2025-08-24 04:03:58.307 | DEBUG    | netra_backend.app.core.unified_logging:_emit_log:165 | <dim>Populated service config for development</dim>\n"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigObservabilityE2E::test_config_summary_provides_insights", "lineno": 456, "outcome": "passed", "keywords": ["test_config_summary_provides_insights", "TestConfigObservabilityE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00020090000180061907, "outcome": "passed"}, "call": {"duration": 0.00017529999968246557, "outcome": "passed"}, "teardown": {"duration": 0.00013309999849298038, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_e2e.py::TestConfigObservabilityE2E::test_environment_overrides_visibility", "lineno": 474, "outcome": "passed", "keywords": ["test_environment_overrides_visibility", "TestConfigObservabilityE2E", "test_unified_config_e2e.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016569999934290536, "outcome": "passed"}, "call": {"duration": 0.001919499998621177, "outcome": "passed"}, "teardown": {"duration": 0.00014960000044084154, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration::test_database_url_retrieval_from_config", "lineno": 22, "outcome": "failed", "keywords": ["test_database_url_retrieval_from_config", "TestDatabaseManagerIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00015910000001895241, "outcome": "passed"}, "call": {"duration": 0.0005319999982020818, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 33, "message": "AssertionError: assert 'testdb' in 'postgresql://test:test@localhost:5432/netra_test'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 33, "message": "in test_database_url_retrieval_from_config"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:33: in test_database_url_retrieval_from_config\n    assert 'testdb' in url\nE   AssertionError: assert 'testdb' in 'postgresql://test:test@localhost:5432/netra_test'"}, "teardown": {"duration": 0.00017609999849810265, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration::test_sync_engine_creation_uses_config", "lineno": 34, "outcome": "passed", "keywords": ["test_sync_engine_creation_uses_config", "TestDatabaseManagerIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001584999990882352, "outcome": "passed"}, "call": {"duration": 0.000561999997444218, "outcome": "passed"}, "teardown": {"duration": 0.00013169999874662608, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration::test_async_engine_creation_uses_config", "lineno": 51, "outcome": "failed", "keywords": ["test_async_engine_creation_uses_config", "TestDatabaseManagerIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001598999988345895, "outcome": "passed"}, "call": {"duration": 0.001071599999704631, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 67, "message": "assert True is False"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 67, "message": "in test_async_engine_creation_uses_config"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:67: in test_async_engine_creation_uses_config\n    assert call_kwargs['echo'] is False  # INFO level disables echo\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   assert True is False"}, "teardown": {"duration": 0.00020349999977042899, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration::test_environment_detection_from_config", "lineno": 68, "outcome": "failed", "keywords": ["test_environment_detection_from_config", "TestDatabaseManagerIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016460000188089907, "outcome": "passed"}, "call": {"duration": 0.00048610000158078037, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 79, "message": "assert False is True"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 79, "message": "in test_environment_detection_from_config"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:79: in test_environment_detection_from_config\n    assert is_local is True\nE   assert False is True"}, "teardown": {"duration": 0.00016479999976581894, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestDatabaseManagerIntegration::test_test_mode_detection_from_config", "lineno": 80, "outcome": "failed", "keywords": ["test_test_mode_detection_from_config", "TestDatabaseManagerIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00015929999790387228, "outcome": "passed"}, "call": {"duration": 0.0004101000013179146, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 90, "message": "AssertionError: assert 'sqlite' in 'postgresql://test:test@localhost:5432/netra_test'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 90, "message": "in test_test_mode_detection_from_config"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:90: in test_test_mode_detection_from_config\n    assert 'sqlite' in url\nE   AssertionError: assert 'sqlite' in 'postgresql://test:test@localhost:5432/netra_test'"}, "teardown": {"duration": 0.00024510000002919696, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestRedisManagerIntegration::test_redis_mode_from_config", "lineno": 95, "outcome": "failed", "keywords": ["test_redis_mode_from_config", "asyncio", "pytestmark", "TestRedisManagerIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0015444000018760562, "outcome": "passed", "stderr": "2025-08-24 04:03:58.344 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.3428316, "msecs": 342.0, "relativeCreated": 5778.477907180786, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0007003999999142252, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 108, "message": "AssertionError: assert 'shared' == 'local'\n  \n  - local\n  + shared"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 108, "message": "in test_redis_mode_from_config"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:108: in test_redis_mode_from_config\n    assert manager._get_redis_mode() == 'local'\nE   AssertionError: assert 'shared' == 'local'\nE     \nE     - local\nE     + shared"}, "teardown": {"duration": 0.0005093999970995355, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestRedisManagerIntegration::test_redis_connection_uses_config", "lineno": 109, "outcome": "failed", "keywords": ["test_redis_connection_uses_config", "asyncio", "pytestmark", "TestRedisManagerIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0011942000019189436, "outcome": "passed", "stderr": "2025-08-24 04:03:58.352 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.3527153, "msecs": 352.0, "relativeCreated": 5788.361549377441, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.001079800000297837, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 133, "message": "AssertionError: assert 'localhost' == 'redis.example.com'\n  \n  - redis.example.com\n  + localhost"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 133, "message": "in test_redis_connection_uses_config"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:133: in test_redis_connection_uses_config\n    assert call_kwargs['host'] == 'redis.example.com'\nE   AssertionError: assert 'localhost' == 'redis.example.com'\nE     \nE     - redis.example.com\nE     + localhost"}, "teardown": {"duration": 0.0005856999996467493, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestRedisManagerIntegration::test_redis_fallback_on_failure", "lineno": 135, "outcome": "failed", "keywords": ["test_redis_fallback_on_failure", "asyncio", "pytestmark", "TestRedisManagerIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0013039000004937407, "outcome": "passed", "stderr": "2025-08-24 04:03:58.361 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.3619668, "msecs": 361.0, "relativeCreated": 5797.613143920898, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0016789999972388614, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 158, "message": "AssertionError: assert 'shared' == 'local'\n  \n  - local\n  + shared"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 158, "message": "in test_redis_fallback_on_failure"}], "stderr": "al fallback...</yellow>\n", "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:158: in test_redis_fallback_on_failure\n    assert config_obj.redis_mode == 'local'\nE   AssertionError: assert 'shared' == 'local'\nE     \nE     - local\nE     + shared"}, "teardown": {"duration": 0.000489699999889126, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestPostgresCoreIntegration::test_sync_database_pool_config", "lineno": 163, "outcome": "failed", "keywords": ["test_sync_database_pool_config", "TestPostgresCoreIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00015139999959501438, "outcome": "passed"}, "call": {"duration": 0.0008066999980655964, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\event\\api.py", "lineno": 34, "message": "sqlalchemy.exc.InvalidRequestError: No such event 'connect' for target '<MagicMock name='create_engine()' id='2197778546368'>'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 177, "message": "in test_sync_database_pool_config"}, {"path": "netra_backend\\app\\db\\postgres_core.py", "lineno": 85, "message": "in __init__"}, {"path": "netra_backend\\app\\db\\postgres_events.py", "lineno": 158, "message": "in setup_sync_engine_events"}, {"path": "netra_backend\\app\\db\\postgres_events.py", "lineno": 144, "message": "in _create_sync_connect_handler"}, {"path": "..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\event\\api.py", "lineno": 165, "message": "in decorate"}, {"path": "..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\event\\api.py", "lineno": 121, "message": "in listen"}, {"path": "..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\event\\api.py", "lineno": 34, "message": "in _event_key"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:177: in test_sync_database_pool_config\n    db = Database('postgresql://test')\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnetra_backend\\app\\db\\postgres_core.py:85: in __init__\n    setup_sync_engine_events(self.engine)\nnetra_backend\\app\\db\\postgres_events.py:158: in setup_sync_engine_events\n    _create_sync_connect_handler(engine)\nnetra_backend\\app\\db\\postgres_events.py:144: in _create_sync_connect_handler\n    @event.listens_for(engine, \"connect\")\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\event\\api.py:165: in decorate\n    listen(target, identifier, fn, *args, **kw)\n..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\event\\api.py:121: in listen\n    _event_key(target, identifier, fn).listen(*args, **kw)\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\event\\api.py:34: in _event_key\n    raise exc.InvalidRequestError(\nE   sqlalchemy.exc.InvalidRequestError: No such event 'connect' for target '<MagicMock name='create_engine()' id='2197778546368'>'"}, "teardown": {"duration": 0.00020950000180164352, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestPostgresCoreIntegration::test_async_database_pool_config", "lineno": 185, "outcome": "failed", "keywords": ["test_async_database_pool_config", "asyncio", "pytestmark", "TestPostgresCoreIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.001248299999133451, "outcome": "passed", "stderr": "2025-08-24 04:03:58.416 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.4168828, "msecs": 416.0, "relativeCreated": 5852.529048919678, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0007393999985652044, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\db\\postgres_core.py", "lineno": 181, "message": "NameError: name 'asyncio' is not defined. Did you forget to import 'asyncio'"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 201, "message": "in test_async_database_pool_config"}, {"path": "netra_backend\\app\\db\\postgres_core.py", "lineno": 181, "message": "in __init__"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:201: in test_async_database_pool_config\n    db = AsyncDatabase('postgresql+asyncpg://test')\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnetra_backend\\app\\db\\postgres_core.py:181: in __init__\n    self._connection_lock = asyncio.Lock()\n                            ^^^^^^^\nE   NameError: name 'asyncio' is not defined. Did you forget to import 'asyncio'"}, "teardown": {"duration": 0.0006633999983023386, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestPostgresCoreIntegration::test_pool_sizing_with_minimum_values", "lineno": 208, "outcome": "passed", "keywords": ["test_pool_sizing_with_minimum_values", "TestPostgresCoreIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00022429999808082357, "outcome": "passed"}, "call": {"duration": 0.03997670000171638, "outcome": "passed"}, "teardown": {"duration": 0.0002697000018088147, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestCacheCoreIntegration::test_cache_config_from_unified", "lineno": 232, "outcome": "failed", "keywords": ["test_cache_config_from_unified", "asyncio", "pytestmark", "TestCacheCoreIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.001853600002505118, "outcome": "passed", "stderr": "2025-08-24 04:03:58.473 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.4732823, "msecs": 473.0, "relativeCreated": 5908.928632736206, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0009570999973220751, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 254, "message": "assert 300 == 600\n +  where 300 = <netra_backend.app.db.cache_core.QueryCache._build_cache_config.<locals>.CacheConfig object at 0x000001FFB4CD8530>.default_ttl\n +    where <netra_backend.app.db.cache_core.QueryCache._build_cache_config.<locals>.CacheConfig object at 0x000001FFB4CD8530> = <netra_backend.app.db.cache_core.QueryCache object at 0x000001FFB4CD84D0>.config"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 254, "message": "in test_cache_config_from_unified"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:254: in test_cache_config_from_unified\n    assert cache.config.default_ttl == 600\nE   assert 300 == 600\nE    +  where 300 = <netra_backend.app.db.cache_core.QueryCache._build_cache_config.<locals>.CacheConfig object at 0x000001FFB4CD8530>.default_ttl\nE    +    where <netra_backend.app.db.cache_core.QueryCache._build_cache_config.<locals>.CacheConfig object at 0x000001FFB4CD8530> = <netra_backend.app.db.cache_core.QueryCache object at 0x000001FFB4CD84D0>.config"}, "teardown": {"duration": 0.000635200001852354, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestCacheCoreIntegration::test_cache_disabled_from_config", "lineno": 257, "outcome": "failed", "keywords": ["test_cache_disabled_from_config", "asyncio", "pytestmark", "TestCacheCoreIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0018541999997978564, "outcome": "passed", "stderr": "2025-08-24 04:03:58.483 | DEBUG    | logging:handle:1028 | <dim>Using proactor: IocpProactor</dim>\n", "log": [{"name": "asyncio", "msg": "Using proactor: IocpProactor", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\miniconda3\\Lib\\asyncio\\proactor_events.py", "filename": "proactor_events.py", "module": "proactor_events", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 634, "funcName": "__init__", "created": 1756033438.483613, "msecs": 483.0, "relativeCreated": 5919.259309768677, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}]}, "call": {"duration": 0.0008459000018774532, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 276, "message": "assert True is False\n +  where True = <netra_backend.app.db.cache_core.QueryCache._build_cache_config.<locals>.CacheConfig object at 0x000001FFB4CDA180>.enabled\n +    where <netra_backend.app.db.cache_core.QueryCache._build_cache_config.<locals>.CacheConfig object at 0x000001FFB4CDA180> = <netra_backend.app.db.cache_core.QueryCache object at 0x000001FFB4CDA120>.config"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 276, "message": "in test_cache_disabled_from_config"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:276: in test_cache_disabled_from_config\n    assert cache.config.enabled is False\nE   assert True is False\nE    +  where True = <netra_backend.app.db.cache_core.QueryCache._build_cache_config.<locals>.CacheConfig object at 0x000001FFB4CDA180>.enabled\nE    +    where <netra_backend.app.db.cache_core.QueryCache._build_cache_config.<locals>.CacheConfig object at 0x000001FFB4CDA180> = <netra_backend.app.db.cache_core.QueryCache object at 0x000001FFB4CDA120>.config"}, "teardown": {"duration": 0.0005477000013343059, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestStartupModuleIntegration::test_postgres_mode_detection_from_config", "lineno": 281, "outcome": "failed", "keywords": ["test_postgres_mode_detection_from_config", "TestStartupModuleIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00039140000080806203, "outcome": "passed"}, "call": {"duration": 0.941348399999697, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 284, "message": "ImportError: cannot import name '_is_postgres_mock_mode' from 'netra_backend.app.startup_module' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\startup_module.py)"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 284, "message": "in test_postgres_mode_detection_from_config"}], "stderr": "2025-08-24 04:03:58.563 | DEBUG    | netra_backend.app.services.metrics.agent_metrics:__init__:29 | <dim>Initialized AgentMetricsCollector with buffer size 5000</dim>\n2025-08-24 04:03:58.605 | INFO     | logging:handle:1028 | <white>BackgroundTaskManager initialized with 120s default timeout</white>\n2025-08-24 04:03:59.228 | DEBUG    | logging:handle:1028 | <dim>Using orjson library for writing JSON byte strings</dim>\n2025-08-24 04:03:59.276 | DEBUG    | logging:handle:1028 | <dim>Looking up time zone info from registry</dim>\n2025-08-24 04:03:59.430 | WARNING  | logging:handle:1028 | <yellow>AuthClientUnifiedShim is DEPRECATED. Use netra_backend.app.clients.auth_client_core instead</yellow>\n", "log": [{"name": "netra_backend.app.services.background_task_manager", "msg": "BackgroundTaskManager initialized with 120s default timeout", "args": null, "levelname": "INFO", "levelno": 20, "pathname": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\services\\background_task_manager.py", "filename": "background_task_manager.py", "module": "background_task_manager", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 41, "funcName": "__init__", "created": 1756033438.6053336, "msecs": 605.0, "relativeCreated": 6040.979862213135, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "clickhouse_connect.json_impl", "msg": "Using orjson library for writing JSON byte strings", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\clickhouse_connect\\json_impl.py", "filename": "json_impl.py", "module": "json_impl", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 45, "funcName": "set_json_library", "created": 1756033439.2287812, "msecs": 228.0, "relativeCreated": 6664.4275188446045, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "tzlocal", "msg": "Looking up time zone info from registry", "args": null, "levelname": "DEBUG", "levelno": 10, "pathname": "C:\\Users\\antho\\AppData\\Roaming\\Python\\Python312\\site-packages\\tzlocal\\win32.py", "filename": "win32.py", "module": "win32", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 55, "funcName": "_get_localzone_name", "created": 1756033439.27633, "msecs": 276.0, "relativeCreated": 6711.9762897491455, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}, {"name": "netra_backend.app.clients.auth_client_unified_shim", "msg": "AuthClientUnifiedShim is DEPRECATED. Use netra_backend.app.clients.auth_client_core instead", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\clients\\auth_client_unified_shim.py", "filename": "auth_client_unified_shim.py", "module": "auth_client_unified_shim", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 37, "funcName": "__init__", "created": 1756033439.430758, "msecs": 430.0, "relativeCreated": 6866.404294967651, "thread": 17632, "threadName": "MainThread", "processName": "MainProcess", "process": 37724, "taskName": null}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:284: in test_postgres_mode_detection_from_config\n    from netra_backend.app.startup_module import _is_postgres_mock_mode\nE   ImportError: cannot import name '_is_postgres_mock_mode' from 'netra_backend.app.startup_module' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\startup_module.py)"}, "teardown": {"duration": 0.00018769999951473437, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestStartupModuleIntegration::test_startup_fallback_on_config_error", "lineno": 295, "outcome": "failed", "keywords": ["test_startup_fallback_on_config_error", "TestStartupModuleIntegration", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001602000011189375, "outcome": "passed"}, "call": {"duration": 0.00016479999976581894, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 298, "message": "ImportError: cannot import name '_is_postgres_mock_mode' from 'netra_backend.app.startup_module' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\startup_module.py)"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_integration.py", "lineno": 298, "message": "in test_startup_fallback_on_config_error"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_integration.py:298: in test_startup_fallback_on_config_error\n    from netra_backend.app.startup_module import _is_postgres_mock_mode\nE   ImportError: cannot import name '_is_postgres_mock_mode' from 'netra_backend.app.startup_module' (C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\startup_module.py)"}, "teardown": {"duration": 0.00019890000112354755, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigConsistency::test_database_and_cache_config_alignment", "lineno": 310, "outcome": "passed", "keywords": ["test_database_and_cache_config_alignment", "TestConfigConsistency", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0002294000005349517, "outcome": "passed"}, "call": {"duration": 0.00016529999993508682, "outcome": "passed"}, "teardown": {"duration": 0.00019460000112303533, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigConsistency::test_service_mode_consistency", "lineno": 322, "outcome": "passed", "keywords": ["test_service_mode_consistency", "TestConfigConsistency", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00020049999875482172, "outcome": "passed"}, "call": {"duration": 0.00016039999900385737, "outcome": "passed"}, "teardown": {"duration": 0.00013140000010025688, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigConsistency::test_security_config_consistency", "lineno": 338, "outcome": "passed", "keywords": ["test_security_config_consistency", "TestConfigConsistency", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0002133999987563584, "outcome": "passed"}, "call": {"duration": 0.00014829999781795777, "outcome": "passed"}, "teardown": {"duration": 0.0001232999966305215, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigHotReload::test_hot_reload_updates_all_components", "lineno": 354, "outcome": "passed", "keywords": ["test_hot_reload_updates_all_components", "TestConfigHotReload", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00013219999891589396, "outcome": "passed"}, "call": {"duration": 0.0011485999966680538, "outcome": "passed"}, "teardown": {"duration": 0.00024169999960577115, "outcome": "passed", "stderr": "2025-08-24 04:03:59.450 | INFO     | netra_backend.app.core.unified_logging:_emit_log:165 | <white>Configuration reloaded</white>\n"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigHotReload::test_hot_reload_disabled_in_production", "lineno": 373, "outcome": "passed", "keywords": ["test_hot_reload_disabled_in_production", "TestConfigHotReload", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00015080000230227597, "outcome": "passed"}, "call": {"duration": 0.0006552999984705821, "outcome": "passed"}, "teardown": {"duration": 0.00014650000230176374, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigErrorHandling::test_database_fallback_on_config_error", "lineno": 390, "outcome": "passed", "keywords": ["test_database_fallback_on_config_error", "TestConfigErrorHandling", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00014369999917107634, "outcome": "passed"}, "call": {"duration": 0.0016634999992675148, "outcome": "passed"}, "teardown": {"duration": 0.00012830000196117908, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigErrorHandling::test_redis_graceful_degradation", "lineno": 399, "outcome": "passed", "keywords": ["test_redis_graceful_degradation", "TestConfigErrorHandling", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00013799999942420982, "outcome": "passed"}, "call": {"duration": 0.00033009999970090576, "outcome": "passed"}, "teardown": {"duration": 0.0001315000008617062, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_integration.py::TestConfigErrorHandling::test_cache_defaults_on_config_error", "lineno": 411, "outcome": "passed", "keywords": ["test_cache_defaults_on_config_error", "TestConfigErrorHandling", "test_unified_config_integration.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.000245400002313545, "outcome": "passed"}, "call": {"duration": 0.0005942000025243033, "outcome": "passed"}, "teardown": {"duration": 0.00031909999961499125, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_singleton_pattern", "lineno": 22, "outcome": "passed", "keywords": ["test_singleton_pattern", "TestUnifiedConfigManager", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.000360099998943042, "outcome": "passed"}, "call": {"duration": 0.00023359999977401458, "outcome": "passed"}, "teardown": {"duration": 0.000149200001033023, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_config_loading_caches_result", "lineno": 28, "outcome": "passed", "keywords": ["test_config_loading_caches_result", "TestUnifiedConfigManager", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00019690000044647604, "outcome": "passed"}, "call": {"duration": 0.00016940000205067918, "outcome": "passed"}, "teardown": {"duration": 0.0001298000024689827, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_environment_detection", "lineno": 35, "outcome": "failed", "keywords": ["test_environment_detection", "TestUnifiedConfigManager", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016870000035851263, "outcome": "passed"}, "call": {"duration": 0.0016503999977430794, "outcome": "failed", "crash": {"path": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\tests\\config\\test_unified_config_unit.py", "lineno": 41, "message": "AssertionError: assert 'testing' == 'staging'\n  \n  - staging\n  + testing"}, "traceback": [{"path": "netra_backend\\tests\\config\\test_unified_config_unit.py", "lineno": 41, "message": "in test_environment_detection"}], "longrepr": "netra_backend\\tests\\config\\test_unified_config_unit.py:41: in test_environment_detection\n    assert env == 'staging'\nE   AssertionError: assert 'testing' == 'staging'\nE     \nE     - staging\nE     + testing"}, "teardown": {"duration": 0.00020030000086990185, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_hot_reload_capability", "lineno": 46, "outcome": "passed", "keywords": ["test_hot_reload_capability", "TestUnifiedConfigManager", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016929999765125103, "outcome": "passed"}, "call": {"duration": 0.0004260000023350585, "outcome": "passed"}, "teardown": {"duration": 0.00013000000035390258, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_config_summary_generation", "lineno": 56, "outcome": "passed", "keywords": ["test_config_summary_generation", "TestUnifiedConfigManager", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00014899999951012433, "outcome": "passed"}, "call": {"duration": 0.0003679000001284294, "outcome": "passed"}, "teardown": {"duration": 0.00012409999908413738, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_configuration_validation", "lineno": 71, "outcome": "passed", "keywords": ["test_configuration_validation", "TestUnifiedConfigManager", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00013830000170855783, "outcome": "passed"}, "call": {"duration": 0.0003919000009773299, "outcome": "passed"}, "teardown": {"duration": 0.0001258000011148397, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_error_handling_with_fallback", "lineno": 82, "outcome": "passed", "keywords": ["test_error_handling_with_fallback", "TestUnifiedConfigManager", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00014460000238614157, "outcome": "passed"}, "call": {"duration": 0.000596500001847744, "outcome": "passed"}, "teardown": {"duration": 0.0001720000000204891, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_config_class_selection_by_environment", "lineno": 91, "outcome": "passed", "keywords": ["test_config_class_selection_by_environment", "TestUnifiedConfigManager", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00016790000154287554, "outcome": "passed"}, "call": {"duration": 0.00018560000171419233, "outcome": "passed"}, "teardown": {"duration": 0.00012140000035287812, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_environment_override_detection", "lineno": 107, "outcome": "passed", "keywords": ["test_environment_override_detection", "TestUnifiedConfigManager", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00015150000035646372, "outcome": "passed"}, "call": {"duration": 0.0017102999991038814, "outcome": "passed"}, "teardown": {"duration": 0.0004034999983559828, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestUnifiedConfigManager::test_configuration_population_order", "lineno": 118, "outcome": "passed", "keywords": ["test_configuration_population_order", "TestUnifiedConfigManager", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0002190000013797544, "outcome": "passed"}, "call": {"duration": 0.0013136999987182207, "outcome": "passed"}, "teardown": {"duration": 0.000145500001963228, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestDatabaseConfigFields::test_database_pool_settings", "lineno": 137, "outcome": "passed", "keywords": ["test_database_pool_settings", "TestDatabaseConfigFields", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001480999999330379, "outcome": "passed"}, "call": {"duration": 0.0010949000024993438, "outcome": "passed"}, "teardown": {"duration": 0.00014069999815546907, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestDatabaseConfigFields::test_database_connection_settings", "lineno": 155, "outcome": "passed", "keywords": ["test_database_connection_settings", "TestDatabaseConfigFields", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00015269999857991934, "outcome": "passed"}, "call": {"duration": 0.00014240000018617138, "outcome": "passed"}, "teardown": {"duration": 0.00012240000069141388, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestDatabaseConfigFields::test_database_advanced_settings", "lineno": 167, "outcome": "passed", "keywords": ["test_database_advanced_settings", "TestDatabaseConfigFields", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00014020000162418, "outcome": "passed"}, "call": {"duration": 0.00014430000010179356, "outcome": "passed"}, "teardown": {"duration": 0.00013099999705445953, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestCacheConfigFields::test_cache_basic_settings", "lineno": 183, "outcome": "passed", "keywords": ["test_cache_basic_settings", "TestCacheConfigFields", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00014139999984763563, "outcome": "passed"}, "call": {"duration": 0.00013799999942420982, "outcome": "passed"}, "teardown": {"duration": 0.00012879999849246815, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestCacheConfigFields::test_cache_adaptive_settings", "lineno": 198, "outcome": "passed", "keywords": ["test_cache_adaptive_settings", "TestCacheConfigFields", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001655000014579855, "outcome": "passed"}, "call": {"duration": 0.00019669999892357737, "outcome": "passed"}, "teardown": {"duration": 0.0001384999995934777, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestConfigHelperFunctions::test_get_unified_config_returns_appconfig", "lineno": 214, "outcome": "passed", "keywords": ["test_get_unified_config_returns_appconfig", "TestConfigHelperFunctions", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00015580000035697594, "outcome": "passed"}, "call": {"duration": 0.0001520000005257316, "outcome": "passed"}, "teardown": {"duration": 0.00013559999933931977, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestConfigHelperFunctions::test_reload_unified_config_delegates_to_manager", "lineno": 219, "outcome": "passed", "keywords": ["test_reload_unified_config_delegates_to_manager", "TestConfigHelperFunctions", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00014910000027157366, "outcome": "passed"}, "call": {"duration": 0.0005975999993097503, "outcome": "passed"}, "teardown": {"duration": 0.00016139999934239313, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestConfigHelperFunctions::test_validate_config_integrity_returns_tuple", "lineno": 225, "outcome": "passed", "keywords": ["test_validate_config_integrity_returns_tuple", "TestConfigHelperFunctions", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00017970000044442713, "outcome": "passed"}, "call": {"duration": 0.00020340000264695846, "outcome": "passed"}, "teardown": {"duration": 0.0001353999978164211, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestAPIKeyConfiguration::test_llm_api_key_fields", "lineno": 235, "outcome": "passed", "keywords": ["test_llm_api_key_fields", "TestAPIKeyConfiguration", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.00015110000094864517, "outcome": "passed"}, "call": {"duration": 0.0001474999990023207, "outcome": "passed"}, "teardown": {"duration": 0.00013129999933880754, "outcome": "passed"}}, {"nodeid": "tests/config/test_unified_config_unit.py::TestAPIKeyConfiguration::test_oauth_credential_fields", "lineno": 243, "outcome": "passed", "keywords": ["test_oauth_credential_fields", "TestAPIKeyConfiguration", "test_unified_config_unit.py", "config", "tests", "netra_backend", ""], "setup": {"duration": 0.0001554000009491574, "outcome": "passed"}, "call": {"duration": 0.0001373999984934926, "outcome": "passed"}, "teardown": {"duration": 0.00025599999935366213, "outcome": "passed"}}], "warnings": [{"message": "Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/", "category": "PydanticDeprecatedSince20", "when": "config", "filename": "C:\\Users\\antho\\OneDrive\\Desktop\\Netra\\netra-core-generation-1\\netra_backend\\app\\schemas\\Config.py", "lineno": 362}]}