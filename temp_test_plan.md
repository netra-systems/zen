## ğŸ“‹ TEST PLAN - Issue #937 WebSocket Agent Events Test Failures

**DEEP ROOT CAUSE IDENTIFIED:** Tests are incorrectly trying to send agent events as input messages instead of triggering workflows that generate agent events as output.

### ğŸ” KEY DISCOVERY

**CRITICAL MISUNDERSTANDING IN TEST DESIGN:**
- âŒ **Current Approach:** Tests send `agent_started`, `tool_executing`, `tool_completed` as **input messages**
- âœ… **Correct Approach:** These events are **output events** generated by the server during agent workflows
- ğŸ¯ **Root Cause:** Test design expects to send agent events and receive them back, but agent events are uni-directional outputs from agent workflows

### ğŸ”§ TECHNICAL ANALYSIS

#### Message Flow - Current vs Expected

**CURRENT (BROKEN) FLOW:**
```
Test â†’ WebSocket: {"type": "agent_started", ...}
WebSocket Server â†’ Route to message_router.route_message()
Message Router â†’ Doesn't recognize "agent_started" as valid input type
Server â†’ Responds with connection_established (default handshake response)
```

**EXPECTED (CORRECT) FLOW:**
```
Test â†’ WebSocket: {"type": "user_message", "message": "Hello"}
WebSocket Server â†’ Routes to agent system
Agent System â†’ Processes request, generates events:
  - agent_started (when agent begins)
  - agent_thinking (during reasoning)
  - tool_executing (when using tools)
  - tool_completed (after tool use)
  - agent_completed (when finished)
Server â†’ Sends these events to WebSocket client
Test â†’ Receives and validates event structures
```

#### Valid Input Message Types (Server Accepts)
- `user_message` - User chat messages
- `chat` - Chat interface messages
- `start_agent` - Agent initiation commands
- `agent_request` - Agent execution requests

#### Agent Events (Server Outputs Only)
- `agent_started` - Server sends when agent begins
- `agent_thinking` - Server sends during agent reasoning
- `tool_executing` - Server sends when agent uses tools
- `tool_completed` - Server sends after tool execution
- `agent_completed` - Server sends when agent finishes

### ğŸ¯ TEST PLAN STRATEGY

#### Phase 1: Input Message Validation Tests
**Objective:** Verify server accepts proper input message types

**New Test Cases:**
1. **test_user_message_triggers_agent_workflow**
   - Send `user_message` with agent request
   - Verify server accepts and processes message
   - Confirm no immediate errors or connection issues

2. **test_start_agent_command_acceptance**
   - Send `start_agent` command with proper parameters
   - Verify server routing works correctly
   - Check for appropriate server response

#### Phase 2: Agent Event Output Validation Tests
**Objective:** Trigger real agent workflows and validate output events

**Modified Test Cases:**
1. **test_agent_started_event_structure** (FIXED)
   - Send `user_message` that triggers agent workflow
   - **Wait for server to send `agent_started` event**
   - Validate event structure matches expected schema

2. **test_tool_executing_event_structure** (FIXED)
   - Send `user_message` requiring tool execution
   - **Wait for server to send `tool_executing` event**
   - Validate event contains required `tool_name` field

3. **test_tool_completed_event_structure** (FIXED)
   - Send `user_message` requiring tool execution
   - **Wait for server to send `tool_completed` event**
   - Validate event contains required `results` field

#### Phase 3: End-to-End Agent Workflow Tests
**Objective:** Validate complete agent conversation flow

**Enhanced Test Cases:**
1. **test_complete_agent_conversation_flow**
   - Send user message requiring complex agent interaction
   - Collect all agent events in sequence
   - Validate all 5 critical events are received:
     - agent_started â†’ agent_thinking â†’ tool_executing â†’ tool_completed â†’ agent_completed

### ğŸ› ï¸ IMPLEMENTATION APPROACH

#### Test Framework Updates Required

1. **Message Sending Pattern Change:**
```python
# OLD (BROKEN)
agent_event = {"type": "agent_started", ...}
await websocket.send_text(json.dumps(agent_event))

# NEW (CORRECT)
user_message = {"type": "user_message", "message": "Please help me with X"}
await websocket.send_text(json.dumps(user_message))
```

2. **Event Collection Pattern Change:**
```python
# OLD (BROKEN) - Expects immediate echo
sent_event = {"type": "agent_started"}
received_event = await websocket.receive_message()
# This gets connection_established, not agent_started

# NEW (CORRECT) - Waits for server-generated events
user_msg = {"type": "user_message", "message": "Hello"}
await websocket.send_text(json.dumps(user_msg))

# Collect multiple events from server
events_received = []
timeout = 30  # Allow time for agent processing
while len(events_received) < 5:  # Expect 5 agent events
    event = await asyncio.wait_for(websocket.receive_message(), timeout)
    if event.get('type') in ['agent_started', 'agent_thinking', 'tool_executing', 'tool_completed', 'agent_completed']:
        events_received.append(event)
```

3. **Event Validation Updates:**
```python
# Validate server-generated events have proper structure
for event in events_received:
    if event['type'] == 'tool_executing':
        assert 'tool_name' in event, "tool_executing missing tool_name"
    elif event['type'] == 'tool_completed':
        assert 'results' in event, "tool_completed missing results"
```

### ğŸ“Š EXPECTED OUTCOMES

#### After Test Plan Implementation:
- **7/7 TESTS PASSING:** All WebSocket agent event tests should pass
- **Proper Event Flow:** Tests will trigger real agent workflows
- **Authentic Validation:** Tests will validate actual server-generated events
- **Business Value Protection:** $500K+ ARR Golden Path functionality properly tested

#### Success Criteria:
- [ ] Server accepts user_message and start_agent input types
- [ ] Server generates all 5 critical agent events during workflows
- [ ] Event structures match expected schemas with required fields
- [ ] Complete agent conversation flows work end-to-end
- [ ] Mission critical test suite achieves 100% pass rate

### ğŸš¨ BUSINESS IMPACT

**CRITICAL DISCOVERY:** This is not a production issue - it's a **test design flaw**. The WebSocket agent event system is likely working correctly in production, but tests were incorrectly designed to send agent events as inputs instead of validating them as outputs.

**GOLDEN PATH PROTECTION:** Once tests are fixed to use proper input â†’ agent workflow â†’ event output pattern, we'll have authentic validation of the $500K+ ARR chat functionality.

### ğŸ”„ NEXT STEPS

1. **Execute Test Plan:** Implement corrected test patterns
2. **Validate Test Logic:** Ensure new tests trigger real agent workflows
3. **Run Test Suite:** Verify all WebSocket agent event tests pass
4. **Staging Validation:** Confirm agent events work properly in staging environment

---
ğŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>