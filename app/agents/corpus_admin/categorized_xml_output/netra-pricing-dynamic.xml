<?xml version="1.0" ?>
<corpus domain="netra-pricing" update_frequency="dynamic">
  <prompt_response>
    <prompt>How does Netra help reduce LLM operational costs (e.g., inference costs)?</prompt>
    <response>Netra helps reduce LLM operational costs in several ways. First, its log analysis feature audits past spending to identify specific inefficiencies, such as using overly powerful models for simple tasks or sending verbose prompts that waste tokens. Second, it models and quantifies the potential savings from techniques like semantic caching. Finally, its real-time gateway automatically executes cost-saving strategies, such as routing queries to the most price-performant model for a given task or serving cached responses for repeated queries, which directly lowers API bills.</response>
  </prompt_response>
  <prompt_response>
    <prompt>How does Netra assist in selecting the most cost-effective model for a task without sacrificing quality?</prompt>
    <response>Netra assists in selecting the most cost-effective model by using a data-driven, systematic approach. It maintains a live 'Supply Catalog' of various AI models and their performance characteristics. The platform analyzes a company's unique traffic patterns to understand the types of tasks being performed. It then evaluates different models from its catalog against these specific tasks to find the 'Pareto-optimal' optionsâ€”those that offer the most efficient trade-off between cost, latency, and quality. This allows teams to move away from using a single, expensive model for all tasks and instead route each job to the most efficient model that meets the required quality bar. </response>
  </prompt_response>
  <prompt_response>
    <prompt>How does Netra help optimize the efficiency and cost of complex multi-agent systems?</prompt>
    <response>Netra helps optimize complex multi-agent systems by providing a unified view of the entire system's operations. It can analyze traffic across a whole fleet of agents to identify cross-request optimization opportunities, such as implementing a shared prefix cache. By profiling each agent's workload and understanding the cost of every tool call and LLM interaction, Netra enables teams to enforce system-wide policies for model selection and resource usage, ensuring the entire multi-agent system operates efficiently and within budget.</response>
  </prompt_response>
</corpus>
<?xml version="1.0" ?>
<corpus domain="netra-pricing" update_frequency="dynamic">
  <prompt_response>
    <prompt>How much does the Netra AI Platform cost?</prompt>
    <response>The Netra AI Platform has several pricing tiers:n*   **Free:** $0/month for developers.n*   **Professional:** $300/month for early-stage startups.n*   **Premium:** $2,500/month plus a performance-based fee of 2.9% of managed spend.n*   **Enterprise:** Custom, volume-based pricing for mature organizations. </response>
  </prompt_response>
</corpus>
<?xml version="1.0" ?>
<corpus domain="netra-pricing" update_frequency="dynamic">
  <prompt_response>
    <prompt>Why is the Optimization Gateway necessary for performance-based pricing?</prompt>
    <response>The Optimization Gateway is necessary for performance-based pricing because it is the component that actively 'manages' the spend. The pricing model is based on a percentage of the spend that Netra is actively optimizing in real-time. The log analysis feature is passive and only provides forecasts; it doesn't manage live traffic. Therefore, only the traffic routed through the gateway is considered 'managed spend' and is subject to the performance-based fee.</response>
  </prompt_response>
</corpus>
