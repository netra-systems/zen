<?xml version="1.0" ?>
<corpus domain="netra-general" update_frequency="dynamic">
  <prompt_response>
    <prompt>Who is the target audience for Netra?</prompt>
    <response>Netra's target audience ranges from developers and early-stage startups to large, mature organizations. Specifically, it is designed for AI-native growing startups and the engineering teams within them who are building and scaling products that rely on Large Language Models (LLMs). The tiered pricing plans cater to different stages of growth: a free plan for individual developers, a professional plan for startups, a premium plan for production teams, and an enterprise plan for mature organizations with advanced security and compliance needs.</response>
  </prompt_response>
  <prompt_response>
    <prompt>What are the core components of the Netra platform?</prompt>
    <response>The Netra platform is built on two primary components that create a comprehensive optimization lifecycle:n1.  **Log Analysis (Ingest Data):** This is the initial, passive phase where Netra securely connects to a company's sanitized production logs. It analyzes this historical data to provide a deep audit of AI spend and performance, identifying and quantifying specific optimization opportunities to generate a savings forecast.n2.  **Real-time Optimization (Activate):** This is the active phase, enabled by an API gateway or middleware. Once activated, live traffic is routed through Netra's control plane, which applies the data-driven optimization strategies in real-time to realize the forecasted savings and performance gains.</response>
  </prompt_response>
  <prompt_response>
    <prompt>What are the ways in which Netra AI optimizes my AI product?</prompt>
    <response>Netra AI optimizes your AI product by providing actionable intelligence and automated controls across your entire inference stack. For third-party APIs, it pinpoints inefficiencies like costly model settings and verbose prompts, quantifies the ROI of advanced caching, and executes data-driven model selection. For self-hosted models, it helps master scheduler trade-offs, de-risks advanced strategies like speculative decoding, and surfaces fleet-wide redundancies to improve silicon efficiency. Ultimately, it systematizes the management of cost, latency, and quality to improve both unit economics and user experience.</response>
  </prompt_response>
  <prompt_response>
    <prompt>Can Netra improve the latency or response time of my AI applications?</prompt>
    <response>Yes! Netra is designed to improve the latency and response time of AI applications. It achieves this through proactive tuning for the best user experience. For example, its real-time gateway can implement semantic caching, which can serve answers to repeated queries almost instantly, dramatically reducing latency. It also helps select the optimal model for a task, which may involve choosing a faster model that still meets quality requirements. For self-hosted models, it provides deep visibility into scheduler tuning to optimize for Time-to-First-Token (TTFT).</response>
  </prompt_response>
  <prompt_response>
    <prompt>How does Netra support the building and deployment of AI agents?</prompt>
    <response>Netra supports the building and deployment of AI agents by acting as an optimization and observability co-pilot. It integrates with popular agentic frameworks like LangChain and LlamaIndex, providing the system-level visibility needed to move an agent from prototype to production. By profiling every workload and providing a clear understanding of the unit economics, Netra gives teams the confidence to scale their agentic applications without risking runaway costs or unpredictable performance. </response>
  </prompt_response>
  <prompt_response>
    <prompt>What specific tools are available for monitoring agent workflows and decision-making processes?</prompt>
    <response>Netra provides an 'Observability Plane' that serves as the primary tool for monitoring agent workflows. This feature transforms each request into a detailed 'Workload Profile,' allowing teams to trace the entire execution flow. It provides visibility into the performance and cost implications of every agentic step, tool call, and user interaction, effectively demystifying the agent's behavior and decision-making process from an operational standpoint. </response>
  </prompt_response>
  <prompt_response>
    <prompt>How do I debug a failing AI agent using Netra?</prompt>
    <response>You can use Netra to help debug a failing or inefficient AI agent by leveraging its deep observability features. By tracing the execution flow of the agent's task, you can pinpoint exactly which step is causing the failure, high latency, or excessive cost. For example, the platform can help you determine if a failure is due to a slow tool call, an inefficient prompt, context rot in a long conversation, or the selection of an inappropriate model for a sub-task.</response>
  </prompt_response>
  <prompt_response>
    <prompt>How can I monitor the performance of my AI applications in real-time?</prompt>
    <response>While the initial phase of Netra involves analyzing historical logs, the 'real' phase involves a real-time gateway that actively manages and optimizes live traffic. This component, combined with the observability plane, allows for near real-time anomaly detection and monitoring of key metrics like cost and latency, enabling you to take action on unexpected issues as they happen.</response>
  </prompt_response>
  <prompt_response>
    <prompt>What key metrics does the Netra dashboard track?</prompt>
    <response>The Netra platform tracks key metrics related to the 'cost-quality-latency-throughput' quadrilemma. This includes AI/LLM spend, latency metrics such as Time-to-First-Token (TTFT) and Time-Per-Output-Token (TPOT), and quality indicators. It also detects operational issues like context rot in conversations. The goal is to provide a comprehensive view of the unit economics and performance of AI applications.</response>
  </prompt_response>
  <prompt_response>
    <prompt>How does Netra help in tracing the execution flow of complex AI requests?</prompt>
    <response>Netra helps trace the execution flow of complex AI requests by providing deep, system-level visibility. It breaks down each request, especially those from autonomous agents, to show the cost and performance impact of every individual step, tool call, and model interaction. This allows developers to follow the chain of events and pinpoint the exact source of latency, high cost, or errors within the workflow.</response>
  </prompt_response>
  <prompt_response>
    <prompt>How does Netra help evaluate the quality and accuracy of AI responses?</prompt>
    <response>Netra's Observability Plane feeds empirical, post-execution data back into its 'Supply Catalog.' This process ensures that decisions about model selection are based not just on cost and latency, but also on the latest real-world performance and quality metrics. By making quality a key variable in its optimization equation, the platform helps teams balance cost-saving measures with the need to maintain high-quality, accurate AI responses.</response>
  </prompt_response>
  <prompt_response>
    <prompt>What features are available for regression testing of AI models?</prompt>
    <response>The provided materials do not describe any specific features for the regression testing of AI models. Netra's focus is on the operational performance, cost, and optimization of AI inference in a production or pre-production environment, rather than on the model validation and testing phase of the development lifecycle.</response>
  </prompt_response>
  <prompt_response>
    <prompt>How do I get started with the Netra AI Platform?</prompt>
    <response>Getting started with Netra involves a three-stage process. The first stage, 'Ingest Data,' involves securely connecting your ClickHouse logs to the platform. This includes creating a secure, read-only user, optionally cleaning your data to remove PII, and then granting Netra access to the sanitized log table. From there, you would proceed to MCP Integration and Activation. For commercial access, the first step is to apply for the pilot program to get a personalized savings report.</response>
  </prompt_response>
  <prompt_response>
    <prompt>How do I sign up for an account and obtain an API key?</prompt>
    <response>You can begin the sign-up process by applying for the Netra Pilot program, which provides a free, no-risk cost analysis and initial recommendations. Full API and SDK access is a feature of the paid Premium and Enterprise plans, so an API key would be provisioned after subscribing to one of those tiers.</response>
  </prompt_response>
</corpus>
<?xml version="1.0" ?>
<corpus domain="netra-general" update_frequency="dynamic">
  <prompt_response>
    <prompt>How difficult is it to integrate Netra into an existing AI application?</prompt>
    <response>It's never been easier! The initial integration for log analysis is designed to be straightforward and fast, typically taking minutes. It involves a simple, secure ClickHouse-to-ClickHouse connection without requiring complex agents or tools. Activating the real-time optimization gateway would involve an additional configuration change in your application to route API calls through the Netra endpoint for proactive monitoring and optimization.</response>
  </prompt_response>
  <prompt_response>
    <prompt>How do I configure the platform to start monitoring my application?</prompt>
    <response>To start monitoring, you begin with the 'Ingest Data' phase. This involves creating a secure, read-only user in your ClickHouse database, creating a sanitized table of your logs with custom PII redaction options, and then granting the Netra user access to that table. This establishes a secure and continuous pipeline of your LLM logs for analysis in the Netra platform. </response>
  </prompt_response>
  <prompt_response>
    <prompt>What features are included in the Free plan?</prompt>
    <response>The Free plan is designed for developers and is free forever. It includes:n*   Basic Log Analysisn*   Limited Analysis Depthn*   Support for 1 Usern*   Community Support.</response>
  </prompt_response>
  <prompt_response>
    <prompt>What features are included in the Professional plan?</prompt>
    <response>The Professional plan costs $300/month and is targeted at early-stage startups. It includes all features from the Free plan, plus:n*   Deeper Analysisn*   Support for up to 5 Usersn*   Email &amp; Chat Support.</response>
  </prompt_response>
  <prompt_response>
    <prompt>What features are included in the Premium plan?</prompt>
    <response>The Premium plan is the most popular offering for production teams. It costs $2,500/month plus a performance-based fee. It includes all features from the Professional plan, plus:n*   The highest limits and deepest analysisn*   Access to the latest optimizations and market supply datan*   Basic Forecasting &amp; Alertsn*   Full API &amp; SDK Accessn*   Support for unlimited users.</response>
  </prompt_response>
  <prompt_response>
    <prompt>What features are included in the Enterprise plan?</prompt>
    <response>The Enterprise plan has custom pricing and is for mature organizations. It includes all Premium features, plus:n*   Advanced Forecasting &amp; FinOps Toolsn*   SAML/SSO Integration &amp; Granular RBACn*   Auditable Cost Attributionn*   Support for SOC 2 and HIPAA compliancen*   A dedicated Account Managern*   A 1-hour critical issue response time SLA.</response>
  </prompt_response>
  <prompt_response>
    <prompt>When should an organization consider upgrading to an Enterprise plan?</prompt>
    <response>An organization should consider upgrading to the Enterprise plan when its needs extend beyond core optimization and require robust security, financial control, compliance, and premium support. Key triggers for upgrading include:nn*   **Security &amp; Identity Management:** The need for SAML/SSO integration for user authentication.n*   **Granular Access Control:** The requirement for Role-Based Access Control (RBAC) to manage permissions across a large team.n*   **Compliance:** The need for support for regulations like SOC 2 or HIPAA.n*   **Financial Operations (FinOps):** The need for advanced forecasting, budgeting tools, and auditable cost attribution for financial planning and accountability.n*   **Premium Support:** The requirement for a dedicated account manager and a guaranteed 1-hour Service Level Agreement (SLA) for critical issues.</response>
  </prompt_response>
</corpus>
<?xml version="1.0" ?>
<corpus domain="netra-general" update_frequency="dynamic">
  <prompt_response>
    <prompt>How does Netra improve developer productivity and the overall AI development lifecycle?</prompt>
    <response>Netra improves developer productivity by acting as an expert co-pilot for AI operations, automating and simplifying the complex task of inference optimization. It replaces guesswork and manual, time-consuming tuning with a data-driven, systematic approach. This frees developers from the 'complexity trap' of managing countless technical trade-offs and allows them to focus on building and iterating on core product features.nnIn the AI development lifecycle, Netra provides a crucial feedback loop between deployment and development. By offering deep observability into how AI applications perform in production, it provides actionable intelligence that informs future development, leading to more efficient, scalable, and cost-effective AI products from the outset.</response>
  </prompt_response>
  <prompt_response>
    <prompt>What kind of insights can I gain just by connecting my logs?</prompt>
    <response>By connecting your logs for analysis, you can gain a comprehensive assessment of your LLM spending and performance without any risk or code changes. Key insights include:nn*   **A Detailed Cost Breakdown:** Understand exactly where your LLM spend is going.n*   **A Personalized Savings Forecast:** See a data-driven estimate of potential cost reductions.n*   **Specific Optimization Opportunities:** Discover actionable recommendations, such as identifying verbose prompts, opportunities for API batching, or tasks where a cheaper model could be used.n*   **ROI Quantification for Advanced Techniques:** Get a clear picture of the potential savings from implementing strategies like semantic caching, tailored to your specific query patterns.</response>
  </prompt_response>
  <prompt_response>
    <prompt>How does the Gateway optimize my AI requests in real-time?</prompt>
    <response>The Optimization Gateway optimizes your AI requests in real-time by acting as an intelligent intermediary. When your application sends an API call through the gateway, it intercepts the request and applies a series of optimizations based on the strategies developed during the log analysis phase. These can include checking a semantic cache for a matching query to provide an instant response, routing the request to the most cost-effective model for that specific task, or compressing the prompt to reduce token count. Once optimized, the request is forwarded to the appropriate LLM provider.</response>
  </prompt_response>
  <prompt_response>
    <prompt>Will routing traffic through the Gateway add latency to my requests?</prompt>
    <response>While any proxy can introduce a marginal amount of network latency, the Netra Optimization Gateway is designed to reduce overall end-to-end latency. Optimizations like semantic caching can dramatically decrease response times by serving answers instantly without calling an LLM at all. The goal of the platform is to proactively tune for the best user experience, which includes improving, not degrading, latency.</response>
  </prompt_response>
</corpus>
<?xml version="1.0" ?>
<corpus domain="netra-general" update_frequency="dynamic">
  <prompt_response>
    <prompt>How does the dashboard transition from showing 'Estimated Savings' (Forecast) to 'Realized Savings' (Actual) once the Gateway is active?</prompt>
    <response>The dashboard transitions from showing 'Estimated Savings' to 'Realized Savings' as soon as you activate the Optimization Gateway and begin routing live traffic through it. The 'Estimated Savings' figure is a forecast based on the analysis of your historical logs. Once the gateway is live, it actively applies optimizations and measures their real-world impact. The dashboard then updates to display 'Realized Savings,' which reflects the actual, measured cost reductions and performance gains resulting directly from the gateway's real-time operations.</response>
  </prompt_response>
  <prompt_response>
    <prompt>How does Netra ensure that analytics and recommendations translate into actual, realized savings?</prompt>
    <response>Netra ensures that analytics translate into realized savings through its two-phase architecture. The initial log analysis provides the data-driven recommendations and a savings forecast. However, the key is the second phase: the Optimization Gateway. By routing live traffic through this gateway, the platform moves from recommendation to execution. The gateway actively applies the recommended optimizations (like intelligent routing and caching) in real-time, which directly reduces costs and improves performance. The dashboard then tracks these 'Realized Savings,' closing the loop between analysis and tangible results.</response>
  </prompt_response>
</corpus>
