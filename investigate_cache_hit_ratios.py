#!/usr/bin/env python3
"""
Issue #1328 Phase 2 Analysis: Investigate Cache Hit Ratio Reports
================================================================

This script investigates the cache hit ratio calculations in the system
to identify which specific status report is showing "unexpectedly high" values.

Tasks:
1. Check actual cache hit/miss patterns in Redis
2. Calculate hit ratios from different cache sources
3. Identify if high percentages are expected behavior
4. Find specific status reports showing high cache percentages
"""

import asyncio
import sys
import json
from datetime import datetime
from typing import Dict, Any, Optional

# Add paths for imports
sys.path.append('/c/netra-apex')
sys.path.append('/c/netra-apex/analytics_service')
sys.path.append('/c/netra-apex/netra_backend')

async def analyze_redis_cache_stats():
    """Analyze Redis cache hit/miss statistics."""
    print("=== Redis Cache Statistics Analysis ===")

    try:
        # Import Redis cache service
        from analytics_service.analytics_core.services.redis_cache_service import RedisCacheService

        cache_service = RedisCacheService()
        stats = await cache_service.get_cache_stats()

        print(f"üìä Cache Statistics Retrieved: {json.dumps(stats, indent=2)}")

        # Calculate hit ratio if we have hits and misses
        hits = stats.get('redis_keyspace_hits', 0)
        misses = stats.get('redis_keyspace_misses', 0)

        if hits is not None and misses is not None:
            total_requests = hits + misses
            if total_requests > 0:
                hit_ratio = (hits / total_requests) * 100
                print(f"üéØ CACHE HIT RATIO: {hit_ratio:.2f}%")
                print(f"   - Hits: {hits:,}")
                print(f"   - Misses: {misses:,}")
                print(f"   - Total Requests: {total_requests:,}")

                if hit_ratio > 95:
                    print(f"‚ö†Ô∏è  HIGH HIT RATIO DETECTED: {hit_ratio:.2f}% (>95%)")
                    print("   This could be the 'unexpectedly high' value mentioned in Issue #1328")

                    # Analyze if this is expected
                    print("\nüîç Analysis of High Hit Ratio:")
                    if total_requests < 100:
                        print("   - Low total requests: High hit ratio might be due to limited testing")
                    elif stats.get('user_session_keys', 0) > 0:
                        print("   - Active user sessions: High hit ratio expected for session caching")
                    elif stats.get('hot_prompts_keys', 0) > 0:
                        print("   - Hot prompts cached: High hit ratio expected for repeated prompts")

            else:
                print("‚ùå No cache requests recorded")
        else:
            print("‚ùå Hit/miss statistics not available")

        return stats

    except ImportError as e:
        print(f"‚ùå Cannot import Redis cache service: {e}")
        return None
    except Exception as e:
        print(f"‚ùå Error getting cache stats: {e}")
        return None

async def check_health_endpoint_cache_stats():
    """Check if health endpoints report cache statistics."""
    print("\n=== Health Endpoint Cache Statistics ===")

    try:
        # Import health monitoring
        from netra_backend.app.core.health_checks import get_health_monitor

        health_monitor = get_health_monitor()
        health_status = await health_monitor.get_health_status()

        print(f"üìä Health Status Retrieved: {json.dumps(health_status, indent=2)}")

        # Look for cache-related information in health checks
        cache_info = {}
        for check_name, check_data in health_status.get('checks', {}).items():
            if 'cache' in check_name.lower() or 'cache' in str(check_data.get('details', {})).lower():
                cache_info[check_name] = check_data

        if cache_info:
            print(f"üéØ CACHE INFO IN HEALTH CHECKS: {json.dumps(cache_info, indent=2)}")
        else:
            print("‚ÑπÔ∏è  No cache information found in health checks")

        return health_status

    except ImportError as e:
        print(f"‚ùå Cannot import health monitoring: {e}")
        return None
    except Exception as e:
        print(f"‚ùå Error getting health status: {e}")
        return None

def analyze_cache_calculations():
    """Analyze the cache percentage calculations from Phase 1."""
    print("\n=== Cache Calculation Analysis from Phase 1 ===")

    # From Phase 1, we found these calculations:
    calculations = [
        {
            "source": "analytics_service/analytics_core/services/redis_cache_service.py:338-339",
            "calculation": "keyspace_hits and keyspace_misses from Redis INFO",
            "type": "Redis native statistics"
        },
        {
            "source": "netra_backend/app/cache/business_cache_strategies.py:117-140",
            "calculation": "cache_hit_count / (cache_hit_count + cache_miss_count) * 100",
            "type": "Application-level cache tracking"
        },
        {
            "source": "auth_service/auth_core/core/jwt_handler.py:451-470",
            "calculation": "cache_entries / total_operations * 100",
            "type": "JWT token cache efficiency"
        },
        {
            "source": "netra_backend/app/db/cache_core.py:89-115",
            "calculation": "successful_gets / total_gets * 100",
            "type": "Database query cache"
        },
        {
            "source": "netra_backend/app/core/performance_optimization_manager.py:267-285",
            "calculation": "optimized_calls / total_calls * 100",
            "type": "Performance optimization cache"
        }
    ]

    print("üìä Cache Percentage Calculation Sources Found:")
    for i, calc in enumerate(calculations, 1):
        print(f"\n{i}. {calc['type']}")
        print(f"   Source: {calc['source']}")
        print(f"   Method: {calc['calculation']}")

    print("\nüéØ HIGH PERCENTAGE SCENARIOS:")
    print("1. Redis keyspace_hits/(keyspace_hits + keyspace_misses) = 99%+")
    print("   - Common in warm cache scenarios or limited key diversity")
    print("2. JWT token cache = 99%+")
    print("   - Expected behavior: tokens cached after first validation")
    print("3. Database query cache = 99%+")
    print("   - Can occur with repetitive queries in development/testing")
    print("4. Performance optimization cache = 99%+")
    print("   - Expected: optimizations cached after first computation")

async def search_for_status_reports():
    """Search for status report components that might display cache stats."""
    print("\n=== Searching for Status Report Displays ===")

    # Check common status report locations
    status_report_locations = [
        "/api/health",
        "/api/status",
        "/health",
        "/status",
        "health endpoint",
        "monitoring dashboard",
        "admin panel",
        "system status"
    ]

    print("üîç Checking common status report endpoints:")
    for location in status_report_locations:
        print(f"   - {location}")

    print("\nüìä Likely Cache Display Locations:")
    print("1. Redis cache service get_cache_stats() method")
    print("2. Health monitoring system")
    print("3. Performance monitoring dashboards")
    print("4. Admin status pages")
    print("5. Development/debugging endpoints")

def simulate_cache_patterns():
    """Simulate different cache usage patterns to understand high percentages."""
    print("\n=== Cache Pattern Simulation ===")

    scenarios = [
        {
            "name": "Warm Cache Scenario",
            "hits": 9900,
            "misses": 100,
            "ratio": 99.0,
            "explanation": "Cache warmed up, mostly hits on existing data"
        },
        {
            "name": "Development Testing",
            "hits": 95,
            "misses": 5,
            "ratio": 95.0,
            "explanation": "Limited test data, repetitive operations"
        },
        {
            "name": "Production Steady State",
            "hits": 8500,
            "misses": 1500,
            "ratio": 85.0,
            "explanation": "Healthy production cache with new data"
        },
        {
            "name": "Cache Initialization",
            "hits": 999,
            "misses": 1,
            "ratio": 99.9,
            "explanation": "Almost all operations hit initialized cache"
        }
    ]

    print("üìä Cache Pattern Analysis:")
    for scenario in scenarios:
        ratio = (scenario['hits'] / (scenario['hits'] + scenario['misses'])) * 100
        print(f"\n{scenario['name']}:")
        print(f"   Hits: {scenario['hits']:,} | Misses: {scenario['misses']:,}")
        print(f"   Ratio: {ratio:.1f}%")
        print(f"   Context: {scenario['explanation']}")

        if ratio >= 99:
            print(f"   üî• THIS COULD BE THE 'UNEXPECTEDLY HIGH' VALUE")

async def main():
    """Execute Phase 2 analysis."""
    print("Issue #1328 Phase 2: Cache Hit Ratio Investigation")
    print("=" * 60)
    print(f"Timestamp: {datetime.now()}")
    print()

    # Run all analysis tasks
    redis_stats = await analyze_redis_cache_stats()
    health_stats = await check_health_endpoint_cache_stats()
    analyze_cache_calculations()
    await search_for_status_reports()
    simulate_cache_patterns()

    # Summary and recommendations
    print("\n" + "=" * 60)
    print("üìã PHASE 2 SUMMARY & RECOMMENDATIONS")
    print("=" * 60)

    print("\nüéØ KEY FINDINGS:")
    print("1. Multiple cache sources can legitimately show 99%+ hit ratios")
    print("2. High percentages are often EXPECTED behavior, not errors")
    print("3. Context matters: development vs production environments")
    print("4. Redis keyspace_hits/misses is the most likely culprit")

    print("\nüîç NEXT STEPS:")
    print("1. Identify WHICH specific status report triggered the concern")
    print("2. Check if 'unexpectedly high' is based on business expectations")
    print("3. Consider if monitoring thresholds need adjustment")
    print("4. Document expected cache behavior for different environments")

    print("\n‚úÖ BUSINESS CONTEXT:")
    print("- High cache hit ratios are generally GOOD for performance")
    print("- 99%+ ratios can indicate efficient caching or limited test data")
    print("- Issue may be monitoring expectation vs actual system behavior")

    print(f"\nüèÅ Phase 2 Complete: {datetime.now()}")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Analysis interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Analysis failed: {e}")
        import traceback
        traceback.print_exc()