[pytest]
markers =
    performance: Performance and SLA validation tests
    slow: Slow tests that may take longer to complete  
    unit: Unit tests for isolated components
    integration: Integration tests for component interaction
    smoke: Quick smoke tests for basic functionality
    critical: Critical path tests that protect revenue
    real_services: Tests requiring real external services
    mock_only: Tests using only mocks
    agents: Agent-specific tests
    real_e2e: End-to-end tests with real services
    real_llm: Tests that use real LLM services
    e2e: End-to-end tests
    websocket: WebSocket-related tests
    database: Database-related tests
    auth: Authentication-related tests
    oauth: OAuth flow tests
    security: Security validation tests  
    api: API endpoint tests
    frontend: Frontend component tests
    rate_limiting: Rate limiting and DDoS protection tests
    stress: Stress tests with high load or concurrency
    spike_testing: Spike testing and recovery validation tests
    benchmark: Performance benchmark tests
    isolation: Isolation and multi-tenancy tests
    cpu_isolation: CPU isolation tests
    filesystem_isolation: File system isolation tests
    memory_isolation: Memory isolation tests
    multi_tenant_isolation: Multi-tenant isolation tests
    network_isolation: Network isolation tests
    resource_isolation: Resource isolation tests
    soak: Long-duration soak testing for stability validation
    resilience: Resilience and recovery validation tests
    redis: Redis-dependent tests requiring real Redis connection
    staging: Staging environment specific tests
    dev: Development environment specific tests
    comprehensive: Comprehensive system-wide integration tests
    coverage_validation: Code coverage validation tests
    real_data: Tests requiring real data generation and processing
    real_database: Tests requiring real database connections
    real_quality: Tests requiring real quality validation services
    flaky: Tests that may fail intermittently
    bad_test: Tests marked as consistently failing

testpaths = 
    tests
    netra_backend/tests
    integration_tests

python_files = test_*.py
python_classes = Test*
python_functions = test_*

addopts = 
    -ra
    --strict-markers
    --disable-warnings
    --tb=short
    --asyncio-mode=auto
    -p test_framework.pytest_bad_test_plugin

asyncio_default_fixture_loop_scope = function

filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning