[pytest]
# Pytest configuration for Netra Core
testpaths = tests netra_backend/tests auth_service/tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*
addopts = -ra --strict-markers --strict-config --timeout=120 --tb=short
minversion = 6.0
asyncio_mode = auto
asyncio_default_fixture_loop_scope = session
markers =
    # Environment markers
    env: Environment-specific tests
    env_test: Tests for test environment compatibility
    test: Tests for test environment only
    dev: Tests for dev environment only  
    staging: Tests for staging environment only
    prod: Tests for production environment only
    
    # Test type markers
    unit: Unit tests
    integration: Integration tests
    e2e: End-to-end tests
    health: Health check tests
    environment: Environment-specific tests
    
    # Service markers
    backend: Backend service tests
    auth: Auth service tests  
    frontend: Frontend tests
    
    # Feature markers
    agents: Agent-related tests
    agent_orchestration: Agent orchestration and workflow tests
    circuit_breaker: Circuit breaker pattern tests
    websocket: WebSocket tests
    database: Database tests
    api: API tests
    chat: Chat interface and messaging tests
    
    # Performance markers
    slow: Slow running tests
    fast: Fast running tests
    fast_test: Quick tests for fast feedback
    stress: Stress tests with high resource usage
    sla: SLA compliance and validation tests
    rate_limiting: Rate limiting tests
    
    # Resource isolation markers
    resource_isolation: General resource isolation tests
    cpu_isolation: CPU isolation tests
    memory_isolation: Memory isolation tests
    network_isolation: Network isolation tests
    file_system_isolation: File system isolation tests
    filesystem_isolation: File system isolation tests (alias)
    multi_tenant_isolation: Multi-tenant isolation tests
    
    # Service dependency markers
    requires_redis: Tests requiring Redis
    requires_postgres: Tests requiring PostgreSQL
    requires_llm: Tests requiring LLM services
    requires_real_services: Tests requiring real running services
    real_llm: Tests using real LLM API calls
    real_services: Tests using real external services
    real_database: Tests requiring real database connections (enables ClickHouse)
    
    # Business logic markers
    billing: Billing-related tests
    auth_flow: Authentication flow tests
    user_management: User management tests
    admin: Admin functionality tests
    oauth: OAuth flow tests
    first_time_user: First-time user experience tests
    
    # Infrastructure markers
    deployment: Deployment tests
    post_deployment: Post-deployment validation tests
    monitoring: Monitoring tests
    security: Security tests
    resilience: System resilience and recovery tests
    logging_metrics: Logging and metrics pipeline tests
    observability: Observability and monitoring tests
    error_handling: Error handling and edge case tests
    
    # Skip markers
    skip_ci: Skip in CI environment
    skip_local: Skip in local environment
    manual: Manual tests only
    
    # Priority markers
    critical: Critical system tests
    mission_critical: Mission critical tests that CANNOT fail
    singleton_removal: Tests validating singleton pattern removal for concurrent user support
    smoke: Basic smoke tests
    startup: System startup tests
    recovery: Recovery tests
    error_recovery: Error recovery tests
    performance: Performance tests
    comprehensive: Comprehensive test coverage
    production: Production environment tests
    coverage_validation: Coverage validation tests
    
    # Additional E2E markers
    real_e2e: Real E2E tests using actual services
    skip_if_no_real_llm: Skip if real LLM is not available
    redis: Redis-specific tests
    soak: Long-running soak tests
    backup_recovery: Backup and recovery tests
    disaster_recovery: Disaster recovery tests