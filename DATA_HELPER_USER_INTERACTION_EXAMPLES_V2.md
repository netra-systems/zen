# Data Helper Agent - User Interaction Examples V2
## With Step-by-Step Data Collection Instructions

---

## Example 1: AWS Cloud Cost Optimization - Complete Instructions âœ…
**User Request**: "Help me optimize my AWS cloud costs"

### Data Helper Request with Detailed Instructions:

```
To optimize your AWS cloud costs, I need specific metrics. Here's exactly how to get them:

ðŸ“Š **STEP 1: Get Your AWS Cost Breakdown**
1. Log into AWS Console â†’ https://console.aws.amazon.com
2. Search for "Cost Explorer" in the top search bar
3. Click "Cost Explorer" â†’ "Cost and Usage"
4. Set date range to "Last 3 months"
5. Group by â†’ "Service"
6. Click "Apply"
7. Take a screenshot of the graph
8. Below the graph, click "Download CSV"
9. Copy and paste the top 10 services from the CSV here

ðŸ“ˆ **STEP 2: Get EC2 Instance Utilization**
1. Go to CloudWatch â†’ https://console.aws.amazon.com/cloudwatch
2. Click "Dashboards" â†’ "Automatic dashboards" â†’ "EC2"
3. For each instance type you use heavily:
   - Click on the instance
   - Go to "Monitoring" tab
   - Take screenshot of CPU Utilization graph
   - Click "View in CloudWatch"
   - Change statistic to "Average"
   - Copy these values:
     * Average CPU: ____%
     * Average Network In: ____ bytes
     * Average Network Out: ____ bytes

ðŸ”§ **STEP 3: Check Reserved Instance Coverage**
1. Go to AWS Console â†’ "Cost Explorer"
2. Left sidebar â†’ Click "Reservation Utilization"
3. Copy this value: "RI Coverage: ____%"
4. Click "Reservation Recommendations"
5. Screenshot the top 3 recommendations

ðŸ’¾ **STEP 4: Storage Analysis**
Run these commands in CloudShell (click CloudShell icon in top bar):

```bash
# List all EBS volumes with size
aws ec2 describe-volumes --query 'Volumes[*].[VolumeId,Size,VolumeType,State]' --output table

# Copy and paste the entire output here
```

```bash
# Get S3 bucket sizes
for bucket in $(aws s3api list-buckets --query 'Buckets[*].Name' --output text); do
  size=$(aws s3api list-object-versions --bucket "$bucket" --query 'Versions[*].Size' --output json 2>/dev/null | jq 'add // 0')
  echo "$bucket: $((size/1024/1024/1024)) GB"
done

# Copy and paste the entire output here
```

ðŸ“Š **STEP 5: Get Traffic Patterns**
1. Go to CloudWatch â†’ Dashboards
2. Click "Create Dashboard" â†’ Name it "TempMetrics"
3. Add widget â†’ Line â†’ EC2 â†’ "By Auto Scaling Group"
4. Select "CPUUtilization"
5. Set time range to "Last 2 weeks"
6. Take screenshot showing daily patterns
7. Note your peak hours: ____

âœ… **WHAT TO PASTE BACK:**
```
=== COST BREAKDOWN (from Step 1) ===
[Paste CSV data here]

=== EC2 UTILIZATION (from Step 2) ===
Instance Type: _____
Average CPU: ____%
Network In: _____
Network Out: _____

=== RI COVERAGE (from Step 3) ===
Current Coverage: ____%

=== STORAGE (from Step 4) ===
[Paste EBS volumes table]
[Paste S3 bucket sizes]

=== TRAFFIC PATTERNS (from Step 5) ===
Peak Hours: _____
Off-Peak Hours: _____
Weekend pattern: _____
```
```

---

## Example 2: Database Performance Optimization - No DBA Access ðŸ”
**User Request**: "Our application database is slow, need optimization recommendations"

### Data Helper Request with Alternative Access Methods:

```
Since you mentioned no DBA access, here's how to get data without admin privileges:

ðŸ” **OPTION A: If you have READ-ONLY database access:**

1. Connect to your database using your preferred client
2. Run these queries (adjust for your database type):

For **PostgreSQL**:
```sql
-- Current connections
SELECT count(*) FROM pg_stat_activity;
-- Copy result: _____

-- Slow queries (if pg_stat_statements is enabled)
SELECT query, mean_exec_time, calls 
FROM pg_stat_statements 
ORDER BY mean_exec_time DESC 
LIMIT 10;
-- Copy and paste the entire result table
```

For **MySQL**:
```sql
-- Current connections
SHOW STATUS LIKE 'Threads_connected';
-- Copy result: _____

-- Table sizes
SELECT table_name, 
       ROUND(data_length/1024/1024, 2) AS data_mb,
       ROUND(index_length/1024/1024, 2) AS index_mb
FROM information_schema.tables 
WHERE table_schema = 'your_database_name'
ORDER BY data_length DESC
LIMIT 10;
-- Copy and paste the entire result table
```

ðŸ“Š **OPTION B: Application-Level Metrics (No DB Access Needed):**

1. **Get Application Logs:**
```bash
# SSH into your application server
ssh your-app-server

# Find slow query logs (adjust path)
grep -i "slow\|timeout\|long" /var/log/application/*.log | head -50
# Copy and paste these lines

# Get database connection errors
grep -i "connection\|pool\|database" /var/log/application/*.log | tail -50
# Copy and paste these lines
```

2. **Application Metrics (if using APM):**
   
   **For New Relic:**
   - Log in â†’ https://one.newrelic.com
   - Go to "APM & Services" â†’ Select your app
   - Click "Databases" tab
   - Screenshot the "Database overview" chart
   - Click on slowest query â†’ Copy the query text
   
   **For DataDog:**
   - Log in â†’ https://app.datadoghq.com
   - Go to "APM" â†’ "Services" â†’ Select your app
   - Click "Resources" â†’ Filter by "Database"
   - Screenshot top 10 slowest endpoints
   - Click each â†’ Copy "Example trace"

3. **CloudWatch Metrics (AWS RDS):**
```
1. AWS Console â†’ RDS â†’ Databases
2. Click your database
3. Click "Monitoring" tab
4. For each metric, click "View in CloudWatch" and copy values:
   
   ðŸ“Š Copy these exact values:
   - CPU Utilization (Average): ____%
   - Database Connections (Max): ____
   - Read IOPS (Average): ____
   - Write IOPS (Average): ____
   - Read Latency (Average): ____ ms
   - Write Latency (Average): ____ ms
   - Free Storage Space: ____ GB
   
5. Take screenshot of "Recent events" section
```

4. **Quick Performance Test (Run from App Server):**
```bash
# Test connection latency
time psql -h your-db-host -U your-user -d your-db -c "SELECT 1"
# Copy result: real ____

# If you have mysql
time mysql -h your-db-host -u your-user -p your-db -e "SELECT 1"
# Copy result: real ____

# Test from application
curl -w "@curl-format.txt" -o /dev/null -s "http://your-app/health"
# Copy all timing values
```

ðŸ“‹ **PASTE TEMPLATE:**
```
=== DATABASE TYPE ===
[ ] PostgreSQL [ ] MySQL [ ] MongoDB [ ] Other: _____

=== CONNECTION METRICS ===
Current connections: _____
Max connections seen: _____
Connection errors (last hour): _____

=== PERFORMANCE METRICS ===
Avg CPU: ____%
Read IOPS: _____
Write IOPS: _____
Read Latency: _____ ms
Write Latency: _____ ms

=== SLOW QUERIES (if available) ===
[Paste query logs or screenshots]

=== APPLICATION LOGS ===
[Paste timeout/slow query logs]

=== TEST RESULTS ===
DB Ping time: _____ ms
App health check time: _____ ms
```
```

---

## Example 3: Kubernetes Resource Optimization - Detailed Guide ðŸš€
**User Request**: "Optimize our k8s cluster resource allocation"

### Data Helper Request with kubectl Commands:

```
Here's exactly how to gather Kubernetes metrics:

ðŸŽ¯ **STEP 1: Access Your Cluster**
```bash
# First, make sure you're connected to the right cluster
kubectl config current-context
# Copy the output: _____

# List all namespaces
kubectl get namespaces
# Copy and paste the list
```

ðŸ“Š **STEP 2: Get Resource Usage (Copy-Paste These Commands)**
```bash
# Overall cluster capacity
kubectl top nodes
# COPY AND PASTE THE ENTIRE OUTPUT HERE

# Pod resource usage by namespace
for ns in $(kubectl get ns -o jsonpath='{.items[*].metadata.name}'); do
  echo "=== Namespace: $ns ==="
  kubectl top pods -n $ns --no-headers | head -20
done
# COPY AND PASTE THE ENTIRE OUTPUT HERE

# Get resource requests vs limits
kubectl get pods --all-namespaces -o json | jq -r '.items[] | 
  {namespace: .metadata.namespace, 
   pod: .metadata.name, 
   requests_cpu: .spec.containers[].resources.requests.cpu, 
   requests_mem: .spec.containers[].resources.requests.memory,
   limits_cpu: .spec.containers[].resources.limits.cpu,
   limits_mem: .spec.containers[].resources.limits.memory} | 
  "\(.namespace),\(.pod),\(.requests_cpu),\(.requests_mem),\(.limits_cpu),\(.limits_mem)"' | head -50
# COPY AND PASTE THE ENTIRE OUTPUT HERE
```

ðŸ” **STEP 3: Identify Problem Pods**
```bash
# Pods that have restarted
kubectl get pods --all-namespaces | grep -v "0/" | grep -v RESTARTS
# COPY AND PASTE ANY RESULTS

# Pending pods
kubectl get pods --all-namespaces --field-selector=status.phase=Pending
# COPY AND PASTE ANY RESULTS

# Recent OOM kills
kubectl get events --all-namespaces | grep -i "oomkill\|evicted" | tail -20
# COPY AND PASTE ANY RESULTS

# Pod describe for any problematic pods
kubectl describe pod [problematic-pod-name] -n [namespace] | grep -A 10 -B 10 "Events\|Conditions"
# COPY AND PASTE FOR ANY PROBLEM PODS
```

ðŸ“ˆ **STEP 4: HPA/VPA Status**
```bash
# Horizontal Pod Autoscalers
kubectl get hpa --all-namespaces
# COPY AND PASTE THE ENTIRE OUTPUT

# Check if VPA is installed
kubectl get vpa --all-namespaces 2>/dev/null || echo "VPA not installed"
# COPY AND PASTE THE RESULT

# Deployment replicas vs desired
kubectl get deployments --all-namespaces -o wide | head -20
# COPY AND PASTE THE OUTPUT
```

ðŸŽ›ï¸ **STEP 5: Get Metrics from Grafana/Prometheus (if available)**
```
1. Open your Grafana dashboard (usually http://grafana.your-domain.com)
2. Go to the Kubernetes dashboard
3. Set time range to "Last 7 days"
4. Take screenshots of:
   - Node CPU/Memory usage graph
   - Pod memory usage by namespace
   - Network I/O graphs

OR if you have Prometheus access:
```bash
# Run these PromQL queries in Prometheus UI:
# Copy results for each:

# CPU usage by namespace
sum(rate(container_cpu_usage_seconds_total[5m])) by (namespace)

# Memory usage by namespace  
sum(container_memory_working_set_bytes) by (namespace) / 1024 / 1024 / 1024

# Node memory pressure
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100
```

âœ… **RESPONSE TEMPLATE:**
```
=== CLUSTER INFO ===
Context: _____
Node Count: _____
Kubernetes Version: _____

=== NODE CAPACITY (from kubectl top nodes) ===
[Paste output here]

=== TOP RESOURCE CONSUMERS (from Step 2) ===
[Paste pod resource usage here]

=== RESOURCE REQUESTS VS LIMITS ===
[Paste CSV data here]

=== PROBLEM PODS ===
Restarted Pods: [paste]
Pending Pods: [paste]
OOM Killed: [paste]

=== AUTOSCALING ===
HPA Status: [paste]
VPA Status: [installed/not installed]

=== GRAFANA SCREENSHOTS ===
[Attach screenshots or describe patterns]
```
```

---

## Example 4: Redis Cache Optimization - Complete Diagnostic ðŸ”´
**User Request**: "Redis cache not effective, need optimization"

### Data Helper Request with Redis Commands:

```
Let's diagnose your Redis cache step-by-step:

ðŸ”‘ **STEP 1: Connect to Redis**
```bash
# SSH into a server with Redis access
ssh your-redis-server

# Connect to Redis CLI
redis-cli -h your-redis-host -p 6379
# If password required:
redis-cli -h your-redis-host -p 6379 -a your-password

# Or if using Redis Cloud/ElastiCache:
redis-cli -h your-redis-endpoint.cache.amazonaws.com
```

ðŸ“Š **STEP 2: Get Cache Statistics (Run These in Redis CLI)**
```redis
# Overall stats
INFO stats
# COPY THESE SPECIFIC VALUES:
# keyspace_hits:_____
# keyspace_misses:_____
# evicted_keys:_____
# expired_keys:_____

# Memory info
INFO memory
# COPY THESE SPECIFIC VALUES:
# used_memory_human:_____
# used_memory_rss_human:_____
# mem_fragmentation_ratio:_____
# maxmemory_human:_____

# Get eviction policy
CONFIG GET maxmemory-policy
# COPY THE RESULT:_____

# Check persistence
INFO persistence
# COPY: rdb_last_save_time:_____
```

ðŸ” **STEP 3: Analyze Key Patterns**
```redis
# Sample keys to see naming patterns
SCAN 0 COUNT 100
# COPY A FEW EXAMPLE KEYS

# Get key count by pattern (adjust patterns based on your keys)
eval "return #redis.call('keys', 'user:*')" 0
eval "return #redis.call('keys', 'session:*')" 0
eval "return #redis.call('keys', 'cache:*')" 0
# COPY COUNTS FOR EACH PATTERN

# Find large keys
redis-cli --bigkeys
# COPY THE SUMMARY SECTION

# Sample TTLs
# For each key pattern, check a few TTLs:
TTL user:12345
TTL session:abc123
TTL cache:product:456
# COPY: Pattern and typical TTL values
```

ðŸ“ˆ **STEP 4: Monitor Real-Time Activity**
```bash
# In a new terminal, monitor commands for 30 seconds
redis-cli MONITOR | head -n 1000 > redis-monitor.txt
# Wait 30 seconds, then Ctrl+C

# Analyze the captured commands
cat redis-monitor.txt | awk '{print $4}' | sort | uniq -c | sort -rn | head -20
# COPY THIS COMMAND FREQUENCY LIST

# Check slow queries
redis-cli SLOWLOG GET 10
# COPY ANY RESULTS
```

ðŸ’» **STEP 5: Application-Side Metrics**

**For Node.js/JavaScript:**
```javascript
// Add this temporarily to your code:
console.log('Cache hits:', redisClient.hits || 'Not tracked');
console.log('Cache misses:', redisClient.misses || 'Not tracked');
console.log('Active connections:', redisClient.connectionCount);
// COPY THE CONSOLE OUTPUT
```

**For Python:**
```python
# Add this temporarily:
import redis
r = redis.Redis(...)
info = r.info()
print(f"Connected clients: {info['connected_clients']}")
print(f"Commands processed: {info['total_commands_processed']}")
# COPY THE OUTPUT
```

**For Spring Boot:**
```java
// Check application.properties:
grep -i redis application.properties
# COPY REDIS CONFIGURATION

// Check metrics endpoint:
curl http://localhost:8080/actuator/metrics/cache.gets
# COPY THE RESPONSE
```

ðŸ”§ **STEP 6: ElastiCache/Cloud Specific (if applicable)**

**AWS ElastiCache:**
```
1. AWS Console â†’ ElastiCache â†’ Redis clusters
2. Click your cluster â†’ "Metrics" tab
3. Copy these values:
   - EngineCPUUtilization: ____%
   - SwapUsage: ____ bytes
   - Evictions (per minute): ____
   - CacheMisses (per minute): ____
   - NetworkBytesIn: ____
   - NetworkBytesOut: ____
4. Click "Events" tab â†’ Screenshot recent events
```

ðŸ“‹ **COMPLETE RESPONSE TEMPLATE:**
```
=== REDIS VERSION & SETUP ===
Redis Version: _____
Deployment Type: [ ] Standalone [ ] Cluster [ ] Sentinel
Cloud Provider: [ ] AWS [ ] Azure [ ] GCP [ ] Self-hosted

=== CACHE PERFORMANCE ===
Hit Rate: ____% (hits: ____, misses: ____)
Evictions/hour: _____
Expired keys/hour: _____

=== MEMORY STATUS ===
Used Memory: _____
Max Memory: _____
Fragmentation Ratio: _____
Eviction Policy: _____

=== KEY PATTERNS ===
Total Keys: _____
Pattern Breakdown:
- user:* â†’ _____ keys
- session:* â†’ _____ keys
- cache:* â†’ _____ keys
- other: _____

=== LARGEST KEYS ===
[Paste bigkeys summary]

=== MOST FREQUENT COMMANDS ===
[Paste command frequency list]

=== SLOW QUERIES ===
[Paste any slow queries]

=== APPLICATION METRICS ===
[Paste application-side stats]
```
```

---

## Example 5: Lambda Cost Optimization - Detailed Collection ðŸ”¸
**User Request**: "Lambda functions are expensive but fast, need balance"

### Data Helper Request with AWS Commands:

```
Let's analyze your Lambda functions for cost optimization:

âš¡ **STEP 1: Lambda Metrics from Console**
```
1. Go to AWS Lambda Console: https://console.aws.amazon.com/lambda
2. Click "Functions" 
3. For your top 5 most-used functions:
   a. Click on function name
   b. Go to "Monitor" tab
   c. Click "View CloudWatch Logs"
   d. In CloudWatch, click "Logs Insights"
   e. Run this query:
   
   fields @timestamp, @duration, @memorySize, @maxMemoryUsed
   | stats avg(@duration) as avg_duration,
           max(@duration) as max_duration,
           min(@duration) as min_duration,
           avg(@maxMemoryUsed/@memorySize) as avg_memory_percent,
           count() as invocations
   | sort invocations desc
   
   f. Copy and paste the results for each function
```

ðŸ’° **STEP 2: Get Cost Breakdown**
```bash
# Run in AWS CloudShell:

# Get last month's Lambda costs by function
aws ce get-cost-and-usage \
  --time-period Start=$(date -d "30 days ago" +%Y-%m-%d),End=$(date +%Y-%m-%d) \
  --granularity MONTHLY \
  --metrics "UnblendedCost" \
  --group-by Type=DIMENSION,Key=SERVICE \
  --filter '{
    "Dimensions": {
      "Key": "SERVICE",
      "Values": ["AWS Lambda"]
    }
  }' \
  --output table

# COPY THE ENTIRE OUTPUT

# Get invocation count for each function
for func in $(aws lambda list-functions --query 'Functions[*].FunctionName' --output text); do
  echo -n "$func: "
  aws cloudwatch get-metric-statistics \
    --namespace AWS/Lambda \
    --metric-name Invocations \
    --dimensions Name=FunctionName,Value=$func \
    --start-time $(date -u -d '7 days ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 604800 \
    --statistics Sum \
    --query 'Datapoints[0].Sum' \
    --output text
done

# COPY ALL FUNCTION INVOCATION COUNTS
```

ðŸ§Š **STEP 3: Analyze Cold Starts**
```
1. Go to CloudWatch â†’ Log Groups
2. Select /aws/lambda/your-function-name
3. Click "Logs Insights"
4. Run this query:

fields @timestamp, @type, @initDuration
| filter @type = "REPORT"
| filter @initDuration > 0
| stats count() as cold_starts,
        avg(@initDuration) as avg_cold_start_ms,
        max(@initDuration) as max_cold_start_ms
| sort cold_starts desc

5. COPY THE RESULTS

6. For cold start pattern analysis:
fields @timestamp, @initDuration
| filter @initDuration > 0
| bin @timestamp span=1h
| stats count() as cold_starts by @timestamp
| sort @timestamp desc
| limit 168

7. COPY TO SEE HOURLY PATTERN
```

ðŸ”§ **STEP 4: Memory and Performance Tuning Data**
```bash
# Get current memory settings for all functions
aws lambda list-functions \
  --query 'Functions[*].[FunctionName,MemorySize,Timeout,Runtime,CodeSize]' \
  --output table

# COPY THE ENTIRE TABLE

# For your most expensive function, get detailed metrics:
FUNCTION_NAME="your-expensive-function"

# Duration statistics
aws cloudwatch get-metric-statistics \
  --namespace AWS/Lambda \
  --metric-name Duration \
  --dimensions Name=FunctionName,Value=$FUNCTION_NAME \
  --start-time $(date -u -d '7 days ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 86400 \
  --statistics Average,Maximum,Minimum \
  --output table

# COPY THE OUTPUT
```

ðŸ“Š **STEP 5: Concurrent Executions**
```bash
# Check concurrent execution patterns
aws cloudwatch get-metric-statistics \
  --namespace AWS/Lambda \
  --metric-name ConcurrentExecutions \
  --start-time $(date -u -d '7 days ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 3600 \
  --statistics Maximum,Average \
  --output json | jq '.Datapoints | sort_by(.Maximum) | reverse | .[0:5]'

# COPY TOP 5 PEAK CONCURRENCY TIMES

# Check for throttles
aws cloudwatch get-metric-statistics \
  --namespace AWS/Lambda \
  --metric-name Throttles \
  --start-time $(date -u -d '7 days ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 86400 \
  --statistics Sum \
  --output table

# COPY IF ANY THROTTLES
```

ðŸŽ¯ **STEP 6: Optimization Opportunities**
```
Run Lambda Power Tuning (if possible):
1. Go to: https://serverlessrepo.aws.amazon.com/applications
2. Search for "aws-lambda-power-tuning"
3. Deploy it
4. Run it against your expensive function:

{
  "lambdaARN": "arn:aws:lambda:region:account:function:your-function",
  "powerValues": [128, 256, 512, 1024, 1536, 2048, 3008],
  "num": 50,
  "payload": {YOUR_TYPICAL_PAYLOAD}
}

5. COPY THE RESULTS URL

OR manually test different memory sizes:
# Update function memory and test
for memory in 128 256 512 1024 1536 2048; do
  aws lambda update-function-configuration \
    --function-name $FUNCTION_NAME \
    --memory-size $memory \
    --output none
  
  sleep 5
  
  echo "Memory: $memory MB"
  aws lambda invoke \
    --function-name $FUNCTION_NAME \
    --payload '{"test": true}' \
    --log-type Tail \
    response.json \
    --query 'LogResult' \
    --output text | base64 -d | grep "Billed Duration"
done

# COPY ALL RESULTS
```

ðŸ“‹ **RESPONSE TEMPLATE:**
```
=== FUNCTION INVENTORY ===
Total Functions: _____
Top 5 by invocations:
1. _____ (_____ invocations/month)
2. _____ (_____ invocations/month)
3. _____ (_____ invocations/month)
4. _____ (_____ invocations/month)
5. _____ (_____ invocations/month)

=== COST BREAKDOWN ===
Total Lambda Cost: $_____/month
Cost per million invocations: $_____
Highest cost function: _____

=== PERFORMANCE METRICS (per function) ===
Function: _____
- Memory Allocated: _____ MB
- Avg Memory Used: _____ MB (____%)
- Avg Duration: _____ ms
- Max Duration: _____ ms
- Cold Starts: _____/day
- Avg Cold Start: _____ ms

=== CONCURRENCY ===
Peak Concurrent: _____
Average Concurrent: _____
Throttles last week: _____

=== OPTIMIZATION TEST RESULTS ===
[Paste memory test results]

Current memory: _____ MB â†’ $_____ /million invocations
Optimal memory: _____ MB â†’ $_____ /million invocations
Potential savings: _____%
```
```

---

## Example 6: Container Registry Optimization - Step by Step ðŸ³
**User Request**: "Our container registry is getting expensive and slow"

### Data Helper Request with Docker/Registry Commands:

```
Let's analyze your container registry usage:

ðŸ³ **STEP 1: Registry Size Analysis**

**For Docker Hub:**
```bash
# Get your auth token
TOKEN=$(curl -s -H "Content-Type: application/json" \
  -X POST -d '{"username": "YOUR_USERNAME", "password": "YOUR_PASSWORD"}' \
  https://hub.docker.com/v2/users/login/ | jq -r .token)

# List repositories with sizes
curl -s -H "Authorization: JWT ${TOKEN}" \
  "https://hub.docker.com/v2/repositories/YOUR_ORG/?page_size=100" | \
  jq -r '.results[] | "\(.name): \(.full_size/1024/1024) MB"'

# COPY THE ENTIRE LIST
```

**For AWS ECR:**
```bash
# List all repositories with sizes
aws ecr describe-repositories --query 'repositories[*].[repositoryName,repositorySizeInBytes]' --output text | \
  while read repo size; do
    echo "$repo: $((size/1024/1024)) MB"
  done | sort -t: -k2 -rn

# COPY THE ENTIRE LIST

# Get image counts per repository
for repo in $(aws ecr describe-repositories --query 'repositories[*].repositoryName' --output text); do
  count=$(aws ecr list-images --repository-name $repo --query 'length(imageIds)')
  echo "$repo: $count images"
done

# COPY IMAGE COUNTS
```

**For GCR/Artifact Registry:**
```bash
# List all images with sizes
gcloud container images list --format="table(name)" | tail -n +2 | \
  while read image; do
    gcloud container images list-tags $image --format="json" | \
    jq -r '.[] | "\(.digest): \(.size/1024/1024) MB"'
  done

# COPY THE OUTPUT
```

ðŸ“Š **STEP 2: Pull/Push Metrics**
```bash
# Get registry access logs (adjust based on your setup)

# For self-hosted registry:
docker exec registry cat /var/lib/registry/access.log | \
  grep -E "PULL|PUSH" | tail -1000 | \
  awk '{print $6}' | sort | uniq -c | sort -rn | head -20

# COPY THE MOST PULLED IMAGES

# For AWS ECR CloudTrail:
aws cloudtrail lookup-events \
  --lookup-attributes AttributeKey=EventName,AttributeValue=BatchGetImage \
  --max-items 100 \
  --query 'Events[*].[EventTime,RequestParameters.repositoryName]' \
  --output table

# COPY RECENT PULL ACTIVITY
```

ðŸ—‘ï¸ **STEP 3: Identify Cleanup Opportunities**
```bash
# Find old/unused images in ECR
for repo in $(aws ecr describe-repositories --query 'repositories[*].repositoryName' --output text); do
  echo "=== Repository: $repo ==="
  aws ecr describe-images --repository-name $repo \
    --query 'sort_by(imageDetails,& imagePushedAt)[*].[imageTags[0],imagePushedAt,imageSizeInBytes]' \
    --output text | \
    head -5
done

# COPY TO SEE OLDEST IMAGES

# Find duplicate layers (for Docker Registry v2)
curl -X GET http://your-registry:5000/v2/_catalog | jq -r '.repositories[]' | \
  while read repo; do
    echo "Checking $repo for duplicate layers..."
    curl -s -X GET http://your-registry:5000/v2/$repo/tags/list | \
    jq -r '.tags[]' | \
    while read tag; do
      curl -s -X GET http://your-registry:5000/v2/$repo/manifests/$tag | \
      jq -r '.fsLayers[].blobSum'
    done | sort | uniq -c | sort -rn | head -5
  done

# COPY DUPLICATE LAYER ANALYSIS
```

âš¡ **STEP 4: Network Performance**
```bash
# Test pull performance
time docker pull your-registry.com/your-image:latest
# COPY: real time _____

# Test with different mirrors/endpoints
for registry in "docker.io" "your-registry.com" "mirror.your-registry.com"; do
  echo "Testing $registry..."
  time docker pull $registry/alpine:latest > /dev/null 2>&1
done

# COPY ALL TIMING RESULTS

# Check bandwidth from different regions (if applicable)
curl -w "@curl-timing.txt" -o /dev/null -s \
  https://your-registry.com/v2/your-image/blobs/sha256:xxxxx

# COPY TIMING DETAILS
```

ðŸ” **STEP 5: Security Scanning Impact**
```bash
# Check if vulnerability scanning is enabled (ECR)
aws ecr describe-repositories \
  --query 'repositories[*].[repositoryName,imageScanningConfiguration.scanOnPush]' \
  --output table

# COPY SCAN SETTINGS

# Get scan findings summary
for repo in $(aws ecr describe-repositories --query 'repositories[*].repositoryName' --output text); do
  findings=$(aws ecr describe-image-scan-findings \
    --repository-name $repo \
    --image-id imageTag=latest \
    --query 'imageScanFindings.findingSeverityCounts' \
    2>/dev/null)
  echo "$repo: $findings"
done

# COPY VULNERABILITY SUMMARIES
```

ðŸ“ˆ **STEP 6: Cost Analysis**
```
AWS Cost Explorer:
1. Go to AWS Console â†’ Cost Explorer
2. Filter by Service = "EC2 Container Registry"
3. Group by = "Usage Type"
4. Download CSV
5. COPY TOP 5 COST DRIVERS:
   - Storage: $_____
   - Data Transfer: $_____
   - Requests: $_____

For self-hosted:
# Check disk usage
df -h /var/lib/docker/registry
# COPY OUTPUT

# Check bandwidth usage (monthly)
vnstat -m | grep "$(date +%b)"
# COPY OUTPUT
```

âœ… **RESPONSE TEMPLATE:**
```
=== REGISTRY TYPE ===
[ ] Docker Hub [ ] ECR [ ] GCR [ ] Self-hosted
Registry URL: _____

=== STORAGE METRICS ===
Total Size: _____ GB
Number of Repositories: _____
Number of Images: _____
Largest Repository: _____ (_____ GB)

=== TOP 10 LARGEST IMAGES ===
[Paste list with sizes]

=== MOST PULLED IMAGES (last week) ===
[Paste pull frequency list]

=== OLD/UNUSED IMAGES ===
Images older than 90 days: _____
Images never pulled: _____
Duplicate layers found: _____

=== PERFORMANCE ===
Average pull time (large image): _____ seconds
Average push time: _____ seconds
Network bandwidth: _____ Mbps

=== COSTS ===
Monthly storage cost: $_____
Monthly bandwidth cost: $_____
Monthly request cost: $_____

=== CLEANUP OPPORTUNITIES ===
Estimated space to reclaim: _____ GB
Estimated monthly savings: $_____
```
```

---

## Summary: Key Improvements in V2

### 1. **Exact Console Navigation**
- Specific URLs for each service
- Click-by-click instructions
- Menu navigation paths

### 2. **Copy-Paste Commands**
- Complete shell commands ready to run
- SQL queries formatted for direct execution
- CloudWatch Insights queries included

### 3. **Screenshot Guidance**
- Specific sections to capture
- Which graphs/charts are most useful
- Where to find hidden metrics

### 4. **Response Templates**
- Pre-formatted sections for users to fill
- Clear value placeholders (_____)
- Checkboxes for options

### 5. **Alternative Methods**
- Multiple ways to get same data
- Fallbacks for restricted access
- Different tools for different environments

### 6. **Time-Saving Features**
- Batch commands that gather multiple metrics
- Scripts that aggregate data automatically
- One-liners for complex analysis

This V2 approach reduces friction by making data collection a simple copy-paste exercise rather than requiring users to figure out where and how to find metrics themselves.