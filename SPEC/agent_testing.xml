<?xml version="1.0" encoding="UTF-8"?>
<specification>
  <metadata>
    <title>Agent Testing Specification</title>
    <version>1.0</version>
    <created>2025-08-14</created>
    <description>Comprehensive testing requirements for multi-agent system</description>
    <priority>CRITICAL</priority>
  </metadata>

  <requirements>
    <requirement id="AGT-001" priority="CRITICAL">
      <title>Test Suite Coverage</title>
      <description>Each agent MUST have a dedicated test suite with minimum 80% code coverage</description>
      <implementation>
        - Create test_[agent_name].py for each agent
        - Minimum 20 tests per agent covering all critical paths
        - Use pytest and pytest-asyncio for async testing
      </implementation>
      <validation>Run pytest with --cov flag to verify coverage</validation>
    </requirement>

    <requirement id="AGT-002" priority="CRITICAL">
      <title>Module Architecture Compliance</title>
      <description>All test files MUST adhere to 300-line limit and 8-line function limit</description>
      <implementation>
        - Test files must be ≤300 lines
        - Each test function must be ≤8 lines
        - Use helper functions to maintain line limits
      </implementation>
      <validation>Automated line count verification in CI/CD</validation>
    </requirement>

    <requirement id="AGT-003" priority="HIGH">
      <title>Mock Strategy</title>
      <description>All external dependencies MUST be mocked for unit testing</description>
      <implementation>
        - Mock LLM, Redis, ClickHouse, WebSocket managers
        - Use MagicMock for sync, AsyncMock for async operations
        - Create reusable fixtures in conftest.py
      </implementation>
      <validation>Tests must run without external services</validation>
    </requirement>

    <requirement id="AGT-004" priority="HIGH">
      <title>State Management Testing</title>
      <description>Use real DeepAgentState objects instead of mocks for state testing</description>
      <implementation>
        - Import DeepAgentState from app.agents.state
        - Create valid state objects with required fields
        - Test state transitions and validations
      </implementation>
      <validation>No MagicMock objects for state parameters</validation>
    </requirement>

    <requirement id="AGT-005" priority="HIGH">
      <title>Entry Conditions Validation</title>
      <description>Each agent MUST validate entry conditions before execution</description>
      <implementation>
        - Test valid entry conditions
        - Test missing prerequisites
        - Test invalid data scenarios
      </implementation>
      <validation>All entry condition paths covered</validation>
    </requirement>

    <requirement id="AGT-006" priority="MEDIUM">
      <title>Error Handling Coverage</title>
      <description>Test suites MUST cover all error scenarios and fallback mechanisms</description>
      <implementation>
        - Test LLM failures and fallbacks
        - Test JSON extraction failures
        - Test network timeouts
        - Test circuit breaker behavior
      </implementation>
      <validation>Error paths have explicit test cases</validation>
    </requirement>

    <requirement id="AGT-007" priority="MEDIUM">
      <title>WebSocket Testing</title>
      <description>Test WebSocket updates and streaming functionality</description>
      <implementation>
        - Mock WebSocket manager
        - Test update sending during execution
        - Test failure handling
        - Verify message format
      </implementation>
      <validation>WebSocket interactions properly mocked and tested</validation>
    </requirement>

    <requirement id="AGT-008" priority="HIGH">
      <title>Cache Testing</title>
      <description>Test caching mechanisms with proper time handling</description>
      <implementation>
        - Import time module for cache timestamps
        - Test cache hit/miss scenarios
        - Test cache expiry and TTL
        - Include _schema_cache_timestamps for DataSubAgent
      </implementation>
      <validation>Cache behavior correctly validated with time</validation>
    </requirement>

    <requirement id="AGT-009" priority="MEDIUM">
      <title>Health Monitoring</title>
      <description>Test health status and circuit breaker monitoring</description>
      <implementation>
        - Test get_health_status method
        - Test circuit breaker state transitions
        - Verify reliability wrapper integration
      </implementation>
      <validation>Health endpoints return expected data</validation>
    </requirement>

    <requirement id="AGT-010" priority="HIGH">
      <title>Test Execution Performance</title>
      <description>Test suites MUST execute efficiently</description>
      <implementation>
        - Individual tests complete in &lt;1 second
        - Full suite completes in &lt;30 seconds
        - Use async operations efficiently
      </implementation>
      <validation>Timed test execution in CI/CD</validation>
    </requirement>
  </requirements>

  <test_suites>
    <suite name="TriageSubAgent" file="tests/test_triage_sub_agent.py">
      <coverage>26 tests</coverage>
      <key_scenarios>
        - Initialization with/without Redis
        - Entry conditions validation
        - Cache hit/miss scenarios
        - Request categorization
        - Entity extraction and enrichment
        - Fallback mechanisms
      </key_scenarios>
    </suite>

    <suite name="DataSubAgent" file="tests/test_data_sub_agent.py">
      <coverage>25 tests</coverage>
      <key_scenarios>
        - Component initialization
        - Schema caching with timestamps
        - ClickHouse operations
        - Main execution flow
        - WebSocket updates
        - Cache management
      </key_scenarios>
    </suite>

    <suite name="ActionsToMeetGoalsSubAgent" file="tests/test_actions_sub_agent.py">
      <coverage>25 tests</coverage>
      <key_scenarios>
        - Agent initialization
        - Entry conditions with state validation
        - JSON extraction and recovery
        - Action plan generation
        - Fallback strategies
        - Large prompt handling
      </key_scenarios>
    </suite>

    <suite name="ReportingSubAgent" file="tests/test_reporting_sub_agent.py">
      <coverage>21 tests</coverage>
      <key_scenarios>
        - Report generation
        - Data aggregation
        - Formatting and summaries
        - Missing data handling
        - Streaming updates
      </key_scenarios>
    </suite>
  </test_suites>

  <integration>
    <test_runner>
      <description>Integration with test_runner.py for automated execution</description>
      <configuration>
        AGENT_TEST_SUITES = [
          "tests/test_triage_sub_agent.py",
          "tests/test_data_sub_agent.py",
          "tests/test_actions_sub_agent.py",
          "tests/test_reporting_sub_agent.py"
        ]
      </configuration>
      <execution_levels>
        - unit: Individual agent methods
        - integration: Agent interactions
        - comprehensive: Full workflow validation
      </execution_levels>
    </test_runner>

    <ci_cd>
      <description>GitHub Actions integration for continuous testing</description>
      <workflow>
        - Run on push to main and PR branches
        - Execute all agent test suites
        - Generate coverage reports
        - Fail build if coverage &lt;80%
      </workflow>
    </ci_cd>
  </integration>

  <best_practices>
    <practice id="BP-001">
      <title>Consistent Fixture Usage</title>
      <description>Use shared fixtures from conftest.py for common mocks</description>
    </practice>

    <practice id="BP-002">
      <title>Deterministic Tests</title>
      <description>All tests must be deterministic and not rely on external state</description>
    </practice>

    <practice id="BP-003">
      <title>Clear Test Names</title>
      <description>Test names should clearly describe what is being tested</description>
    </practice>

    <practice id="BP-004">
      <title>Single Responsibility</title>
      <description>Each test should validate exactly one behavior</description>
    </practice>

    <practice id="BP-005">
      <title>Fast Feedback</title>
      <description>Tests should provide immediate, clear feedback on failures</description>
    </practice>
  </best_practices>

  <troubleshooting>
    <issue id="TS-001">
      <problem>Import errors when running tests</problem>
      <solution>Ensure PYTHONPATH includes project root</solution>
    </issue>

    <issue id="TS-002">
      <problem>Async test warnings</problem>
      <solution>Use pytest-asyncio fixtures properly</solution>
    </issue>

    <issue id="TS-003">
      <problem>State validation failures</problem>
      <solution>Use real DeepAgentState objects, not MagicMock</solution>
    </issue>

    <issue id="TS-004">
      <problem>Cache timestamp errors</problem>
      <solution>Import time module and initialize _schema_cache_timestamps</solution>
    </issue>
  </troubleshooting>

  <learnings>
    <learning date="2025-08-14">
      <issue>DataSubAgent cache tests failing due to missing time import</issue>
      <solution>Added import time to test file and initialized _schema_cache_timestamps</solution>
    </learning>

    <learning date="2025-08-14">
      <issue>ActionsSubAgent tests failing due to state validation</issue>
      <solution>Use real DeepAgentState objects instead of MagicMock for state</solution>
    </learning>

    <learning date="2025-08-14">
      <issue>Test files exceeding 300-line limit</issue>
      <solution>Split tests into focused groups, extract common setup to fixtures</solution>
    </learning>
  </learnings>

  <metrics>
    <metric name="Total Tests">97</metric>
    <metric name="Coverage Target">80%</metric>
    <metric name="Execution Time Target">&lt;30 seconds</metric>
    <metric name="Line Limit">300 lines per file</metric>
    <metric name="Function Limit">8 lines per function</metric>
  </metrics>
</specification>