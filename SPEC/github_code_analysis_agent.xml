<?xml version='1.0' encoding='utf-8'?>
<spec>
  <metadata>
    <last_edited>2025-08-21T08:47:28.483639</last_edited>
    <legacy_status is_legacy="true" identified_date="2025-08-21T08:47:28.483639">
      <reasons>
        <reason>Content contains: DEPRECATED</reason>
        <reason>Content contains: deprecated</reason>
      </reasons>
    </legacy_status>
  </metadata>
  <name>GitHub Code Analysis Agent</name>
  <version>1.0.0</version>
  <description>
    Agent for analyzing GitHub repositories to map AI/LLM operations, configurations, and usage patterns.
    Creates comprehensive maps of AI infrastructure within codebases.
  </description>
  <system_integration>
    <supervisor_integration>
      <description>Operates under supervisor agent control</description>
      <state_management>Uses existing StateManager from app.agents.supervisor.state_manager</state_management>
      <error_handling>Integrates with triage_sub_agent for error recovery</error_handling>
      <compensation>Uses existing compensation_engine for rollback operations</compensation>
    </supervisor_integration>
    <data_flow>
      <input>Repository URL or local path from corpus_service</input>
      <processing>Leverages data_sub_agent patterns for data processing</processing>
      <output>Structured AI operations map to database via existing models</output>
    </data_flow>
    <shared_components>
      <llm_integration>Uses app.llm.fallback_handler for resilient LLM calls</llm_integration>
      <database>Uses existing session_manager and query patterns</database>
      <monitoring>Integrates with system_health_monitor</monitoring>
      <websocket>Reports progress via existing WebSocket infrastructure</websocket>
    </shared_components>
  </system_integration>
  <architecture>
    <module_structure>
      <base_path>app/agents/github_analyzer/</base_path>
      <modules>
        <module name="agent.py" max_lines="300">Main agent orchestration</module>
        <module name="scanner_core.py" max_lines="300">Core scanning logic</module>
        <module name="pattern_detector.py" max_lines="300">AI pattern detection</module>
        <module name="config_parser.py" max_lines="300">Configuration extraction</module>
        <module name="llm_mapper.py" max_lines="300">LLM call mapping</module>
        <module name="tool_analyzer.py" max_lines="300">Tool usage analysis</module>
        <module name="output_formatter.py" max_lines="300">Map generation</module>
        <module name="github_client.py" max_lines="300">GitHub API integration</module>
      </modules>
    </module_structure>
    <function_constraints>
      <max_lines_per_function>8</max_lines_per_function>
      <composition>Small functions composed into larger operations</composition>
    </function_constraints>
  </architecture>
  <detection_patterns>
    <llm_providers>
      <openai>
        <patterns>
          <pattern>openai\.ChatCompletion</pattern>
          <pattern>OpenAI\(\)</pattern>
          <pattern>gpt-[34]|text-davinci</pattern>
          <pattern>OPENAI_API_KEY</pattern>
        </patterns>
        <config_keys>temperature, max_tokens, top_p, frequency_penalty</config_keys>
      </openai>
      <anthropic>
        <patterns>
          <pattern>anthropic\.Client</pattern>
          <pattern>claude-[23]</pattern>
          <pattern>ANTHROPIC_API_KEY</pattern>
        </patterns>
        <config_keys>max_tokens_to_sample, temperature, top_k, top_p</config_keys>
      </anthropic>
      <langchain>
        <patterns>
          <pattern>from langchain</pattern>
          <pattern>LLMChain|ConversationChain</pattern>
          <pattern>ChatOpenAI|ChatAnthropic</pattern>
        </patterns>
        <config_keys>memory, callbacks, verbose</config_keys>
      </langchain>
    </llm_providers>
    <agent_frameworks>
      <autogen>
        <patterns>
          <pattern>autogen\.Agent</pattern>
          <pattern>ConversableAgent</pattern>
        </patterns>
      </autogen>
      <crewai>
        <patterns>
          <pattern>from crewai</pattern>
          <pattern>Agent\(|Task\(|Crew\(</pattern>
        </patterns>
      </crewai>
      <custom_agents>
        <patterns>
          <pattern>class \w+Agent</pattern>
          <pattern>def execute_agent</pattern>
        </patterns>
      </custom_agents>
    </agent_frameworks>
    <tool_usage>
      <function_calling>
        <patterns>
          <pattern>tools=|functions=</pattern>
          <pattern>function_call|tool_calls</pattern>
        </patterns>
      </function_calling>
      <retrieval>
        <patterns>
          <pattern>VectorStore|Embeddings</pattern>
          <pattern>similarity_search|retrieve</pattern>
        </patterns>
      </retrieval>
    </tool_usage>
  </detection_patterns>
  <output_schema>
    <ai_operations_map>
      <repository_info>
        <url>string</url>
        <branch>string</branch>
        <commit_hash>string</commit_hash>
        <analyzed_at>datetime</analyzed_at>
      </repository_info>
      <ai_infrastructure>
        <llm_endpoints>
          <endpoint>
            <file_path>string</file_path>
            <line_number>int</line_number>
            <provider>string</provider>
            <model>string</model>
            <configuration>dict</configuration>
          </endpoint>
        </llm_endpoints>
        <agents>
          <agent>
            <name>string</name>
            <file_path>string</file_path>
            <type>string</type>
            <tools>list[string]</tools>
            <dependencies>list[string]</dependencies>
          </agent>
        </agents>
        <prompts>
          <prompt>
            <file_path>string</file_path>
            <line_number>int</line_number>
            <type>system|user|assistant</type>
            <content_preview>string</content_preview>
          </prompt>
        </prompts>
        <configurations>
          <config>
            <file_path>string</file_path>
            <type>env|json|yaml</type>
            <ai_related_keys>list[string]</ai_related_keys>
          </config>
        </configurations>
      </ai_infrastructure>
      <metrics>
        <total_llm_calls>int</total_llm_calls>
        <unique_models>list[string]</unique_models>
        <agent_count>int</agent_count>
        <tool_count>int</tool_count>
        <estimated_complexity>low|medium|high</estimated_complexity>
      </metrics>
    </ai_operations_map>
  </output_schema>
  <capabilities>
    <file_operations>
      <search>Recursive file search with pattern matching</search>
      <parse>Multi-language parsing (Python, JS, TS, Go, Java)</parse>
      <cache>Intelligent caching of analyzed results</cache>
    </file_operations>
    <analysis_features>
      <dependency_tracking>Track AI library dependencies</dependency_tracking>
      <cost_estimation>Estimate token usage and costs</cost_estimation>
      <security_scanning>Identify exposed API keys</security_scanning>
      <best_practices>Check against AI coding standards</best_practices>
    </analysis_features>
    <reporting>
      <formats>JSON, Markdown, HTML</formats>
      <visualizations>Dependency graphs, usage heatmaps</visualizations>
      <alerts>Security issues, deprecated patterns</alerts>
    </reporting>
  </capabilities>
  <performance>
    <repository_size_limits>
      <small>Up to 100 files - complete scan</small>
      <medium>100-1000 files - targeted scan</medium>
      <large>1000+ files - sampling strategy</large>
    </repository_size_limits>
    <scanning_strategy>
      <prioritization>
        <high>Known AI directories (agents/, llm/, ai/)</high>
        <medium>Configuration files</medium>
        <low>Test files, documentation</low>
      </prioritization>
      <optimization>
        <parallel_processing>Use asyncio for concurrent file analysis</parallel_processing>
        <early_termination>Stop on resource limits</early_termination>
        <incremental_updates>Support resume from checkpoint</incremental_updates>
      </optimization>
    </scanning_strategy>
  </performance>
  <error_handling>
    <integration>
      <triage_agent>Delegate complex errors to triage_sub_agent</triage_agent>
      <recovery>Use agent_recovery_strategies for resilience</recovery>
      <compensation>Rollback partial analyses on failure</compensation>
    </integration>
    <specific_errors>
      <rate_limits>Implement exponential backoff</rate_limits>
      <parse_errors>Log and continue with next file</parse_errors>
      <access_denied>Report in output, continue scan</access_denied>
    </specific_errors>
  </error_handling>
  <testing>
    <unit_tests>
      <coverage>Minimum 80% for all modules</coverage>
      <mock_repositories>Test against synthetic codebases</mock_repositories>
      <pattern_validation>Test all detection patterns</pattern_validation>
    </unit_tests>
    <integration_tests>
      <supervisor_communication>Test state updates</supervisor_communication>
      <database_operations>Test map storage and retrieval</database_operations>
      <websocket_updates>Test progress reporting</websocket_updates>
    </integration_tests>
    <e2e_tests>
      <real_repositories>Test against known AI projects</real_repositories>
      <performance_benchmarks>Measure scan times</performance_benchmarks>
      <accuracy_validation>Verify detection accuracy</accuracy_validation>
    </e2e_tests>
  </testing>
  <deployment>
    <routes>
      <analyze>/api/github/analyze</analyze>
      <status>/api/github/analysis/{id}/status</status>
      <results>/api/github/analysis/{id}/results</results>
    </routes>
    <permissions>
      <required>corpus_admin role for analysis initiation</required>
      <public>Read-only access to completed analyses</public>
    </permissions>
    <monitoring>
      <metrics>Scan duration, files processed, patterns detected</metrics>
      <alerts>Failed scans, security issues found</alerts>
      <dashboards>Analysis trends, popular patterns</dashboards>
    </monitoring>
  </deployment>
  <future_enhancements>
    <ml_classification>Use ML to classify AI usage patterns</ml_classification>
    <recommendation_engine>Suggest AI improvements</recommendation_engine>
    <cross_repo_analysis>Compare AI usage across projects</cross_repo_analysis>
    <real_time_monitoring>Watch repositories for AI changes</real_time_monitoring>
  </future_enhancements>
</spec>