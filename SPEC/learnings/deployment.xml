<?xml version='1.0' encoding='utf-8'?>
<specification>
  <metadata>
    <name>Deployment Learnings</name>
    <type>learnings</type>
    <version>1.0</version>
    <last_updated>2025-08-22</last_updated>
    <description>Comprehensive deployment learnings including staging environment setup</description>
    <critical>true</critical>
    <business_impact>Mission Critical - Deployment Success Required for Customer Access</business_impact>
  </metadata>
  
  <staging_deployment_learnings>
    <learning>
      <id>staging-gunicorn-uvicorn-workers</id>
      <category>deployment</category>
      <date>2025-08-22</date>
      <severity>critical</severity>
      <title>Use Gunicorn with Uvicorn Workers for Cloud Run</title>
      <problem>
        <description>Default uvicorn server doesn't handle Cloud Run requirements properly</description>
        <symptoms>
          <symptom>Service startup failures in Cloud Run</symptom>
          <symptom>Request handling issues under load</symptom>
          <symptom>Poor performance in production environment</symptom>
        </symptoms>
        <root_cause>Single-process uvicorn not optimal for Cloud Run container lifecycle</root_cause>
      </problem>
      <solution>
        <description>Use gunicorn with uvicorn workers for Cloud Run deployments</description>
        <implementation>
          <configuration>gunicorn --worker-class uvicorn.workers.UvicornWorker</configuration>
          <benefits>
            <benefit>Better process management</benefit>
            <benefit>Improved request handling</benefit>
            <benefit>Cloud Run compatibility</benefit>
          </benefits>
        </implementation>
        <verification>
          <step>Deploy to staging with gunicorn configuration</step>
          <step>Verify service starts correctly</step>
          <step>Test request handling under load</step>
        </verification>
      </solution>
      <prevention>
        <guideline>Always use gunicorn with uvicorn workers for production deployments</guideline>
        <guideline>Test deployment configuration in staging before production</guideline>
      </prevention>
    </learning>
    
    <learning>
      <id>staging-database-ssl-requirements</id>
      <category>deployment</category>
      <date>2025-08-22</date>
      <severity>critical</severity>
      <title>DATABASE_URL Must Include sslmode=require for Cloud SQL</title>
      <problem>
        <description>Database connections fail without proper SSL configuration</description>
        <symptoms>
          <symptom>Database connection errors in staging/production</symptom>
          <symptom>SSL-related connection failures</symptom>
          <symptom>Health checks failing with database errors</symptom>
        </symptoms>
        <root_cause>Cloud SQL requires SSL connections but URL doesn't specify sslmode</root_cause>
      </problem>
      <solution>
        <description>Include sslmode=require parameter in DATABASE_URL for staging/production</description>
        <implementation>
          <example>postgresql://user:pass@host:5432/db?sslmode=require</example>
          <note>Required for all Cloud SQL connections</note>
        </implementation>
        <verification>
          <step>Test database connection with SSL parameter</step>
          <step>Verify health checks pass in staging</step>
          <step>Check connection works in production</step>
        </verification>
      </solution>
      <prevention>
        <guideline>Always include sslmode=require for Cloud SQL connections</guideline>
        <guideline>Validate database URLs in deployment scripts</guideline>
        <guideline>Test database connectivity before deploying</guideline>
      </prevention>
    </learning>
    
    <learning>
      <id>staging-frontend-api-url-configuration</id>
      <category>deployment</category>
      <date>2025-08-22</date>
      <severity>high</severity>
      <title>Frontend API URL Must Point to Backend for Proxy Rewrites</title>
      <problem>
        <description>Frontend cannot connect to backend API in staging</description>
        <symptoms>
          <symptom>API requests from frontend failing</symptom>
          <symptom>CORS errors in staging environment</symptom>
          <symptom>Proxy rewrites not working correctly</symptom>
        </symptoms>
        <root_cause>NEXT_PUBLIC_API_URL not pointing to correct backend URL</root_cause>
      </problem>
      <solution>
        <description>Configure NEXT_PUBLIC_API_URL to point to backend API URL</description>
        <implementation>
          <example>NEXT_PUBLIC_API_URL=https://api.staging.netrasystems.ai</example>
          <note>Required for proxy rewrites to work correctly</note>
        </implementation>
        <verification>
          <step>Test frontend API calls work in staging</step>
          <step>Verify proxy rewrites function correctly</step>
          <step>Check CORS configuration allows requests</step>
        </verification>
      </solution>
      <prevention>
        <guideline>Always configure frontend API URL for each environment</guideline>
        <guideline>Test frontend-backend connectivity in staging</guideline>
        <guideline>Document API URL requirements for each environment</guideline>
      </prevention>
    </learning>
    
    <learning>
      <id>staging-health-check-503-errors</id>
      <category>deployment</category>
      <date>2025-08-22</date>
      <severity>high</severity>
      <title>Health Check 503 Errors Due to Database Connectivity</title>
      <problem>
        <description>Health check endpoints returning 503 in staging</description>
        <symptoms>
          <symptom>/health/ready endpoint fails with 503</symptom>
          <symptom>Database connectivity issues in health checks</symptom>
          <symptom>Service marked as unhealthy in Cloud Run</symptom>
        </symptoms>
        <root_cause>Database connectivity not properly configured for health checks</root_cause>
      </problem>
      <solution>
        <description>Fix database connectivity and SSL settings for health checks</description>
        <implementation>
          <check>Verify DATABASE_URL includes SSL settings</check>
          <check>Ensure database credentials are correct</check>
          <check>Test database connection from health check code</check>
        </implementation>
        <verification>
          <step>Test /health/ready endpoint returns 200</step>
          <step>Verify database connection works in health check</step>
          <step>Check Cloud Run service shows as healthy</step>
        </verification>
      </solution>
      <prevention>
        <guideline>Always test health checks before deploying</guideline>
        <guideline>Validate database connectivity in staging</guideline>
        <guideline>Monitor health check endpoints post-deployment</guideline>
      </prevention>
    </learning>
    
    <learning>
      <id>staging-oauth-separate-domain</id>
      <category>deployment</category>
      <date>2025-08-22</date>
      <severity>high</severity>
      <title>OAuth Flow Requires Auth Service at Separate Domain</title>
      <problem>
        <description>OAuth authentication flow fails in staging</description>
        <symptoms>
          <symptom>OAuth redirects not working</symptom>
          <symptom>CORS issues with auth service</symptom>
          <symptom>Callback URL configuration problems</symptom>
        </symptoms>
        <root_cause>Auth service needs separate domain for proper OAuth flow</root_cause>
      </problem>
      <solution>
        <description>Deploy auth service at separate domain with proper CORS and callback configuration</description>
        <implementation>
          <example>auth.staging.netrasystems.ai</example>
          <requirements>
            <requirement>Separate domain for auth service</requirement>
            <requirement>Proper CORS configuration</requirement>
            <requirement>Correct callback URL setup</requirement>
          </requirements>
        </implementation>
        <verification>
          <step>Test OAuth flow works end-to-end</step>
          <step>Verify callback URLs are correctly configured</step>
          <step>Check CORS allows cross-domain requests</step>
        </verification>
      </solution>
      <prevention>
        <guideline>Always use separate domain for auth service</guideline>
        <guideline>Test OAuth flow in staging before production</guideline>
        <guideline>Document OAuth domain requirements</guideline>
      </prevention>
    </learning>
    
    <learning>
      <id>staging-oauth-proxy-configuration</id>
      <category>deployment</category>
      <date>2025-08-22</date>
      <severity>critical</severity>
      <title>USE_OAUTH_PROXY Must Be "true" for Token Validation</title>
      <problem>
        <description>Backend cannot validate tokens through auth service</description>
        <symptoms>
          <symptom>Token validation failures between services</symptom>
          <symptom>Cross-service authentication not working</symptom>
          <symptom>Users cannot access protected endpoints</symptom>
        </symptoms>
        <root_cause>USE_OAUTH_PROXY not set to "true" even when OAUTH_PROXY_URL is configured</root_cause>
      </problem>
      <solution>
        <description>Set USE_OAUTH_PROXY="true" for backend to validate tokens through auth service</description>
        <implementation>
          <requirement>USE_OAUTH_PROXY=true</requirement>
          <requirement>OAUTH_PROXY_URL=https://auth.staging.netrasystems.ai</requirement>
          <note>Both settings required for proper token validation</note>
        </implementation>
        <verification>
          <step>Test token validation works between services</step>
          <step>Verify protected endpoints are accessible with valid tokens</step>
          <step>Check cross-service authentication flows</step>
        </verification>
      </solution>
      <prevention>
        <guideline>Always set USE_OAUTH_PROXY=true when using auth service proxy</guideline>
        <guideline>Validate token validation configuration in staging</guideline>
        <guideline>Test cross-service authentication before deployment</guideline>
      </prevention>
    </learning>
    
    <learning>
      <id>staging-deployment-command</id>
      <category>deployment</category>
      <date>2025-08-22</date>
      <severity>info</severity>
      <title>Recommended Staging Deployment Command</title>
      <description>Established best practice command for staging deployments</description>
      <command>python scripts/deploy_to_gcp.py --project netra-staging --build-local --run-checks</command>
      <benefits>
        <benefit>Local builds are 5-10x faster than Cloud Build</benefit>
        <benefit>Pre-deployment checks catch issues early</benefit>
        <benefit>Reliable deployment process</benefit>
      </benefits>
      <verification>
        <step>All services deploy successfully</step>
        <step>Health checks pass post-deployment</step>
        <step>Services are accessible at staging URLs</step>
      </verification>
    </learning>
    
    <learning>
      <id>staging-missing-secrets</id>
      <category>deployment</category>
      <date>2025-08-22</date>
      <severity>medium</severity>
      <title>Missing GCP Secrets for Full Staging Functionality</title>
      <problem>
        <description>Some features not working due to missing secrets</description>
        <symptoms>
          <symptom>LLM agent functionality limited</symptom>
          <symptom>Encryption features not available</symptom>
          <symptom>Some integrations failing</symptom>
        </symptoms>
        <missing_secrets>
          <secret>OPENAI_API_KEY</secret>
          <secret>FERNET_KEY</secret>
          <secret>Additional LLM API keys</secret>
        </missing_secrets>
      </problem>
      <solution>
        <description>Add missing secrets to GCP Secret Manager for full functionality</description>
        <implementation>
          <step>Identify all required secrets for staging</step>
          <step>Add secrets to GCP Secret Manager</step>
          <step>Update deployment configuration to use secrets</step>
          <step>Test full functionality with all secrets available</step>
        </implementation>
        <verification>
          <step>All LLM agent features work in staging</step>
          <step>Encryption functionality operational</step>
          <step>All integrations working correctly</step>
        </verification>
      </solution>
      <prevention>
        <guideline>Audit required secrets before staging deployment</guideline>
        <guideline>Maintain secret inventory for each environment</guideline>
        <guideline>Test functionality requiring secrets in staging</guideline>
      </prevention>
    </learning>
    
    <learning>
      <id>staging-service-discovery-needed</id>
      <category>deployment</category>
      <date>2025-08-22</date>
      <severity>medium</severity>
      <title>Service URL Discovery Needed for Dynamic Configuration</title>
      <problem>
        <description>Services need to discover each other's URLs dynamically</description>
        <symptoms>
          <symptom>Hard-coded service URLs in configuration</symptom>
          <symptom>Manual URL updates required for deployments</symptom>
          <symptom>Configuration drift between environments</symptom>
        </symptoms>
        <root_cause>No automated service discovery mechanism</root_cause>
      </problem>
      <solution>
        <description>Implement service discovery for dynamic URL configuration</description>
        <implementation>
          <approach>Use GCP service discovery APIs</approach>
          <approach>Environment-based service URL configuration</approach>
          <approach>Automatic service registration and discovery</approach>
        </implementation>
        <verification>
          <step>Services automatically discover each other</step>
          <step>Configuration updates automatically</step>
          <step>No manual URL configuration required</step>
        </verification>
      </solution>
      <prevention>
        <guideline>Implement service discovery from the start</guideline>
        <guideline>Avoid hard-coded service URLs</guideline>
        <guideline>Use environment-based configuration</guideline>
      </prevention>
    </learning>
  </staging_deployment_learnings>
  
  <deployment_best_practices>
    <practice priority="critical">
      <title>Pre-Deployment Validation</title>
      <steps>
        <step>Run all tests locally before deployment</step>
        <step>Validate configuration for target environment</step>
        <step>Check all required secrets are available</step>
        <step>Verify database connectivity settings</step>
        <step>Test OAuth configuration for environment</step>
      </steps>
    </practice>
    
    <practice priority="high">
      <title>Deployment Process</title>
      <steps>
        <step>Use --build-local for faster builds</step>
        <step>Always use --run-checks for validation</step>
        <step>Monitor deployment logs for errors</step>
        <step>Verify all services start successfully</step>
        <step>Test critical user flows post-deployment</step>
      </steps>
    </practice>
    
    <practice priority="medium">
      <title>Post-Deployment Verification</title>
      <steps>
        <step>Test all health check endpoints</step>
        <step>Verify frontend-backend connectivity</step>
        <step>Test authentication flows</step>
        <step>Check WebSocket connections</step>
        <step>Validate LLM agent functionality</step>
      </steps>
    </practice>
  </deployment_best_practices>
  
  <troubleshooting>
    <issue symptom="503 health check errors">
      <cause>Database connectivity issues</cause>
      <solution>Check DATABASE_URL includes sslmode=require</solution>
    </issue>
    
    <issue symptom="OAuth flow failures">
      <cause>Callback URL or domain configuration</cause>
      <solution>Verify auth service domain and OAuth settings</solution>
    </issue>
    
    <issue symptom="Frontend API failures">
      <cause>NEXT_PUBLIC_API_URL misconfiguration</cause>
      <solution>Point frontend to correct backend API URL</solution>
    </issue>
    
    <issue symptom="Token validation failures">
      <cause>USE_OAUTH_PROXY not set correctly</cause>
      <solution>Set USE_OAUTH_PROXY=true for auth service proxy</solution>
    </issue>
    
    <issue symptom="Service startup failures">
      <cause>Wrong server configuration for Cloud Run</cause>
      <solution>Use gunicorn with uvicorn workers</solution>
    </issue>
  </troubleshooting>
  
  <critical_deployment_learnings>
    <learning>
      <id>no-minimal-backend-versions</id>
      <category>deployment</category>
      <date>2025-08-23</date>
      <severity>critical</severity>
      <title>NEVER Create Minimal Backend Versions for Staging/Production</title>
      <problem>
        <description>Creating "minimal" versions of the backend (like main_minimal.py) for deployment causes severe issues</description>
        <symptoms>
          <symptom>Missing critical functionality in staging/production</symptom>
          <symptom>Incomplete API endpoints deployed</symptom>
          <symptom>WebSocket functionality missing</symptom>
          <symptom>Agent systems not available</symptom>
          <symptom>Database migrations not executed</symptom>
          <symptom>Health checks incomplete or misleading</symptom>
        </symptoms>
        <root_cause>Attempting to reduce resource usage by deploying stripped-down versions</root_cause>
      </problem>
      <solution>
        <description>ALWAYS deploy the full main.py application to all environments</description>
        <implementation>
          <requirement>Use netra_backend.app.main:app in Dockerfile CMD</requirement>
          <requirement>Never create main_minimal.py or similar reduced versions</requirement>
          <requirement>Deploy complete application with all features</requirement>
          <note>Resource optimization should be done through proper configuration, not code removal</note>
        </implementation>
        <verification>
          <step>Verify Dockerfile uses main:app not main_minimal:app</step>
          <step>Ensure no minimal versions exist in codebase</step>
          <step>Test all features work in staging</step>
          <step>Confirm WebSocket and agent systems functional</step>
        </verification>
      </solution>
      <prevention>
        <guideline>NEVER create minimal versions of the main application</guideline>
        <guideline>This is a VIOLATION of deployment best practices</guideline>
        <guideline>Use environment variables and configuration for resource management</guideline>
        <guideline>Deploy the same codebase to all environments</guideline>
        <guideline>Use Cloud Run scaling settings to manage resources</guideline>
      </prevention>
      <violation_severity>CRITICAL</violation_severity>
      <violation_message>Creating minimal backend versions is a CRITICAL VIOLATION that breaks production functionality</violation_message>
    </learning>
    
    <learning>
      <id>docker-build-node-modules-exclusion</id>
      <category>deployment</category>
      <date>2025-08-23</date>
      <severity>critical</severity>
      <title>Frontend Docker Builds Must Exclude node_modules</title>
      <problem>
        <description>Frontend Docker builds include massive node_modules directory causing 1.4GB+ context transfers</description>
        <symptoms>
          <symptom>Docker build context exceeds 1GB for frontend</symptom>
          <symptom>Extremely slow build times (10+ minutes)</symptom>
          <symptom>Deployment failures due to timeouts</symptom>
          <symptom>Unnecessary bandwidth usage</symptom>
          <symptom>Docker daemon performance issues</symptom>
        </symptoms>
        <root_cause>Missing or improperly configured .dockerignore for frontend directory</root_cause>
      </problem>
      <solution>
        <description>Create frontend-specific .dockerignore to exclude node_modules and other unnecessary files</description>
        <implementation>
          <step>Create frontend/.dockerignore file</step>
          <step>Include node_modules as first line</step>
          <step>Add other build artifacts (.next, coverage, etc.)</step>
          <step>Optionally add cleanup step in Dockerfile: RUN rm -rf node_modules</step>
          <note>Root .dockerignore may not apply to subdirectory contexts</note>
        </implementation>
        <example_dockerignore>
node_modules
.next
coverage
cypress
__tests__
*.log
*.md
.env
.env.*
test-*
jest.*
*.test.*
*.spec.*
tsconfig.tsbuildinfo
        </example_dockerignore>
        <verification>
          <step>Monitor Docker build context size (should be under 100MB)</step>
          <step>Verify build completes in under 2 minutes</step>
          <step>Check that node_modules is excluded from context</step>
        </verification>
      </solution>
      <prevention>
        <guideline>ALWAYS create service-specific .dockerignore files</guideline>
        <guideline>Monitor Docker build context sizes during deployment</guideline>
        <guideline>Test Docker builds locally before deploying</guideline>
        <guideline>Never rely solely on root .dockerignore for subdirectories</guideline>
      </prevention>
      <impact>
        <performance>10x faster Docker builds</performance>
        <bandwidth>1.3GB+ bandwidth saved per build</bandwidth>
        <reliability>Prevents deployment timeouts</reliability>
      </impact>
    </learning>
    
    <learning>
      <id>dockerignore-multiple-files-conflict</id>
      <category>deployment</category>
      <date>2025-08-23</date>
      <severity>high</severity>
      <title>Multiple .dockerignore Files Can Cause Confusion</title>
      <problem>
        <description>Having .dockerignore files in both root and subdirectories creates confusion about which exclusions apply</description>
        <symptoms>
          <symptom>Unexpected files included in Docker context</symptom>
          <symptom>Subdirectory .dockerignore files ignored when building from root</symptom>
          <symptom>Different behavior between local and CI/CD builds</symptom>
          <symptom>Context size varies unexpectedly</symptom>
        </symptoms>
        <root_cause>Docker only uses the .dockerignore from the build context directory, not subdirectories</root_cause>
      </problem>
      <solution>
        <description>Use only root .dockerignore with proper path specifications for all services</description>
        <implementation>
          <step>Remove subdirectory .dockerignore files (e.g., frontend/.dockerignore)</step>
          <step>Consolidate all exclusions in root .dockerignore</step>
          <step>Use proper path prefixes for service-specific exclusions</step>
          <example>
# Root .dockerignore
# Frontend exclusions
frontend/node_modules
frontend/.next
frontend/coverage
frontend/__tests__
frontend/cypress
# Backend exclusions  
**/__pycache__
**/*.pyc
# General exclusions
**/node_modules
**/.env
          </example>
        </implementation>
        <verification>
          <step>Verify only one .dockerignore exists at root</step>
          <step>Test Docker builds for all services</step>
          <step>Monitor context sizes remain small</step>
        </verification>
      </solution>
      <prevention>
        <guideline>ONLY use root .dockerignore when building from root context</guideline>
        <guideline>Document Docker build context clearly in deployment scripts</guideline>
        <guideline>Test exclusions work for all services</guideline>
        <guideline>Remove any subdirectory .dockerignore files to avoid confusion</guideline>
      </prevention>
      <key_insight>When Docker builds from root with "docker build -f Dockerfile.frontend .", it uses root .dockerignore, NOT frontend/.dockerignore</key_insight>
    </learning>

    <learning>
      <id>docker-context-size-optimization-success</id>
      <category>deployment</category>
      <date>2025-08-23</date>
      <severity>info</severity>
      <title>Successfully Reduced Frontend Docker Context from 1.5GB to 179MB</title>
      <problem_solved>
        <original_issue>Frontend Docker build context was 1.5GB+ causing slow deployments</original_issue>
        <root_cause>node_modules and test files were being included in context</root_cause>
      </problem_solved>
      <solution_applied>
        <description>Fixed root .dockerignore to properly exclude frontend/node_modules and other unnecessary files</description>
        <changes>
          <change>Added frontend/node_modules to root .dockerignore</change>
          <change>Added **/node_modules for comprehensive exclusion</change>
          <change>Added frontend-specific test and build artifact exclusions</change>
          <change>Kept Dockerfile simple with COPY frontend/ instead of selective copying</change>
        </changes>
        <results>
          <result>Backend context: 147MB (good)</result>
          <result>Auth context: 7.8MB (excellent)</result>
          <result>Frontend context: 179MB (down from 1.5GB - 88% reduction)</result>
          <result>Build time reduced significantly</result>
          <result>Deployment reliability improved</result>
        </results>
      </solution_applied>
      <best_practices>
        <practice>Always check Docker context size during builds</practice>
        <practice>Use root .dockerignore for all exclusions when building from root</practice>
        <practice>Test .dockerignore effectiveness before deployments</practice>
        <practice>Keep Dockerfile COPY commands simple, let .dockerignore handle exclusions</practice>
      </best_practices>
    </learning>
    <learning>
      <id>auth-service-enhanced-security-secrets</id>
      <category>deployment</category>
      <date>2025-08-23</date>
      <severity>critical</severity>
      <title>Auth Service Requires SERVICE_SECRET and SERVICE_ID in Staging/Production</title>
      <problem>
        <description>Auth service fails to start in staging/production without enhanced security environment variables</description>
        <symptoms>
          <symptom>Service startup failures with ValueError: SERVICE_SECRET must be set in production/staging</symptom>
          <symptom>Worker processes crash during gunicorn/uvicorn initialization</symptom>
          <symptom>Health checks return 503 Service Unavailable</symptom>
          <symptom>Continuous worker restart loops in Cloud Run logs</symptom>
          <symptom>Service marked as unhealthy despite container being ready</symptom>
        </symptoms>
        <root_cause>Enhanced JWT security requires SERVICE_SECRET and SERVICE_ID for production environments</root_cause>
      </problem>
      <solution>
        <description>Create and map SERVICE_SECRET and SERVICE_ID secrets in GCP Secret Manager</description>
        <implementation>
          <step>Generate secure SERVICE_SECRET: openssl rand -hex 32</step>
          <step>Create SERVICE_ID with timestamp: netra-auth-staging-$(date +%s)</step>
          <step>Add secrets to GCP Secret Manager:
            - gcloud secrets create service-secret-staging --data-file=-
            - gcloud secrets create service-id-staging --data-file=-
          </step>
          <step>Update Cloud Run service to map secrets:
            --update-secrets="SERVICE_SECRET=service-secret-staging:latest,SERVICE_ID=service-id-staging:latest"
          </step>
          <step>Update deploy_to_gcp.py to include these secrets in auth service deployment</step>
        </implementation>
        <verification>
          <step>Check /health endpoint returns 200 OK</step>
          <step>Verify service uptime is stable</step>
          <step>Confirm no worker restart loops in logs</step>
          <step>Test JWT token validation works correctly</step>
        </verification>
      </solution>
      <prevention>
        <guideline>Always include SERVICE_SECRET and SERVICE_ID in auth service deployments</guideline>
        <guideline>Document all required environment variables in deployment scripts</guideline>
        <guideline>Test auth service startup in staging before production</guideline>
        <guideline>Monitor for startup failures after deployments</guideline>
      </prevention>
      <impact>Without these secrets, auth service cannot start and authentication is completely unavailable</impact>
    </learning>

    <learning>
      <id>staging-url-domain-consistency</id>
      <category>deployment</category>
      <date>2025-08-23</date>
      <severity>high</severity>
      <title>Always Use Staging Domain Names, Not Raw Cloud Run URLs</title>
      <problem>
        <description>Regression where staging domain URLs were replaced with raw Cloud Run URLs</description>
        <symptoms>
          <symptom>Frontend configured with Cloud Run URLs instead of domain names</symptom>
          <symptom>API calls may fail if Cloud Run URLs change</symptom>
          <symptom>CORS configuration becomes brittle</symptom>
          <symptom>SSL certificate validation issues</symptom>
          <symptom>Difficult to migrate or update services</symptom>
        </symptoms>
        <root_cause>Direct use of Cloud Run URLs bypasses domain abstraction layer</root_cause>
      </problem>
      <solution>
        <description>Always use consistent staging domain names for service configuration</description>
        <implementation>
          <correct_configuration>
            staging_api_url = "https://api.staging.netrasystems.ai"
            staging_auth_url = "https://auth.staging.netrasystems.ai"
            staging_ws_url = "wss://api.staging.netrasystems.ai/ws"
          </correct_configuration>
          <incorrect_configuration>
            # NEVER use raw Cloud Run URLs like these:
            staging_api_url = "https://netra-backend-staging-701982941522.us-central1.run.app"
            staging_auth_url = "https://netra-auth-service-701982941522.us-central1.run.app"
          </incorrect_configuration>
        </implementation>
        <verification>
          <step>Check deploy_to_gcp.py uses domain names not Cloud Run URLs</step>
          <step>Verify frontend environment variables use proper domains</step>
          <step>Test that services are accessible via domain names</step>
        </verification>
      </solution>
      <prevention>
        <guideline>ALWAYS use domain names for service URLs in configuration</guideline>
        <guideline>Never hardcode Cloud Run URLs in deployment scripts</guideline>
        <guideline>Set up domain mapping in Cloud Run for all services</guideline>
        <guideline>Document the correct domain URLs for each environment</guideline>
      </prevention>
      <benefits>
        <benefit>Services can be migrated without breaking configurations</benefit>
        <benefit>Consistent URLs across deployments</benefit>
        <benefit>Better SSL certificate management</benefit>
        <benefit>Cleaner CORS configuration</benefit>
      </benefits>
    </learning>
  </critical_deployment_learnings>
</specification>