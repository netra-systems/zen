<?xml version="1.0" encoding="UTF-8"?>
<specification>
    <metadata>
        <name>OrchestrationDataHandlingPatterns</name>
        <type>AgentOrchestrationLearning</type>
        <version>1.0</version>
        <created>2025-09-04</created>
        <severity>CRITICAL</severity>
        <business-impact>40-60% value delivery possible even with partial data, conversion optimization for insufficient data</business-impact>
    </metadata>

    <summary>
        Comprehensive patterns for handling partial and insufficient data in system orchestration agent prompts.
        Ensures graceful degradation, progressive value delivery, and optimal user engagement when data is incomplete.
        Critical for Free/Early tier conversion and maintaining value delivery across all segments.
    </summary>

    <problem-statement>
        System orchestration agents were not handling partial or insufficient data scenarios effectively.
        This resulted in:
        1. Complete workflow failures when data was incomplete
        2. Lost opportunities for progressive value delivery
        3. Poor user experience and conversion rates
        4. No educational guidance for data collection
        5. Binary success/failure with no middle ground
    </problem-statement>

    <root-cause>
        <primary>
            Workflows were designed for "happy path" with complete data only.
            No adaptive logic for varying data completeness levels.
        </primary>
        <secondary>
            Lack of progressive enhancement patterns - either full optimization or nothing.
            Missing educational and conversion-focused messaging for Free/Early users.
        </secondary>
    </root-cause>

    <solution>
        <overview>
            Implemented three-tier data sufficiency model with adaptive workflows:
            1. Sufficient (80-100%): Full optimization workflow
            2. Partial (40-79%): Modified workflow with caveats and data requests
            3. Insufficient (&lt;40%): Data collection focus with education and value demonstration
        </overview>

        <key-patterns>
            <pattern name="Progressive Value Delivery">
                Always provide immediate value with available data while requesting additional information
                for enhanced optimization. Never return empty responses.
            </pattern>

            <pattern name="Transparent Communication">
                Clearly indicate confidence levels (0.0-1.0) and provide caveats for recommendations
                based on incomplete data. Users understand limitations.
            </pattern>

            <pattern name="Educational Approach">
                When data is insufficient, educate users on why data matters with concrete examples
                and success stories. Show potential value to drive engagement.
            </pattern>

            <pattern name="Phased Implementation">
                Provide phased action plans that start with quick wins using available data,
                then expand as more data becomes available.
            </pattern>

            <pattern name="Conversion Optimization">
                Use social proof, urgency creation, and risk reversal to convert Free/Early users
                even with minimal data. Focus on demonstrating value potential.
            </pattern>
        </key-patterns>

        <workflow-adaptations>
            <sufficient-data>
                Triage → Data → Optimization → Actions → Reporting
                (Full workflow with high confidence)
            </sufficient-data>

            <partial-data>
                Triage → Data Helper (early) → Data → Optimization (with caveats) → Actions (phased) → Reporting
                (Modified workflow with medium confidence, progressive data collection)
            </partial-data>

            <insufficient-data>
                Triage → Data Helper (comprehensive education and templates)
                (Minimal workflow focused on data collection and value demonstration)
            </insufficient-data>
        </workflow-adaptations>
    </solution>

    <implementation-details>
        <files-created>
            <file>ORCHESTRATION_DATA_HANDLING_PATTERNS.md</file>
            <file>tests/mission_critical/test_orchestration_partial_data_handling.py</file>
            <file>tests/mission_critical/test_orchestration_insufficient_data_handling.py</file>
        </files-created>

        <prompt-engineering>
            System prompts must classify data sufficiency and select appropriate workflow.
            Confidence scoring formula: base_confidence + (completeness * scaling_factor).
            Always structure responses with workflow type, confidence, immediate value, and data needs.
        </prompt-engineering>

        <test-coverage>
            - Partial data scenarios: 13+ test cases
            - Insufficient data scenarios: 14+ test cases
            - Edge cases: conflicting data, urgency, privacy concerns
            - Integration tests for end-to-end workflows
        </test-coverage>
    </implementation-details>

    <business-value>
        <segment impact="Free">
            Conversion optimization through education and value demonstration.
            Quick templates reduce friction to 2-5 minutes.
        </segment>
        <segment impact="Early">
            Progressive value delivery maintains engagement while collecting data.
            40-60% value possible with partial data.
        </segment>
        <segment impact="Mid/Enterprise">
            Phased implementation plans enable immediate action.
            Quality preservation for critical domains (healthcare, finance).
        </segment>
    </business-value>

    <metrics>
        <metric name="Conversion Rate">Users who provide requested data after initial insufficient data</metric>
        <metric name="Value Delivery Rate">Successful optimizations despite partial data</metric>
        <metric name="User Satisfaction">Feedback on partial data handling experience</metric>
        <metric name="Data Collection Success">Percentage of complete data sets obtained</metric>
        <metric name="Confidence Accuracy">Correlation between confidence scores and actual outcomes</metric>
    </metrics>

    <cross-references>
        <reference>
            <path>ORCHESTRATION_DATA_HANDLING_PATTERNS.md</path>
            <description>Complete documentation with 20 examples and implementation patterns</description>
        </reference>
        <reference>
            <path>SPEC/learnings/agent_execution_order_fix_20250904.xml</path>
            <description>Related learning about correct agent execution order</description>
        </reference>
        <reference>
            <path>docs/AGENT_ARCHITECTURE_DISAMBIGUATION_GUIDE.md</path>
            <description>Agent architecture patterns and relationships</description>
        </reference>
        <reference>
            <path>docs/GOLDEN_AGENT_INDEX.md</path>
            <description>Golden patterns for agent implementation</description>
        </reference>
    </cross-references>

    <prevention>
        <guideline>
            Always design workflows with data completeness tiers in mind.
            Never assume complete data availability.
        </guideline>
        <guideline>
            Implement confidence scoring for all agent outputs based on data completeness.
        </guideline>
        <guideline>
            Include educational content and quick templates in all data collection requests.
        </guideline>
        <guideline>
            Test with varying levels of data completeness (0%, 25%, 50%, 75%, 100%).
        </guideline>
    </prevention>

    <validation>
        <test>Run test_orchestration_partial_data_handling.py for 40-79% completeness scenarios</test>
        <test>Run test_orchestration_insufficient_data_handling.py for &lt;40% completeness scenarios</test>
        <test>Verify confidence scores correlate with data completeness</test>
        <test>Confirm immediate value delivery even with minimal data</test>
        <test>Check educational content and templates are user-friendly</test>
    </validation>
</specification>